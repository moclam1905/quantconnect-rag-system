{
  "source_file": "Quantconnect-Lean-Engine.html",
  "document_index": 1,
  "total_documents_in_file": 2,
  "parse_timestamp": "2025-06-01T17:42:43.592922",
  "sections": [
    {
      "id": "1",
      "title": "Getting Started",
      "level": 1,
      "section_number": "1",
      "breadcrumb": "Getting Started",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Lean Engine is an open-source algorithmic trading engine built for easy strategy research, backtesting and live trading. We integrate with common data providers and brokerages so you can quickly deploy algorithmic trading strategies.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The core of the LEAN Engine is written in C#; but it operates seamlessly on Linux, Mac and Windows operating systems. It supports algorithms written in Python 3.11 or C#. Lean drives the web-based algorithmic trading platform\n   QuantConnect\n   .",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### System Overview",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Developing with Lean CLI",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "QuantConnect recommends\n   using Lean CLI\n   for local algorithm development. This is because it is a great tool for working with your algorithms locally while still being able to deploy to the cloud and have access to Lean data. It is also able to run algorithms on your local machine with your data through our official docker images.",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Reference QuantConnects documentation on Lean CLI\n   here\n   .",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Installation Instructions",
          "order": 8,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This section will cover how to install lean locally for you to use in your own environment.",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Refer to the following readme files for a detailed guide regarding using your local IDE with Lean:",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To install locally, download the zip file with the\n   latest master\n   and unzip it to your favorite location. Alternatively, install\n   Git\n   and clone the repo:",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ git clone https://github.com/QuantConnect/Lean.git\n$ cd Lean",
          "order": 9,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Install\n    Visual Studio for Mac\nOpen\n    QuantConnect.Lean.sln(code)\n    in Visual Studio",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Visual Studio will automatically start to restore the Nuget packages. If not, in the menu bar,",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "click\n    Project > Restore NuGet Packages(code)\nIn the menu bar, click\n    Run > Start Debugging(code)",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Alternatively, run the compiled\n   dll(code)\n   file:",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ cd Lean/Launcher/bin/Debug\n$ dotnet QuantConnect.Lean.Launcher.dll",
          "order": 9,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "click\n    Build > Build All(code)\nrun the following code:",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Linux (Debian, Ubuntu)",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ dotnet build QuantConnect.Lean.sln",
          "order": 9,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ cd Launcher/bin/Debug\n$ dotnet QuantConnect.Lean.Launcher.dll",
          "order": 9,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Install\n    dotnet 6\nCompile Lean Solution\n\nRun Lean",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To set up Interactive Brokers integration, make sure you fix the\n   ib-tws-dir(code)\n   and\n   ib-controller-dir(code)\n   fields in the\n   config.json(code)\n   file with the actual paths to the TWS and the IBController folders respectively. If after all you still receive connection refuse error, try changing the\n   ib-port(code)\n   field in the\n   config.json(code)\n   file from 4002 to 4001 to match the settings in your IBGateway/TWS.",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Install\n    Visual Studio\nOpen\n    QuantConnect.Lean.sln(code)\n    in Visual Studio\nBuild the solution by clicking\n    Build Menu -> Build Solution(code)\nPress\n    F5(code)\n    to run",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Python Support",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "A full explanation of the Python installation process can be found in the\n   Algorithm.Python\n   project.",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Local-Cloud Hybrid Development",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Seamlessly develop locally in your favorite development environment, with full autocomplete and debugging support to quickly and easily identify problems with your strategy. For more information please see the\n   CLI documentation\n   .",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Roadmap",
          "order": 29,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Our\n   Roadmap\n   shows the feature requests and bugs that receive the most attention from community members. \n  The core QuantConnect team gives priority to the feature requests and bugs that have the most votes.\n  If you want to shape the future of QuantConnect and LEAN, vote today.\n  To add a new item to the roadmap,\n   create a new GitHub Issue on the LEAN repository\n   and then react to it with a thumbs up emoji.",
          "order": 30,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Sponsorships",
          "order": 31,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Sponsor QuantConnect to support our developers as we improve a revolutionary quantitative trading platform LEAN, in an open, collaborative way. We will continue to level the playing field with industry-grade tools and data accessibility. We use sponsorship funds to achieve the following goals:",
          "order": 32,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To continue the development of LEANâ€™s infrastructure\nTo create free, high-quality research and educational material\nTo provide continued support for our community\nTo make terabytes of data accessible in the Dataset Market\nTo bring LEAN to global financial markets\nTo increase live trading brokerage connections\nTo connect more individuals with financial institutions so individuals can gain income for their ideas at scale",
          "order": 32,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To become a QuantConnect sponsor, see the\n   Sponsorship page\n   on GitHub.",
          "order": 32,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": null
    },
    {
      "id": "2",
      "title": "Contributions",
      "level": 1,
      "section_number": "2",
      "breadcrumb": "Contributions",
      "mixed_content": [],
      "tables": [],
      "subsections": [
        {
          "id": "2.1",
          "title": "Datasets",
          "level": 2,
          "section_number": "2.1",
          "breadcrumb": "Contributions > Datasets",
          "mixed_content": [],
          "tables": [],
          "subsections": [
            {
              "id": "2.1.1",
              "title": "Key Concepts",
              "level": 3,
              "section_number": "2.1.1",
              "breadcrumb": "Contributions > Datasets > Key Concepts",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Listing Process",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Datasets contributed to LEAN can be quickly listed in the QuantConnect Dataset Marketplace, and distributed for sale to more than 250,000 users in the QuantConnect community. To list a dataset, reach out to the\n   QuantConnect Team\n   for  a quick review, then proceed with the data creation and process steps in the following pages.",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Datasets must be well defined, with realistic timestamps for when the data was available (\"point in time\"). Ideally datasets need at least a 2 year track record and to be maintained by a reputable company. They should be accompanied with full documentation and code examples so the community can harness the data.",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Data Sources",
                  "order": 5,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   GetSource(csharp)\nget_source(python)\n   method of your dataset class instructs LEAN where to find the data. This method must return a\n   SubscriptionDataSource\n   object, which contains the data location and format. We host your data, so the\n   transportMedium(csharp)\ntransport_medium(python)\n   must be\n   SubscriptionTransportMedium.LocalFile(code)\n   and the\n   format(code)\n   must be\n   FileFormat.Csv(code)\n   .",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### TimeZones",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   DataTimeZone(code)\n   method of your data source class declares the time zone of your dataset. This method returns a\n   NodaTime\n   .DateTimeZone object. If your dataset provides trading data and universe data, the\n   DataTimeZone(code)\n   methods in your\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>.cs\n   and\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Universe.cs\n   files must be the same.",
                  "order": 8,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Linked Datasets",
                  "order": 9,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Your dataset is linked if any of the following statements are true:",
                  "order": 10,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Your dataset describes market price properties of specific securities (for example, the closing price of AAPL).\nYour alternative dataset is linked to individual securities (for example, the Wikipedia page view count of AAPL).",
                  "order": 10,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Examples of unlinked datasets would be the weather of New York City, where data is not relevant to a specific security.",
                  "order": 10,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "When a dataset is linked, it needs to be mapped to underlying assets through time. \n    The\n   RequiresMapping(code)\n   boolean instructs LEAN to handle the security and ticker mapping issues.",
                  "order": 10,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1"
            },
            {
              "id": "2.1.2",
              "title": "Defining Data Models",
              "level": 3,
              "section_number": "2.1.2",
              "breadcrumb": "Contributions > Datasets > Defining Data Models",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to set up the data source SDK and use it to create data models.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Part 1/ Set up SDK",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to create a repository for your dataset:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ git clone https://github.com/username/Lean.DataSource.<vendorNameDatasetName>.git",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ chmod +x ./renameDataset",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ renameDataset.sh",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Open the\n    Lean.DataSource.SDK repository\n    and click\n    Use this template > Create a new repository\n    .\n\nStart with the SDK repository instead of existing data source implementations because we periodically update the SDK repository.\nOn the Create a new repository from Lean.DataSource.SDK page, set the repository name to\n    Lean.DataSource.<vendorNameDatasetName>\n    (for example,\n    Lean.DataSource.XYZAirlineTicketSales\n    ).\nIf your dataset contains multiple series, use\n    <vendorName>\n    instead of\n    <vendorNameDatasetName>\n    . For instance, the Federal Reserve Economic Data (FRED) dataset repository has the name\n    Lean.DataSource.FRED\n    because it has\n    many different series\n    .\nClick\n    Create repository from template\n    .\nClone\n    the\n    Lean.DataSource.<vendorNameDatasetName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, run the\n    renameDataset.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.DataSource.<vendorNameDatasetName>\n    directory and renames some files according to your dataset's\n    <vendorNameDatasetName>.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Part 2/ Create Data Models",
                  "order": 9,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "api_content",
                  "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
                  "order": 10,
                  "language": "python",
                  "title": "API: QuantConnect.Resolution",
                  "context": "Resolved from data-tree: QuantConnect.Resolution"
                },
                {
                  "type": "api_content",
                  "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
                  "order": 11,
                  "language": "csharp",
                  "title": "API: QuantConnect.Resolution (C#)",
                  "context": "Resolved from data-tree: QuantConnect.Resolution"
                },
                {
                  "type": "text",
                  "content": "### Part 3/ Create Universe Models",
                  "order": 12,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "api_content",
                  "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
                  "order": 13,
                  "language": "python",
                  "title": "API: QuantConnect.Resolution",
                  "context": "Resolved from data-tree: QuantConnect.Resolution"
                },
                {
                  "type": "api_content",
                  "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
                  "order": 14,
                  "language": "csharp",
                  "title": "API: QuantConnect.Resolution (C#)",
                  "context": "Resolved from data-tree: QuantConnect.Resolution"
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1"
            },
            {
              "id": "2.1.3",
              "title": "Rendering Data",
              "level": 3,
              "section_number": "2.1.3",
              "breadcrumb": "Contributions > Datasets > Rendering Data",
              "mixed_content": [],
              "tables": [],
              "subsections": [
                {
                  "id": "2.1.3.1",
                  "title": "Rendering Data with Python",
                  "level": 4,
                  "section_number": "2.1.3.1",
                  "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Python",
                  "mixed_content": [
                    {
                      "type": "text",
                      "content": "### Introduction",
                      "order": 1,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "This page explains how to create a script to download and process your dataset with Python for QuantConnect distribution.",
                      "order": 2,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### Using Processing Framework",
                      "order": 3,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect.\n    The script should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Your dataset is not linked to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In a terminal, compile the data processing project.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                      "order": 4,
                      "language": "cli",
                      "title": "Command Line Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file, import the\n   CLRImports(code)\n   library.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "from CLRImports import *",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Create and initialize a map file provider.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Create a security identifier.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Copy the\n   process.sample.py\n   script to the\n   DataProcessing / bin / debug / net9.0\n   directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "You need to place the script under the\n   bin\n   directory so that LEAN's packages dlls are correctly loaded for the\n   CLRImports(code)\n   .",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "$ cp process.sample.py DataProcessing/bin/Debug/net9.0",
                      "order": 4,
                      "language": "cli",
                      "title": "Command Line Example",
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "$ cd DataProcessing/bin/debug/net9.0/\n$ python process.sample.py",
                      "order": 4,
                      "language": "cli",
                      "title": "Command Line Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Run the\n   DataProcessing / bin / debug / net9.0 / process.sample.py\n   script to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.\n   \nNote: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### Python Processor Examples",
                      "order": 25,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "The following examples are rendering datasets with Python processing:",
                      "order": 26,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Lean.DataSource.BitcoinMetadata\nLean.DataSource.BrainSentiment\nLean.DataSource.CryptoSlamNFTSale\nLean.DataSource.QuiverQuantTwitterFollowers\nLean.DataSource.Regalytics",
                      "order": 26,
                      "language": null,
                      "title": null,
                      "context": null
                    }
                  ],
                  "tables": [],
                  "subsections": [],
                  "parent_id": "2.1.3"
                },
                {
                  "id": "2.1.3.2",
                  "title": "Rendering Data with CSharp",
                  "level": 4,
                  "section_number": "2.1.3.2",
                  "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with CSharp",
                  "mixed_content": [
                    {
                      "type": "text",
                      "content": "### Introduction",
                      "order": 1,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "This page explains how to create a script to download and process your dataset with C# for QuantConnect distribution.",
                      "order": 2,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### Using Processing Framework",
                      "order": 3,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n    The program should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, create and initialize a map file provider.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "var mapFileProvider = new LocalZipMapFileProvider();\nvar mapFileProvider.Initialize(new DefaultDataProvider());",
                      "order": 4,
                      "language": "csharp",
                      "title": "C# Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Create a security identifier.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "var sid = SecurityIdentifier.GenerateEquity(pointInIimeTicker,\n    Market.USA, true, mapFileProvider, csvDate)",
                      "order": 4,
                      "language": "csharp",
                      "title": "C# Code Example",
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                      "order": 4,
                      "language": "cli",
                      "title": "Command Line Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In a terminal, compile the data processing project to generate the\n   process.exe\n   executable file.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "After you finish compiling the\n   Program.cs\n   file, run the\n   process.exe\n   file to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### CSharp Processor Examples",
                      "order": 18,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "The following examples are rendering datasets with C# processing:",
                      "order": 19,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Lean.DataSource.BinanceFundingRate\nLean.DataSource.CoinGecko\nLean.DataSource.CryptoCoarseFundamentalUniverse\nLean.DataSource.QuiverInsiderTrading\nLean.DataSource.VIXCentral",
                      "order": 19,
                      "language": null,
                      "title": null,
                      "context": null
                    }
                  ],
                  "tables": [],
                  "subsections": [],
                  "parent_id": "2.1.3"
                },
                {
                  "id": "2.1.3.3",
                  "title": "Rendering Data with Notebooks",
                  "level": 4,
                  "section_number": "2.1.3.3",
                  "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Notebooks",
                  "mixed_content": [
                    {
                      "type": "text",
                      "content": "### Introduction",
                      "order": 1,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "This page explains how to create a script to download and process your dataset with Jupyter Notebooks for QuantConnect distribution.",
                      "order": 2,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### Using Processing Framework",
                      "order": 3,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n     The notebook should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In a terminal, compile the data processing project.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                      "order": 4,
                      "language": "cli",
                      "title": "Command Line Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file, import the\n   CLRImports(code)\n   library.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "from CLRImports import *",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Create and initialize a map file provider.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Create a security identifier.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "code",
                      "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
                      "order": 4,
                      "language": "python",
                      "title": "Python Code Example",
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "After you finish editing the\n   process.sample.ipynb\n   script, run its cells to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                      "order": 4,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "### Notebook Processor Examples",
                      "order": 22,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "The following examples are rendering datasets with Jupyter Notebook processing:",
                      "order": 23,
                      "language": null,
                      "title": null,
                      "context": null
                    },
                    {
                      "type": "text",
                      "content": "Lean.DataSource.KavoutCompositeFactorBundle\nLean.DataSource.USEnergy",
                      "order": 23,
                      "language": null,
                      "title": null,
                      "context": null
                    }
                  ],
                  "tables": [],
                  "subsections": [],
                  "parent_id": "2.1.3"
                }
              ],
              "parent_id": "2.1"
            },
            {
              "id": "2.1.4",
              "title": "Testing Data Models",
              "level": 3,
              "section_number": "2.1.4",
              "breadcrumb": "Contributions > Datasets > Testing Data Models",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The implementation of your Data Source must be thoroughly tested to be listed on the\n   Dataset Market\n   .",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Run Demonstration Algorithms",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to test if your demonstration algorithm will run in production with the processed data:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ git pull upstream master",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ git clone https://github.com/<username>/Lean.git",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"QuantConnect.Algorithm.CSharp.dll\",",
                  "order": 4,
                  "language": "text",
                  "title": "Code Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"../../../Algorithm.Python/<vendorNameDatasetName>Algorithm.py\",",
                  "order": 4,
                  "language": "text",
                  "title": "Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Open the\n    Lean.DataSource.<vendorNameDatasetName> / QuantConnect.DataSource.csproj\n    file in Visual Studio.\nIn the top menu bar of Visual Studio, click\n    Build > Build Solution\n    .\nThe Output panel displays the build status of the project.\nClose Visual Studio.\n Install LEAN \nIf you have a local copy of LEAN, pull the latest changes.\n\nIf you don't have a local copy of LEAN,\n    fork the LEAN repository\n    and then\n    clone it\n    .\n\n Place data into LEAN \nCopy the contents of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory and paste them into the\n    Lean / Data\n    directory.\n Add data source to LEAN \nOpen the\n    Lean / QuantConnect.Lean.sln\n    file in Visual Studio.\nIn the Solution Explorer panel of Visual Studio, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Existing Itemâ€¦\n    .\nIn the Add Existing Item window, click the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    file and then click\n    Add\n    .\nIn the Solution Explorer panel, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Project Reference...\n    .\nIn the Reference Manager window, click\n    Browseâ€¦\n    .\nIn the Select the files to referenceâ€¦ window, click the\n    Lean.DataSource.<vendorNameDatasetName> / bin / Debug / net9.0 / QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file and then click\n    Add\n    .\nThe Reference Manager window displays the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file with the check box beside it enabled.\nClick\n    OK\n    .\nThe Solution Explorer panel adds the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file under\n    QuantConnect.Algorithm.CSharp > Dependencies > Assemblies\n    .\n Write demo C# algorithm \nIn the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\n Write demo Python algorithm \nCopy the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    file and paste it in\n    Lean / Algorithm.Python\n    directory.\nIn the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\nImportant: Your backtests must run without error. If your backtests produce errors, correct them and then run the backtest again.\n Copy demo algorithms back to data source repo \nCopy the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    .\nCopy the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Run Unit Tests",
                  "order": 10,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "You must\n   run your demonstration algorithms\n   without error before you set up unit tests.",
                  "order": 11,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Tests.cs\n   file, define the\n   CreateNewInstance(code)\n   method to return an instance of your\n   DataSource(code)\n   class and then execute the following commands to run the unit tests:",
                  "order": 11,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ dotnet build tests/Tests.csproj\n$ dotnet test tests/bin/Debug/net9.0/Tests.dll",
                  "order": 11,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1"
            },
            {
              "id": "2.1.5",
              "title": "Data Documentation",
              "level": 3,
              "section_number": "2.1.5",
              "breadcrumb": "Contributions > Datasets > Data Documentation",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to provide documentation for your dataset so QuantConnect members can use it in their trading algorithms.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Required Key Properties",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "You need to process the entire dataset to collect the following information:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 4,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Provide Documentation",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "To provide documentation for your dataset, in the\n   Lean.DataSource.<vendorNameDatasetName> / listing-about.md\n   and\n   Lean.DataSource.<vendorNameDatasetName> / listing-documentation.md\n   files, fill in the missing content.",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Next Steps",
                  "order": 8,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "After we review and accept your dataset contribution, we will create a page in our\n   Dataset Market\n   . At that point, you will be able to write algorithms in QuantConnect Cloud using your dataset and you can contribute an example algorithm for the dataset listing. After your dataset listing is complete, we'll include your new dataset in our\n   downloading data tutorial\n   .",
                  "order": 9,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [
                {
                  "headers": [
                    "Property",
                    "Description"
                  ],
                  "rows": [
                    [
                      "Start Date",
                      "Date and time of the first data point"
                    ],
                    [
                      "Asset Coverage",
                      "Number of assets covered by the dataset"
                    ],
                    [
                      "Data density",
                      "Dense for tick data. Regular or Sparse according to the frequency."
                    ],
                    [
                      "Resolution",
                      "Options: Tick, Second, Minute, Hourly, & Daily."
                    ],
                    [
                      "Timezone",
                      "Data timezone. This is a property of the data source."
                    ],
                    [
                      "Data process time",
                      "Time and days of the week to process the data."
                    ],
                    [
                      "Data process duration",
                      "Time to process the entire the dataset."
                    ],
                    [
                      "Update process duration",
                      "Time to update the dataset."
                    ]
                  ],
                  "caption": null
                }
              ],
              "subsections": [],
              "parent_id": "2.1"
            }
          ],
          "parent_id": "2"
        },
        {
          "id": "2.2",
          "title": "Brokerages",
          "level": 2,
          "section_number": "2.2",
          "breadcrumb": "Contributions > Brokerages",
          "mixed_content": [
            {
              "type": "text",
              "content": "Creating a fully supported brokerage is a challenging endeavor. LEAN requires a number of individual pieces which work together to form a complete brokerage implementation. This guide aims to describe in as much detail as possible what you need to do for each module.\nThe end goal is to submit a pull request that passes all tests. Partially-completed brokerage implementations are acceptable if they are merged to a branch. It's easy to fall behind master, so be sure to keep your branch updated with the master branch. Before you start, read LEAN's\n     coding style guidelines\n     to comply with the code commenting and design standards.\nThe root of the brokerage system is the algorithm job packets, which hold configuration information about how to run LEAN. The program logic is a little convoluted. It moves from\n     config.json > create job packet > create brokerage factory matching name > set job packet brokerage data > factory creates brokerage instance\n     . As a result, we'll start creating a brokerage at the root, the configuration and brokerage factory.\nSetting Up Your Environment\n       Set up your local brokerage repository.\nLaying the Foundation\n       (\n       IBrokerageFactory(code)\n       ) Stub out the implementation and initialize a brokerage instance.\nCreating the Brokerage\n       (\n       IBrokerage(code)\n       ) Instal key brokerage application logic, where possible using a brokerage SDK.\nTranslating Symbol Conventions\n       (\n       ISymbolMapper(code)\n       ) Translate brokerage specific tickers to LEAN format for a uniform algorithm design experience.\nDescribing Brokerage Limitations\n       (\n       IBrokerageModel(code)\n       ) Describe brokerage support of orders and set transaction models.\nEnabling Live Data Streaming\n       (\n       IDataQueueHandler(code)\n       ) Set up a live streaming data service from a brokerage-supplied source.\nEnabling Historical Data\n       (\n       IHistoryProvider(code)\n       ) Tap into the brokerage historical data API to serve history for live algorithms.\nDownloading Data\n       (\n       IDataDownloader(code)\n       ) Save data from the brokerage to disk in LEAN format.\nModeling Fee Structures\n       (\n       IFeeModel(code)\n       ) Enable accurate backtesting with specific fee structures of the brokerage.\nUpdating the Algorithm API\n       (\n       ISecurityTransactionModel(code)\n       ) Combine the various models together to form a brokerage set.\nSee Also\nDataset Market\n\nPurchasing Datasets",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [
            {
              "id": "2.2.1",
              "title": "Setting Up Your Environment",
              "level": 3,
              "section_number": "2.2.1",
              "breadcrumb": "Contributions > Brokerages > Setting Up Your Environment",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to set up your coding environment to create, develop, and test your brokerage before you contribute it to LEAN.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Prerequisites",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Working knowledge of C#. You also need to\n   install .NET 6.0\n   .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Set Up Environment",
                  "order": 5,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to set up your environment:",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ git clone https://github.com/username/Lean.Brokerages.<brokerageName>.git",
                  "order": 6,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ chmod +x ./renameBrokerage",
                  "order": 6,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ renameBrokerage.sh",
                  "order": 6,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Fork\n    Lean\n    and then clone your forked repository to your local machine.\nOpen the\n    Lean.Brokerages.Template repository\n    and click\n    Use this template\n    .\nOn the Create a new repository from Lean.Brokerages.Template page, set the repository name to\n    Lean.Brokerages.<brokerageName>\n    (for example,\n    Lean.Brokerages.XYZ\n    ).\nClick\n    Create repository from template\n    .\nClone the\n    Lean.Brokerages.<brokerageName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.Brokerages.<brokerageName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.Brokerages.<brokerageName>\n    directory, run the\n    renameBrokerage.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.Brokerages.<brokerageName>\n    directory and renames some files according to your brokerage name.",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.2",
              "title": "Laying the Foundation",
              "level": 3,
              "section_number": "2.2.2",
              "breadcrumb": "Contributions > Brokerages > Laying the Foundation",
              "mixed_content": [
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 1,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   IBrokerageFactory\n   creates brokerage instances and configures LEAN with a\n   Job Packet\n   . To create the right\n   BrokerageFactory(code)\n   type, LEAN uses the brokerage name in the job packet. To set the brokerage name, LEAN uses the\n   live-mode-brokerage(code)\n   value in the\n   configuration file\n   .",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Prerequisites",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "You need to\n   set up your environment\n   before you can lay the foundation for a new brokerage.",
                  "order": 5,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Lay the Foundation",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to stub out the implementation and initialize a brokerage instance:",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "namespace QuantConnect.Brokerages\n{\n    public class BrokerageNameBrokerageModel : DefaultBrokerageModel\n    {\n        \n    }\n}",
                  "order": 7,
                  "language": "csharp",
                  "title": "C# Code Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "public override IBrokerageModel GetBrokerageModel(IOrderProvider orderProvider)\n{\n    return new BrokerageNameBrokerageModel();\n}",
                  "order": 7,
                  "language": "csharp",
                  "title": "C# Code Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "// defines the 'live-brokerage-name' environment\n\"live-brokerage-name\": {\n  \"live-mode\": true,\n\n  \"live-mode-brokerage\": \"BrokerageName\",\n\n  \"setup-handler\": \"QuantConnect.Lean.Engine.Setup.BrokerageSetupHandler\",\n  \"result-handler\": \"QuantConnect.Lean.Engine.Results.LiveTradingResultHandler\",\n  \"data-feed-handler\": \"QuantConnect.Lean.Engine.DataFeeds.LiveTradingDataFeed\",\n  \"data-queue-handler\": [ \"QuantConnect.Lean.Engine.DataFeeds.Queues.LiveDataQueue\" ],\n  \"real-time-handler\": \"QuantConnect.Lean.Engine.RealTime.LiveTradingRealTimeHandler\",\n  \"transaction-handler\": \"QuantConnect.Lean.Engine.TransactionHandlers.BacktestingTransactionHandler\"\n},",
                  "order": 7,
                  "language": "text",
                  "title": "Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n    Lean / Launcher / config.json\n    file, add a few key-value pairs with your brokerage configuration information.\nFor example,\n    oanda-access-token(code)\n    and\n    oanda-account-id(code)\n    keys. These key-value pairs will be used for most local debugging and testing as the default. LEAN automatically copies these pairs to the\n    BrokerageData\n    member of the job packet as a dictionary of\n    <string,string>(code)\n    pairs.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Factory.cs\n    file, update the\n    BrokerageData(code)\n    member so it uses the\n    Config(code)\n    class to load all the required configuration settings from the\n    Lean / Launcher / config.json\n    file.\nFor instance,\n    Config.Get(\"oanda-access-token\")(code)\n    returns the\n    \"oanda-access-token\"(code)\n    value from the configuration file. For a full example, see the\n    BrokerageData member\n    in the\n    BitfinexBrokerageFactory(code)\n    .\nIn the\n    IBrokerageFactory(code)\n    examples, you'll see code like\n    Composer.Instance.AddPart<IDataQueueHandler>(dataQueueHandler)(code)\n    , which adds parts to the\n    Composer\n    . The Composer is a system in LEAN for dynamically loading types. In this case, it's adding an instance of the\n    DataQueueHandler(code)\n    for the brokerage to the composer. You can think of the Composer as a library and adding parts is like adding books to its collection.\nIn the\n    Lean / Common / Brokerages\n    folder, create a\n    <brokerageName>BrokerageModel.cs\n    file with a stub implementation that inherits from the\n    DefaultBrokerageModel\n    .\nBrokerage models tell LEAN what order types a brokerage supports, whether we're allowed to update an order, and what\n    reality models\n    to use. Use the following stub implementation for now:\n\nwhere\n    BrokerageName(code)\n    is the name of your brokerage. For example, if the brokerage name is XYZ, then\n    BrokerageNameBrokerageModel(code)\n    should be\n    XYZBrokerageModel(code)\n    . You'll extend this implementation later.\nIn the\n    Lean.Brokerages.<BrokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define\n    GetBrokerageModel(code)\n    to return an instance of your new brokerage model.\n\nIf your brokerage uses websockets to send data, in the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName> / <brokerageName>Brokerage.cs\n    file, replace the\n    Brokerage(code)\n    base class for\n    BaseWebsocketsBrokerage(code)\n    .\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n    file, update the constructor to save required authentication data to private variables.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define the\n    CreateBrokerage(code)\n    method to create and return an instance of your new brokerage model without connecting to the brokerage.\nThe Brokerage Factory uses a job packet to create an initialized brokerage instance in the\n    CreateBrokerage(code)\n    method. Assume the\n    job(code)\n    argument has the best source of data, not the\n    BrokerageData(code)\n    property. The\n    BrokerageData(code)\n    property in the factory are the starting default values from the configuration file, which can be overridden by a runtime job.\nIn the\n    Lean / Launcher / config.json\n    file, add a\n    live-<brokerageName>(code)\n    key.\nThese\n    live-<brokerageName>(code)\n    keys group configuration flags together and override the root configuration values. Use the following key-value pair as a starting point:\n\nwhere\n    brokerage-name(code)\n    and\n    \"BrokerageName\"(code)\n    are placeholders for your brokerage name.\nIn the\n    Lean / Launcher / config.json\n    file, set the\n    environment(code)\n    value to the your new brokerage environment.\nFor example,\n    \"live-brokerage-name\"(code)\n    .\nBuild the solution.\nRunning the solution won't work, but the stub implementation should still build.",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [
                {
                  "headers": [
                    "IBrokerageFactory"
                  ],
                  "rows": [
                    [
                      "Primary Role",
                      "Create and initialize a brokerage instance."
                    ],
                    [
                      "Interface",
                      "IBrokerageFactory.cs"
                    ],
                    [
                      "Example",
                      "BitfinexBrokerageFactory.cs"
                    ],
                    [
                      "Target Location",
                      "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
                    ]
                  ],
                  "caption": null
                }
              ],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.3",
              "title": "Creating the Brokerage",
              "level": 3,
              "section_number": "2.2.3",
              "breadcrumb": "Contributions > Brokerages > Creating the Brokerage",
              "mixed_content": [
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 1,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   IBrokerage\n   holds the bulk of the core logic responsible for running the brokerage implementation. Many smaller models described later internally use the brokerage implementation, so its best to now start implementating the\n   IBrokerage(code)\n   . Brokerage classes can get quite large, so use a\n   partial(code)\n   class modifier to break up the files in appropriate categories.",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Prerequisites",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "You need to\n   lay the foundation\n   before you can create a new brokerage.",
                  "order": 5,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Brokerage Roles",
                  "order": 6,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The brokerage has many the following important roles vital for the stability of a running algorithm:",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Maintain Connection - Connect and maintain connection while algorithm running.\nSetup State - Initialize the algorithm portfolio, open orders and cashbook.\nOrder Operations - Create, update and cancel orders.\nOrder Events - Receive order fills and apply them to portfolio.\nAccount Events - Track non-order events (cash deposits/removals).\nBrokerage Events - Interpret brokerage messages and act when required.\nServe History Requests - Provide historical data on request.",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Brokerages often have their own ticker styles, order class names, and event names. Many of the methods in the brokerage implementation may simply be converting from the brokerage object format into LEAN format. You should plan accordingly to write neat code.",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The brokerage must implement the following interfaces:",
                  "order": 7,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "class MyBrokerage : Brokerage, IDataQueueHandler, IDataQueueUniverseProvider { ... }",
                  "order": 7,
                  "language": "csharp",
                  "title": "C# Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Implementation Style",
                  "order": 12,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This guide focuses on implementing the brokerage step-by-step in LEAN because it's a more natural workflow for most people. You can also follow a more test-driven development process by following the test harness. To do this, create a new test class that extends from the base class in\n   Lean / Tests / Brokerages / BrokerageTests.cs\n   . This test-framework tests all the methods for an\n   IBrokerage(code)\n   implementation.",
                  "order": 13,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Connection Requirements",
                  "order": 14,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "LEAN is best used with streaming or socket-based brokerage connections. Streaming brokerage implementations allow for the easiest translation of broker events into LEAN events. Without streaming order events, you will need to poll for to check for fills. In our experience, this is fraught with additional risks and challenges.",
                  "order": 15,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### SDK Libraries",
                  "order": 16,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Most brokerages provide a wrapper for their API. If it has a permissive license and it's compatible with .NET 6, you should utilize it. Although it is technically possible to embed an external github repository, we've elected to not do this to make LEAN easier to install (submodules can be tricky for beginners). Instead, copy the library into its own subfolder of the brokerage implementation. For example,\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / BrokerLib / *\n   . After you add a library, build the project again to make sure the library successfully compiles.",
                  "order": 17,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "LEAN\n   \n   Open-Source. If you copy and paste code from an external source, leave the comments and headers intact. If they don't have a comment header, add one to each file, referencing the source. Let's keep the attributions in place.",
                  "order": 17,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Define the Brokerage Class",
                  "order": 19,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following sections describe components of the brokerage implementation in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n   file.",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Using a base class is optional but allows you to reuse event methods we have provided. The\n   Brokerage(code)\n   object implements these event handlers and marks the remaining items as\n   abstract(code)\n   .",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "LEAN provides an optional base class\n   BaseWebsocketsBrokerage(code)\n   which seeks to connect and maintain a socket connection and pass messages to an event handler. As each socket connection is different, carefully consider before using this class. It might be easier and more maintainable to simply maintain your own socket connection.",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Brush up on the\n   partial(code)\n   class keyword. It will help you break-up your class later.",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Class Constructor",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Once the scaffolding brokerage methods are in place (overrides of the abstract base classes), you can focus on the class constructor. If you are using a brokerage SDK, create a new instance of their library and store it to a class variable for later use. You should define the constructor so that it accepts all the arguments you pass it during the\n   CreateBrokerage(code)\n   method you implemented in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n   file.",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following table provides some example implementations of the brokerage class constructor:",
                  "order": 20,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 20,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "string Name(code)",
                  "order": 21,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   Name(csharp)\nname(python)\n   property is a human-readable brokerage name for debugging and logging. For US Equity-regulated brokerages, convention states this name generally ends in the word \"Brokerage\".",
                  "order": 21,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "void Connect()(code)",
                  "order": 21,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   Connect(code)\n   method triggers logic for establishing a link to your brokerage. Normally, we don't do this in the constructor because it makes algorithms and brokerages die in the\n   BrokerageFactory(code)\n   process. For most brokerages, to establish a connection with the brokerage, call the connect method on your SDK library.",
                  "order": 21,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following table provides some example implementations of the\n   Connect(code)\n   method:",
                  "order": 21,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 21,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If a soft failure occurs like a lost internet connection or a server 502 error, create a new\n   BrokerageMessageEvent(code)\n   so you allow the algorithm to\n   handle the brokerage messages\n   . For example, Interactive Brokers resets socket connections at different times globally, so users in other parts of the world can get disconnected at strange times of the day. Knowing this, they may elect to have their algorithm ignore specific disconnection attempts.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If a hard failure occurs like an incorrect password or an unsupported API method, throw a real exception with details of the error.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "void Disconnect()(code)",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   Disconnect(code)\n   method is called at the end of the algorithm before LEAN shuts down.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool IsConnected(code)",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   IsConnected(code)\n   property is a boolean that indicates the state of the brokerage connection. Depending on your connection style, this may be automatically handled for you and simply require passing back the value from your SDK. Alternatively, you may need to maintain your own connection state flag in your brokerage class.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool PlaceOrder(Order order)(code)",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   PlaceOrder(code)\n   method should send a new LEAN order to the brokerage and report back the success or failure. The\n   PlaceOrder(code)\n   method accepts a generic\n   Order(code)\n   object, which is the base class for all order types. The first step of placing an order is often to convert it from LEAN format into the format that the brokerage SDK requires. Your brokerage implementation should aim to support as many\n   LEAN order types\n   as possible. There may be other order types in the brokerage, but implementing them is considered out of scope of a rev-0 brokerage implementation.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Converting order types is an error-prone process and you should carefully review each order after you've ported it. Some brokerages have many properties on their orders, so check each required property for each order. To simplify the process, define an internal\n   BrokerOrder ConvertOrder(Order order)(code)\n   method to convert orders between LEAN format and your brokerage format. Part of the order conversion might be converting the brokerage ticker (for example, LEAN name \"EURUSD\" vs OANDA name \"EUR/USD\"). This is done with a\n   BrokerageSymbolMapper(code)\n   class. You can add this functionality later. For now, pass a request for the brokerage ticker to the stub implementation.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Once the order type is converted, use the\n   IsConnected(code)\n   property to check if you're connected before placing the order. If you're not connected, throw an exception to halt the algorithm. Otherwise, send the order to your brokerage submit API. Oftentimes, you receive an immediate reply indicating the order was successfully placed. The\n   PlaceOrder(code)\n   method should return true when the order is accepted by the brokerage. If the order is invalid, immediately rejected, or there is an internet outage, the method should return false.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool UpdateOrder(Order order)(code)",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The\n   UpdateOrder(code)\n   method transmits an update request to the API and returns true if it was successfully processed. Updating an order is one of the most tricky parts of brokerage implementations. You can easily run into synchronization issues.",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following table provides some example implementations of the\n   UpdateOrder(code)\n   method:",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "table",
                  "content": "[Table Data]",
                  "order": 22,
                  "language": null,
                  "title": "Data Table",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool CancelOrder(Order order)(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool UpdateOrder(Order order)(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "List<Order> GetOpenOrders()(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "List<Holding> GetAccountHoldings()(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "List<Cash> GetCashBalance()(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool AccountInstantlyUpdated(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "IEnumerable<BaseData> GetHistory(HistoryRequest request)(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "bool AccountInstantlyUpdated(code)",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [
                {
                  "headers": [
                    "IBrokerage"
                  ],
                  "rows": [
                    [
                      "Primary Role",
                      "Brokerage connection, orders, and fill events."
                    ],
                    [
                      "Interface",
                      "IBrokerage.cs"
                    ],
                    [
                      "Example",
                      "BitfinexBrokerage.cs"
                    ],
                    [
                      "Target Location",
                      "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
                    ]
                  ],
                  "caption": null
                },
                {
                  "headers": [
                    "Brokerage",
                    "Description"
                  ],
                  "rows": [
                    [
                      "Interactive Brokers",
                      "Launches an external process to create the brokerage."
                    ],
                    [
                      "OANDA",
                      "Creates an SDK instance and assigns internal event handlers."
                    ],
                    [
                      "Coinbase",
                      "Offloads constructor work toBrokerageFactoryand uses theBaseWebsocketBrokeragebase class."
                    ]
                  ],
                  "caption": null
                },
                {
                  "headers": [
                    "Brokerage",
                    "Description"
                  ],
                  "rows": [
                    [
                      "Interactive Brokers",
                      "Connects to an external process with the brokerage SDK."
                    ],
                    [
                      "OANDA",
                      "Simple example that calls the brokerage SDK."
                    ],
                    [
                      "Coinbase",
                      "Establishes the WebSocket connection and monitoring in a thread."
                    ]
                  ],
                  "caption": null
                },
                {
                  "headers": [
                    "Brokerage",
                    "Description"
                  ],
                  "rows": [
                    [
                      "Interactive Brokers",
                      "Updates multiple asset classes with an external application."
                    ],
                    [
                      "OANDA",
                      "Simple example that calls the brokerage SDK."
                    ],
                    [
                      "Coinbase",
                      "Throws an exception because order updates are not supported."
                    ]
                  ],
                  "caption": null
                }
              ],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.4",
              "title": "Translating Symbol Conventions",
              "level": 3,
              "section_number": "2.2.4",
              "breadcrumb": "Contributions > Brokerages > Translating Symbol Conventions",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.5",
              "title": "Describing Brokerage Limitations",
              "level": 3,
              "section_number": "2.2.5",
              "breadcrumb": "Contributions > Brokerages > Describing Brokerage Limitations",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.6",
              "title": "Enabling Live Data Streaming",
              "level": 3,
              "section_number": "2.2.6",
              "breadcrumb": "Contributions > Brokerages > Enabling Live Data Streaming",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.7",
              "title": "Enabling Historical Data",
              "level": 3,
              "section_number": "2.2.7",
              "breadcrumb": "Contributions > Brokerages > Enabling Historical Data",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.8",
              "title": "Downloading Data",
              "level": 3,
              "section_number": "2.2.8",
              "breadcrumb": "Contributions > Brokerages > Downloading Data",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.9",
              "title": "Modeling Fee Structures",
              "level": 3,
              "section_number": "2.2.9",
              "breadcrumb": "Contributions > Brokerages > Modeling Fee Structures",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            },
            {
              "id": "2.2.10",
              "title": "Updating the Algorithm API",
              "level": 3,
              "section_number": "2.2.10",
              "breadcrumb": "Contributions > Brokerages > Updating the Algorithm API",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This brokerage development guide is still under construction.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.2"
            }
          ],
          "parent_id": "2"
        },
        {
          "id": "2.3",
          "title": "Indicators",
          "level": 2,
          "section_number": "2.3",
          "breadcrumb": "Contributions > Indicators",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "LEAN currently supports over 100\n   indicators\n   .\n  This page explains how to contribute a new indicator to the open-source project by making a pull request to Lean. \n  Before you get started, familiarize yourself with our\n   contributing guidelines\n   .\n  If you don't already have a new indicator in mind that you want to contribute, see\n   the GitHub Issues in the Lean repository\n   for a list of indicators that community members have requested.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Get Third-Party Values",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "As a quantitative algorithmic trading engine, accuracy and reliability are very important to LEAN. \n When you submit a new indicator to the LEAN, you must include third-party source values are required as reference points in your pull request to contrast the values output by your indicator implementation. \n This requirement validates that your indicator implementation is correct.\n The following sections explain some examples of acceptable third-party sources.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Renowned Open-source Projects",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Developed and maintained by expert teams, these sources undergo rigorous testing and optimization, ensuring accurate calculations. \n The transparent nature of open-source projects allows for community scrutiny, resulting in bug fixes and continuous improvements.\n Open-source projects provide thorough information on how the indicator values are calculated, which provides excellent reproducibility. \n Thus, we accept values from these projects with high confidence. \n Example projects include\n   TA-Lib\n   and\n   QuantLib\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Highly Credible Websites",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Similar reasons apply to these websites as well. \n The site should be either the original source or a very popular trading data provider, such that we have confidence in their accuracy and reliability.\n These sources might provide structured data samples, like a\n   JSON\n   response,\n   CSV\n   /Excel file, or scripts for calculating the indicator values.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Define the Class",
              "order": 9,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "api_content",
              "content": "## IndicatorStatus Enumeration\n`enumQuantConnect.Indicators.IndicatorStatus`\nThe possible states returned by\n`fieldSUCCESS`\nThe indicator successfully calculated a value for the input data (0)\n`fieldINVALID_INPUT`\nThe indicator detected an invalid input data point or tradebar (1)\n`fieldMATH_ERROR`\nThe indicator encountered a math error during calculations (2)\n`fieldVALUE_NOT_READY`\nThe indicator value is not ready (3)",
              "order": 10,
              "language": "python",
              "title": "API: QuantConnect.Indicators.IndicatorStatus",
              "context": "Resolved from data-tree: QuantConnect.Indicators.IndicatorStatus"
            },
            {
              "type": "api_content",
              "content": "## IndicatorStatus Enumeration\n`enumQuantConnect.Indicators.IndicatorStatus`\nThe possible states returned by\n`fieldSuccess`\nThe indicator successfully calculated a value for the input data (0)\n`fieldInvalidInput`\nThe indicator detected an invalid input data point or tradebar (1)\n`fieldMathError`\nThe indicator encountered a math error during calculations (2)\n`fieldValueNotReady`\nThe indicator value is not ready (3)",
              "order": 11,
              "language": "csharp",
              "title": "API: QuantConnect.Indicators.IndicatorStatus (C#)",
              "context": "Resolved from data-tree: QuantConnect.Indicators.IndicatorStatus"
            },
            {
              "type": "text",
              "content": "### Define the Helper Method",
              "order": 12,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The preceding indicator class is sufficient to instatiate a\n   manual version\n   of the indicator.\n To enable users to create an\n   automatic version\n   of the indicator, add a new method to the\n   Lean / Algorithm / QCAlgorithm.Indicators.cs\n   file.\n Name the method a short abbreviation of the indicator's full name.\n In the method definition, call the\n   InitializeIndicator(code)\n   method to create a\n   consolidator\n   and register the indicator for automatic updates with the consolidated data.",
              "order": 13,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "public CustomIndicator CI(Symbol symbol, Resolution? resolution = null, Func<IBaseData, IBaseDataBar> selector = null)\n{\n    var name = CreateIndicatorName(symbol, $\"CI()\", resolution);\n    var ci = new CustomIndicator(name, symbol);\n    InitializeIndicator(symbol, ci, resolution, selector);\n    return ci;\n}",
              "order": 13,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "### Add Unit Tests",
              "order": 15,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Unit tests ensure your indicator functions correctly and produces accurate values. \n Follow these steps to add unit tests for your indicator:",
              "order": 16,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "<Content Include=\"TestData\\<filePath>.csv\">\n  <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n</Content>",
              "order": 16,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "code",
              "content": "namespace QuantConnect.Tests.Indicators\n{\n    [TestFixture]\n    public class CustomIndicatorTests : CommonIndicatorTests<T>\n    {\n        protected override IndicatorBase<T> CreateIndicator()\n        {\n            return new CustomIndicator();\n        }\n\n        protected override string TestFileName => \"custom_3rd_party_data.csv\";\n\n        protected override string TestColumnName => \"CustomIndicatorValueColumn\";\n\n        // How do you compare the values\n        protected override Action<IndicatorBase<T>, double> Assertion\n        {\n            get { return (indicator, expected) => Assert.AreEqual(expected, (double)indicator.Current.Value, 1e-4); }        // allow 0.0001 error margin of indicator values\n        }\n    }\n}",
              "order": 16,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Save the\n    third-party values\n    in the\n    Lean / Tests / TestData\n    directory as a\n    CSV\n    file.\nIn the\n    Lean / Tests / QuantConnect.Tests.csproj\n    file, reference the new data file.\nCreate a\n    Lean / Tests / Indicators / <IndicatorName>Tests.cs\n    file with the following content:\nSet the values of the\n    TestFileName(code)\n    and\n    TestColumnName(code)\n    attributes to the\n    CSV\n    file name and the column name of the testing values in the CSV file of third-party values, respectively.\nAdd test cases.\nTest if the constructor,\n    IsReady(code)\n    flag, and\n    Reset(code)\n    method work. If there are other custom calculation methods in your indicator class, add a tests for them.",
              "order": 16,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following example shows the testing class structure:",
              "order": 16,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "namespace QuantConnect.Tests.Indicators\n{\n    [TestFixture]\n    public class CustomIndicatorTests : CommonIndicatorTests<T>\n    {\n        protected override IndicatorBase<T> CreateIndicator()\n        {\n            return new CustomIndicator();\n        }\n\n        protected override string TestFileName => \"custom_3rd_party_data.csv\";\n\n        protected override string TestColumnName => \"CustomIndicatorValueColumn\";\n\n        // How do you compare the values\n        protected override Action<IndicatorBase<T>, double> Assertion\n        {\n            get { return (indicator, expected) => Assert.AreEqual(expected, (double)indicator.Current.Value, 1e-4); }        // allow 0.0001 error margin of indicator values\n        }\n\n        [Test]\n        public void IsReadyAfterPeriodUpdates()\n        {\n            var ci = CreateIndicator();\n\n            Assert.IsFalse(ci.IsReady);\n            ci.Update(DateTime.UtcNow, 1m);\n            Assert.IsTrue(ci.IsReady);\n        }\n\n        [Test]\n        public override void ResetsProperly()\n        {\n            var ci = CreateIndicator();\n\n            ci.Update(DateTime.UtcNow, 1m);\n            Assert.IsTrue(ci.IsReady);\n            \n            ci.Reset();\n\n            TestHelper.AssertIndicatorIsInDefaultState(ci);\n        }\n    }\n}",
              "order": 16,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "For a full example, see\n   SimpleMovingAverageTests.cs\n   in the LEAN repository.",
              "order": 16,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Documentation Changes",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "After the indicator was merged in the Lean engine, make sure you also ensure it is porperly documented in the documentation. Follow the below steps to do so:",
              "order": 24,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "'<hyphenated-title-case-of-the-indicator>':\n{\n    'code': <IndicatorConstructor>(<constructor-arguments>),\n    'title' : '<CSharpHelperMethod>(<helper-method-arguments>)',\n    'columns' : [<any-extra-series-of-the-indicator>]\n},",
              "order": 24,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create an issue in the\n    Documentation GitHub repository\n    regarding the required changes in the documentation.\nFork the Documentation GitHub repository and create a new branch named by\n    feature-<ISSUE_NUMBER>-<INDICATOR_NAME>-indicator(code)\n    .\nEdit the\n    IndicatorImageGenerator.py\n    file to include the details of the newly added indicator for documentation page generation.\nIf the indicator only involves 1 symbol and does not depend on other indicators, put it under the\n    indicators(code)\n    dictionary.\nIf the indicator involves 2 or more symbols or it is a composite indicator, put it under the\n    special_indicators(code)\n    dictionary.\nIf the indicator is an option-related indicator (e.g. option greeks indicator), put it under the\n    option_indicators(code)\n    dictionary.\nFormat of the added member should be as below:\n\nSave the file and run the\n    API generator\n    . It will help generate the indicator reference page.\n(Optional) Run the\n    IndicatorImageGenerator.py(code)\n    in LeanCLI to obtain the generated plotly image of the indicator. You can retreive it from the\n    storage(code)\n    folder from the root directory of the LeanCLI. Put it in the\n    Resource indicator image folder\n    by the name\n    <hyphenated-title-case-of-the-indicator>(code)\n    .\nPush the branch and start a\n    pull request\n    on the documentation changes.",
              "order": 24,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Extra Steps for Moving Average Types",
              "order": 27,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "api_content",
              "content": "## MovingAverageType Enumeration\n`enumQuantConnect.Indicators.MovingAverageType`\nDefines the different types of moving averages\n`fieldSIMPLE`\nAn unweighted, arithmetic mean (0)\n`fieldEXPONENTIAL`\nThe standard exponential moving average, using a smoothing factor of 2/(n+1) (1)\n`fieldWILDERS`\nAn exponential moving average, using a smoothing factor of 1/n and simple moving average as seeding (2)\n`fieldLINEAR_WEIGHTED_MOVING_AVERAGE`\nA weighted moving average type (3)\n`fieldDOUBLE_EXPONENTIAL`\nThe double exponential moving average (4)\n`fieldTRIPLE_EXPONENTIAL`\nThe triple exponential moving average (5)\n`fieldTRIANGULAR`\nThe triangular moving average (6)\n`fieldT_3`\nThe T3 moving average (7)\n`fieldKAMA`\nThe Kaufman Adaptive Moving Average (8)\n`fieldHULL`\nThe Hull Moving Average (9)\n`fieldALMA`\nThe Arnaud Legoux Moving Average (10)\n`fieldZLEMA`\nThe Zero Lag Exponential Moving Average (11)\n`fieldMGD`\nThe McGinley Dynamic moving average (12)",
              "order": 28,
              "language": "python",
              "title": "API: QuantConnect.Indicators.MovingAverageType",
              "context": "Resolved from data-tree: QuantConnect.Indicators.MovingAverageType"
            },
            {
              "type": "api_content",
              "content": "## MovingAverageType Enumeration\n`enumQuantConnect.Indicators.MovingAverageType`\nDefines the different types of moving averages\n`fieldSimple`\nAn unweighted, arithmetic mean (0)\n`fieldExponential`\nThe standard exponential moving average, using a smoothing factor of 2/(n+1) (1)\n`fieldWilders`\nAn exponential moving average, using a smoothing factor of 1/n and simple moving average as seeding (2)\n`fieldLinearWeightedMovingAverage`\nA weighted moving average type (3)\n`fieldDoubleExponential`\nThe double exponential moving average (4)\n`fieldTripleExponential`\nThe triple exponential moving average (5)\n`fieldTriangular`\nThe triangular moving average (6)\n`fieldT3`\nThe T3 moving average (7)\n`fieldKama`\nThe Kaufman Adaptive Moving Average (8)\n`fieldHull`\nThe Hull Moving Average (9)\n`fieldAlma`\nThe Arnaud Legoux Moving Average (10)\n`fieldZlema`\nThe Zero Lag Exponential Moving Average (11)\n`fieldMGD`\nThe McGinley Dynamic moving average (12)",
              "order": 29,
              "language": "csharp",
              "title": "API: QuantConnect.Indicators.MovingAverageType (C#)",
              "context": "Resolved from data-tree: QuantConnect.Indicators.MovingAverageType"
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2"
        }
      ],
      "parent_id": null
    },
    {
      "id": "2.1",
      "title": "Datasets",
      "level": 2,
      "section_number": "2.1",
      "breadcrumb": "Contributions > Datasets",
      "mixed_content": [],
      "tables": [],
      "subsections": [
        {
          "id": "2.1.1",
          "title": "Key Concepts",
          "level": 3,
          "section_number": "2.1.1",
          "breadcrumb": "Contributions > Datasets > Key Concepts",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Listing Process",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Datasets contributed to LEAN can be quickly listed in the QuantConnect Dataset Marketplace, and distributed for sale to more than 250,000 users in the QuantConnect community. To list a dataset, reach out to the\n   QuantConnect Team\n   for  a quick review, then proceed with the data creation and process steps in the following pages.",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Datasets must be well defined, with realistic timestamps for when the data was available (\"point in time\"). Ideally datasets need at least a 2 year track record and to be maintained by a reputable company. They should be accompanied with full documentation and code examples so the community can harness the data.",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Data Sources",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   GetSource(csharp)\nget_source(python)\n   method of your dataset class instructs LEAN where to find the data. This method must return a\n   SubscriptionDataSource\n   object, which contains the data location and format. We host your data, so the\n   transportMedium(csharp)\ntransport_medium(python)\n   must be\n   SubscriptionTransportMedium.LocalFile(code)\n   and the\n   format(code)\n   must be\n   FileFormat.Csv(code)\n   .",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### TimeZones",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   DataTimeZone(code)\n   method of your data source class declares the time zone of your dataset. This method returns a\n   NodaTime\n   .DateTimeZone object. If your dataset provides trading data and universe data, the\n   DataTimeZone(code)\n   methods in your\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>.cs\n   and\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Universe.cs\n   files must be the same.",
              "order": 8,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Linked Datasets",
              "order": 9,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Your dataset is linked if any of the following statements are true:",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Your dataset describes market price properties of specific securities (for example, the closing price of AAPL).\nYour alternative dataset is linked to individual securities (for example, the Wikipedia page view count of AAPL).",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Examples of unlinked datasets would be the weather of New York City, where data is not relevant to a specific security.",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "When a dataset is linked, it needs to be mapped to underlying assets through time. \n    The\n   RequiresMapping(code)\n   boolean instructs LEAN to handle the security and ticker mapping issues.",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1"
        },
        {
          "id": "2.1.2",
          "title": "Defining Data Models",
          "level": 3,
          "section_number": "2.1.2",
          "breadcrumb": "Contributions > Datasets > Defining Data Models",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to set up the data source SDK and use it to create data models.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Part 1/ Set up SDK",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to create a repository for your dataset:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ git clone https://github.com/username/Lean.DataSource.<vendorNameDatasetName>.git",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ chmod +x ./renameDataset",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ renameDataset.sh",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Open the\n    Lean.DataSource.SDK repository\n    and click\n    Use this template > Create a new repository\n    .\n\nStart with the SDK repository instead of existing data source implementations because we periodically update the SDK repository.\nOn the Create a new repository from Lean.DataSource.SDK page, set the repository name to\n    Lean.DataSource.<vendorNameDatasetName>\n    (for example,\n    Lean.DataSource.XYZAirlineTicketSales\n    ).\nIf your dataset contains multiple series, use\n    <vendorName>\n    instead of\n    <vendorNameDatasetName>\n    . For instance, the Federal Reserve Economic Data (FRED) dataset repository has the name\n    Lean.DataSource.FRED\n    because it has\n    many different series\n    .\nClick\n    Create repository from template\n    .\nClone\n    the\n    Lean.DataSource.<vendorNameDatasetName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, run the\n    renameDataset.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.DataSource.<vendorNameDatasetName>\n    directory and renames some files according to your dataset's\n    <vendorNameDatasetName>.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Part 2/ Create Data Models",
              "order": 9,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "api_content",
              "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
              "order": 10,
              "language": "python",
              "title": "API: QuantConnect.Resolution",
              "context": "Resolved from data-tree: QuantConnect.Resolution"
            },
            {
              "type": "api_content",
              "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
              "order": 11,
              "language": "csharp",
              "title": "API: QuantConnect.Resolution (C#)",
              "context": "Resolved from data-tree: QuantConnect.Resolution"
            },
            {
              "type": "text",
              "content": "### Part 3/ Create Universe Models",
              "order": 12,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "api_content",
              "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
              "order": 13,
              "language": "python",
              "title": "API: QuantConnect.Resolution",
              "context": "Resolved from data-tree: QuantConnect.Resolution"
            },
            {
              "type": "api_content",
              "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
              "order": 14,
              "language": "csharp",
              "title": "API: QuantConnect.Resolution (C#)",
              "context": "Resolved from data-tree: QuantConnect.Resolution"
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1"
        },
        {
          "id": "2.1.3",
          "title": "Rendering Data",
          "level": 3,
          "section_number": "2.1.3",
          "breadcrumb": "Contributions > Datasets > Rendering Data",
          "mixed_content": [],
          "tables": [],
          "subsections": [
            {
              "id": "2.1.3.1",
              "title": "Rendering Data with Python",
              "level": 4,
              "section_number": "2.1.3.1",
              "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Python",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to create a script to download and process your dataset with Python for QuantConnect distribution.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Using Processing Framework",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect.\n    The script should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Your dataset is not linked to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In a terminal, compile the data processing project.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file, import the\n   CLRImports(code)\n   library.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "from CLRImports import *",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Create and initialize a map file provider.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Create a security identifier.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Copy the\n   process.sample.py\n   script to the\n   DataProcessing / bin / debug / net9.0\n   directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "You need to place the script under the\n   bin\n   directory so that LEAN's packages dlls are correctly loaded for the\n   CLRImports(code)\n   .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ cp process.sample.py DataProcessing/bin/Debug/net9.0",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ cd DataProcessing/bin/debug/net9.0/\n$ python process.sample.py",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Run the\n   DataProcessing / bin / debug / net9.0 / process.sample.py\n   script to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.\n   \nNote: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Python Processor Examples",
                  "order": 25,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following examples are rendering datasets with Python processing:",
                  "order": 26,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Lean.DataSource.BitcoinMetadata\nLean.DataSource.BrainSentiment\nLean.DataSource.CryptoSlamNFTSale\nLean.DataSource.QuiverQuantTwitterFollowers\nLean.DataSource.Regalytics",
                  "order": 26,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1.3"
            },
            {
              "id": "2.1.3.2",
              "title": "Rendering Data with CSharp",
              "level": 4,
              "section_number": "2.1.3.2",
              "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with CSharp",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to create a script to download and process your dataset with C# for QuantConnect distribution.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Using Processing Framework",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n    The program should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, create and initialize a map file provider.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "var mapFileProvider = new LocalZipMapFileProvider();\nvar mapFileProvider.Initialize(new DefaultDataProvider());",
                  "order": 4,
                  "language": "csharp",
                  "title": "C# Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Create a security identifier.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "var sid = SecurityIdentifier.GenerateEquity(pointInIimeTicker,\n    Market.USA, true, mapFileProvider, csvDate)",
                  "order": 4,
                  "language": "csharp",
                  "title": "C# Code Example",
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In a terminal, compile the data processing project to generate the\n   process.exe\n   executable file.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "After you finish compiling the\n   Program.cs\n   file, run the\n   process.exe\n   file to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### CSharp Processor Examples",
                  "order": 18,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following examples are rendering datasets with C# processing:",
                  "order": 19,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Lean.DataSource.BinanceFundingRate\nLean.DataSource.CoinGecko\nLean.DataSource.CryptoCoarseFundamentalUniverse\nLean.DataSource.QuiverInsiderTrading\nLean.DataSource.VIXCentral",
                  "order": 19,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1.3"
            },
            {
              "id": "2.1.3.3",
              "title": "Rendering Data with Notebooks",
              "level": 4,
              "section_number": "2.1.3.3",
              "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Notebooks",
              "mixed_content": [
                {
                  "type": "text",
                  "content": "### Introduction",
                  "order": 1,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This page explains how to create a script to download and process your dataset with Jupyter Notebooks for QuantConnect distribution.",
                  "order": 2,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Using Processing Framework",
                  "order": 3,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n     The notebook should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Follow these steps to set up the downloading and processing script for your dataset:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In a terminal, compile the data processing project.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
                  "order": 4,
                  "language": "cli",
                  "title": "Command Line Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file, import the\n   CLRImports(code)\n   library.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "from CLRImports import *",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Create and initialize a map file provider.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Create a security identifier.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "code",
                  "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
                  "order": 4,
                  "language": "python",
                  "title": "Python Code Example",
                  "context": null
                },
                {
                  "type": "text",
                  "content": "After you finish editing the\n   process.sample.ipynb\n   script, run its cells to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
                  "order": 4,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "### Notebook Processor Examples",
                  "order": 22,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "The following examples are rendering datasets with Jupyter Notebook processing:",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                },
                {
                  "type": "text",
                  "content": "Lean.DataSource.KavoutCompositeFactorBundle\nLean.DataSource.USEnergy",
                  "order": 23,
                  "language": null,
                  "title": null,
                  "context": null
                }
              ],
              "tables": [],
              "subsections": [],
              "parent_id": "2.1.3"
            }
          ],
          "parent_id": "2.1"
        },
        {
          "id": "2.1.4",
          "title": "Testing Data Models",
          "level": 3,
          "section_number": "2.1.4",
          "breadcrumb": "Contributions > Datasets > Testing Data Models",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The implementation of your Data Source must be thoroughly tested to be listed on the\n   Dataset Market\n   .",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Run Demonstration Algorithms",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to test if your demonstration algorithm will run in production with the processed data:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ git pull upstream master",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ git clone https://github.com/<username>/Lean.git",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"QuantConnect.Algorithm.CSharp.dll\",",
              "order": 4,
              "language": "text",
              "title": "Code Example",
              "context": null
            },
            {
              "type": "code",
              "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"../../../Algorithm.Python/<vendorNameDatasetName>Algorithm.py\",",
              "order": 4,
              "language": "text",
              "title": "Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Open the\n    Lean.DataSource.<vendorNameDatasetName> / QuantConnect.DataSource.csproj\n    file in Visual Studio.\nIn the top menu bar of Visual Studio, click\n    Build > Build Solution\n    .\nThe Output panel displays the build status of the project.\nClose Visual Studio.\n Install LEAN \nIf you have a local copy of LEAN, pull the latest changes.\n\nIf you don't have a local copy of LEAN,\n    fork the LEAN repository\n    and then\n    clone it\n    .\n\n Place data into LEAN \nCopy the contents of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory and paste them into the\n    Lean / Data\n    directory.\n Add data source to LEAN \nOpen the\n    Lean / QuantConnect.Lean.sln\n    file in Visual Studio.\nIn the Solution Explorer panel of Visual Studio, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Existing Itemâ€¦\n    .\nIn the Add Existing Item window, click the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    file and then click\n    Add\n    .\nIn the Solution Explorer panel, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Project Reference...\n    .\nIn the Reference Manager window, click\n    Browseâ€¦\n    .\nIn the Select the files to referenceâ€¦ window, click the\n    Lean.DataSource.<vendorNameDatasetName> / bin / Debug / net9.0 / QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file and then click\n    Add\n    .\nThe Reference Manager window displays the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file with the check box beside it enabled.\nClick\n    OK\n    .\nThe Solution Explorer panel adds the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file under\n    QuantConnect.Algorithm.CSharp > Dependencies > Assemblies\n    .\n Write demo C# algorithm \nIn the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\n Write demo Python algorithm \nCopy the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    file and paste it in\n    Lean / Algorithm.Python\n    directory.\nIn the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\nImportant: Your backtests must run without error. If your backtests produce errors, correct them and then run the backtest again.\n Copy demo algorithms back to data source repo \nCopy the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    .\nCopy the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Run Unit Tests",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "You must\n   run your demonstration algorithms\n   without error before you set up unit tests.",
              "order": 11,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Tests.cs\n   file, define the\n   CreateNewInstance(code)\n   method to return an instance of your\n   DataSource(code)\n   class and then execute the following commands to run the unit tests:",
              "order": 11,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ dotnet build tests/Tests.csproj\n$ dotnet test tests/bin/Debug/net9.0/Tests.dll",
              "order": 11,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1"
        },
        {
          "id": "2.1.5",
          "title": "Data Documentation",
          "level": 3,
          "section_number": "2.1.5",
          "breadcrumb": "Contributions > Datasets > Data Documentation",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to provide documentation for your dataset so QuantConnect members can use it in their trading algorithms.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Required Key Properties",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "You need to process the entire dataset to collect the following information:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 4,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "### Provide Documentation",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "To provide documentation for your dataset, in the\n   Lean.DataSource.<vendorNameDatasetName> / listing-about.md\n   and\n   Lean.DataSource.<vendorNameDatasetName> / listing-documentation.md\n   files, fill in the missing content.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Next Steps",
              "order": 8,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "After we review and accept your dataset contribution, we will create a page in our\n   Dataset Market\n   . At that point, you will be able to write algorithms in QuantConnect Cloud using your dataset and you can contribute an example algorithm for the dataset listing. After your dataset listing is complete, we'll include your new dataset in our\n   downloading data tutorial\n   .",
              "order": 9,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [
            {
              "headers": [
                "Property",
                "Description"
              ],
              "rows": [
                [
                  "Start Date",
                  "Date and time of the first data point"
                ],
                [
                  "Asset Coverage",
                  "Number of assets covered by the dataset"
                ],
                [
                  "Data density",
                  "Dense for tick data. Regular or Sparse according to the frequency."
                ],
                [
                  "Resolution",
                  "Options: Tick, Second, Minute, Hourly, & Daily."
                ],
                [
                  "Timezone",
                  "Data timezone. This is a property of the data source."
                ],
                [
                  "Data process time",
                  "Time and days of the week to process the data."
                ],
                [
                  "Data process duration",
                  "Time to process the entire the dataset."
                ],
                [
                  "Update process duration",
                  "Time to update the dataset."
                ]
              ],
              "caption": null
            }
          ],
          "subsections": [],
          "parent_id": "2.1"
        }
      ],
      "parent_id": "2"
    },
    {
      "id": "2.1.1",
      "title": "Key Concepts",
      "level": 3,
      "section_number": "2.1.1",
      "breadcrumb": "Contributions > Datasets > Key Concepts",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Listing Process",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Datasets contributed to LEAN can be quickly listed in the QuantConnect Dataset Marketplace, and distributed for sale to more than 250,000 users in the QuantConnect community. To list a dataset, reach out to the\n   QuantConnect Team\n   for  a quick review, then proceed with the data creation and process steps in the following pages.",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Datasets must be well defined, with realistic timestamps for when the data was available (\"point in time\"). Ideally datasets need at least a 2 year track record and to be maintained by a reputable company. They should be accompanied with full documentation and code examples so the community can harness the data.",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Data Sources",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   GetSource(csharp)\nget_source(python)\n   method of your dataset class instructs LEAN where to find the data. This method must return a\n   SubscriptionDataSource\n   object, which contains the data location and format. We host your data, so the\n   transportMedium(csharp)\ntransport_medium(python)\n   must be\n   SubscriptionTransportMedium.LocalFile(code)\n   and the\n   format(code)\n   must be\n   FileFormat.Csv(code)\n   .",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### TimeZones",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   DataTimeZone(code)\n   method of your data source class declares the time zone of your dataset. This method returns a\n   NodaTime\n   .DateTimeZone object. If your dataset provides trading data and universe data, the\n   DataTimeZone(code)\n   methods in your\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>.cs\n   and\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Universe.cs\n   files must be the same.",
          "order": 8,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Linked Datasets",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Your dataset is linked if any of the following statements are true:",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Your dataset describes market price properties of specific securities (for example, the closing price of AAPL).\nYour alternative dataset is linked to individual securities (for example, the Wikipedia page view count of AAPL).",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Examples of unlinked datasets would be the weather of New York City, where data is not relevant to a specific security.",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "When a dataset is linked, it needs to be mapped to underlying assets through time. \n    The\n   RequiresMapping(code)\n   boolean instructs LEAN to handle the security and ticker mapping issues.",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1"
    },
    {
      "id": "2.1.2",
      "title": "Defining Data Models",
      "level": 3,
      "section_number": "2.1.2",
      "breadcrumb": "Contributions > Datasets > Defining Data Models",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to set up the data source SDK and use it to create data models.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Part 1/ Set up SDK",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to create a repository for your dataset:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ git clone https://github.com/username/Lean.DataSource.<vendorNameDatasetName>.git",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ chmod +x ./renameDataset",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ renameDataset.sh",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Open the\n    Lean.DataSource.SDK repository\n    and click\n    Use this template > Create a new repository\n    .\n\nStart with the SDK repository instead of existing data source implementations because we periodically update the SDK repository.\nOn the Create a new repository from Lean.DataSource.SDK page, set the repository name to\n    Lean.DataSource.<vendorNameDatasetName>\n    (for example,\n    Lean.DataSource.XYZAirlineTicketSales\n    ).\nIf your dataset contains multiple series, use\n    <vendorName>\n    instead of\n    <vendorNameDatasetName>\n    . For instance, the Federal Reserve Economic Data (FRED) dataset repository has the name\n    Lean.DataSource.FRED\n    because it has\n    many different series\n    .\nClick\n    Create repository from template\n    .\nClone\n    the\n    Lean.DataSource.<vendorNameDatasetName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.DataSource.<vendorNameDatasetName>\n    directory, run the\n    renameDataset.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.DataSource.<vendorNameDatasetName>\n    directory and renames some files according to your dataset's\n    <vendorNameDatasetName>.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Part 2/ Create Data Models",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "api_content",
          "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
          "order": 10,
          "language": "python",
          "title": "API: QuantConnect.Resolution",
          "context": "Resolved from data-tree: QuantConnect.Resolution"
        },
        {
          "type": "api_content",
          "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
          "order": 11,
          "language": "csharp",
          "title": "API: QuantConnect.Resolution (C#)",
          "context": "Resolved from data-tree: QuantConnect.Resolution"
        },
        {
          "type": "text",
          "content": "### Part 3/ Create Universe Models",
          "order": 12,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "api_content",
          "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTICK`\nTick Resolution (0)\n`fieldSECOND`\nSecond Resolution (1)\n`fieldMINUTE`\nMinute Resolution (2)\n`fieldHOUR`\nHour Resolution (3)\n`fieldDAILY`\nDaily Resolution (4)",
          "order": 13,
          "language": "python",
          "title": "API: QuantConnect.Resolution",
          "context": "Resolved from data-tree: QuantConnect.Resolution"
        },
        {
          "type": "api_content",
          "content": "## Resolution Enumeration\n`enumQuantConnect.Resolution`\nResolution of data requested.\n`fieldTick`\nTick Resolution (0)\n`fieldSecond`\nSecond Resolution (1)\n`fieldMinute`\nMinute Resolution (2)\n`fieldHour`\nHour Resolution (3)\n`fieldDaily`\nDaily Resolution (4)",
          "order": 14,
          "language": "csharp",
          "title": "API: QuantConnect.Resolution (C#)",
          "context": "Resolved from data-tree: QuantConnect.Resolution"
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1"
    },
    {
      "id": "2.1.3",
      "title": "Rendering Data",
      "level": 3,
      "section_number": "2.1.3",
      "breadcrumb": "Contributions > Datasets > Rendering Data",
      "mixed_content": [],
      "tables": [],
      "subsections": [
        {
          "id": "2.1.3.1",
          "title": "Rendering Data with Python",
          "level": 4,
          "section_number": "2.1.3.1",
          "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Python",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to create a script to download and process your dataset with Python for QuantConnect distribution.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Using Processing Framework",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect.\n    The script should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to set up the downloading and processing script for your dataset:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Your dataset is not linked to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In a terminal, compile the data processing project.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file, import the\n   CLRImports(code)\n   library.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "from CLRImports import *",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create and initialize a map file provider.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create a security identifier.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Copy the\n   process.sample.py\n   script to the\n   DataProcessing / bin / debug / net9.0\n   directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "You need to place the script under the\n   bin\n   directory so that LEAN's packages dlls are correctly loaded for the\n   CLRImports(code)\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ cp process.sample.py DataProcessing/bin/Debug/net9.0",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ cd DataProcessing/bin/debug/net9.0/\n$ python process.sample.py",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Run the\n   DataProcessing / bin / debug / net9.0 / process.sample.py\n   script to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.\n   \nNote: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Python Processor Examples",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following examples are rendering datasets with Python processing:",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Lean.DataSource.BitcoinMetadata\nLean.DataSource.BrainSentiment\nLean.DataSource.CryptoSlamNFTSale\nLean.DataSource.QuiverQuantTwitterFollowers\nLean.DataSource.Regalytics",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1.3"
        },
        {
          "id": "2.1.3.2",
          "title": "Rendering Data with CSharp",
          "level": 4,
          "section_number": "2.1.3.2",
          "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with CSharp",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to create a script to download and process your dataset with C# for QuantConnect distribution.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Using Processing Framework",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n    The program should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to set up the downloading and processing script for your dataset:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, create and initialize a map file provider.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "var mapFileProvider = new LocalZipMapFileProvider();\nvar mapFileProvider.Initialize(new DefaultDataProvider());",
              "order": 4,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create a security identifier.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "var sid = SecurityIdentifier.GenerateEquity(pointInIimeTicker,\n    Market.USA, true, mapFileProvider, csvDate)",
              "order": 4,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "In a terminal, compile the data processing project to generate the\n   process.exe\n   executable file.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "After you finish compiling the\n   Program.cs\n   file, run the\n   process.exe\n   file to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### CSharp Processor Examples",
              "order": 18,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following examples are rendering datasets with C# processing:",
              "order": 19,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Lean.DataSource.BinanceFundingRate\nLean.DataSource.CoinGecko\nLean.DataSource.CryptoCoarseFundamentalUniverse\nLean.DataSource.QuiverInsiderTrading\nLean.DataSource.VIXCentral",
              "order": 19,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1.3"
        },
        {
          "id": "2.1.3.3",
          "title": "Rendering Data with Notebooks",
          "level": 4,
          "section_number": "2.1.3.3",
          "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Notebooks",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to create a script to download and process your dataset with Jupyter Notebooks for QuantConnect distribution.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Using Processing Framework",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n     The notebook should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to set up the downloading and processing script for your dataset:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In a terminal, compile the data processing project.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
              "order": 4,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file, import the\n   CLRImports(code)\n   library.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "from CLRImports import *",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create and initialize a map file provider.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Create a security identifier.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
              "order": 4,
              "language": "python",
              "title": "Python Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "After you finish editing the\n   process.sample.ipynb\n   script, run its cells to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Notebook Processor Examples",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following examples are rendering datasets with Jupyter Notebook processing:",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Lean.DataSource.KavoutCompositeFactorBundle\nLean.DataSource.USEnergy",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.1.3"
        }
      ],
      "parent_id": "2.1"
    },
    {
      "id": "2.1.3.1",
      "title": "Rendering Data with Python",
      "level": 4,
      "section_number": "2.1.3.1",
      "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Python",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to create a script to download and process your dataset with Python for QuantConnect distribution.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Using Processing Framework",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect.\n    The script should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to set up the downloading and processing script for your dataset:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Your dataset is not linked to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In a terminal, compile the data processing project.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.py\n   file, import the\n   CLRImports(code)\n   library.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "from CLRImports import *",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create and initialize a map file provider.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create a security identifier.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Copy the\n   process.sample.py\n   script to the\n   DataProcessing / bin / debug / net9.0\n   directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "You need to place the script under the\n   bin\n   directory so that LEAN's packages dlls are correctly loaded for the\n   CLRImports(code)\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ cp process.sample.py DataProcessing/bin/Debug/net9.0",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ cd DataProcessing/bin/debug/net9.0/\n$ python process.sample.py",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Run the\n   DataProcessing / bin / debug / net9.0 / process.sample.py\n   script to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.\n   \nNote: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Python Processor Examples",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following examples are rendering datasets with Python processing:",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Lean.DataSource.BitcoinMetadata\nLean.DataSource.BrainSentiment\nLean.DataSource.CryptoSlamNFTSale\nLean.DataSource.QuiverQuantTwitterFollowers\nLean.DataSource.Regalytics",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1.3"
    },
    {
      "id": "2.1.3.2",
      "title": "Rendering Data with CSharp",
      "level": 4,
      "section_number": "2.1.3.2",
      "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with CSharp",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to create a script to download and process your dataset with C# for QuantConnect distribution.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Using Processing Framework",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n    The program should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to set up the downloading and processing script for your dataset:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, create and initialize a map file provider.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "var mapFileProvider = new LocalZipMapFileProvider();\nvar mapFileProvider.Initialize(new DefaultDataProvider());",
          "order": 4,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create a security identifier.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "var sid = SecurityIdentifier.GenerateEquity(pointInIimeTicker,\n    Market.USA, true, mapFileProvider, csvDate)",
          "order": 4,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "In a terminal, compile the data processing project to generate the\n   process.exe\n   executable file.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "After you finish compiling the\n   Program.cs\n   file, run the\n   process.exe\n   file to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### CSharp Processor Examples",
          "order": 18,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following examples are rendering datasets with C# processing:",
          "order": 19,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Lean.DataSource.BinanceFundingRate\nLean.DataSource.CoinGecko\nLean.DataSource.CryptoCoarseFundamentalUniverse\nLean.DataSource.QuiverInsiderTrading\nLean.DataSource.VIXCentral",
          "order": 19,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1.3"
    },
    {
      "id": "2.1.3.3",
      "title": "Rendering Data with Notebooks",
      "level": 4,
      "section_number": "2.1.3.3",
      "breadcrumb": "Contributions > Datasets > Rendering Data > Rendering Data with Notebooks",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to create a script to download and process your dataset with Jupyter Notebooks for QuantConnect distribution.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Using Processing Framework",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "During this part of the contribution process, you need to edit the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file so it transforms and moves your raw data into the format and location the\n   GetSource methods\n   expect. \n     The notebook should save all the data history to the\n   output\n   directory in your machine's root directory (for example,\n   C: / output\n   ) and it should save a sample of the data history to the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to set up the downloading and processing script for your dataset:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Change the structure of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory to match the path structure you defined in the\n    GetSource(csharp)\nget_source(python)\n    methods (for example,\n    output / alternative / xyzairline / ticketsales\n    ).\nIn the\n    Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n    file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.\nYou need this information for when you provide the\n    dataset documentation\n    . We need to know how long it takes to process your dataset so we can schedule its processing job.\nIn the processing file, load the raw data from your source.\nYou can fetch data from any of the following sources:\nSource\nConsiderations\nLocal Files\nIt can help to first copy the data into location.\nRemote API\nStay within the rate limits. You can use the rate gate class.\nYou should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.\nIf your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.\nIf any of the following statements are true, skip the rest of the steps in this tutorial:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Your dataset is not related to Equities.\nYour dataset is related to Equities and already includes the point-in-time tickers.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If you don't have the\n   US Equity Security Master dataset\n   ,\n   contact us\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / Program.cs\n   file, remove the statements of the\n   Main(code)\n   method",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In a terminal, compile the data processing project.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ dotnet build .\\DataProcessing\\DataProcessing.csproj",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "This step generates a file that the\n   CLRImports(code)\n   library uses.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / DataProcessing / process.sample.ipynb\n   file, import the\n   CLRImports(code)\n   library.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "from CLRImports import *",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create and initialize a map file provider.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "map_file_provider = LocalZipMapFileProvider()\nmap_file_provider.Initialize(DefaultDataProvider())",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create a security identifier.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "sid = SecurityIdentifier.generate_equity(point_in_time_ticker,\n    Market.USA, True, map_file_provider, csv_date)",
          "order": 4,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "After you finish editing the\n   process.sample.ipynb\n   script, run its cells to populate the\n   Lean.DataSource.<vendorNameDatasetName> / output\n   directory and the\n   output\n   directory in your machine's root directory.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Notebook Processor Examples",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following examples are rendering datasets with Jupyter Notebook processing:",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Lean.DataSource.KavoutCompositeFactorBundle\nLean.DataSource.USEnergy",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1.3"
    },
    {
      "id": "2.1.4",
      "title": "Testing Data Models",
      "level": 3,
      "section_number": "2.1.4",
      "breadcrumb": "Contributions > Datasets > Testing Data Models",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The implementation of your Data Source must be thoroughly tested to be listed on the\n   Dataset Market\n   .",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Run Demonstration Algorithms",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to test if your demonstration algorithm will run in production with the processed data:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ git pull upstream master",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ git clone https://github.com/<username>/Lean.git",
          "order": 4,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"QuantConnect.Algorithm.CSharp.dll\",",
          "order": 4,
          "language": "text",
          "title": "Code Example",
          "context": null
        },
        {
          "type": "code",
          "content": "\"algorithm-type-name\": \"<vendorNameDatasetName>Algorithm\",\n\"algorithm-location\": \"../../../Algorithm.Python/<vendorNameDatasetName>Algorithm.py\",",
          "order": 4,
          "language": "text",
          "title": "Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Open the\n    Lean.DataSource.<vendorNameDatasetName> / QuantConnect.DataSource.csproj\n    file in Visual Studio.\nIn the top menu bar of Visual Studio, click\n    Build > Build Solution\n    .\nThe Output panel displays the build status of the project.\nClose Visual Studio.\n Install LEAN \nIf you have a local copy of LEAN, pull the latest changes.\n\nIf you don't have a local copy of LEAN,\n    fork the LEAN repository\n    and then\n    clone it\n    .\n\n Place data into LEAN \nCopy the contents of the\n    Lean.DataSource.<vendorNameDatasetName> / output\n    directory and paste them into the\n    Lean / Data\n    directory.\n Add data source to LEAN \nOpen the\n    Lean / QuantConnect.Lean.sln\n    file in Visual Studio.\nIn the Solution Explorer panel of Visual Studio, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Existing Itemâ€¦\n    .\nIn the Add Existing Item window, click the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    file and then click\n    Add\n    .\nIn the Solution Explorer panel, right-click\n    QuantConnect.Algorithm.CSharp\n    and then click\n    Add > Project Reference...\n    .\nIn the Reference Manager window, click\n    Browseâ€¦\n    .\nIn the Select the files to referenceâ€¦ window, click the\n    Lean.DataSource.<vendorNameDatasetName> / bin / Debug / net9.0 / QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file and then click\n    Add\n    .\nThe Reference Manager window displays the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file with the check box beside it enabled.\nClick\n    OK\n    .\nThe Solution Explorer panel adds the\n    QuantConnect.DataSource.<vendorNameDatasetName>.dll\n    file under\n    QuantConnect.Algorithm.CSharp > Dependencies > Assemblies\n    .\n Write demo C# algorithm \nIn the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\n Write demo Python algorithm \nCopy the\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    file and paste it in\n    Lean / Algorithm.Python\n    directory.\nIn the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file,\n    write an algorithm\n    that uses your new dataset.\nIn the Solution Explorer panel, click\n    QuantConnect.Lean.Launcher > config.json\n    .\nIn the\n    config.json\n    file, set the following keys:\n\nPress\n    Ctrl+F5\n    to backtest your demonstration algorithm.\nImportant: Your backtests must run without error. If your backtests produce errors, correct them and then run the backtest again.\n Copy demo algorithms back to data source repo \nCopy the\n    Lean / Algorithm.CSharp / <vendorNameDatasetName>Algorithm.cs\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.cs\n    .\nCopy the\n    Lean / Algorithm.Python / <vendorNameDatasetName>Algorithm.py\n    file to\n    Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Algorithm.py\n    .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Run Unit Tests",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "You must\n   run your demonstration algorithms\n   without error before you set up unit tests.",
          "order": 11,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n   Lean.DataSource.<vendorNameDatasetName> / <vendorNameDatasetName>Tests.cs\n   file, define the\n   CreateNewInstance(code)\n   method to return an instance of your\n   DataSource(code)\n   class and then execute the following commands to run the unit tests:",
          "order": 11,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ dotnet build tests/Tests.csproj\n$ dotnet test tests/bin/Debug/net9.0/Tests.dll",
          "order": 11,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.1"
    },
    {
      "id": "2.1.5",
      "title": "Data Documentation",
      "level": 3,
      "section_number": "2.1.5",
      "breadcrumb": "Contributions > Datasets > Data Documentation",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to provide documentation for your dataset so QuantConnect members can use it in their trading algorithms.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Required Key Properties",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "You need to process the entire dataset to collect the following information:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 4,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "### Provide Documentation",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To provide documentation for your dataset, in the\n   Lean.DataSource.<vendorNameDatasetName> / listing-about.md\n   and\n   Lean.DataSource.<vendorNameDatasetName> / listing-documentation.md\n   files, fill in the missing content.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Next Steps",
          "order": 8,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "After we review and accept your dataset contribution, we will create a page in our\n   Dataset Market\n   . At that point, you will be able to write algorithms in QuantConnect Cloud using your dataset and you can contribute an example algorithm for the dataset listing. After your dataset listing is complete, we'll include your new dataset in our\n   downloading data tutorial\n   .",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [
        {
          "headers": [
            "Property",
            "Description"
          ],
          "rows": [
            [
              "Start Date",
              "Date and time of the first data point"
            ],
            [
              "Asset Coverage",
              "Number of assets covered by the dataset"
            ],
            [
              "Data density",
              "Dense for tick data. Regular or Sparse according to the frequency."
            ],
            [
              "Resolution",
              "Options: Tick, Second, Minute, Hourly, & Daily."
            ],
            [
              "Timezone",
              "Data timezone. This is a property of the data source."
            ],
            [
              "Data process time",
              "Time and days of the week to process the data."
            ],
            [
              "Data process duration",
              "Time to process the entire the dataset."
            ],
            [
              "Update process duration",
              "Time to update the dataset."
            ]
          ],
          "caption": null
        }
      ],
      "subsections": [],
      "parent_id": "2.1"
    },
    {
      "id": "2.2",
      "title": "Brokerages",
      "level": 2,
      "section_number": "2.2",
      "breadcrumb": "Contributions > Brokerages",
      "mixed_content": [
        {
          "type": "text",
          "content": "Creating a fully supported brokerage is a challenging endeavor. LEAN requires a number of individual pieces which work together to form a complete brokerage implementation. This guide aims to describe in as much detail as possible what you need to do for each module.\nThe end goal is to submit a pull request that passes all tests. Partially-completed brokerage implementations are acceptable if they are merged to a branch. It's easy to fall behind master, so be sure to keep your branch updated with the master branch. Before you start, read LEAN's\n     coding style guidelines\n     to comply with the code commenting and design standards.\nThe root of the brokerage system is the algorithm job packets, which hold configuration information about how to run LEAN. The program logic is a little convoluted. It moves from\n     config.json > create job packet > create brokerage factory matching name > set job packet brokerage data > factory creates brokerage instance\n     . As a result, we'll start creating a brokerage at the root, the configuration and brokerage factory.\nSetting Up Your Environment\n       Set up your local brokerage repository.\nLaying the Foundation\n       (\n       IBrokerageFactory(code)\n       ) Stub out the implementation and initialize a brokerage instance.\nCreating the Brokerage\n       (\n       IBrokerage(code)\n       ) Instal key brokerage application logic, where possible using a brokerage SDK.\nTranslating Symbol Conventions\n       (\n       ISymbolMapper(code)\n       ) Translate brokerage specific tickers to LEAN format for a uniform algorithm design experience.\nDescribing Brokerage Limitations\n       (\n       IBrokerageModel(code)\n       ) Describe brokerage support of orders and set transaction models.\nEnabling Live Data Streaming\n       (\n       IDataQueueHandler(code)\n       ) Set up a live streaming data service from a brokerage-supplied source.\nEnabling Historical Data\n       (\n       IHistoryProvider(code)\n       ) Tap into the brokerage historical data API to serve history for live algorithms.\nDownloading Data\n       (\n       IDataDownloader(code)\n       ) Save data from the brokerage to disk in LEAN format.\nModeling Fee Structures\n       (\n       IFeeModel(code)\n       ) Enable accurate backtesting with specific fee structures of the brokerage.\nUpdating the Algorithm API\n       (\n       ISecurityTransactionModel(code)\n       ) Combine the various models together to form a brokerage set.\nSee Also\nDataset Market\n\nPurchasing Datasets",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [
        {
          "id": "2.2.1",
          "title": "Setting Up Your Environment",
          "level": 3,
          "section_number": "2.2.1",
          "breadcrumb": "Contributions > Brokerages > Setting Up Your Environment",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page explains how to set up your coding environment to create, develop, and test your brokerage before you contribute it to LEAN.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Prerequisites",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Working knowledge of C#. You also need to\n   install .NET 6.0\n   .",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Set Up Environment",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to set up your environment:",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "$ git clone https://github.com/username/Lean.Brokerages.<brokerageName>.git",
              "order": 6,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ chmod +x ./renameBrokerage",
              "order": 6,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "code",
              "content": "$ renameBrokerage.sh",
              "order": 6,
              "language": "cli",
              "title": "Command Line Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Fork\n    Lean\n    and then clone your forked repository to your local machine.\nOpen the\n    Lean.Brokerages.Template repository\n    and click\n    Use this template\n    .\nOn the Create a new repository from Lean.Brokerages.Template page, set the repository name to\n    Lean.Brokerages.<brokerageName>\n    (for example,\n    Lean.Brokerages.XYZ\n    ).\nClick\n    Create repository from template\n    .\nClone the\n    Lean.Brokerages.<brokerageName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.Brokerages.<brokerageName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.Brokerages.<brokerageName>\n    directory, run the\n    renameBrokerage.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.Brokerages.<brokerageName>\n    directory and renames some files according to your brokerage name.",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.2",
          "title": "Laying the Foundation",
          "level": 3,
          "section_number": "2.2.2",
          "breadcrumb": "Contributions > Brokerages > Laying the Foundation",
          "mixed_content": [
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 1,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "### Introduction",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   IBrokerageFactory\n   creates brokerage instances and configures LEAN with a\n   Job Packet\n   . To create the right\n   BrokerageFactory(code)\n   type, LEAN uses the brokerage name in the job packet. To set the brokerage name, LEAN uses the\n   live-mode-brokerage(code)\n   value in the\n   configuration file\n   .",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Prerequisites",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "You need to\n   set up your environment\n   before you can lay the foundation for a new brokerage.",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Lay the Foundation",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Follow these steps to stub out the implementation and initialize a brokerage instance:",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "namespace QuantConnect.Brokerages\n{\n    public class BrokerageNameBrokerageModel : DefaultBrokerageModel\n    {\n        \n    }\n}",
              "order": 7,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "code",
              "content": "public override IBrokerageModel GetBrokerageModel(IOrderProvider orderProvider)\n{\n    return new BrokerageNameBrokerageModel();\n}",
              "order": 7,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "code",
              "content": "// defines the 'live-brokerage-name' environment\n\"live-brokerage-name\": {\n  \"live-mode\": true,\n\n  \"live-mode-brokerage\": \"BrokerageName\",\n\n  \"setup-handler\": \"QuantConnect.Lean.Engine.Setup.BrokerageSetupHandler\",\n  \"result-handler\": \"QuantConnect.Lean.Engine.Results.LiveTradingResultHandler\",\n  \"data-feed-handler\": \"QuantConnect.Lean.Engine.DataFeeds.LiveTradingDataFeed\",\n  \"data-queue-handler\": [ \"QuantConnect.Lean.Engine.DataFeeds.Queues.LiveDataQueue\" ],\n  \"real-time-handler\": \"QuantConnect.Lean.Engine.RealTime.LiveTradingRealTimeHandler\",\n  \"transaction-handler\": \"QuantConnect.Lean.Engine.TransactionHandlers.BacktestingTransactionHandler\"\n},",
              "order": 7,
              "language": "text",
              "title": "Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "In the\n    Lean / Launcher / config.json\n    file, add a few key-value pairs with your brokerage configuration information.\nFor example,\n    oanda-access-token(code)\n    and\n    oanda-account-id(code)\n    keys. These key-value pairs will be used for most local debugging and testing as the default. LEAN automatically copies these pairs to the\n    BrokerageData\n    member of the job packet as a dictionary of\n    <string,string>(code)\n    pairs.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Factory.cs\n    file, update the\n    BrokerageData(code)\n    member so it uses the\n    Config(code)\n    class to load all the required configuration settings from the\n    Lean / Launcher / config.json\n    file.\nFor instance,\n    Config.Get(\"oanda-access-token\")(code)\n    returns the\n    \"oanda-access-token\"(code)\n    value from the configuration file. For a full example, see the\n    BrokerageData member\n    in the\n    BitfinexBrokerageFactory(code)\n    .\nIn the\n    IBrokerageFactory(code)\n    examples, you'll see code like\n    Composer.Instance.AddPart<IDataQueueHandler>(dataQueueHandler)(code)\n    , which adds parts to the\n    Composer\n    . The Composer is a system in LEAN for dynamically loading types. In this case, it's adding an instance of the\n    DataQueueHandler(code)\n    for the brokerage to the composer. You can think of the Composer as a library and adding parts is like adding books to its collection.\nIn the\n    Lean / Common / Brokerages\n    folder, create a\n    <brokerageName>BrokerageModel.cs\n    file with a stub implementation that inherits from the\n    DefaultBrokerageModel\n    .\nBrokerage models tell LEAN what order types a brokerage supports, whether we're allowed to update an order, and what\n    reality models\n    to use. Use the following stub implementation for now:\n\nwhere\n    BrokerageName(code)\n    is the name of your brokerage. For example, if the brokerage name is XYZ, then\n    BrokerageNameBrokerageModel(code)\n    should be\n    XYZBrokerageModel(code)\n    . You'll extend this implementation later.\nIn the\n    Lean.Brokerages.<BrokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define\n    GetBrokerageModel(code)\n    to return an instance of your new brokerage model.\n\nIf your brokerage uses websockets to send data, in the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName> / <brokerageName>Brokerage.cs\n    file, replace the\n    Brokerage(code)\n    base class for\n    BaseWebsocketsBrokerage(code)\n    .\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n    file, update the constructor to save required authentication data to private variables.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define the\n    CreateBrokerage(code)\n    method to create and return an instance of your new brokerage model without connecting to the brokerage.\nThe Brokerage Factory uses a job packet to create an initialized brokerage instance in the\n    CreateBrokerage(code)\n    method. Assume the\n    job(code)\n    argument has the best source of data, not the\n    BrokerageData(code)\n    property. The\n    BrokerageData(code)\n    property in the factory are the starting default values from the configuration file, which can be overridden by a runtime job.\nIn the\n    Lean / Launcher / config.json\n    file, add a\n    live-<brokerageName>(code)\n    key.\nThese\n    live-<brokerageName>(code)\n    keys group configuration flags together and override the root configuration values. Use the following key-value pair as a starting point:\n\nwhere\n    brokerage-name(code)\n    and\n    \"BrokerageName\"(code)\n    are placeholders for your brokerage name.\nIn the\n    Lean / Launcher / config.json\n    file, set the\n    environment(code)\n    value to the your new brokerage environment.\nFor example,\n    \"live-brokerage-name\"(code)\n    .\nBuild the solution.\nRunning the solution won't work, but the stub implementation should still build.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [
            {
              "headers": [
                "IBrokerageFactory"
              ],
              "rows": [
                [
                  "Primary Role",
                  "Create and initialize a brokerage instance."
                ],
                [
                  "Interface",
                  "IBrokerageFactory.cs"
                ],
                [
                  "Example",
                  "BitfinexBrokerageFactory.cs"
                ],
                [
                  "Target Location",
                  "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
                ]
              ],
              "caption": null
            }
          ],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.3",
          "title": "Creating the Brokerage",
          "level": 3,
          "section_number": "2.2.3",
          "breadcrumb": "Contributions > Brokerages > Creating the Brokerage",
          "mixed_content": [
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 1,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "### Introduction",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   IBrokerage\n   holds the bulk of the core logic responsible for running the brokerage implementation. Many smaller models described later internally use the brokerage implementation, so its best to now start implementating the\n   IBrokerage(code)\n   . Brokerage classes can get quite large, so use a\n   partial(code)\n   class modifier to break up the files in appropriate categories.",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Prerequisites",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "You need to\n   lay the foundation\n   before you can create a new brokerage.",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Brokerage Roles",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The brokerage has many the following important roles vital for the stability of a running algorithm:",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Maintain Connection - Connect and maintain connection while algorithm running.\nSetup State - Initialize the algorithm portfolio, open orders and cashbook.\nOrder Operations - Create, update and cancel orders.\nOrder Events - Receive order fills and apply them to portfolio.\nAccount Events - Track non-order events (cash deposits/removals).\nBrokerage Events - Interpret brokerage messages and act when required.\nServe History Requests - Provide historical data on request.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Brokerages often have their own ticker styles, order class names, and event names. Many of the methods in the brokerage implementation may simply be converting from the brokerage object format into LEAN format. You should plan accordingly to write neat code.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The brokerage must implement the following interfaces:",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "class MyBrokerage : Brokerage, IDataQueueHandler, IDataQueueUniverseProvider { ... }",
              "order": 7,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "### Implementation Style",
              "order": 12,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This guide focuses on implementing the brokerage step-by-step in LEAN because it's a more natural workflow for most people. You can also follow a more test-driven development process by following the test harness. To do this, create a new test class that extends from the base class in\n   Lean / Tests / Brokerages / BrokerageTests.cs\n   . This test-framework tests all the methods for an\n   IBrokerage(code)\n   implementation.",
              "order": 13,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Connection Requirements",
              "order": 14,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "LEAN is best used with streaming or socket-based brokerage connections. Streaming brokerage implementations allow for the easiest translation of broker events into LEAN events. Without streaming order events, you will need to poll for to check for fills. In our experience, this is fraught with additional risks and challenges.",
              "order": 15,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### SDK Libraries",
              "order": 16,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Most brokerages provide a wrapper for their API. If it has a permissive license and it's compatible with .NET 6, you should utilize it. Although it is technically possible to embed an external github repository, we've elected to not do this to make LEAN easier to install (submodules can be tricky for beginners). Instead, copy the library into its own subfolder of the brokerage implementation. For example,\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / BrokerLib / *\n   . After you add a library, build the project again to make sure the library successfully compiles.",
              "order": 17,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "LEAN\n   \n   Open-Source. If you copy and paste code from an external source, leave the comments and headers intact. If they don't have a comment header, add one to each file, referencing the source. Let's keep the attributions in place.",
              "order": 17,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Define the Brokerage Class",
              "order": 19,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following sections describe components of the brokerage implementation in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n   file.",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Using a base class is optional but allows you to reuse event methods we have provided. The\n   Brokerage(code)\n   object implements these event handlers and marks the remaining items as\n   abstract(code)\n   .",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "LEAN provides an optional base class\n   BaseWebsocketsBrokerage(code)\n   which seeks to connect and maintain a socket connection and pass messages to an event handler. As each socket connection is different, carefully consider before using this class. It might be easier and more maintainable to simply maintain your own socket connection.",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Brush up on the\n   partial(code)\n   class keyword. It will help you break-up your class later.",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Class Constructor",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Once the scaffolding brokerage methods are in place (overrides of the abstract base classes), you can focus on the class constructor. If you are using a brokerage SDK, create a new instance of their library and store it to a class variable for later use. You should define the constructor so that it accepts all the arguments you pass it during the\n   CreateBrokerage(code)\n   method you implemented in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n   file.",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following table provides some example implementations of the brokerage class constructor:",
              "order": 20,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 20,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "string Name(code)",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   Name(csharp)\nname(python)\n   property is a human-readable brokerage name for debugging and logging. For US Equity-regulated brokerages, convention states this name generally ends in the word \"Brokerage\".",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "void Connect()(code)",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   Connect(code)\n   method triggers logic for establishing a link to your brokerage. Normally, we don't do this in the constructor because it makes algorithms and brokerages die in the\n   BrokerageFactory(code)\n   process. For most brokerages, to establish a connection with the brokerage, call the connect method on your SDK library.",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following table provides some example implementations of the\n   Connect(code)\n   method:",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 21,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "If a soft failure occurs like a lost internet connection or a server 502 error, create a new\n   BrokerageMessageEvent(code)\n   so you allow the algorithm to\n   handle the brokerage messages\n   . For example, Interactive Brokers resets socket connections at different times globally, so users in other parts of the world can get disconnected at strange times of the day. Knowing this, they may elect to have their algorithm ignore specific disconnection attempts.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "If a hard failure occurs like an incorrect password or an unsupported API method, throw a real exception with details of the error.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "void Disconnect()(code)",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   Disconnect(code)\n   method is called at the end of the algorithm before LEAN shuts down.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool IsConnected(code)",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   IsConnected(code)\n   property is a boolean that indicates the state of the brokerage connection. Depending on your connection style, this may be automatically handled for you and simply require passing back the value from your SDK. Alternatively, you may need to maintain your own connection state flag in your brokerage class.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool PlaceOrder(Order order)(code)",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   PlaceOrder(code)\n   method should send a new LEAN order to the brokerage and report back the success or failure. The\n   PlaceOrder(code)\n   method accepts a generic\n   Order(code)\n   object, which is the base class for all order types. The first step of placing an order is often to convert it from LEAN format into the format that the brokerage SDK requires. Your brokerage implementation should aim to support as many\n   LEAN order types\n   as possible. There may be other order types in the brokerage, but implementing them is considered out of scope of a rev-0 brokerage implementation.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Converting order types is an error-prone process and you should carefully review each order after you've ported it. Some brokerages have many properties on their orders, so check each required property for each order. To simplify the process, define an internal\n   BrokerOrder ConvertOrder(Order order)(code)\n   method to convert orders between LEAN format and your brokerage format. Part of the order conversion might be converting the brokerage ticker (for example, LEAN name \"EURUSD\" vs OANDA name \"EUR/USD\"). This is done with a\n   BrokerageSymbolMapper(code)\n   class. You can add this functionality later. For now, pass a request for the brokerage ticker to the stub implementation.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Once the order type is converted, use the\n   IsConnected(code)\n   property to check if you're connected before placing the order. If you're not connected, throw an exception to halt the algorithm. Otherwise, send the order to your brokerage submit API. Oftentimes, you receive an immediate reply indicating the order was successfully placed. The\n   PlaceOrder(code)\n   method should return true when the order is accepted by the brokerage. If the order is invalid, immediately rejected, or there is an internet outage, the method should return false.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool UpdateOrder(Order order)(code)",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   UpdateOrder(code)\n   method transmits an update request to the API and returns true if it was successfully processed. Updating an order is one of the most tricky parts of brokerage implementations. You can easily run into synchronization issues.",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The following table provides some example implementations of the\n   UpdateOrder(code)\n   method:",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 22,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "bool CancelOrder(Order order)(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool UpdateOrder(Order order)(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "List<Order> GetOpenOrders()(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "List<Holding> GetAccountHoldings()(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "List<Cash> GetCashBalance()(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool AccountInstantlyUpdated(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "IEnumerable<BaseData> GetHistory(HistoryRequest request)(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "bool AccountInstantlyUpdated(code)",
              "order": 23,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [
            {
              "headers": [
                "IBrokerage"
              ],
              "rows": [
                [
                  "Primary Role",
                  "Brokerage connection, orders, and fill events."
                ],
                [
                  "Interface",
                  "IBrokerage.cs"
                ],
                [
                  "Example",
                  "BitfinexBrokerage.cs"
                ],
                [
                  "Target Location",
                  "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Brokerage",
                "Description"
              ],
              "rows": [
                [
                  "Interactive Brokers",
                  "Launches an external process to create the brokerage."
                ],
                [
                  "OANDA",
                  "Creates an SDK instance and assigns internal event handlers."
                ],
                [
                  "Coinbase",
                  "Offloads constructor work toBrokerageFactoryand uses theBaseWebsocketBrokeragebase class."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Brokerage",
                "Description"
              ],
              "rows": [
                [
                  "Interactive Brokers",
                  "Connects to an external process with the brokerage SDK."
                ],
                [
                  "OANDA",
                  "Simple example that calls the brokerage SDK."
                ],
                [
                  "Coinbase",
                  "Establishes the WebSocket connection and monitoring in a thread."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Brokerage",
                "Description"
              ],
              "rows": [
                [
                  "Interactive Brokers",
                  "Updates multiple asset classes with an external application."
                ],
                [
                  "OANDA",
                  "Simple example that calls the brokerage SDK."
                ],
                [
                  "Coinbase",
                  "Throws an exception because order updates are not supported."
                ]
              ],
              "caption": null
            }
          ],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.4",
          "title": "Translating Symbol Conventions",
          "level": 3,
          "section_number": "2.2.4",
          "breadcrumb": "Contributions > Brokerages > Translating Symbol Conventions",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.5",
          "title": "Describing Brokerage Limitations",
          "level": 3,
          "section_number": "2.2.5",
          "breadcrumb": "Contributions > Brokerages > Describing Brokerage Limitations",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.6",
          "title": "Enabling Live Data Streaming",
          "level": 3,
          "section_number": "2.2.6",
          "breadcrumb": "Contributions > Brokerages > Enabling Live Data Streaming",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.7",
          "title": "Enabling Historical Data",
          "level": 3,
          "section_number": "2.2.7",
          "breadcrumb": "Contributions > Brokerages > Enabling Historical Data",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.8",
          "title": "Downloading Data",
          "level": 3,
          "section_number": "2.2.8",
          "breadcrumb": "Contributions > Brokerages > Downloading Data",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.9",
          "title": "Modeling Fee Structures",
          "level": 3,
          "section_number": "2.2.9",
          "breadcrumb": "Contributions > Brokerages > Modeling Fee Structures",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        },
        {
          "id": "2.2.10",
          "title": "Updating the Algorithm API",
          "level": 3,
          "section_number": "2.2.10",
          "breadcrumb": "Contributions > Brokerages > Updating the Algorithm API",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This brokerage development guide is still under construction.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "2.2"
        }
      ],
      "parent_id": "2"
    },
    {
      "id": "2.2.1",
      "title": "Setting Up Your Environment",
      "level": 3,
      "section_number": "2.2.1",
      "breadcrumb": "Contributions > Brokerages > Setting Up Your Environment",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page explains how to set up your coding environment to create, develop, and test your brokerage before you contribute it to LEAN.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Prerequisites",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Working knowledge of C#. You also need to\n   install .NET 6.0\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Set Up Environment",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to set up your environment:",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "$ git clone https://github.com/username/Lean.Brokerages.<brokerageName>.git",
          "order": 6,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ chmod +x ./renameBrokerage",
          "order": 6,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "code",
          "content": "$ renameBrokerage.sh",
          "order": 6,
          "language": "cli",
          "title": "Command Line Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Fork\n    Lean\n    and then clone your forked repository to your local machine.\nOpen the\n    Lean.Brokerages.Template repository\n    and click\n    Use this template\n    .\nOn the Create a new repository from Lean.Brokerages.Template page, set the repository name to\n    Lean.Brokerages.<brokerageName>\n    (for example,\n    Lean.Brokerages.XYZ\n    ).\nClick\n    Create repository from template\n    .\nClone the\n    Lean.Brokerages.<brokerageName>\n    repository.\n\nIf you're on a Linux terminal, in your\n    Lean.Brokerages.<brokerageName>\n    directory, change the access permissions of the bash script.\n\nIn your\n    Lean.Brokerages.<brokerageName>\n    directory, run the\n    renameBrokerage.sh\n    bash script.\n\nThe bash script replaces some placeholder text in the\n    Lean.Brokerages.<brokerageName>\n    directory and renames some files according to your brokerage name.",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.2",
      "title": "Laying the Foundation",
      "level": 3,
      "section_number": "2.2.2",
      "breadcrumb": "Contributions > Brokerages > Laying the Foundation",
      "mixed_content": [
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 1,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "### Introduction",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   IBrokerageFactory\n   creates brokerage instances and configures LEAN with a\n   Job Packet\n   . To create the right\n   BrokerageFactory(code)\n   type, LEAN uses the brokerage name in the job packet. To set the brokerage name, LEAN uses the\n   live-mode-brokerage(code)\n   value in the\n   configuration file\n   .",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Prerequisites",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "You need to\n   set up your environment\n   before you can lay the foundation for a new brokerage.",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Lay the Foundation",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Follow these steps to stub out the implementation and initialize a brokerage instance:",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "namespace QuantConnect.Brokerages\n{\n    public class BrokerageNameBrokerageModel : DefaultBrokerageModel\n    {\n        \n    }\n}",
          "order": 7,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "code",
          "content": "public override IBrokerageModel GetBrokerageModel(IOrderProvider orderProvider)\n{\n    return new BrokerageNameBrokerageModel();\n}",
          "order": 7,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "code",
          "content": "// defines the 'live-brokerage-name' environment\n\"live-brokerage-name\": {\n  \"live-mode\": true,\n\n  \"live-mode-brokerage\": \"BrokerageName\",\n\n  \"setup-handler\": \"QuantConnect.Lean.Engine.Setup.BrokerageSetupHandler\",\n  \"result-handler\": \"QuantConnect.Lean.Engine.Results.LiveTradingResultHandler\",\n  \"data-feed-handler\": \"QuantConnect.Lean.Engine.DataFeeds.LiveTradingDataFeed\",\n  \"data-queue-handler\": [ \"QuantConnect.Lean.Engine.DataFeeds.Queues.LiveDataQueue\" ],\n  \"real-time-handler\": \"QuantConnect.Lean.Engine.RealTime.LiveTradingRealTimeHandler\",\n  \"transaction-handler\": \"QuantConnect.Lean.Engine.TransactionHandlers.BacktestingTransactionHandler\"\n},",
          "order": 7,
          "language": "text",
          "title": "Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "In the\n    Lean / Launcher / config.json\n    file, add a few key-value pairs with your brokerage configuration information.\nFor example,\n    oanda-access-token(code)\n    and\n    oanda-account-id(code)\n    keys. These key-value pairs will be used for most local debugging and testing as the default. LEAN automatically copies these pairs to the\n    BrokerageData\n    member of the job packet as a dictionary of\n    <string,string>(code)\n    pairs.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Factory.cs\n    file, update the\n    BrokerageData(code)\n    member so it uses the\n    Config(code)\n    class to load all the required configuration settings from the\n    Lean / Launcher / config.json\n    file.\nFor instance,\n    Config.Get(\"oanda-access-token\")(code)\n    returns the\n    \"oanda-access-token\"(code)\n    value from the configuration file. For a full example, see the\n    BrokerageData member\n    in the\n    BitfinexBrokerageFactory(code)\n    .\nIn the\n    IBrokerageFactory(code)\n    examples, you'll see code like\n    Composer.Instance.AddPart<IDataQueueHandler>(dataQueueHandler)(code)\n    , which adds parts to the\n    Composer\n    . The Composer is a system in LEAN for dynamically loading types. In this case, it's adding an instance of the\n    DataQueueHandler(code)\n    for the brokerage to the composer. You can think of the Composer as a library and adding parts is like adding books to its collection.\nIn the\n    Lean / Common / Brokerages\n    folder, create a\n    <brokerageName>BrokerageModel.cs\n    file with a stub implementation that inherits from the\n    DefaultBrokerageModel\n    .\nBrokerage models tell LEAN what order types a brokerage supports, whether we're allowed to update an order, and what\n    reality models\n    to use. Use the following stub implementation for now:\n\nwhere\n    BrokerageName(code)\n    is the name of your brokerage. For example, if the brokerage name is XYZ, then\n    BrokerageNameBrokerageModel(code)\n    should be\n    XYZBrokerageModel(code)\n    . You'll extend this implementation later.\nIn the\n    Lean.Brokerages.<BrokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define\n    GetBrokerageModel(code)\n    to return an instance of your new brokerage model.\n\nIf your brokerage uses websockets to send data, in the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName> / <brokerageName>Brokerage.cs\n    file, replace the\n    Brokerage(code)\n    base class for\n    BaseWebsocketsBrokerage(code)\n    .\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n    file, update the constructor to save required authentication data to private variables.\nIn the\n    Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n    file, define the\n    CreateBrokerage(code)\n    method to create and return an instance of your new brokerage model without connecting to the brokerage.\nThe Brokerage Factory uses a job packet to create an initialized brokerage instance in the\n    CreateBrokerage(code)\n    method. Assume the\n    job(code)\n    argument has the best source of data, not the\n    BrokerageData(code)\n    property. The\n    BrokerageData(code)\n    property in the factory are the starting default values from the configuration file, which can be overridden by a runtime job.\nIn the\n    Lean / Launcher / config.json\n    file, add a\n    live-<brokerageName>(code)\n    key.\nThese\n    live-<brokerageName>(code)\n    keys group configuration flags together and override the root configuration values. Use the following key-value pair as a starting point:\n\nwhere\n    brokerage-name(code)\n    and\n    \"BrokerageName\"(code)\n    are placeholders for your brokerage name.\nIn the\n    Lean / Launcher / config.json\n    file, set the\n    environment(code)\n    value to the your new brokerage environment.\nFor example,\n    \"live-brokerage-name\"(code)\n    .\nBuild the solution.\nRunning the solution won't work, but the stub implementation should still build.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [
        {
          "headers": [
            "IBrokerageFactory"
          ],
          "rows": [
            [
              "Primary Role",
              "Create and initialize a brokerage instance."
            ],
            [
              "Interface",
              "IBrokerageFactory.cs"
            ],
            [
              "Example",
              "BitfinexBrokerageFactory.cs"
            ],
            [
              "Target Location",
              "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
            ]
          ],
          "caption": null
        }
      ],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.3",
      "title": "Creating the Brokerage",
      "level": 3,
      "section_number": "2.2.3",
      "breadcrumb": "Contributions > Brokerages > Creating the Brokerage",
      "mixed_content": [
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 1,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "### Introduction",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   IBrokerage\n   holds the bulk of the core logic responsible for running the brokerage implementation. Many smaller models described later internally use the brokerage implementation, so its best to now start implementating the\n   IBrokerage(code)\n   . Brokerage classes can get quite large, so use a\n   partial(code)\n   class modifier to break up the files in appropriate categories.",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Prerequisites",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "You need to\n   lay the foundation\n   before you can create a new brokerage.",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Brokerage Roles",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The brokerage has many the following important roles vital for the stability of a running algorithm:",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Maintain Connection - Connect and maintain connection while algorithm running.\nSetup State - Initialize the algorithm portfolio, open orders and cashbook.\nOrder Operations - Create, update and cancel orders.\nOrder Events - Receive order fills and apply them to portfolio.\nAccount Events - Track non-order events (cash deposits/removals).\nBrokerage Events - Interpret brokerage messages and act when required.\nServe History Requests - Provide historical data on request.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Brokerages often have their own ticker styles, order class names, and event names. Many of the methods in the brokerage implementation may simply be converting from the brokerage object format into LEAN format. You should plan accordingly to write neat code.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The brokerage must implement the following interfaces:",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "class MyBrokerage : Brokerage, IDataQueueHandler, IDataQueueUniverseProvider { ... }",
          "order": 7,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "### Implementation Style",
          "order": 12,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This guide focuses on implementing the brokerage step-by-step in LEAN because it's a more natural workflow for most people. You can also follow a more test-driven development process by following the test harness. To do this, create a new test class that extends from the base class in\n   Lean / Tests / Brokerages / BrokerageTests.cs\n   . This test-framework tests all the methods for an\n   IBrokerage(code)\n   implementation.",
          "order": 13,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Connection Requirements",
          "order": 14,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "LEAN is best used with streaming or socket-based brokerage connections. Streaming brokerage implementations allow for the easiest translation of broker events into LEAN events. Without streaming order events, you will need to poll for to check for fills. In our experience, this is fraught with additional risks and challenges.",
          "order": 15,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### SDK Libraries",
          "order": 16,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Most brokerages provide a wrapper for their API. If it has a permissive license and it's compatible with .NET 6, you should utilize it. Although it is technically possible to embed an external github repository, we've elected to not do this to make LEAN easier to install (submodules can be tricky for beginners). Instead, copy the library into its own subfolder of the brokerage implementation. For example,\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / BrokerLib / *\n   . After you add a library, build the project again to make sure the library successfully compiles.",
          "order": 17,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "LEAN\n   \n   Open-Source. If you copy and paste code from an external source, leave the comments and headers intact. If they don't have a comment header, add one to each file, referencing the source. Let's keep the attributions in place.",
          "order": 17,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Define the Brokerage Class",
          "order": 19,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following sections describe components of the brokerage implementation in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>Brokerage.cs\n   file.",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Using a base class is optional but allows you to reuse event methods we have provided. The\n   Brokerage(code)\n   object implements these event handlers and marks the remaining items as\n   abstract(code)\n   .",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "LEAN provides an optional base class\n   BaseWebsocketsBrokerage(code)\n   which seeks to connect and maintain a socket connection and pass messages to an event handler. As each socket connection is different, carefully consider before using this class. It might be easier and more maintainable to simply maintain your own socket connection.",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Brush up on the\n   partial(code)\n   class keyword. It will help you break-up your class later.",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Class Constructor",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Once the scaffolding brokerage methods are in place (overrides of the abstract base classes), you can focus on the class constructor. If you are using a brokerage SDK, create a new instance of their library and store it to a class variable for later use. You should define the constructor so that it accepts all the arguments you pass it during the\n   CreateBrokerage(code)\n   method you implemented in the\n   Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage / <brokerageName>BrokerageFactory.cs\n   file.",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following table provides some example implementations of the brokerage class constructor:",
          "order": 20,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 20,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "string Name(code)",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   Name(csharp)\nname(python)\n   property is a human-readable brokerage name for debugging and logging. For US Equity-regulated brokerages, convention states this name generally ends in the word \"Brokerage\".",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "void Connect()(code)",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   Connect(code)\n   method triggers logic for establishing a link to your brokerage. Normally, we don't do this in the constructor because it makes algorithms and brokerages die in the\n   BrokerageFactory(code)\n   process. For most brokerages, to establish a connection with the brokerage, call the connect method on your SDK library.",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following table provides some example implementations of the\n   Connect(code)\n   method:",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 21,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "If a soft failure occurs like a lost internet connection or a server 502 error, create a new\n   BrokerageMessageEvent(code)\n   so you allow the algorithm to\n   handle the brokerage messages\n   . For example, Interactive Brokers resets socket connections at different times globally, so users in other parts of the world can get disconnected at strange times of the day. Knowing this, they may elect to have their algorithm ignore specific disconnection attempts.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "If a hard failure occurs like an incorrect password or an unsupported API method, throw a real exception with details of the error.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "void Disconnect()(code)",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   Disconnect(code)\n   method is called at the end of the algorithm before LEAN shuts down.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool IsConnected(code)",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   IsConnected(code)\n   property is a boolean that indicates the state of the brokerage connection. Depending on your connection style, this may be automatically handled for you and simply require passing back the value from your SDK. Alternatively, you may need to maintain your own connection state flag in your brokerage class.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool PlaceOrder(Order order)(code)",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   PlaceOrder(code)\n   method should send a new LEAN order to the brokerage and report back the success or failure. The\n   PlaceOrder(code)\n   method accepts a generic\n   Order(code)\n   object, which is the base class for all order types. The first step of placing an order is often to convert it from LEAN format into the format that the brokerage SDK requires. Your brokerage implementation should aim to support as many\n   LEAN order types\n   as possible. There may be other order types in the brokerage, but implementing them is considered out of scope of a rev-0 brokerage implementation.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Converting order types is an error-prone process and you should carefully review each order after you've ported it. Some brokerages have many properties on their orders, so check each required property for each order. To simplify the process, define an internal\n   BrokerOrder ConvertOrder(Order order)(code)\n   method to convert orders between LEAN format and your brokerage format. Part of the order conversion might be converting the brokerage ticker (for example, LEAN name \"EURUSD\" vs OANDA name \"EUR/USD\"). This is done with a\n   BrokerageSymbolMapper(code)\n   class. You can add this functionality later. For now, pass a request for the brokerage ticker to the stub implementation.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Once the order type is converted, use the\n   IsConnected(code)\n   property to check if you're connected before placing the order. If you're not connected, throw an exception to halt the algorithm. Otherwise, send the order to your brokerage submit API. Oftentimes, you receive an immediate reply indicating the order was successfully placed. The\n   PlaceOrder(code)\n   method should return true when the order is accepted by the brokerage. If the order is invalid, immediately rejected, or there is an internet outage, the method should return false.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool UpdateOrder(Order order)(code)",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   UpdateOrder(code)\n   method transmits an update request to the API and returns true if it was successfully processed. Updating an order is one of the most tricky parts of brokerage implementations. You can easily run into synchronization issues.",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following table provides some example implementations of the\n   UpdateOrder(code)\n   method:",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 22,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "bool CancelOrder(Order order)(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool UpdateOrder(Order order)(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "List<Order> GetOpenOrders()(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "List<Holding> GetAccountHoldings()(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "List<Cash> GetCashBalance()(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool AccountInstantlyUpdated(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "IEnumerable<BaseData> GetHistory(HistoryRequest request)(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "bool AccountInstantlyUpdated(code)",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [
        {
          "headers": [
            "IBrokerage"
          ],
          "rows": [
            [
              "Primary Role",
              "Brokerage connection, orders, and fill events."
            ],
            [
              "Interface",
              "IBrokerage.cs"
            ],
            [
              "Example",
              "BitfinexBrokerage.cs"
            ],
            [
              "Target Location",
              "Lean.Brokerages.<brokerageName> / QuantConnect.<brokerageName>Brokerage /"
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Brokerage",
            "Description"
          ],
          "rows": [
            [
              "Interactive Brokers",
              "Launches an external process to create the brokerage."
            ],
            [
              "OANDA",
              "Creates an SDK instance and assigns internal event handlers."
            ],
            [
              "Coinbase",
              "Offloads constructor work toBrokerageFactoryand uses theBaseWebsocketBrokeragebase class."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Brokerage",
            "Description"
          ],
          "rows": [
            [
              "Interactive Brokers",
              "Connects to an external process with the brokerage SDK."
            ],
            [
              "OANDA",
              "Simple example that calls the brokerage SDK."
            ],
            [
              "Coinbase",
              "Establishes the WebSocket connection and monitoring in a thread."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Brokerage",
            "Description"
          ],
          "rows": [
            [
              "Interactive Brokers",
              "Updates multiple asset classes with an external application."
            ],
            [
              "OANDA",
              "Simple example that calls the brokerage SDK."
            ],
            [
              "Coinbase",
              "Throws an exception because order updates are not supported."
            ]
          ],
          "caption": null
        }
      ],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.4",
      "title": "Translating Symbol Conventions",
      "level": 3,
      "section_number": "2.2.4",
      "breadcrumb": "Contributions > Brokerages > Translating Symbol Conventions",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.5",
      "title": "Describing Brokerage Limitations",
      "level": 3,
      "section_number": "2.2.5",
      "breadcrumb": "Contributions > Brokerages > Describing Brokerage Limitations",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.6",
      "title": "Enabling Live Data Streaming",
      "level": 3,
      "section_number": "2.2.6",
      "breadcrumb": "Contributions > Brokerages > Enabling Live Data Streaming",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.7",
      "title": "Enabling Historical Data",
      "level": 3,
      "section_number": "2.2.7",
      "breadcrumb": "Contributions > Brokerages > Enabling Historical Data",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.8",
      "title": "Downloading Data",
      "level": 3,
      "section_number": "2.2.8",
      "breadcrumb": "Contributions > Brokerages > Downloading Data",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.9",
      "title": "Modeling Fee Structures",
      "level": 3,
      "section_number": "2.2.9",
      "breadcrumb": "Contributions > Brokerages > Modeling Fee Structures",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.2.10",
      "title": "Updating the Algorithm API",
      "level": 3,
      "section_number": "2.2.10",
      "breadcrumb": "Contributions > Brokerages > Updating the Algorithm API",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This brokerage development guide is still under construction.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2.2"
    },
    {
      "id": "2.3",
      "title": "Indicators",
      "level": 2,
      "section_number": "2.3",
      "breadcrumb": "Contributions > Indicators",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "LEAN currently supports over 100\n   indicators\n   .\n  This page explains how to contribute a new indicator to the open-source project by making a pull request to Lean. \n  Before you get started, familiarize yourself with our\n   contributing guidelines\n   .\n  If you don't already have a new indicator in mind that you want to contribute, see\n   the GitHub Issues in the Lean repository\n   for a list of indicators that community members have requested.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Get Third-Party Values",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "As a quantitative algorithmic trading engine, accuracy and reliability are very important to LEAN. \n When you submit a new indicator to the LEAN, you must include third-party source values are required as reference points in your pull request to contrast the values output by your indicator implementation. \n This requirement validates that your indicator implementation is correct.\n The following sections explain some examples of acceptable third-party sources.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Renowned Open-source Projects",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Developed and maintained by expert teams, these sources undergo rigorous testing and optimization, ensuring accurate calculations. \n The transparent nature of open-source projects allows for community scrutiny, resulting in bug fixes and continuous improvements.\n Open-source projects provide thorough information on how the indicator values are calculated, which provides excellent reproducibility. \n Thus, we accept values from these projects with high confidence. \n Example projects include\n   TA-Lib\n   and\n   QuantLib\n   .",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Highly Credible Websites",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Similar reasons apply to these websites as well. \n The site should be either the original source or a very popular trading data provider, such that we have confidence in their accuracy and reliability.\n These sources might provide structured data samples, like a\n   JSON\n   response,\n   CSV\n   /Excel file, or scripts for calculating the indicator values.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Define the Class",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "api_content",
          "content": "## IndicatorStatus Enumeration\n`enumQuantConnect.Indicators.IndicatorStatus`\nThe possible states returned by\n`fieldSUCCESS`\nThe indicator successfully calculated a value for the input data (0)\n`fieldINVALID_INPUT`\nThe indicator detected an invalid input data point or tradebar (1)\n`fieldMATH_ERROR`\nThe indicator encountered a math error during calculations (2)\n`fieldVALUE_NOT_READY`\nThe indicator value is not ready (3)",
          "order": 10,
          "language": "python",
          "title": "API: QuantConnect.Indicators.IndicatorStatus",
          "context": "Resolved from data-tree: QuantConnect.Indicators.IndicatorStatus"
        },
        {
          "type": "api_content",
          "content": "## IndicatorStatus Enumeration\n`enumQuantConnect.Indicators.IndicatorStatus`\nThe possible states returned by\n`fieldSuccess`\nThe indicator successfully calculated a value for the input data (0)\n`fieldInvalidInput`\nThe indicator detected an invalid input data point or tradebar (1)\n`fieldMathError`\nThe indicator encountered a math error during calculations (2)\n`fieldValueNotReady`\nThe indicator value is not ready (3)",
          "order": 11,
          "language": "csharp",
          "title": "API: QuantConnect.Indicators.IndicatorStatus (C#)",
          "context": "Resolved from data-tree: QuantConnect.Indicators.IndicatorStatus"
        },
        {
          "type": "text",
          "content": "### Define the Helper Method",
          "order": 12,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The preceding indicator class is sufficient to instatiate a\n   manual version\n   of the indicator.\n To enable users to create an\n   automatic version\n   of the indicator, add a new method to the\n   Lean / Algorithm / QCAlgorithm.Indicators.cs\n   file.\n Name the method a short abbreviation of the indicator's full name.\n In the method definition, call the\n   InitializeIndicator(code)\n   method to create a\n   consolidator\n   and register the indicator for automatic updates with the consolidated data.",
          "order": 13,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "public CustomIndicator CI(Symbol symbol, Resolution? resolution = null, Func<IBaseData, IBaseDataBar> selector = null)\n{\n    var name = CreateIndicatorName(symbol, $\"CI()\", resolution);\n    var ci = new CustomIndicator(name, symbol);\n    InitializeIndicator(symbol, ci, resolution, selector);\n    return ci;\n}",
          "order": 13,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "### Add Unit Tests",
          "order": 15,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Unit tests ensure your indicator functions correctly and produces accurate values. \n Follow these steps to add unit tests for your indicator:",
          "order": 16,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "<Content Include=\"TestData\\<filePath>.csv\">\n  <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>\n</Content>",
          "order": 16,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "code",
          "content": "namespace QuantConnect.Tests.Indicators\n{\n    [TestFixture]\n    public class CustomIndicatorTests : CommonIndicatorTests<T>\n    {\n        protected override IndicatorBase<T> CreateIndicator()\n        {\n            return new CustomIndicator();\n        }\n\n        protected override string TestFileName => \"custom_3rd_party_data.csv\";\n\n        protected override string TestColumnName => \"CustomIndicatorValueColumn\";\n\n        // How do you compare the values\n        protected override Action<IndicatorBase<T>, double> Assertion\n        {\n            get { return (indicator, expected) => Assert.AreEqual(expected, (double)indicator.Current.Value, 1e-4); }        // allow 0.0001 error margin of indicator values\n        }\n    }\n}",
          "order": 16,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Save the\n    third-party values\n    in the\n    Lean / Tests / TestData\n    directory as a\n    CSV\n    file.\nIn the\n    Lean / Tests / QuantConnect.Tests.csproj\n    file, reference the new data file.\nCreate a\n    Lean / Tests / Indicators / <IndicatorName>Tests.cs\n    file with the following content:\nSet the values of the\n    TestFileName(code)\n    and\n    TestColumnName(code)\n    attributes to the\n    CSV\n    file name and the column name of the testing values in the CSV file of third-party values, respectively.\nAdd test cases.\nTest if the constructor,\n    IsReady(code)\n    flag, and\n    Reset(code)\n    method work. If there are other custom calculation methods in your indicator class, add a tests for them.",
          "order": 16,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The following example shows the testing class structure:",
          "order": 16,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "namespace QuantConnect.Tests.Indicators\n{\n    [TestFixture]\n    public class CustomIndicatorTests : CommonIndicatorTests<T>\n    {\n        protected override IndicatorBase<T> CreateIndicator()\n        {\n            return new CustomIndicator();\n        }\n\n        protected override string TestFileName => \"custom_3rd_party_data.csv\";\n\n        protected override string TestColumnName => \"CustomIndicatorValueColumn\";\n\n        // How do you compare the values\n        protected override Action<IndicatorBase<T>, double> Assertion\n        {\n            get { return (indicator, expected) => Assert.AreEqual(expected, (double)indicator.Current.Value, 1e-4); }        // allow 0.0001 error margin of indicator values\n        }\n\n        [Test]\n        public void IsReadyAfterPeriodUpdates()\n        {\n            var ci = CreateIndicator();\n\n            Assert.IsFalse(ci.IsReady);\n            ci.Update(DateTime.UtcNow, 1m);\n            Assert.IsTrue(ci.IsReady);\n        }\n\n        [Test]\n        public override void ResetsProperly()\n        {\n            var ci = CreateIndicator();\n\n            ci.Update(DateTime.UtcNow, 1m);\n            Assert.IsTrue(ci.IsReady);\n            \n            ci.Reset();\n\n            TestHelper.AssertIndicatorIsInDefaultState(ci);\n        }\n    }\n}",
          "order": 16,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "For a full example, see\n   SimpleMovingAverageTests.cs\n   in the LEAN repository.",
          "order": 16,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Documentation Changes",
          "order": 23,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "After the indicator was merged in the Lean engine, make sure you also ensure it is porperly documented in the documentation. Follow the below steps to do so:",
          "order": 24,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "'<hyphenated-title-case-of-the-indicator>':\n{\n    'code': <IndicatorConstructor>(<constructor-arguments>),\n    'title' : '<CSharpHelperMethod>(<helper-method-arguments>)',\n    'columns' : [<any-extra-series-of-the-indicator>]\n},",
          "order": 24,
          "language": "python",
          "title": "Python Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Create an issue in the\n    Documentation GitHub repository\n    regarding the required changes in the documentation.\nFork the Documentation GitHub repository and create a new branch named by\n    feature-<ISSUE_NUMBER>-<INDICATOR_NAME>-indicator(code)\n    .\nEdit the\n    IndicatorImageGenerator.py\n    file to include the details of the newly added indicator for documentation page generation.\nIf the indicator only involves 1 symbol and does not depend on other indicators, put it under the\n    indicators(code)\n    dictionary.\nIf the indicator involves 2 or more symbols or it is a composite indicator, put it under the\n    special_indicators(code)\n    dictionary.\nIf the indicator is an option-related indicator (e.g. option greeks indicator), put it under the\n    option_indicators(code)\n    dictionary.\nFormat of the added member should be as below:\n\nSave the file and run the\n    API generator\n    . It will help generate the indicator reference page.\n(Optional) Run the\n    IndicatorImageGenerator.py(code)\n    in LeanCLI to obtain the generated plotly image of the indicator. You can retreive it from the\n    storage(code)\n    folder from the root directory of the LeanCLI. Put it in the\n    Resource indicator image folder\n    by the name\n    <hyphenated-title-case-of-the-indicator>(code)\n    .\nPush the branch and start a\n    pull request\n    on the documentation changes.",
          "order": 24,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Extra Steps for Moving Average Types",
          "order": 27,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "api_content",
          "content": "## MovingAverageType Enumeration\n`enumQuantConnect.Indicators.MovingAverageType`\nDefines the different types of moving averages\n`fieldSIMPLE`\nAn unweighted, arithmetic mean (0)\n`fieldEXPONENTIAL`\nThe standard exponential moving average, using a smoothing factor of 2/(n+1) (1)\n`fieldWILDERS`\nAn exponential moving average, using a smoothing factor of 1/n and simple moving average as seeding (2)\n`fieldLINEAR_WEIGHTED_MOVING_AVERAGE`\nA weighted moving average type (3)\n`fieldDOUBLE_EXPONENTIAL`\nThe double exponential moving average (4)\n`fieldTRIPLE_EXPONENTIAL`\nThe triple exponential moving average (5)\n`fieldTRIANGULAR`\nThe triangular moving average (6)\n`fieldT_3`\nThe T3 moving average (7)\n`fieldKAMA`\nThe Kaufman Adaptive Moving Average (8)\n`fieldHULL`\nThe Hull Moving Average (9)\n`fieldALMA`\nThe Arnaud Legoux Moving Average (10)\n`fieldZLEMA`\nThe Zero Lag Exponential Moving Average (11)\n`fieldMGD`\nThe McGinley Dynamic moving average (12)",
          "order": 28,
          "language": "python",
          "title": "API: QuantConnect.Indicators.MovingAverageType",
          "context": "Resolved from data-tree: QuantConnect.Indicators.MovingAverageType"
        },
        {
          "type": "api_content",
          "content": "## MovingAverageType Enumeration\n`enumQuantConnect.Indicators.MovingAverageType`\nDefines the different types of moving averages\n`fieldSimple`\nAn unweighted, arithmetic mean (0)\n`fieldExponential`\nThe standard exponential moving average, using a smoothing factor of 2/(n+1) (1)\n`fieldWilders`\nAn exponential moving average, using a smoothing factor of 1/n and simple moving average as seeding (2)\n`fieldLinearWeightedMovingAverage`\nA weighted moving average type (3)\n`fieldDoubleExponential`\nThe double exponential moving average (4)\n`fieldTripleExponential`\nThe triple exponential moving average (5)\n`fieldTriangular`\nThe triangular moving average (6)\n`fieldT3`\nThe T3 moving average (7)\n`fieldKama`\nThe Kaufman Adaptive Moving Average (8)\n`fieldHull`\nThe Hull Moving Average (9)\n`fieldAlma`\nThe Arnaud Legoux Moving Average (10)\n`fieldZlema`\nThe Zero Lag Exponential Moving Average (11)\n`fieldMGD`\nThe McGinley Dynamic moving average (12)",
          "order": 29,
          "language": "csharp",
          "title": "API: QuantConnect.Indicators.MovingAverageType (C#)",
          "context": "Resolved from data-tree: QuantConnect.Indicators.MovingAverageType"
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "2"
    },
    {
      "id": "3",
      "title": "Data Format",
      "level": 1,
      "section_number": "3",
      "breadcrumb": "Data Format",
      "mixed_content": [],
      "tables": [],
      "subsections": [
        {
          "id": "3.1",
          "title": "Key Concepts",
          "level": 2,
          "section_number": "3.1",
          "breadcrumb": "Data Format > Key Concepts",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "From the beginning, LEAN has strived to use an open, human-readable data format - independent of any specific database or file format. From this core philosophy, we built LEAN to read its financial data from flat files on disk. Data compression is done in zip format, and all individual files are CSV or JSON.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The prices are expressed in the asset\n   quote currency\n   . For example, the value 0.06920 for ETHBTC is the amount of BTC, the quote currency, you need to buy 1 ETH.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "When there is no activity for a security, the price is omitted from the file. Only new ticks and price changes are recorded.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Folder Structure",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Data files are separated and nested in a few predictable layers:",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Tick, Second and Minute:\n    /data/securityType/marketName/resolution/ticker/date_tradeType.zip\nHour, Daily:\n    /data/securityType/marketName/resolution/ticker.zip",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The\n   marketName\n   value is used to separate different tradable assets with the same ticker. E.g. BTCUSDT is traded on multiple brokerages all with slightly different prices.",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Price Representation",
              "order": 9,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The prices are expressed in the asset\n   quote currency\n   . For example, the value 0.06920 for ETHBTC is the amount of BTC, the quote currency, you need to buy 1 ETH.",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "When there is no activity for a security, the price is omitted from the file. Only new ticks and price changes are recorded.",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [],
          "subsections": [],
          "parent_id": "3"
        },
        {
          "id": "3.2",
          "title": "Core Data Types",
          "level": 2,
          "section_number": "3.2",
          "breadcrumb": "Data Format > Core Data Types",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "This page shows the file schema of the core data types represented in\n   supported asset classes\n   .",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Trade Tick",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Tick(code)\n   of\n   TickType.(code)\nTrade(csharp)\nQuote(python)\n   represents an individual record of trades for an asset. Tick data does not have a period.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The file schema is as follows:",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 4,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "The trade has one of the following\n   QuoteConditionFlags(code)\n   :",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 5,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "See more information in the\n   AlgoSeek whitepaper\n   .",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Quote Tick",
              "order": 10,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Tick(code)\n   of\n   TickType.(code)\nQuote(csharp)\nQUOTE(python)\n   represents an individual record of quote updates for an asset. Tick data does not have a period.",
              "order": 11,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The file schema is as follows:",
              "order": 11,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 11,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "The quote has one of the following\n   QuoteConditionFlags(code)\n   :",
              "order": 12,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 12,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "See more information in the\n   AlgoSeek whitepaper\n   .",
              "order": 13,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Trade Bar",
              "order": 17,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "TradeBar(code)\n   represents trade ticks of assets consolidated for a period.",
              "order": 18,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The file schema is as follows:",
              "order": 18,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 18,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "### Quote Bar",
              "order": 21,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "QuoteBar(code)\n   represents top of book quote data consolidated over a period of time (bid and ask bar).",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The file schema is as follows:",
              "order": 22,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 22,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "### Open Interest",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "OpenIntest(code)\n   represents the outstanding contracts.",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The file schema is as follows:",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 26,
              "language": null,
              "title": "Data Table",
              "context": null
            }
          ],
          "tables": [
            {
              "headers": [
                "Column",
                "Description"
              ],
              "rows": [
                [
                  "Time",
                  "Milliseconds since midnight in the timezone of the data format"
                ],
                [
                  "Trade Sale",
                  "Most recent trade price"
                ],
                [
                  "Quantity",
                  "Amount of asset purchased or sold"
                ],
                [
                  "Exchange",
                  "Location of the sale"
                ],
                [
                  "Trade Sale Condition",
                  "Notes on the sale"
                ],
                [
                  "Suspicious",
                  "Boolean indicating the tick is flagged as suspicious according to AlgoSeek's algorithms. This generally indicates the trade is far from other market prices and may be reversed.TradeBar dataexcludes suspicious ticks."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "TradeConditionFlags",
                "Status",
                "Description"
              ],
              "rows": [
                [
                  "RegularREGULAR",
                  "Included",
                  "A trade made without stated conditions is deemed the regular way for settlement on the third business day following the transaction date."
                ],
                [
                  "FormTFORM_T",
                  "Included",
                  "Trading in extended hours enables investors to react quickly to events that typically occur outside regular market hours, such as earnings reports. However, liquidity may be constrained during such Form T trading, resulting in wide bid-ask spreads."
                ],
                [
                  "CashCASH",
                  "Included",
                  "A transaction that requires delivery of securities and payment on the same day the trade takes place."
                ],
                [
                  "ExtendedHoursEXTENDED_HOURS",
                  "Included",
                  "Identifies a trade that was executed outside of regular primary market hours and is reported as an extended hours trade."
                ],
                [
                  "NextDayNEXT_DAY",
                  "Included",
                  "A transaction that requires the delivery of securities on the first business day following the trade date."
                ],
                [
                  "OfficialCloseOFFICIAL_CLOSE",
                  "Included",
                  "Indicates the \"official\" closing value determined by a Market Center. This transaction report will contain the market center generated closing price."
                ],
                [
                  "OfficialOpenOFFICIAL_OPEN",
                  "Included",
                  "Indicates the 'Official' open value as determined by a Market Center. This transaction report will contain the market center generated opening price."
                ],
                [
                  "ClosingPrintsCLOSING_PRINTS",
                  "Included",
                  "The transaction that constituted the trade-through was a single priced closing transaction by the Market Center."
                ],
                [
                  "OpeningPrintsOPENING_PRINTS",
                  "Included",
                  "The trade that constituted the trade-through was a single priced opening transaction by the Market Center."
                ],
                [
                  "IntermarketSweepINTERMARKET_SWEEP",
                  "Excluded",
                  "The transaction that constituted the trade-through was the execution of an order identified as an Intermarket Sweep Order."
                ],
                [
                  "TradeThroughExemptTRADE_THROUGH_EXEMPT",
                  "Excluded",
                  "Denotes whether or not a trade is exempt (Rule 611)."
                ],
                [
                  "OddLotODD_LOT",
                  "Excluded",
                  "Denotes the trade is an odd lot less than a 100 shares."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Column",
                "Description"
              ],
              "rows": [
                [
                  "Time",
                  "Milliseconds since midnight in the timezone of the data format"
                ],
                [
                  "Bid Price",
                  "Best bid price"
                ],
                [
                  "Ask Price",
                  "Best ask price"
                ],
                [
                  "Bid Size",
                  "Best bid price's size/quantity"
                ],
                [
                  "Ask Size",
                  "Best ask price's size/quantity"
                ],
                [
                  "Exchange",
                  "Location of the sale"
                ],
                [
                  "Quote Sale Condition",
                  "Notes on the sale."
                ],
                [
                  "Suspicious",
                  "Boolean indicating the tick is flagged as suspicious according to AlgoSeek's algorithms. This generally indicates the quote is far from other market prices and may be reversed. Each quote tick contains either bid or ask data only.QuoteBar datadata excludes suspicious ticks."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "QuoteConditionFlags",
                "Status",
                "Description"
              ],
              "rows": [
                [
                  "ClosingCLOSING",
                  "Included",
                  "Indicates that this quote was the last quote for a security for that Participant."
                ],
                [
                  "NewsDisseminationNEWS_DISSEMINATION",
                  "Included",
                  "Denotes a regulatory trading halt when relevant news influencing the security is being disseminated. Trading is \nsuspended until the primary market determines that an adequate publication or disclosure of information has occurred."
                ],
                [
                  "NewsPendingNEWS_PENDING",
                  "Included",
                  "Denotes a regulatory Trading Halt due to an expected news announcement, which may influence the security. An Opening Delay or Trading Halt may be continued once the news has been disseminated."
                ],
                [
                  "TradingRangeIndicationTRADING_RANGE_INDICATION",
                  "Included",
                  "Denotes the probable trading range (Bid and Offer prices, no sizes) of a security that is not Opening Delayed or Trading Halted. The Trading Range Indication is used prior to or after the opening of a security."
                ],
                [
                  "OrderImbalanceORDER_IMBALANCE",
                  "Included",
                  "Denotes a non-regulatory halt condition where there is a significant imbalance of buy or sell orders."
                ],
                [
                  "ResumeRESUME",
                  "Included",
                  "Indicates that trading for a Participant is no longer suspended in a security that had been Opening Delayed or Trading Halted."
                ],
                [
                  "RegularREGULAR",
                  "Excluded",
                  "This condition is used for the majority of quotes to indicate a normal trading environment."
                ],
                [
                  "SlowSLOW",
                  "Excluded",
                  "This condition is used to indicate that the quote is a Slow Quote on both the bid and offer sides due to a Set Slow List that includes high price securities."
                ],
                [
                  "GapGAP",
                  "Excluded",
                  "While in this mode, auto-execution is not eligible, the quote is then considered manual and non-firm in the bid and offer, and either or both sides can be traded through as per Regulation NMS."
                ],
                [
                  "OpeningQuoteOPENING_QUOTE",
                  "Excluded",
                  "This condition can be disseminated to indicate that this quote was the opening quote for a security for that Participant."
                ],
                [
                  "FastTradingFAST_TRADING",
                  "Excluded",
                  "For extremely active periods of short duration. While in this mode, the UTP Participant will enter quotations on a best efforts basis."
                ],
                [
                  "ResumeRESUME",
                  "Excluded",
                  "Indicate that trading for a Participant is no longer suspended in a security which had been Opening Delayed or Trading Halted."
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Column",
                "Description"
              ],
              "rows": [
                [
                  "Time",
                  "Second and Minute: Milliseconds since midnight in the timezone of the data formatHour or Daily: Date/time formatted asYYYYMMDD HH:mm"
                ],
                [
                  "Open",
                  "Open Price"
                ],
                [
                  "High",
                  "High Price"
                ],
                [
                  "Low",
                  "Low Price"
                ],
                [
                  "Close",
                  "Close Price"
                ],
                [
                  "Volume",
                  "Number of shares traded in the period"
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Column",
                "Description"
              ],
              "rows": [
                [
                  "Time",
                  "Second and Minute: Milliseconds since midnight in the timezone of the data formatHour or Daily: Date/time formatted asYYYYMMDD HH:mm"
                ],
                [
                  "Bid Open",
                  "Bid Open Price"
                ],
                [
                  "Bid High",
                  "Bid High Price"
                ],
                [
                  "Bid Low",
                  "Bid Low Price"
                ],
                [
                  "Bid Close",
                  "Bid Close Price"
                ],
                [
                  "Bid Size",
                  "Number of shares being bid that quoted in this QuoteBar"
                ],
                [
                  "Ask Open",
                  "Ask Open Price"
                ],
                [
                  "Ask High",
                  "Ask High Price"
                ],
                [
                  "Ask Low",
                  "Ask Low Price"
                ],
                [
                  "Ask Close",
                  "Ask Close Price"
                ],
                [
                  "Ask Size",
                  "Number of shares being asked that quoted in this QuoteBar"
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Column",
                "Description"
              ],
              "rows": [
                [
                  "Open Interest",
                  "Outstanding contracts"
                ]
              ],
              "caption": null
            }
          ],
          "subsections": [],
          "parent_id": "3"
        }
      ],
      "parent_id": null
    },
    {
      "id": "3.1",
      "title": "Key Concepts",
      "level": 2,
      "section_number": "3.1",
      "breadcrumb": "Data Format > Key Concepts",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "From the beginning, LEAN has strived to use an open, human-readable data format - independent of any specific database or file format. From this core philosophy, we built LEAN to read its financial data from flat files on disk. Data compression is done in zip format, and all individual files are CSV or JSON.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The prices are expressed in the asset\n   quote currency\n   . For example, the value 0.06920 for ETHBTC is the amount of BTC, the quote currency, you need to buy 1 ETH.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "When there is no activity for a security, the price is omitted from the file. Only new ticks and price changes are recorded.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Folder Structure",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Data files are separated and nested in a few predictable layers:",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Tick, Second and Minute:\n    /data/securityType/marketName/resolution/ticker/date_tradeType.zip\nHour, Daily:\n    /data/securityType/marketName/resolution/ticker.zip",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The\n   marketName\n   value is used to separate different tradable assets with the same ticker. E.g. BTCUSDT is traded on multiple brokerages all with slightly different prices.",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Price Representation",
          "order": 9,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The prices are expressed in the asset\n   quote currency\n   . For example, the value 0.06920 for ETHBTC is the amount of BTC, the quote currency, you need to buy 1 ETH.",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "When there is no activity for a security, the price is omitted from the file. Only new ticks and price changes are recorded.",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": "3"
    },
    {
      "id": "3.2",
      "title": "Core Data Types",
      "level": 2,
      "section_number": "3.2",
      "breadcrumb": "Data Format > Core Data Types",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "This page shows the file schema of the core data types represented in\n   supported asset classes\n   .",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Trade Tick",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Tick(code)\n   of\n   TickType.(code)\nTrade(csharp)\nQuote(python)\n   represents an individual record of trades for an asset. Tick data does not have a period.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The file schema is as follows:",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 4,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "The trade has one of the following\n   QuoteConditionFlags(code)\n   :",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 5,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "See more information in the\n   AlgoSeek whitepaper\n   .",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Quote Tick",
          "order": 10,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Tick(code)\n   of\n   TickType.(code)\nQuote(csharp)\nQUOTE(python)\n   represents an individual record of quote updates for an asset. Tick data does not have a period.",
          "order": 11,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The file schema is as follows:",
          "order": 11,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 11,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "The quote has one of the following\n   QuoteConditionFlags(code)\n   :",
          "order": 12,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 12,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "See more information in the\n   AlgoSeek whitepaper\n   .",
          "order": 13,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Trade Bar",
          "order": 17,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "TradeBar(code)\n   represents trade ticks of assets consolidated for a period.",
          "order": 18,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The file schema is as follows:",
          "order": 18,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 18,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "### Quote Bar",
          "order": 21,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "QuoteBar(code)\n   represents top of book quote data consolidated over a period of time (bid and ask bar).",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The file schema is as follows:",
          "order": 22,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 22,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "### Open Interest",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "OpenIntest(code)\n   represents the outstanding contracts.",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The file schema is as follows:",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 26,
          "language": null,
          "title": "Data Table",
          "context": null
        }
      ],
      "tables": [
        {
          "headers": [
            "Column",
            "Description"
          ],
          "rows": [
            [
              "Time",
              "Milliseconds since midnight in the timezone of the data format"
            ],
            [
              "Trade Sale",
              "Most recent trade price"
            ],
            [
              "Quantity",
              "Amount of asset purchased or sold"
            ],
            [
              "Exchange",
              "Location of the sale"
            ],
            [
              "Trade Sale Condition",
              "Notes on the sale"
            ],
            [
              "Suspicious",
              "Boolean indicating the tick is flagged as suspicious according to AlgoSeek's algorithms. This generally indicates the trade is far from other market prices and may be reversed.TradeBar dataexcludes suspicious ticks."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "TradeConditionFlags",
            "Status",
            "Description"
          ],
          "rows": [
            [
              "RegularREGULAR",
              "Included",
              "A trade made without stated conditions is deemed the regular way for settlement on the third business day following the transaction date."
            ],
            [
              "FormTFORM_T",
              "Included",
              "Trading in extended hours enables investors to react quickly to events that typically occur outside regular market hours, such as earnings reports. However, liquidity may be constrained during such Form T trading, resulting in wide bid-ask spreads."
            ],
            [
              "CashCASH",
              "Included",
              "A transaction that requires delivery of securities and payment on the same day the trade takes place."
            ],
            [
              "ExtendedHoursEXTENDED_HOURS",
              "Included",
              "Identifies a trade that was executed outside of regular primary market hours and is reported as an extended hours trade."
            ],
            [
              "NextDayNEXT_DAY",
              "Included",
              "A transaction that requires the delivery of securities on the first business day following the trade date."
            ],
            [
              "OfficialCloseOFFICIAL_CLOSE",
              "Included",
              "Indicates the \"official\" closing value determined by a Market Center. This transaction report will contain the market center generated closing price."
            ],
            [
              "OfficialOpenOFFICIAL_OPEN",
              "Included",
              "Indicates the 'Official' open value as determined by a Market Center. This transaction report will contain the market center generated opening price."
            ],
            [
              "ClosingPrintsCLOSING_PRINTS",
              "Included",
              "The transaction that constituted the trade-through was a single priced closing transaction by the Market Center."
            ],
            [
              "OpeningPrintsOPENING_PRINTS",
              "Included",
              "The trade that constituted the trade-through was a single priced opening transaction by the Market Center."
            ],
            [
              "IntermarketSweepINTERMARKET_SWEEP",
              "Excluded",
              "The transaction that constituted the trade-through was the execution of an order identified as an Intermarket Sweep Order."
            ],
            [
              "TradeThroughExemptTRADE_THROUGH_EXEMPT",
              "Excluded",
              "Denotes whether or not a trade is exempt (Rule 611)."
            ],
            [
              "OddLotODD_LOT",
              "Excluded",
              "Denotes the trade is an odd lot less than a 100 shares."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Column",
            "Description"
          ],
          "rows": [
            [
              "Time",
              "Milliseconds since midnight in the timezone of the data format"
            ],
            [
              "Bid Price",
              "Best bid price"
            ],
            [
              "Ask Price",
              "Best ask price"
            ],
            [
              "Bid Size",
              "Best bid price's size/quantity"
            ],
            [
              "Ask Size",
              "Best ask price's size/quantity"
            ],
            [
              "Exchange",
              "Location of the sale"
            ],
            [
              "Quote Sale Condition",
              "Notes on the sale."
            ],
            [
              "Suspicious",
              "Boolean indicating the tick is flagged as suspicious according to AlgoSeek's algorithms. This generally indicates the quote is far from other market prices and may be reversed. Each quote tick contains either bid or ask data only.QuoteBar datadata excludes suspicious ticks."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "QuoteConditionFlags",
            "Status",
            "Description"
          ],
          "rows": [
            [
              "ClosingCLOSING",
              "Included",
              "Indicates that this quote was the last quote for a security for that Participant."
            ],
            [
              "NewsDisseminationNEWS_DISSEMINATION",
              "Included",
              "Denotes a regulatory trading halt when relevant news influencing the security is being disseminated. Trading is \nsuspended until the primary market determines that an adequate publication or disclosure of information has occurred."
            ],
            [
              "NewsPendingNEWS_PENDING",
              "Included",
              "Denotes a regulatory Trading Halt due to an expected news announcement, which may influence the security. An Opening Delay or Trading Halt may be continued once the news has been disseminated."
            ],
            [
              "TradingRangeIndicationTRADING_RANGE_INDICATION",
              "Included",
              "Denotes the probable trading range (Bid and Offer prices, no sizes) of a security that is not Opening Delayed or Trading Halted. The Trading Range Indication is used prior to or after the opening of a security."
            ],
            [
              "OrderImbalanceORDER_IMBALANCE",
              "Included",
              "Denotes a non-regulatory halt condition where there is a significant imbalance of buy or sell orders."
            ],
            [
              "ResumeRESUME",
              "Included",
              "Indicates that trading for a Participant is no longer suspended in a security that had been Opening Delayed or Trading Halted."
            ],
            [
              "RegularREGULAR",
              "Excluded",
              "This condition is used for the majority of quotes to indicate a normal trading environment."
            ],
            [
              "SlowSLOW",
              "Excluded",
              "This condition is used to indicate that the quote is a Slow Quote on both the bid and offer sides due to a Set Slow List that includes high price securities."
            ],
            [
              "GapGAP",
              "Excluded",
              "While in this mode, auto-execution is not eligible, the quote is then considered manual and non-firm in the bid and offer, and either or both sides can be traded through as per Regulation NMS."
            ],
            [
              "OpeningQuoteOPENING_QUOTE",
              "Excluded",
              "This condition can be disseminated to indicate that this quote was the opening quote for a security for that Participant."
            ],
            [
              "FastTradingFAST_TRADING",
              "Excluded",
              "For extremely active periods of short duration. While in this mode, the UTP Participant will enter quotations on a best efforts basis."
            ],
            [
              "ResumeRESUME",
              "Excluded",
              "Indicate that trading for a Participant is no longer suspended in a security which had been Opening Delayed or Trading Halted."
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Column",
            "Description"
          ],
          "rows": [
            [
              "Time",
              "Second and Minute: Milliseconds since midnight in the timezone of the data formatHour or Daily: Date/time formatted asYYYYMMDD HH:mm"
            ],
            [
              "Open",
              "Open Price"
            ],
            [
              "High",
              "High Price"
            ],
            [
              "Low",
              "Low Price"
            ],
            [
              "Close",
              "Close Price"
            ],
            [
              "Volume",
              "Number of shares traded in the period"
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Column",
            "Description"
          ],
          "rows": [
            [
              "Time",
              "Second and Minute: Milliseconds since midnight in the timezone of the data formatHour or Daily: Date/time formatted asYYYYMMDD HH:mm"
            ],
            [
              "Bid Open",
              "Bid Open Price"
            ],
            [
              "Bid High",
              "Bid High Price"
            ],
            [
              "Bid Low",
              "Bid Low Price"
            ],
            [
              "Bid Close",
              "Bid Close Price"
            ],
            [
              "Bid Size",
              "Number of shares being bid that quoted in this QuoteBar"
            ],
            [
              "Ask Open",
              "Ask Open Price"
            ],
            [
              "Ask High",
              "Ask High Price"
            ],
            [
              "Ask Low",
              "Ask Low Price"
            ],
            [
              "Ask Close",
              "Ask Close Price"
            ],
            [
              "Ask Size",
              "Number of shares being asked that quoted in this QuoteBar"
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Column",
            "Description"
          ],
          "rows": [
            [
              "Open Interest",
              "Outstanding contracts"
            ]
          ],
          "caption": null
        }
      ],
      "subsections": [],
      "parent_id": "3"
    },
    {
      "id": "4",
      "title": "Statistics",
      "level": 1,
      "section_number": "4",
      "breadcrumb": "Statistics",
      "mixed_content": [],
      "tables": [],
      "subsections": [
        {
          "id": "4.1",
          "title": "Capacity",
          "level": 2,
          "section_number": "4.1",
          "breadcrumb": "Statistics > Capacity",
          "mixed_content": [
            {
              "type": "text",
              "content": "### Introduction",
              "order": 1,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Capacity is a measure of how much capital a strategy can trade before the performance of the strategy degrades from market impact. The capacity calculation is done on a rolling basis with one snapshot taken at the end of each week. This page outlines how LEAN performs the entire calculation.",
              "order": 2,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Security Capacity",
              "order": 3,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The first step to determine the capacity of the strategy is to compute the capacity of each security the strategy trades.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Market Capacity Dollar Volume",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Following each order fill, LEAN monitors and records the dollar-volume for a series of bars. To get an estimate of the available capacity, we combine many second and minute trade bars together. For hourly or daily data resolutions, we only use one bar.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "_marketCapacityDollarVolume += bar.Close * _fastTradingVolumeDiscountFactor * bar.Volume * conversionRate * Security.SymbolProperties.ContractMultiplier;",
              "order": 4,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "Crypto Volume",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Crypto trade volume is light, but there is significant capacity even at the very top of the order book. The estimated volume of Crypto is based on the average size on the bid and ask.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Forex and CFD Volume",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Forex and CFD assets do not have a trade volume or quote size information so they were approximated as deeply liquid assets with approximately $25,000,000 depth per minute.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Volume Accumulation Period",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "The number of bars we use to calculate the market volume estimate depends on the asset liquidity. The following table shows the formulas LEAN uses to determine how long of a period the market capacity dollar volume is accumulated for after each order fill, as a function of the security resolution. The $AvgDollarVolume$ in the table represents the average dollar volume per minute for the security you're trading. Notice that for the edge case where the average dollar volume is zero, the calculations use 10 minutes of data.",
              "order": 4,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 4,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "Only a fraction of the market capacity dollar volume is available to be taken by a strategyâ€™s orders because there are other market participants. The data resolution of the security determines how much of the market capacity dollar volume is available for the strategy to consume. The following table shows what percentage of the market capacity dollar volume is available for each of the data resolutions:",
              "order": 5,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "table",
              "content": "[Table Data]",
              "order": 5,
              "language": null,
              "title": "Data Table",
              "context": null
            },
            {
              "type": "text",
              "content": "Fast Trading Volume Discount Factor",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "To accommodate high-frequency trading strategies, the\n   _fastTradingVolumeDiscountFactor(code)\n   variable scales down the market capacity dollar volume of the security proportional to the number of trades that it places per day for the security. The more frequently the strategy trades a security, the lower the capacity of the security goes since it becomes harder to get into a larger position without incurring significant market impact. The formula that LEAN uses to discount the capacity of the securities that the algorithm trades intraday is",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "\\[ d_i = \\left\\{\n  \\begin{array}{ c l }\n    1,& \\text{if } i = 1\\\\\n    \\min(1, \\max(0.2, d_{i-1} * \\frac{m}{390})), & \\text{if } i > 1\n  \\end{array}\n\\right. \\]",
              "order": 6,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "where \\( d_i\\in{[0.2, 1]} \\) is the fast trading volume discount factor after order \\(i\\) and \\(m\\) is the number of minutes since order \\( i-1 \\) was filled. We divide \\( m \\) by 390 because there are \\( 390 = 6.5 * 60 \\) minutes of trading in a regular Equity trading day.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Sale Volume",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "In addition to the market capacity dollar volume, for each security the strategy trades, LEAN also accumulates the weekly sale volume of the order fills. The sale volume scales down the weekly snapshot capacity.",
              "order": 7,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "code",
              "content": "SaleVolume += orderEvent.FillPrice * orderEvent.AbsoluteFillQuantity * Security.SymbolProperties.ContractMultiplier;",
              "order": 7,
              "language": "csharp",
              "title": "C# Code Example",
              "context": null
            },
            {
              "type": "text",
              "content": "### Portfolio Capacity",
              "order": 24,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Now that we have the values to calculate the capacity of each security, we can compute the capacity of the portfolio.",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Snapshot Capacity",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "To calculate the strategy capactiy, weekly snapshots are taken. When itâ€™s time to take a snapshot, the capacity of the strategy for the current snapshot is calculated by first selecting the security with the least market capacity dollar volume available. The fraction of trading volume that was available for this security is scaled down by the number of orders that were filled for the security during the week. The result is scaled down further by the largest value between the weight of the securityâ€™s sale volume in the portfolio sale volume and the weight of the securityâ€™s holding value in the total portfolio value. The result of this final scaling is the strategyâ€™s capacity in the current snapshot.",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "\\[ Snapshot \\ Capacity = \\frac{\\frac{Market \\ Capacity \\ Dollar \\ Volume}{Number \\ Of \\ Trades}}{\\max(\\frac{Sale \\ Volume}{Portfolio \\ Sale \\ Volume}, \\frac{Buying \\ Power \\ Used}{Total \\ Portfolio \\ Value})} \\]",
              "order": 25,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "When any of the denominators are 0 in the preceding formula, the quotient that the denominator is part of defaults to a value of 0. After the snapshot is taken, the sale volume and market capacity dollar volume of each security is reset to 0.",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Strategy Capacity",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Instead of using the strategyâ€™s capacity at the current snapshot as the final strategy capacity value, the strategy capacity is smoothed across the weekly snapshots. First, the capacity estimate of the current snapshot is calculated, then the final strategy capacity value is set using the following exponentially-weighted model:",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "\\[ Strategy \\ Capacity = \\left\\{\n  \\begin{array}{ c l }\n    S_{i},& \\text{if } i = 1\\\\\n    0.66 * S_{i-1} + 0.33 * S_{i}, & \\text{if } i > 1\n  \\end{array}\n\\right. \\]",
              "order": 26,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "where \\( S_i \\) is the snapshot capacity of week \\(i\\).",
              "order": 27,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "### Summary",
              "order": 34,
              "language": null,
              "title": null,
              "context": null
            },
            {
              "type": "text",
              "content": "Strategies that have a larger capacity are able to trade more capital without suffering from significant market impact. In general, a strategy that trades a large weight of the portfolio in liquid securities with high volume will have a large capacity. To avoid reducing the strategy capacity too much, only trade a small portion of your portfolio in illiquid assets with low volume.",
              "order": 35,
              "language": null,
              "title": null,
              "context": null
            }
          ],
          "tables": [
            {
              "headers": [
                "Resolution",
                "Timeout Period"
              ],
              "rows": [
                [
                  "Second",
                  "\\[ k = \\left\\{\n  \\begin{array}{ c l }\n    \\frac{100,000}{AvgDollarVolume},& \\text{if } AvgDollarVolume \\neq 0\\\\\n    10, & \\text{otherwise}\n  \\end{array}\n\\right. \\]\n                \n\\[ \\min(120, \\max(5, k)) \\in [5, 120] \\text{ minutes} \\]"
                ],
                [
                  "Minute",
                  "\\[ k = \\left\\{\n  \\begin{array}{ c l }\n    \\frac{6,000,000}{AvgDollarVolume},& \\text{if } AvgDollarVolume \\neq 0\\\\\n    10, & \\text{otherwise}\n  \\end{array}\n\\right. \\]\n                \n\\[ \\min(120, \\max(1, k)) \\in [1, 120] \\text{ minutes} \\]"
                ],
                [
                  "Hour",
                  "1 hour"
                ],
                [
                  "Daily",
                  "1 day"
                ]
              ],
              "caption": null
            },
            {
              "headers": [
                "Resolution",
                "Available Portion of Market Capacity Dollar Volume (%)"
              ],
              "rows": [
                [
                  "Daily",
                  "2"
                ],
                [
                  "Hour",
                  "5"
                ],
                [
                  "Minute",
                  "20"
                ],
                [
                  "Second",
                  "50"
                ],
                [
                  "Tick",
                  "50"
                ]
              ],
              "caption": null
            }
          ],
          "subsections": [],
          "parent_id": "4"
        }
      ],
      "parent_id": null
    },
    {
      "id": "4.1",
      "title": "Capacity",
      "level": 2,
      "section_number": "4.1",
      "breadcrumb": "Statistics > Capacity",
      "mixed_content": [
        {
          "type": "text",
          "content": "### Introduction",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Capacity is a measure of how much capital a strategy can trade before the performance of the strategy degrades from market impact. The capacity calculation is done on a rolling basis with one snapshot taken at the end of each week. This page outlines how LEAN performs the entire calculation.",
          "order": 2,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Security Capacity",
          "order": 3,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The first step to determine the capacity of the strategy is to compute the capacity of each security the strategy trades.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Market Capacity Dollar Volume",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Following each order fill, LEAN monitors and records the dollar-volume for a series of bars. To get an estimate of the available capacity, we combine many second and minute trade bars together. For hourly or daily data resolutions, we only use one bar.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "_marketCapacityDollarVolume += bar.Close * _fastTradingVolumeDiscountFactor * bar.Volume * conversionRate * Security.SymbolProperties.ContractMultiplier;",
          "order": 4,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "Crypto Volume",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Crypto trade volume is light, but there is significant capacity even at the very top of the order book. The estimated volume of Crypto is based on the average size on the bid and ask.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Forex and CFD Volume",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Forex and CFD assets do not have a trade volume or quote size information so they were approximated as deeply liquid assets with approximately $25,000,000 depth per minute.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Volume Accumulation Period",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "The number of bars we use to calculate the market volume estimate depends on the asset liquidity. The following table shows the formulas LEAN uses to determine how long of a period the market capacity dollar volume is accumulated for after each order fill, as a function of the security resolution. The $AvgDollarVolume$ in the table represents the average dollar volume per minute for the security you're trading. Notice that for the edge case where the average dollar volume is zero, the calculations use 10 minutes of data.",
          "order": 4,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 4,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "Only a fraction of the market capacity dollar volume is available to be taken by a strategyâ€™s orders because there are other market participants. The data resolution of the security determines how much of the market capacity dollar volume is available for the strategy to consume. The following table shows what percentage of the market capacity dollar volume is available for each of the data resolutions:",
          "order": 5,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "table",
          "content": "[Table Data]",
          "order": 5,
          "language": null,
          "title": "Data Table",
          "context": null
        },
        {
          "type": "text",
          "content": "Fast Trading Volume Discount Factor",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To accommodate high-frequency trading strategies, the\n   _fastTradingVolumeDiscountFactor(code)\n   variable scales down the market capacity dollar volume of the security proportional to the number of trades that it places per day for the security. The more frequently the strategy trades a security, the lower the capacity of the security goes since it becomes harder to get into a larger position without incurring significant market impact. The formula that LEAN uses to discount the capacity of the securities that the algorithm trades intraday is",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "\\[ d_i = \\left\\{\n  \\begin{array}{ c l }\n    1,& \\text{if } i = 1\\\\\n    \\min(1, \\max(0.2, d_{i-1} * \\frac{m}{390})), & \\text{if } i > 1\n  \\end{array}\n\\right. \\]",
          "order": 6,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "where \\( d_i\\in{[0.2, 1]} \\) is the fast trading volume discount factor after order \\(i\\) and \\(m\\) is the number of minutes since order \\( i-1 \\) was filled. We divide \\( m \\) by 390 because there are \\( 390 = 6.5 * 60 \\) minutes of trading in a regular Equity trading day.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Sale Volume",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "In addition to the market capacity dollar volume, for each security the strategy trades, LEAN also accumulates the weekly sale volume of the order fills. The sale volume scales down the weekly snapshot capacity.",
          "order": 7,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "code",
          "content": "SaleVolume += orderEvent.FillPrice * orderEvent.AbsoluteFillQuantity * Security.SymbolProperties.ContractMultiplier;",
          "order": 7,
          "language": "csharp",
          "title": "C# Code Example",
          "context": null
        },
        {
          "type": "text",
          "content": "### Portfolio Capacity",
          "order": 24,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Now that we have the values to calculate the capacity of each security, we can compute the capacity of the portfolio.",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Snapshot Capacity",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "To calculate the strategy capactiy, weekly snapshots are taken. When itâ€™s time to take a snapshot, the capacity of the strategy for the current snapshot is calculated by first selecting the security with the least market capacity dollar volume available. The fraction of trading volume that was available for this security is scaled down by the number of orders that were filled for the security during the week. The result is scaled down further by the largest value between the weight of the securityâ€™s sale volume in the portfolio sale volume and the weight of the securityâ€™s holding value in the total portfolio value. The result of this final scaling is the strategyâ€™s capacity in the current snapshot.",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "\\[ Snapshot \\ Capacity = \\frac{\\frac{Market \\ Capacity \\ Dollar \\ Volume}{Number \\ Of \\ Trades}}{\\max(\\frac{Sale \\ Volume}{Portfolio \\ Sale \\ Volume}, \\frac{Buying \\ Power \\ Used}{Total \\ Portfolio \\ Value})} \\]",
          "order": 25,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "When any of the denominators are 0 in the preceding formula, the quotient that the denominator is part of defaults to a value of 0. After the snapshot is taken, the sale volume and market capacity dollar volume of each security is reset to 0.",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Strategy Capacity",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Instead of using the strategyâ€™s capacity at the current snapshot as the final strategy capacity value, the strategy capacity is smoothed across the weekly snapshots. First, the capacity estimate of the current snapshot is calculated, then the final strategy capacity value is set using the following exponentially-weighted model:",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "\\[ Strategy \\ Capacity = \\left\\{\n  \\begin{array}{ c l }\n    S_{i},& \\text{if } i = 1\\\\\n    0.66 * S_{i-1} + 0.33 * S_{i}, & \\text{if } i > 1\n  \\end{array}\n\\right. \\]",
          "order": 26,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "where \\( S_i \\) is the snapshot capacity of week \\(i\\).",
          "order": 27,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "### Summary",
          "order": 34,
          "language": null,
          "title": null,
          "context": null
        },
        {
          "type": "text",
          "content": "Strategies that have a larger capacity are able to trade more capital without suffering from significant market impact. In general, a strategy that trades a large weight of the portfolio in liquid securities with high volume will have a large capacity. To avoid reducing the strategy capacity too much, only trade a small portion of your portfolio in illiquid assets with low volume.",
          "order": 35,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [
        {
          "headers": [
            "Resolution",
            "Timeout Period"
          ],
          "rows": [
            [
              "Second",
              "\\[ k = \\left\\{\n  \\begin{array}{ c l }\n    \\frac{100,000}{AvgDollarVolume},& \\text{if } AvgDollarVolume \\neq 0\\\\\n    10, & \\text{otherwise}\n  \\end{array}\n\\right. \\]\n                \n\\[ \\min(120, \\max(5, k)) \\in [5, 120] \\text{ minutes} \\]"
            ],
            [
              "Minute",
              "\\[ k = \\left\\{\n  \\begin{array}{ c l }\n    \\frac{6,000,000}{AvgDollarVolume},& \\text{if } AvgDollarVolume \\neq 0\\\\\n    10, & \\text{otherwise}\n  \\end{array}\n\\right. \\]\n                \n\\[ \\min(120, \\max(1, k)) \\in [1, 120] \\text{ minutes} \\]"
            ],
            [
              "Hour",
              "1 hour"
            ],
            [
              "Daily",
              "1 day"
            ]
          ],
          "caption": null
        },
        {
          "headers": [
            "Resolution",
            "Available Portion of Market Capacity Dollar Volume (%)"
          ],
          "rows": [
            [
              "Daily",
              "2"
            ],
            [
              "Hour",
              "5"
            ],
            [
              "Minute",
              "20"
            ],
            [
              "Second",
              "50"
            ],
            [
              "Tick",
              "50"
            ]
          ],
          "caption": null
        }
      ],
      "subsections": [],
      "parent_id": "4"
    },
    {
      "id": "5",
      "title": "Class Reference",
      "level": 1,
      "section_number": "5",
      "breadcrumb": "Class Reference",
      "mixed_content": [
        {
          "type": "text",
          "content": "{\n   \"type\": \"link\",\n   \"heading\": \"Class Reference\",\n   \"subHeading\": \"\",\n   \"content\": \"\",\n   \"alsoLinks\": [],\n   \"href\": \"https://www.lean.io/docs/v2/lean-engine/class-reference/\"\n}",
          "order": 1,
          "language": null,
          "title": null,
          "context": null
        }
      ],
      "tables": [],
      "subsections": [],
      "parent_id": null
    }
  ],
  "statistics": {
    "document_index": 1,
    "sections": 29,
    "code_blocks": 39,
    "tables": 15,
    "status": "success"
  }
}