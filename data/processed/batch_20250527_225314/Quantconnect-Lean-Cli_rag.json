[
  {
    "id": "1",
    "title": "Key Concepts",
    "level": 1,
    "path": "Key Concepts",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Key Concepts",
      "section_number": "1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "1.1",
    "title": "Getting Started",
    "level": 2,
    "path": "Key Concepts > Getting Started",
    "content": "### Introduction\n\nThe Lean CLI is a cross-platform CLI which makes it easier to develop with the LEAN engine locally and in the cloud.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Prerequisites\n\nBefore you start installing the Lean CLI, check the requirements ofdeploying with your brokerageto ensure you have a compatible machine and review theintegration documentation for your brokerageso you are aware of what functionality is available through the integration.\n\nThe Lean CLI is distributed as a Python package, so it requirespipto be installed. SeeInstalling pipto learn how to install pip on your operating system. Note that the Python distribution from the Microsoft Store is not supported, we recommend using the Anaconda distribution instead.\n\nThe commands which run the LEAN engine locally also depend onDockerbeing installed and running. SeeInstall Dockerto learn how to install Docker on your operating system.\n\n### Installation\n\nRunpip install leanin a terminal to install the latest version of the CLI.\n\nAfter installing the CLI, open a terminal in an empty directory and runlean loginto log in to your QuantConnect account and then runlean initto create your first organization workspace.\nThelean initcommand downloads the latest configuration file and sample data from theQuantConnect/Leanrepository.\nWe recommend running all Lean CLI commands in your organization workspace directory.\n\n$ lean init\nDownloading latest sample data from the Lean repository...\nThe following objects have been created:\n- lean.json contains the configuration used when running the LEAN engine locally\n- data/ contains the data that is used when running the LEAN engine locally\n...\n\nIf you are running Docker on Windows using the legacy Hyper-V backend instead of the new WSL 2 backend, you need to enable file sharing for your temporary directories and for your organization workspace.\nTo do so, open your Docker settings, go toResources > File Sharingand addC: / Users / <username> / AppData / Local / Tempand your organization workspace path to the list.\nClickApply & Restartafter making the required changes.\n\n### Authentication\n\nMost of the Lean CLI commands need to communicate with the QuantConnect API.\nIf you use any commands which interact with the cloud ordeploy a live algorithm locally, you must log in using your QuantConnect account so the CLI can send authenticated API requests.\n\nRunlean loginto open an interactive wizard which asks you for your user Id and API token.Request these credentialsand we'll email them to you.\n\n$ lean login\nYour user Id and API token are needed to make authenticated requests to the QuantConnect API\nYou can request these credentials on https://www.quantconnect.com/account\nBoth will be saved in /home/<username>/.lean/credentials\nUser id: <user id>\nAPI token: <api token>\nSuccessfully logged in\n\n### Basic Usage\n\nThe CLI contains a lot of commands to make working on LEAN algorithms easier and more productive.\nBelow we list some of the most common tasks, see the pages in the sidebar and theAPI referencefor a complete overview of the supported features.\n\nPull Projects From the Cloud\n\nRunlean cloud pullto pull your QuantConnect projects to your local drive.\nThis command pulls all your cloud projects to your local drive while preserving your QuantConnect directory structure.\nIf you have a lot of projects and only want to work locally on a few of them you can run this command with the--project \"<projectName>\"option, which makes the command pull a single project instead.\n\n$ lean cloud pull\n[1/3] Pulling 'Creative Red Mule'\nSuccessfully pulled 'Creative Red Mule/main.py'\n[2/3] Pulling 'Determined Yellow-Green Duck'\nSuccessfully pulled 'Determined Yellow-Green Duck/main.py'\nSuccessfully pulled 'Determined Yellow-Green Duck/research.ipynb'\n[3/3] Pulling 'Halloween Strategy'\nSuccessfully pulled 'Halloween Strategy/benchmark.py'\nSuccessfully pulled 'Halloween Strategy/main.py'\nSuccessfully pulled 'Halloween Strategy/research.ipynb'\n\nSource Data\n\nRunlean data generate --start 20180101 --symbol-count 100to generate realistic fake market data to test with.\nYou can also choose todownload datafrom QuantConnect Datasets or convert your own data into LEAN-compatible data.\n\n$ lean data generate --start 20180101 --symbol-count 100\nBegin data generation of 100 randomly generated Equity assets...\n...\n\nRun a Local Backtest\n\nRunlean backtest \"<projectName>\"to run a local backtest for the specified project.\nThis command runs a backtest in a Docker container containing the same packages as the ones used on QuantConnect.com, but with your own data.\n\n$ lean backtest \"Project Name\"\n20210308 23:58:35.354 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210308 23:58:35.360 TRACE:: Engine.Main(): Started 11:58 PM\n...\n\nPush Local Changes to the Cloud\n\nRunlean cloud pushto push local changes to the QuantConnect.\nThis command pushes all your local projects to the cloud and creates new cloud projects when necessary.\nIf you only want to push a single project you can run this command with the--project \"<projectName>\"option.\n\n$ lean cloud push\n[1/3] Pushing 'Creative Red Mule'\nSuccessfully updated cloud file 'Creative Red Mule/main.py'\n[2/3] Pushing 'Determined Yellow-Green Duck'\n[3/3] Pushing 'Halloween Strategy'\n\nRun a Cloud Backtest\n\nRunlean cloud backtest \"<projectName>\"to run a cloud backtest for the specified project.\nBy default, a summary of the results and a link to the full results are shown in the terminal.\nRunning this command with the--openflag automatically opens the full results in the browser once the backtest is finished.\nAdditionally, you can run this command with the--pushflag to push all local changes to the project to the cloud before running the backtest.\n\n$ lean cloud backtest \"Project Name\"\nStarted compiling project 'Project Name'\nDetected parameters (2):\n- main.py:19 :: 1 Order Event parameter detected near \"SetHoldings(self.spy, 1)\".\n- main.py:21 :: 1 Order Event parameter detected near \"SetHoldings(self.spy, 0)\".\nBuild Request Successful for Project ID: 4882833, with CompileID: eaf9b677c91cfadd0a9032eb95918beb-c3b92b55d26a6d610e9b792ce561a687, Lean Version: 2.5.0.0.11058\nSuccessfully compiled project 'Project Name'\nStarted backtest named 'Swimming Orange Lemur' for project 'Project Name'\n...\n\n### LEAN vs LEAN CLI\n\nLEAN is the open-source algorithmic trading engine. LEAN CLI is the way we recommend you run LEAN on your local machine. The LEAN CLI can do almost everything that LEAN can do. There are just some programs in theToolBoxthat the LEAN CLI can't currently run. Thelean data generateis a wrapper for the random data generator in the ToolBox. However, if you need any of the other programs in the ToolBox, you'll have to run LEAN manually and move the downloaded/parsed data to the CLI'sdatadirectory.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "1",
      "breadcrumb": "Key Concepts > Getting Started",
      "section_number": "1.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "1.2",
    "title": "Troubleshooting",
    "level": 2,
    "path": "Key Concepts > Troubleshooting",
    "content": "### Introduction\n\nYou might occassionally receive an error indicating that something went wrong.\nWe try to provide accurate error descriptions in the CLI, but in some cases, those might not be enough.\nThis page lists common errors with their possible cause and a way to fix them.\nIn case you still need help after that this page also contains instructions on how to report issues to our engineers in a way that makes it easy for us to help you with your issue.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Common Errors\n\nThe following table describes errors you may see when using the CLI:\n\n[Table - 13 rows]\n\n### Report Issues\n\nIf with the information on this page and the error message shown by the CLI you're still unable to solve your issues you are welcome to contact our engineers by opening an issue in theQuantConnect/lean-cli repositoryon GitHub.\nBefore doing so, please run the command that's giving issues with the--verboseflag and copy and paste the output into the issue (feel free to mask sensitive information).\nThe--verboseflag enables debug messages to be printed, which makes it easier for us to help you.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "1",
      "breadcrumb": "Key Concepts > Troubleshooting",
      "section_number": "1.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Error Message | Possible Cause and Fix |\n| --- | --- |\n| No such command '<name>'No such option: <option> | The command you tried to run does not exist or it doesn't support the option you provided.\n                If the documentation says it is available you are probably using an outdated version of the CLI.\n                Runpip install --upgrade leanto update to the latest version. |\n| No such file | Follow these steps:Open the advance settings in Docker Desktop.Disable theAllow the default Docker socket to be usedsetting.Save and restart the Docker container.Enable theAllow the default Docker socket to be usedsetting.Save and restart the Docker container. |\n| Invalid credentials, please log in using `lean login` | You are trying to use a command which communicates with the QuantConnect API and you haven't authenticated yourself yet.\n                Runlean loginto log in with your API credentials. |\n| Please make sure Docker is installed and running | You are trying to use a command which needs to run the LEAN engine locally, which always happens in a Docker container.\n                Make sure Docker is running if youinstalled italready.\n                If Docker is already running, run your command with--verbosefor more information. |\n| Your venv probably has a non standard docker path or no docker access. Uninstall andreinstalldocker. |  |\n| This command requires a Lean configuration file, run `lean init` in an empty directory to create one, or specify the file to use with --lean-config | The command you are trying to run requires aLean configurationfile.\n                The CLI automatically tries to find this file by recursively looking in the current directory and all of the parent directories for alean.jsonfile.\n                This error is shown if no such file can be found.\n                It can be fixed by running the command in yourorganization workspace directory(which generates thelean.jsonfile), or by specifying the path to thelean.jsonfile with the--lean-configoption. |\n| We couldn't find you account in the given organization, ORG: <32-char-hash> | The organization Id found in thelean.jsonis incorrect. You need tore-installLean CLI runninglean initin an empty directory. |\n| Invalid value for 'PROJECT': Path '<path>' does not exist. | You are trying to run an action on a project but specified an invalid project path.\n                Make sure you are running the command from yourorganization workspace directoryand make sure./<path>points to an existing directory. |\n| '<path>' is not a valid path | You provided a path that is not valid for your operating system.\n                This error is most likely to appear on Windows, where the following characters are not allowed in path components:<,>,:,\",|,?, and*.\n                On top of those characters the following names are not allowed (case-insensitive):CON,PRN,AUX,NUL,COM1untilCOM9, andLPT1untilLPT9.\n                Last but not least, path components cannot start or end with a space or end with a period on Windows. |\n| invalid mount config for type \"bind\": bind source path does not exist:/ var / folders / <path> / config.jsonMounts denied: The path/ Users / <path> / datais not shared from the host and is not known to Docker | Your Mac's Docker file sharing settings do not permit binding one or more directories that we need to share with the container.\n                Go to Docker'sSettings > Resources > File Sharingand add/ private / var / foldersand either/ Usersto share your entire/ Usersdirectory, or/ Users / <path>where<path>is the path to your QuantConnect directory, which should have\n                adatachild directory, and child directories for your individual projects. |\n| Docker wants access to <path> | You are running Docker on Windows using the legacy Hyper-V backend and haven't configured file sharing correctly.\n                You need to enable file sharing for your temporary directories and for yourorganization workspace directory.\n                To do so, open your Docker settings, go toResources > File Sharingand addC: / Users / <username> / AppData / Local / Tempand your organization workspace directory to the list.\n                ClickApply & Restartafter making the required changes. |\n| Could not open '/lib64/ld-linux-x86-64.so.2': No such file or directory | Your Docker installation has pulled the incorrect platform version of the LEAN Docker image. Open your terminal. Rundocker rmi quantconnect/leanto remove thequantconnect/leanimage and then rundocker pull quantconnect/lean --platform=linux/amd64. |\n| Could not find file '/root/ibgateway/ibgateway'. | Your Docker installation has pulled the ARM platform version of the LEAN Docker image. This version doesn't include IB Gateway, because QuantConnect doesn't support Interactive Brokers integration with ARM chips (e.g.: Apple M1, M2, and M3 chips). |"
  },
  {
    "id": "2",
    "title": "Installation",
    "level": 1,
    "path": "Installation",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Installation",
      "section_number": "2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "2.1",
    "title": "Installing pip",
    "level": 2,
    "path": "Installation > Installing pip",
    "content": "### Introduction\n\nThe Lean CLI is distributed as a Python package, so it requirespipto be installed. Becausepipis distributed as a part of Python, you must install Python before you can install the CLI. If you want to install a non-Debian packaged Python application, it may be easiest to usepipx install xyz, which will manage a virtual environment for you.\n\nThis page contains installation instructions forAnaconda, which is a Python distribution containing a lot of packages that are also available when running the LEAN engine. Having these packages installed locally makes it possible for your editor to provide autocomplete for them.\n\nThe Python distribution from the Microsoft Store is not supported.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Install on Windows\n\nFollow these steps to install Anaconda on your computer:\n\nDownload the latest64-bit Graphical Installerfor Windows.Run the installer and clickNext.Read the licensing terms and click theI Agreecheck box.Select theJust Mecheck box and clickNext.Select the destination folder to install Anaconda in (make sure this path does not contain spaces) and clickNext.In the Advanced Options, enable theAdd Anaconda3 to my PATH environment variableandRegister Anaconda3 as my default Python 3.xcheck boxes and then clickInstall.After the installation has completed, restart your computer to make sure changes are propagated.Open a terminal and run:$ conda update --all\n\n### Install on macOS (Intel)\n\nFollow these steps to install Anaconda on your Mac with an Intel chip:\n\nDownload the latest64-bit Graphical Installerfor macOS.ClickContinueon the Introduction, Read Me, and License pages.Agree to the license by clickingAgree.ClickInstallon the Installation Type page to install to start the installation.After the installation has finished, clickContinueon the PyCharm IDE page andCloseon the Summary page to close the installer.\n\n### Install on macOS (Apple)\n\nAnaconda does not support Apple chips.\nFollow these steps to install Miniforge, a minimal version of Anaconda, on your Mac with an Apple chip:\n\nDownloadMiniforge3-MacOSX-arm64.sh.Open a terminal in the directory containing the installer.Runbash Miniforge3-MacOSX-arm64.shto start the installer.PressEnterto view the license terms, pressQto exit the license terms, and enterYesto accept the license terms.Specify where Miniforge should be installed or accept the default.EnterYeswhen the installer prompts whether you want the installer to initialize Miniforge.Re-open the terminal window after the installation has finished.\n\n### Install on Linux\n\nFollow these steps to install Anaconda on your computer:\n\nDownload the latest64-bit (x86) Installerfor Linux.Open a terminal in the directory containing the installer.Runbash <fileName>where<fileName>is the name of the installer.PressEnterto view the license terms, pressQto exit the license terms, and enterYesto accept the license terms.Specify where Anaconda should be installed or accept the default.EnterYeswhen the installer prompts whether you want the installer to initialize Anaconda.Re-open the terminal window after the installation has finished.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "2",
      "breadcrumb": "Installation > Installing pip",
      "section_number": "2.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "2.2",
    "title": "Installing Lean CLI",
    "level": 2,
    "path": "Installation > Installing Lean CLI",
    "content": "### Introduction\n\nThe Lean CLI is distributed as a Python package, so it requirespipto be installed. To learn how to installpipon your operating system, seeInstalling pip.\n\nThe commands which run the LEAN engine locally also depend onDockerbeing installed and running.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Install Docker\n\nIf you run the LEAN engine locally with the CLI, LEAN executes in a Docker container.\nThese Docker containers contain a minimal Linux-based operating system, the LEAN engine, and all the packages available to you on QuantConnect.com.\nIt is therefore required to install Docker if you plan on using the CLI to run the LEAN engine locally.\n\nInstall on Windows\n\nWindows systems must meet the following requirements to install Docker:\n\nA 64-bit processor4 GB RAM or moreWindows 10, version 1903 or higher (released May 2019)Hardware virtualization enabled in the BIOS60 GB hard drive or more\n\nFollow these steps to install Docker:\n\nFollow theInstall Docker Desktop on Windowstutorial in the Docker documentation.As you install docker, enable WSL 2 features.Restart your computer.If Docker prompts you that the WSL 2 installation is incomplete, follow the instructions in the dialog shown by Docker to finish the WSL 2 installation.Open PowerShell with adminstrator privledges and run:$ wsl --update\n\nBy default, Docker doesn't automatically start when your computer starts.\nSo, when you run the LEAN engine with the CLI for the first time after starting your computer, you must manually start Docker.\nTo automatically start Docker, open the Docker Desktop application, clickSettings > General, and  then enable theStart Docker Desktop when you log incheck box.\n\nInstall on macOS\n\nMac systems must meet the following requirements to install Docker:\n\nMac hardware from 2010 or newer with an Intel processormacOS 10.14 or newer (Mojave, Catalina, or Big Sur)4 GB RAM or more60 GB hard drive or more\n\nTo install Docker, seeInstall Docker Desktop on Macin the Docker documentation.\n\nInstall on Linux\n\nTo install, seeInstall Docker Desktop on Linuxin the Docker documentation.\n\n### Install LEAN CLI\n\nBefore you install the LEAN CLI, check if it's already installed.\n\n$ lean --version\n\nFollow these steps to install the LEAN CLI:\n\nInstall pip.Install Docker.If you are on a Windows machine, open PowerShell as the adminstrator for the following commands.Install the LEAN CLI with pip.$ pip install --upgrade lean\n\n### Next Steps\n\nLog in to youraccountand then set up your firstorganization workspace.\n\n### Stay Up To Date\n\nWe regularly update the CLI to add new features and to fix issues. Therefore, it's important to keep both the CLI and the Docker images that the CLI uses up-to-date.\n\nKeep the CLI Up-To-Date\n\nTo update the CLI to the latest version, runpip install --upgrade lean. The CLI automatically performs a version check once a day and warns you in case you are running an outdated version.\n\nKeep the Docker Images Up-To-Date\n\nVarious commands likelean backtest,lean optimizeandlean researchrun the LEAN engine in a Docker container to ensure all the required dependencies are available. When you run these commands for the first time the Docker image containing LEAN and its dependencies is downloaded and stored. Run these commands with the--updateflag to update the images they use. Additionally, these commands automatically perform a version check once a week and update the image they use when you are using an outdated Docker image.\n\n### Uninstall\n\nTo uninstall the Lean CLI, runpip uninstall lean.\nTo perform a full uninstallation, you must also deleteconfiguration filesthat the CLI generates, which you can find in the following directories:\n\nThe.leandirectory in your user's home directoryYourorganization workspaces",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "2",
      "breadcrumb": "Installation > Installing Lean CLI",
      "section_number": "2.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "3",
    "title": "Initialization",
    "level": 1,
    "path": "Initialization",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Initialization",
      "section_number": "3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "3.1",
    "title": "Authentication",
    "level": 2,
    "path": "Initialization > Authentication",
    "content": "### Introduction\n\nMost of the Lean CLI commands need to communicate with the QuantConnect API.\nIf you use any commands which interact with the cloud ordeploy a live algorithm locally, you must log in using your QuantConnect account so the CLI can send authenticated API requests.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Log In\n\nFollow these steps to log in to your QuantConnect account with the CLI:\n\nRequest your user-id and API token.Retrieve your user-id and API token from the email you registered on QuantConnect.Runlean loginto log in to the CLI, and enter your user-id and token when prompted. This command opens an interactive wizard asking you for your user-id and API token.$ lean login\nYour user Id and API token are needed to make authenticated requests to the QuantConnect API\nYou can request these credentials on https://www.quantconnect.com/account\nBoth will be saved in C:\\Users\\john\\.lean\\credentials\nUser id: 123456\nAPI token: ******************\nSuccessfully logged in\n\n### Log Out\n\nRunlean logoutto log out.\nThis command removes theglobal configuration filecontaining your user Id and API token.\n\n### Check Account Status\n\nRunlean whoamito see the name and email address of the user who is currently logged in.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Initialization > Authentication",
      "section_number": "3.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "3.2",
    "title": "Organization Workspaces",
    "level": 2,
    "path": "Initialization > Organization Workspaces",
    "content": "### Introduction\n\nAfter youinstall the CLIandlog in to your account, you need to create an organization workspace. Your organization workspace connects a directory on your local machine with one of yourorganizationsin QuantConnect Cloud. Your organization workspace includes the basic files and folders necessary to use LEAN, including a local data directory and a LEAN configuration file.\n\nWe recommend running all Lean CLI commands in the root of your organization workspace directory.\nDoing so ensures the directory structure is always kept consistent when synchronizing projects between the cloud and your local drive.\nIt also makes it possible for the CLI to automatically find the Lean configuration file when you run the LEAN engine on your local machine.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Create Workspaces\n\nTo create an organization workspace for one of your organizations, open a terminal in an empty directory, runlean initand then select an organization to link with the organization workspace.\nThis command scaffolds a standard directory structure containing adatadirectory and aLean configuration file, both of which are required to run the LEAN engine locally.\n\nIf you are running Docker on Windows using the legacy Hyper-V backend instead of the new WSL 2 backend, you need to enable file sharing for your temporary directories and for your organization workspace.\nTo do so, open your Docker settings, go toResources > File Sharingand addC: / Users / <username> / AppData / Local / Tempand your organization workspace path to the list.\nClickApply & Restartafter making the required changes.\n\nTo set the default language of new projects in a new organization workspace, runlean init --language <value>where the<value>ispythonorcsharp.\n\n### Directory Structure\n\nThelean initcommands creates the following structure:\n\n.\n├── data/\n│   ├── alternative/\n│   ├── crypto/\n│   ├── equity/\n│   ├── ...\n│   ├── market-hours/\n│   ├── option/\n│   ├── symbol-properties/\n│   └── readme.md\n│── storage/\n└── lean.json\n\nThese files contain the following content:\n\n[Table - 3 rows]\n\nWhen you create new projects or pull existing projects from the cloud, your organization workspace stores the project files.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Initialization > Organization Workspaces",
      "section_number": "3.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| File/Directory | Description |\n| --- | --- |\n| data / | This directory contains thelocal datathat LEAN uses to run locally. This directory is comes withsample data from the QuantConnect/Lean repository. As youdownload additional datafrom the dataset market, it's stored in this directory. Each organization workspace has its owndatadirectory because each organization has its own data licenses. |\n| storage / | This directory contains theObject Storedata that LEAN uses to run locally. |\n| lean.json | This file contains theLean configurationthat is used when running the LEAN engine locally. |"
  },
  {
    "id": "3.3",
    "title": "Configuration",
    "level": 2,
    "path": "Initialization > Configuration",
    "content": "### Introduction\n\nThe CLI stores its persistent configuration in various places depending on the context of the configuration.\nWe make the distinction between global configuration, Lean configuration, and project configuration, all of which store a specific subset of configurable properties.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Global Configuration\n\nThe global CLI configuration directory stores the CLI defaults and API credentials.\nThe exact location of the directory depends on your operating system. The following table shows the path of each operating system:\n\n[Table - 3 rows]\n\nThe global CLI configuration directory contains three files and one directory. The following table describes the files and directory:\n\n[Table - 4 rows]\n\nThe global configuration files are always updated via the CLI and should not be updated or removed manually, unless when you are uninstalling the CLI.\n\n### Lean Configuration\n\nThe Lean configuration contains settings for locally running the LEAN engine.\nThis configuration is created in thelean.jsonfile when you runlean initin an empty directory.\nThe configuration is stored as JSON, with support for both single-line and multiline comments.\n\nThe Lean configuration file is based on theLauncher / config.jsonfile from the Lean GitHub repository.\nWhen you runlean init, the latest version of this file is downloaded and stored in your organization workspace.\nBefore the file is stored, some properties are automatically removed because the CLI automatically sets them.\n\nThe CLI commands can update most of the values of thelean.jsonfile. The following table shows the configuration settings that you need to manually adjust in thelean.jsonfile if you want to change their values:\n\n[Table - 5 rows]\n\n### Project Configuration\n\nFor information about project configuration, seeProjects > Configuration.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Initialization > Configuration",
      "section_number": "3.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Operating System | Path |\n| --- | --- |\n| Windows | C: \\ Users \\ <username> \\ .lean |\n| macOS | / Users / <username> / .lean |\n| Linux | / home / <username> / .lean |",
    "table_1": "| Name | Description |\n| --- | --- |\n| credentials | This file contains the API credentials given vialean login. |\n| config | This file contains the CLI defaults, like the default project language used when runninglean project-create. |\n| cache | This file contains an internal cache that the CLI uses whenever it needs to persistently store data. One of its uses is to store the last time an update check has run to make sure we don't check for updates too often. |\n| ssh | This directory contains the SSH keys that are needed to debug over SSH when debugging with Rider. |",
    "table_2": "| Name | Description | Default |\n| --- | --- | --- |\n| show-missing-data-logs | Log missing data files. This is useful for debugging. | true |\n| algorithm-manager-time-loop-maximum | The maximum amount of time the algorithm can spend in a singletime loop. | 20 |\n| maximum-warmup-history-days-look-back | The maximum number of days of data the history provider will provide duringwarm-upin live trading. The history provider expects older data to be on disk. | 5 |\n| maximum-chart-series | The maximum number of chart series you can create in backtests. | 30 |\n| maximum-data-points-per-chart-series | The maximum number of data points you can add to a chart series in backtests. | 1,000,000 |"
  },
  {
    "id": "4",
    "title": "Datasets",
    "level": 1,
    "path": "Datasets",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Datasets",
      "section_number": "4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.1",
    "title": "Format and Storage",
    "level": 2,
    "path": "Datasets > Format and Storage",
    "content": "### Introduction\n\nLEAN strives to use an open, human-readable format, so all data is stored in flat files (formatted as CSV or JSON). The data is compressed on disk using zip\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Default Location\n\nWhen you create anorganization workspacein an empty directory, the CLI downloads the latestdata directory from the LEAN repository.\nThis directory contains a standard directory structure from which the LEAN engine reads.\nOnce downloaded, thedatadirectory tree looks like this:\n\ndata\n├── alternative/\n├── cfd/\n├── crypto/\n├── equity/\n├── forex/\n├── future/\n├── futureoption/\n├── index/\n├── indexoption/\n├── market-hours/\n├── option/\n├── symbol-properties/\n└── readme.md\n\nBy default, thedatadirectory contains a small amount of sample data for all asset types to demonstrate how data files must be formatted.\nAdditionally, thedatadirectory itself and most of its subdirectories containreadme.mdfiles containing more documentation on the format of the data files of each asset type.\n\n### Change Location\n\nYou can configure the data directory to use in thedata-folderproperty in yourLean configuration file.\nThe path this property is set to is used as thedatadirectory by all commands that run the LEAN engine locally.\nBy default, this property points to thedatadirectory inside yourorganization workspace.\nIf this property is set to a relative path, it is resolved relative to the Lean configuration file's parent directory.\n\nThedatadirectory is the only local directory that is mounted into all Docker containers ran by the CLI, so it must contain all the local files you want to read from your algorithms.\nYou can get the path to this directory in your algorithm using theGlobals.DataFoldervariable.\n\n### Data Updates\n\nEvery day, the LEAN CLI updates theexchange market hours(data / market-hours / market-hours-database.json) and thesymbol propertiesdatabase (data / symbol-properties / symbol-properties-database.csv).\nTo disable the updates, open theLEAN configuration file(lean.json) and set thefile-database-last-updatevalue to a date in the future.\n\n### Other Data Sources\n\nIf you already have data of your own you can convert it to a LEAN-compatible format yourself.\nIn that case, we recommend that you read thereadme.mdfiles generated by thelean initcommand in thedatadirectory, as these files contain up-to-date documentation on the expected format of the data files.\n\nFor development purposes, it is also possible togenerate datausing the CLI.\nThis generator uses aBrownian motion modelto generate realistic market data, which might be helpful when you're testing strategies locally but don't have access to real market data.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Format and Storage",
      "section_number": "4.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.2",
    "title": "Generating Data",
    "level": 2,
    "path": "Datasets > Generating Data",
    "content": "### Introduction\n\nRunning the LEAN engine locally with the CLI requires you to have your own local data, but real market data can be expensive and governed by difficult redistribution licenses.\nInstead of using actual market data, you can also opt to use realistic fake data by using LEAN's random data generator.\nThis generator uses a Brownian motion model to generate realistic market data.\nIt is capable of generating data for most of LEAN's supported security types and resolutions, which makes it a good solution to design and test algorithms without the need to buy real financial data.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Security Types\n\nThe random data generator supports the following security types and resolutions:\n\n[Table - 6 rows]\n\n### Supported Densities\n\nThe random data generator supports the following densities:\n\n[Table - 3 rows]\n\n### Run the Generator\n\nFollow these steps to generate random data:\n\nOpen a terminal in one of yourorganization workspaces.Runlean data generate --start 20150101 --symbol-count 10to generate dense minute Equity data since 01-01-2015 for 10 random symbols.$ lean data generate --start 20150101 --symbol-count 10\nBegin data generation of 10 randomly generated Equity assets...You can also specify an end date using--end <yyyyMMdd>, generate data for a different security type using--security-type <type>, for a different resolution using--resolution <resolution>, or with a different density using--data-density <density>.For a full list of options, runlean data generate --helpor seeOptions.\n\nThe following image shows an example time series of simulated data:",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Generating Data",
      "section_number": "4.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Security Type | Supported Resolutions |\n| --- | --- |\n| Equity |  |\n| Forex |  |\n| CFD |  |\n| Future |  |\n| Crypto |  |\n| Option |  |",
    "table_1": "| Density | Description |\n| --- | --- |\n| Dense | At least one data point per resolution step. |\n| Sparse | At least one data point per 5 resolution steps. |\n| VerySparse | At least one data point per 50 resolution steps. |"
  },
  {
    "id": "4.3",
    "title": "Custom Data",
    "level": 2,
    "path": "Datasets > Custom Data",
    "content": "### Introduction\n\nRunning the LEAN engine locally with the CLI requires you to have your own local data.\nBesides market data, LEAN also supports importing custom data into your algorithm.\nThis page explains how to access data from local files in your algorithm when running the LEAN engine locally.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Import Local Files\n\nWhen running LEAN locally using the CLI, you can already use all of the features explained in theImporting Datapage of the LEAN documentation.\nHowever, sometimes you may not want to upload your file to a cloud storage service like Dropbox.\nYou can follow these steps to convert your custom data class (the class extendingBaseDataPythonData) to retrieve data from a local file instead of a remote one:\n\nCopy the data file that you want to use to thedatadirectory in yourorganization workspace.Open the source file containing your custom data class in an editor.Update yourGetSourceget_sourcemethod to load data from the local file in yourdatadirectory. Make sure you only use forward slashes. Backward slashes as path separators don't work. For theWeatherexample in the LEAN documentation, that is done like this:using System;\nusing System.IO;\nusing QuantConnect.Data;\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class Weather : BaseData\n{\npublic override SubscriptionDataSource GetSource(SubscriptionDataConfig config, DateTime date, bool isLive)\n{\n// Old:\n// var source = \"https://www.dropbox.com/s/8v6z949n25hyk9o/custom_weather_data.csv?dl=1\";\n// return new SubscriptionDataSource(source, SubscriptionTransportMedium.RemoteFile);\n\n// New:\n// Replace custom_weather_data.csv with the path to your data file in the data directory\nvar source = Path.Combine(Globals.DataFolder, \"custom_weather_data.csv\");\nreturn new SubscriptionDataSource(source, SubscriptionTransportMedium.LocalFile);\n}\n}\n}import os\n\nfrom QuantConnect import Globals, SubscriptionTransportMedium\nfrom QuantConnect.Data import SubscriptionDataSource\nfrom QuantConnect.Python import PythonData\n\nclass Weather(PythonData):\ndef get_source(self, config: SubscriptionDataConfig, date: datetime, is_live: bool) -> SubscriptionDataSource:\n# Old:\n# source = \"https://www.dropbox.com/s/8v6z949n25hyk9o/custom_weather_data.csv?dl=1\"\n# return SubscriptionDataSource(source, SubscriptionTransportMedium.REMOTE_FILE)\n\n# New:\n# Replace custom_weather_data.csv with the path to your data file in the data directory\nsource = os.path.join(Globals.data_folder, \"custom_weather_data.csv\")\nreturn SubscriptionDataSource(source, SubscriptionTransportMedium.LOCAL_FILE)Save the source file.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Custom Data",
      "section_number": "4.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4",
    "title": "QuantConnect",
    "level": 2,
    "path": "Datasets > QuantConnect",
    "content": "QuantConnect was founded in 2012 to serve quants everywhere with the best possible algorithmic trading technology. Seeking to disrupt a notoriously closed-source industry, QuantConnect takes a radically open-source approach to algorithmic trading. Through the QuantConnect web platform, more than 50,000 quants are served every month.To locally run the LEAN engine, you need local data. We recommend you source local data from ourDataset Market, so you can use the same data that is available to your algorithm when you run it in the cloud. There are two methods of downloading data. You can download smaller discrete datasets at a low cost or download complete collections in bulk to avoid selection bias.Download By TickerLow cost option for individual tickersDownload in BulkAll tickers to avoid selection biasSee AlsoDatasets",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > QuantConnect",
      "section_number": "4.4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4.1",
    "title": "Download By Ticker",
    "level": 3,
    "path": "Datasets > QuantConnect > Download By Ticker",
    "content": "Downloading data by the ticker is the ideal, low-cost option to acquiring local trading data if you don't need an entire universe. This technique is for smaller, discrete downloads.Key ConceptsCostsSee AlsoDownload in Bulk",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4.4",
      "breadcrumb": "Datasets > QuantConnect > Download By Ticker",
      "section_number": "4.4.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4.1.1",
    "title": "Key Concepts",
    "level": 4,
    "path": "Datasets > QuantConnect > Download By Ticker > Key Concepts",
    "content": "### Introduction\n\nDownloading data by the ticker is the ideal, low-cost option to acquiring local trading data if you don't need an entire universe. This technique is for smaller, discrete downloads. You can download our ticker data through the CLI or LEAN in exchange for someQuantConnect Credit(QCC). Before the CLI or LEAN download new files, they check if your local machine already stores the files.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Using the CLI\n\nYou can download datasets with the CLI using the non-interactive mode or the interactive mode.\n\nNon-Interactive Mode\n\nFollow these steps to download datasets with the non-interactive mode of the CLI:\n\nOpen thelisting page of the datasetthat you want to download.Click theCLItab.If there is noCLItab, you can't download the dataset.Fill in the Command Line Generator form.SelectWindowsorUnix.Copy the CLI command that the form displays.Open a terminal in yourorganization workspaceand then run the command.If you haven't already agreed to theCLI API Access and Data Agreement, in the browser window that opens, read the document and clickI Accept The Data Agreement.\n\nThe CLI displays a summary of your purchase and the download progress.\n\nData that will be purchased and downloaded:\n┌───────────────────────────┬─────────┬────────────────────────┬────────────┬─────────┐\n│ Dataset                   │ Vendor  │ Details                │ File count │ Price   │\n├───────────────────────────┼─────────┼────────────────────────┼────────────┼─────────┤\n│ Binance Crypto Price Data │ CoinAPI │ Data type: Trade       │ 32         │ 800 QCC │\n│                           │         │ Ticker: BTCBUSD        │            │         │\n│                           │         │ Resolution: Second     │            │         │\n│                           │         │ Start date: 2022-05-05 │            │         │\n│                           │         │ End date: 2022-06-05   │            │         │\n└───────────────────────────┴─────────┴────────────────────────┴────────────┴─────────┘\nTotal price: 800 QCC\nOrganization balance: 1,000 QCC\n\nData Terms of Use has been signed previously.\nFind full agreement at: https://www.quantconnect.com/terms/data/?organization=<organizationId>\n==========================================================================\nCLI API Access Agreement: On 2022-04-12 22:34:26 You Agreed:\n- Display or distribution of data obtained through CLI API Access is not permitted.\n- Data and Third Party Data obtained via CLI API Access can only be used for individual or internal employee's use.\n- Data is provided in LEAN format can not be manipulated for transmission or use in other applications.\n- QuantConnect is not liable for the quality of data received and is not responsible for trading losses.\n==========================================================================\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% (32/32)\n\nInteractive Mode\n\nFollow these steps to download datasets with the interactive mode of the CLI:\n\nLog into the CLI if you haven't done so already.Open a terminal in one of yourorganization workspace directories.Runlean data downloadto start an interactive downloading wizard.Go through the interactive wizard to configure the data you want to download.After configuring the data you want to download, enterNwhen asked whether you want to download more data.$ lean data download\nSelected data:\n...\nTotal price: 10 QCC\nOrganization balance: 10,400 QCC\nDo you want to download more data? [y/N]: NIn the browser window that opens, read theCLI API Access and Data Agreementand clickI Accept The Data Agreement.Go back to the terminal and confirm the purchase to start downloading.$ lean data download\nYou will be charged 10 QCC from your organization's QCC balance\nAfter downloading all files your organization will have 10,400 QCC left\nContinue? [y/N]: y\n[1/1] Downloading equity/usa/daily/spy.zip (10 QCC)\n\nMany of the datasets depend on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes. To check if a dataset depends the US Equity Security Master, see the listing in theDataset Market. If you try to download a dataset through the CLI that depends on the US Equity Security Master and you don't have an active subscription to it, you'll get an error.\n\nFor example, follow these steps to download US Equity data from the Dataset Market:\n\nOpen a terminal in one of yourorganization workspace directories.Runlean data downloadto start an interactive downloading wizard and then enter the dataset category number.$ lean data download\nSelect a category:\n1) Commerce Data (3 datasets)\n2) Consumer Data (2 datasets)\n3) Energy Data (2 datasets)\n4) Environmental Data (1 dataset)\n5) Financial Market Data (30 datasets)\n6) Industry Data (1 dataset)\n7) Legal Data (2 datasets)\n8) News and Events (4 datasets)\n9) Political Data (2 datasets)\n10) Transport and Logistics Data (1 dataset)\n11) Web Data (9 datasets)\nEnter an option: 5Enter the dataset number.$ lean data download\nSelect a dataset:\n1) Binance Crypto Future Margin Rate Data\n2) Binance Crypto Future Price Data\n3) Binance Crypto Price Data\n4) Binance US Crypto Price Data\n5) Bitcoin Metadata\n6) Bitfinex Crypto Price Data\n7) Brain Language Metrics on Company Filings\n8) Brain ML Stock Ranking\n9) CFD Data\n10) Coinbase Crypto Price Data\n11) Composite Factor Bundle\n12) Cross Asset Model\n13) FOREX Data\n14) Insider Trading\n15) Kraken Crypto Price Data\n16) NFT Sales\n17) Tactical\n18) US Congress Trading\n19) US ETF Constituents\n20) US Equities\n21) US Equity Coarse Universe\n22) US Equity Options\n23) US Equity Security Master\n24) US Federal Reserve (FRED)\n25) US Futures\n26) US Futures Security Master\n27) US Index Options\n28) US SEC Filings\n29) US Treasury Yield Curve\n30) VIX Central Contango\n31) VIX Daily Price\nEnter an option: 20If you don't have an active subscription to the US Equity Security Master, you'll get the following error message:Your organization needs to have an active Security Master subscription to download data from the 'US Equities' datasetYou can add the subscription at https://www.quantconnect.com/datasets/quantconnect-security-master/pricingEnter the data type.$ lean data download\nData type:\n1) Trade\n2) Quote\n3) Bulk\nEnter an option: 1Enter the ticker(s).$ lean data download\nTicker(s) (comma-separated): SPYEnter the resolution.$ lean data download\nResolution:\n1) Tick\n2) Second\n3) Minute\n4) Hour\n5) Daily\nEnter an option: 3If you selected tick, second, or minute resolution in the previous step, enter the start and end date.$ lean data download\nStart date (yyyyMMdd): 20230101\nEnd date (yyyyMMdd): 20230105Review your selected data and enter whether you would like to download more data.$ lean data download\nSelected data:\n┌─────────────┬──────────┬────────────────────────┬────────────┬────────┐\n│ Dataset     │ Vendor   │ Details                │ File count │ Price  │\n├─────────────┼──────────┼────────────────────────┼────────────┼────────┤\n│ US Equities │ AlgoSeek │ Data type: Trade       │ 3          │ 15 QCC │\n│             │          │ Ticker: SPY            │            │        │\n│             │          │ Resolution: Minute     │            │        │\n│             │          │ Start date: 2023-01-01 │            │        │\n│             │          │ End date: 2023-01-05   │            │        │\n└─────────────┴──────────┴────────────────────────┴────────────┴────────┘\nTotal price: 15 QCC\nOrganization balance: 10,000 QCC\nDo you want to download more data? [y/N]: nIf you haven't already agreed to theCLI API Access and Data Agreement, in the browser window that opens, read the document and clickI Accept The Data Agreement.Confirm your data purchase.$ lean data download\nData Terms of Use has been signed previously.\nFind full agreement at: https://www.quantconnect.com/terms/data/?organization=<organizationId>\n==========================================================================\nCLI API Access Agreement: On 2022-04-12 22:34:26 You Agreed:\n- Display or distribution of data obtained through CLI API Access is not permitted.\n- Data and Third Party Data obtained via CLI API Access can only be used for individual or internal employee's use.\n- Data is provided in LEAN format can not be manipulated for transmission or use in other applications.\n- QuantConnect is not liable for the quality of data received and is not responsible for trading losses.\n==========================================================================\n\nYou will be charged 15 QCC from your organization's QCC balance\nAfter downloading all files your organization will have 9,985 QCC left\nContinue? [y/N]: yAfter you confirm your data purchsae, the CLI downloads the data and prints its progress.$ lean data download\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% (3/3)\n\n### Using Lean\n\nFor more information about using LEAN to download datasets, seeDownload Datasets During Backtests.\n\n### Supported Datasets\n\nTo view all of the supported datasets, see theDataset Market.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4.4.1",
      "breadcrumb": "Datasets > QuantConnect > Download By Ticker > Key Concepts",
      "section_number": "4.4.1.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4.1.2",
    "title": "Costs",
    "level": 4,
    "path": "Datasets > QuantConnect > Download By Ticker > Costs",
    "content": "### Introduction\n\nThis page describes how to calculate the approximate cost of downloading local data for algorithms of each asset class. The prices reflect the data prices at the time of writing. To view the current prices of each dataset, open a dataset listing in theDataset Marketand then click thePricingtab. To download the data, use thelean data downloadcommand or theApiDataProvider.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### US Equity\n\nUS Equity algorithms require theUS Equity Security Masterand some data from theUS Equitiesdataset. The following table shows the cost of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nThe US Equities dataset is available is several resolutions. The resolution you need depends on the US Equity subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 5 rows]\n\nIf you add universes to your algorithm, the following table shows the additional datasets you need:\n\n[Table - 2 rows]\n\nFor example, the following algorithm creates a dollar volume universe with 100 securities and then subscribes to minute resolution data for each US Equity in the universe:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class USEquityDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nUniverseSettings.Asynchronous = true;\nAddUniverse(Universe.DollarVolume.Top(100));\n}\n}\n}class USEquityDataAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.universe_settings.asynchronous = True\nself.add_universe(self.universe.dollar_volume.top(100))\n\nThe following table shows the data cost of the preceding algorithm on the Quant Researcher tier:\n\n[Table - 3 rows]\n\nThe preceding table assumes you download trade and quote data, but you can run backtests with only trade data.\n\n### Equity Options\n\nEquity Option algorithms require the following data:\n\nUS Equity Security MasterUS Equity Option UniverseSome data from theUS Equity OptionsdatasetData for the underlyingUS Equity universes and assets\n\nThe following table shows the cost of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nThe file format of the US Equity Option Universe data is one file per underlying Equity and each file costs 100 QCC = $1 USD.\n\nThe US Equity Options dataset is available is several resolutions. The resolution you need depends on the US Equity Option subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 3 rows]\n\nFor example, the following algorithm subscribes to minute resolution data for an Equity Option and its underlying asset:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class USEquityOptionsDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nUniverseSettings.Asynchronous = true;\nvar underlying = AddEquity(\"GOOG\").Symbol;\nAddOption(underlying);\n}\n}\n}class USEquityOptionsDataAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.universe_settings.asynchronous = True\nunderlying = self.add_equity(\"GOOG\").symbol\nself.add_option(underlying)\n\nThe following table shows the data cost of the preceding algorithm on the Quant Researcher tier:\n\n[Table - 4 rows]\n\nThe preceding table assumes you download trade, quote, and open interest data. However, you can run backtests with only trade data.\n\n### Crypto\n\nCrypto algorithms require at least one of theCoinAPI datasets. The CoinAPI datasets are available is several resolutions. The resolution you need depends on the Crypto subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 5 rows]\n\nIf you add universes to your algorithm, you also needCryptoUniversedata. The file format ofCryptoUniversedata is one file per day per brokerage and each file costs 100 QCC = $1 USD.\n\nFor example, the following algorithm creates a universe of 100 Cryptocurrencies and then subscribes to minute resolution data for each one in the universe:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class CryptoDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nUniverseSettings.Asynchronous = true;\nAddUniverse(CryptoUniverse.Coinbase(universeDay => universeDay.OrderByDescending(cf => cf.VolumeInUsd).Take(100).Select(x => x.Symbol))\n);\n}\n}\n}class CryptoDataAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.universe_settings.asynchronous = True\nself.add_universe(CryptoUniverse.coinbase(self.universe_filter))\n\ndef universe_filter(self, universe_day: list[CryptoUniverse]) -> list[Symbol]:\nsorted_by_dollar_volume = sorted(universe_day, key=lambda cf: cf.volume_in_usd, reverse=True)\nreturn [cf.symbol for cf in sorted_by_dollar_volume[:100]]\n\nThe following table shows the data cost of the preceding algorithm:\n\n[Table - 2 rows]\n\nThe preceding table assumes you download trade and quote data, but you can run backtests with only trade data.\n\n### Forex\n\nForex algorithms require some data from theFOREXdataset. The FOREX dataset is available is several resolutions. The resolution you need depends on the Forex subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 4 rows]\n\nFor example, the following algorithm subscribes to minute resolution data for one Forex pair:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class ForexDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nAddForex(\"USDCAD\");\n}\n}\n}class ForexDataAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.add_forex(\"USDCAD\")\n\nThe following table shows the data cost of the preceding algorithm:\n\n[Table - 1 rows]\n\n### Futures\n\nFutures algorithms require some data from theUS Futuresdataset. The US Futures dataset is available in several resolutions. The resolution you need depends on the US Future subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 5 rows]\n\nIf you wantcontinuous contractsin your algorithm, you also need theUS Futures Security Masterdataset. The following table shows the cost of an annual subscription to the US Futures Security Master for each organization tier:\n\n[Table - 4 rows]\n\nFor example, the following algorithm subscribes to minute resolution data for a universe of ES Futures contracts and creates a continuous contract:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class USFuturesDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nvar future = AddFuture(Futures.Indices.SP500EMini,\ndataNormalizationMode: DataNormalizationMode.BackwardsRatio,\ndataMappingMode: DataMappingMode.OpenInterest,\ncontractDepthOffset: 0\n);\nfuture.SetFilter(0, 90);\n}\n}\n}class USFuturesDataAlgorithm(QCAlgorithm):\ndef initialize(self):\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nfuture = self.add_future(Futures.Indices.SP500E_MINI,\ndata_normalization_mode = DataNormalizationMode.BACKWARDS_RATIO,\ndata_mapping_mode = DataMappingMode.OPEN_INTEREST,\ncontract_depth_offset = 0)\nfuture.set_filter(0, 90)\n\nThe following table shows the data cost of the preceding algorithm on the Quant Researcher tier:\n\n[Table - 2 rows]\n\nThe preceding table assumes you download trade, quote, and open interest data. However, you can run backtests with only trade data.\n\n### Index Options\n\nIndex Options algorithms require theUS Index Option Universedataset and some data from theUS Index Optionsdataset.\nThe file format of the US Equity Option Universe data is one file per underlying Equity and each file costs 100 QCC = $1 USD.\nThe US Index Options dataset is available in several resolutions.\nThe resolution you need depends on the US Index Option subscriptions you create in your algorithm and the resolution of data you get inhistory requests.\nThe following table describes the file format and costs of each resolution:\n\n[Table - 3 rows]\n\nFor example, the following algorithm subscribes to minute resolution data for a universe of VIX Index Option contracts:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class USIndexOptionsDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nAddIndexOption(\"VIX\");\n}\n}\n}class USIndexOptionsDataAlgorithm(QCAlgorithm):\ndef initialize(self):\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.add_index_option(\"VIX\")\n\nThe following table shows the data cost of the preceding algorithm:\n\n[Table - 2 rows]\n\nThe preceding table assumes you download trade, quote, and open interest data. However, you can run backtests with only trade data.\n\n### CFD\n\nCFD algorithms require some data from theCFDdataset. The CFD dataset is available is several resolutions. The resolution you need depends on the CFD subscriptions you create in your algorithm and the resolution of data you get inhistory requests. The following table describes the file format and costs of each resolution:\n\n[Table - 4 rows]\n\nFor example, the following algorithm subscribes to minute resolution data for one CFD contract:\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class CFDDataAlgorithm : QCAlgorithm\n{\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetEndDate(2021, 1, 1);\nAddCfd(\"XAUUSD\");\n}\n}\n}class CFDDataAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_end_date(2021, 1, 1)\nself.add_cfd(\"XAUUSD\")\n\nThe following table shows the data cost of the preceding algorithm:\n\n[Table - 1 rows]\n\n### Alternative Data\n\nAlgorithms that use alternative data require some data from the associated alternative dataset. To view the cost of each alternative dataset, open a dataset listing in theDataset Marketand then click thePricingtab.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.1",
      "breadcrumb": "Datasets > QuantConnect > Download By Ticker > Costs",
      "section_number": "4.4.1.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |",
    "table_1": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Tick | One file per security per trading day per data format. Quote and trade data are separate files. | 6 QCC = $0.06 USD |\n| Second | One file per security per trading day per data format. Quote and trade data are separate files. | 5 QCC = $0.05 USD |\n| Minute | One file per security per trading day per data format. Quote and trade data are separate files. | 5 QCC = $0.05 USD |\n| Hour | One file per security. | 300 QCC = $3 USD |\n| Daily | One file per security. | 100 QCC = $1 USD |",
    "table_2": "| Universe Type | Required Dataset | File Format | Cost per file |\n| --- | --- | --- | --- |\n| FundamentalorDollar Volume | US Equity Coarse Universe | One file per day. | 5 QCC = $0.05 USD |\n| ETF Constituents | US ETF Constituents | One file per ETF per day. | 50 QCC = $0.50 USD |",
    "table_3": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| US Equity Security Master | Download On Premise | $600 USD | $600 USD/year |\n| US Equity Coarse Universe | On Premise Download | 252 trading days=> 252 files252 files @ 5 QCC/file=> 252 * 5 QCC= 12,600 QCC= $126 USD | 1 trading day=> 1 file1 file/day @ 5 QCC/file=> 5 QCC/day= $0.05 USD/day |\n| US Equity | Minute Download | 100 securities over 252 trading days with 2 data formats=> 100 * 252 * 2 files= 50,400 files50,400 files @ 5 QCC/file=> 50,400 * 5 QCC= 252,000 QCC= $2,520 USD | 100 securities with 2 data formats=> 100 * 2 files/day= 200 files/day200 files/day @ 5 QCC/file=> 200 * 5 QCC/day= 1,000 QCC/day= $10 USD/day |",
    "table_4": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |",
    "table_5": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Minute | One file per Option per trading day per data format. Quote, trade, and open interest data are separate files. | 15 QCC = $0.15 USD |\n| Hour | One file per Option per year per data format. Trade and open interest data are separate files. | 900 QCC = $9 USD |\n| Daily | One file per Option per year. Trade and open interest data are separate files. | 300 QCC = $3 USD |",
    "table_6": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| US Equity Security Master | Download On Premise | $600 USD | $600 USD/year |\n| US Equity Option Universe | Download On Premise | 1 underlying Equity over 252 trading days=> 1 * 252 files= 252 files252 files @ 100 QCC/file=> 252 * 100 QCC= 25,200 QCC= $252 USD | 1 underlying Equity=> 1 file/day1 file/day @ 100 QCC/file= 100 QCC/day= $1 USD/day |\n| US Equity | Minute Download | 1 security over 252 trading days with 2 data formats=> 1 * 252 * 2 files= 504 files504 files @ 5 QCC/file=> 504 * 5 QCC= 2,520 QCC= $25.20 USD | 1 security with 2 data formats=> 2 files/day2 files/day @ 5 QCC/file=> 2 * 5 QCC/day= 10 QCC/day= $0.10 USD/day |\n| US Equity Options | Minute Download | 1 Option over 252 trading days with 3 data formats=> 1 * 252 * 3 files= 756 files756 files @ 15 QCC/file=> 756 * 15 QCC= 11,360 QCC= $113.60 USD | 1 Option with 3 data formats=> 3 files/day3 files/day @ 15 QCC/file=> 3 * 15 QCC/day= 45 QCC/day= $0.45 USD/day |",
    "table_7": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Tick | One file per security per trading day per brokerage per data format. Quote and trade data are separate files. | 100 QCC = $1 USD |\n| Second | One file per security per trading day per brokerage per data format. Quote and trade data are separate files. | 25 QCC = $0.25 USD |\n| Minute | One file per security per trading day per brokerage per data format. Quote and trade data are separate files. | 5 QCC = $0.05 USD |\n| Hour | One file per security per brokerage. | 400 QCC = $4 USD |\n| Daily | One file per security per brokerage. | 100 QCC = $1 USD |",
    "table_8": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| Coinbase Crypto Price Data | Universe Download | 365 days=> 365 files365 files @ 100 QCC/file=> 365 * 100 QCC= 36,500 QCC= $365 USD | 1 file per day @ 100 QCC/file=> 100 QCC/day= $1 USD/day |\n| Coinbase Crypto Price Data | Minute Download | 100 securities over 365 trading days with 2 data formats=> 1 * 100 * 365 * 2 files= 73,000 files73,000 files @ 5 QCC/file=> 73,000 * 5 QCC= 365,000 QCC= $3,650 USD | 100 securities with 2 data formats=> 100 * 2 files/day= 200 files/day200 files/day @ 5 QCC/file=> 200 * 5 QCC/day= 1,000 QCC/day= $10 USD/day |",
    "table_9": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Second | One file per currency pair per trading day. | 3 QCC = $0.03 USD |\n| Minute | One file per currency pair per trading day. | 3 QCC = $0.03 USD |\n| Hour | One file per currency pair. | 3 QCC = $0.03 USD |\n| Daily | One file per currency pair. | 3 QCC = $0.03 USD |",
    "table_10": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| FOREX Data | Minute Download | 1 currency pair over 312 trading days=> 312 files312 files @ 3 QCC/file=> 312 * 3 QCC= 936 QCC= $9.36 USD | 1 currency pair/day=> 1 file/day1 file/day @ 3 QCC/file=> 3 QCC/day= $0.03 USD/day |",
    "table_11": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Tick | One file per ticker per trading day per data format. Trade, quote, and open interest data are separate files. | 6 QCC = $0.06 USD |\n| Second | One file per ticker per trading day per data format. Trade, quote, and open interest data are separate files. | 5 QCC = $0.05 USD |\n| Minute | One file per ticker per trading day per data format. Trade, quote, and open interest data are separate files. | 5 QCC = $0.05 USD |\n| Hour | One file per ticker per data format. Trade, quote, and open interest data are separate files. | 300 QCC = $3 USD |\n| Daily | One file per ticker per data format. Trade, quote, and open interest data are separate files. | 100 QCC = $1 USD |",
    "table_12": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |",
    "table_13": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| US Futures Security Master | Download On Premise | $600 USD | $0 USD/year |\n| US Futures | Minute Download | 1 ticker over 252 trading days with 3 data formats=> 1 * 252 * 3 files=  756 files756 files @ 5 QCC/file=> 756 * 5 QCC= 3,780 QCC= $37.80 USD | 1 ticker with 3 data formats=> 3 files/day3 file/day @ 5 QCC/file=> 15 QCC/day= $0.15 USD/day |",
    "table_14": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Minute | One file per ticker per trading day per data format. Trade, quote, and open interest data are separate files. | 15 QCC = $0.15 USD |\n| Hour | One file per ticker per data format. Trade, quote, and open interest data are separate files. | 900 QCC = $9 USD |\n| Daily | One file per ticker per data format. Trade, quote, and open interest data are separate files. | 300 QCC = $3 USD |",
    "table_15": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| US Index Option Universe | Download On Premise | 1 underlying Index over 252 trading days=> 1 * 252 files= 252 files252 files @ 100 QCC/file=> 252 * 100 QCC= 25,200 QCC= $252 USD | 1 underlying Index=> 1 file/day1 file/day @ 100 QCC/file=> 100 QCC/day= $1 USD/day |\n| US Index Options | Minute Download | 1 ticker over 252 trading days with 3 data formats=> 1 * 252 * 3 files= 756 files756 files @ 15 QCC/file=> 756 * 15 QCC= 11,340 QCC= $113.40 USD | 1 ticker with 3 data formats=> 3 files/day3 files/day @ 15 QCC/file=> 45 QCC/day= $0.45 USD/day |",
    "table_16": "| Resolution | File Format | Cost per file |\n| --- | --- | --- |\n| Second | One file per contract per trading day. | 3 QCC = $0.03 USD |\n| Minute | One file per contract per trading day. | 3 QCC = $0.03 USD |\n| Hour | One file per contract. | 3 QCC = $0.03 USD |\n| Daily | One file per contract. | 3 QCC = $0.03 USD |",
    "table_17": "| Dataset | Package | Initial Cost | Ongoing Cost |\n| --- | --- | --- | --- |\n| CFD Data | Minute Download | 1 contract over 314 trading days=> 314 files314 files @ 3 QCC/file=> 314 * 3 QCC= 942 QCC= $9.42 USD | 1 contract/day=> 1 file/day1 file/day @ 3 QCC/file=> 3 QCC/day= $0.03 USD/day |"
  },
  {
    "id": "4.4.2",
    "title": "Download in Bulk",
    "level": 3,
    "path": "Datasets > QuantConnect > Download in Bulk",
    "content": "Download any of the following datasets in bulk to get all of the data and avoid selection bias:CFD DataFOREX DataUS EquitiesUS Equity Coarse UniverseUS Equity OptionsUS Equity Option UniverseUS ETF ConstituentsUS FuturesUS Future OptionsUS Index OptionsUS Index Option UniverseSee AlsoDatasets",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4.4",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk",
      "section_number": "4.4.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4.2.1",
    "title": "CFD Data",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > CFD Data",
    "content": "### Introduction\n\nDownload theCFD datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain data for every ticker and trading day.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the CFD dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nOANDA CFD - Daily HistoryOANDA CFD - Hour HistoryOANDA CFD - Minute HistoryOANDA CFD - Second History\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, follow these steps to download the data:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the CFD dataset, new daily updates are available at 3 PM Coordinated Universal Time (UTC) after each trading day. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nOANDA CFD - Daily UpdatesOANDA CFD - Hour UpdatesOANDA CFD - Minute UpdatesOANDA CFD - Second Updates\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the CFD dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. Alternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"CFD Data\" --data-type \"Bulk\"  --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\", \"second\"]:\ndir_name = f\"cfd/oanda/{resolution}/xauusd\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"cfd/oanda/{resolution}/xauusd.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent XAUUSD data you have for second and minute resolutions. If there is new data available for either of these resolutions, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size and format of the CFD dataset for each resolution:\n\n[Table - 4 rows]\n\n### Price\n\nThe following table shows the price of the CFD dataset subscriptions:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > CFD Data",
      "section_number": "4.4.2.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 500 MB | 1 file per ticker |\n| Hour | 1 GB | 1 file per ticker |\n| Minute | 50 GB | 1 file per ticker per day |\n| Second | 200 TB | 1 file per ticker per day |",
    "table_1": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | 799.92 | 199.92 |\n| Hour | 799.92 | 199.92 |\n| Minute | 799.92 | 199.92 |\n| Second | 799.92 | 199.92 |"
  },
  {
    "id": "4.4.2.2",
    "title": "FOREX Data",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > FOREX Data",
    "content": "### Introduction\n\nDownload theFOREX datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain data for every ticker and trading day.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the Forex dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nOANDA Forex - Daily HistoryOANDA Forex - Hour HistoryOANDA Forex - Minute HistoryOANDA Forex - Second History\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, follow these steps to download the data:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the Forex dataset, new daily updates are available at 3 PM Coordinated Universal Time (UTC)  after each trading day. To gain access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nOANDA Forex - Daily UpdatesOANDA Forex - Hour UpdatesOANDA Forex - Minute UpdatesOANDA Forex - Second Updates\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the Forex dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. Alternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"FOREX Data\" --data-type \"Bulk\"  --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\", \"second\"]:\ndir_name = f\"forex/oanda/{resolution}/eurusd\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"forex/oanda/{resolution}/eurusd.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nTo update your local dataset, the preceding script checks the date of the most recent EURUSD data you have for all resolutions. If there is new data available for either of these resolutions, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size of the Forex dataset for each resolution:\n\n[Table - 4 rows]\n\n### Price\n\nThe following table shows the price of the Forex dataset subscriptions:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > FOREX Data",
      "section_number": "4.4.2.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 500 MB | 1 file per ticker |\n| Hour | 1 GB | 1 file per ticker |\n| Minute | 50 GB | 1 file per ticker per day |\n| Second | 200 TB | 1 file per ticker per day |",
    "table_1": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | 799.92 | 199.92 |\n| Hour | 799.92 | 199.92 |\n| Minute | 799.92 | 199.92 |\n| Second | 799.92 | 199.92 |"
  },
  {
    "id": "4.4.2.3",
    "title": "US Equities",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Equities",
    "content": "### Introduction\n\nDownload theUS Equities datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain data for every ticker and trading day. If the resolution you download provides trade and quote data, the bulk download contains both data types. To check which data types each resolution provides, seeResolutions.\n\nThe US Equities dataset depends on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Equities dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Equity Daily History by AlgoSeekUS Equity Hourly History by AlgoSeekUS Equity Minute History by AlgoSeekUS Equity Second History by AlgoSeekUS Equity Tick History by AlgoSeek\n\nIf you don't already subscribe to theUS Equity Security Master by QuantConnectdata package, subscribe to it too. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US Equities data, follow these steps:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\nTo download the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\n### Download Daily Updates\n\nAfter you bulk download the US Equities dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Equity Daily Updates by AlgoSeekUS Equity Hourly Updates by AlgoSeekUS Equity Minute Updates by AlgoSeekUS Equity Second Updates by AlgoSeekUS Equity Tick Updates by AlgoSeek\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Equities dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. To update your local copy of the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\nAlternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"US Equities\" --data-type \"Bulk\"  --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\", \"second\", \"tick\"]:\ndir_name = f\"equity/usa/{resolution}/spy\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"equity/usa/{resolution}/spy.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent SPY data you have for all resolutions. If there is new data available for any of these resolutions, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size and format of the US Equities dataset for each resolution:\n\n[Table - 5 rows]\n\n### Price\n\nThe following table shows the price of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nThe following table shows the price of the US Equity dataset subscriptions:\n\n[Table - 5 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Equities",
      "section_number": "4.4.2.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 2 GB | 1 file per ticker |\n| Hour | 4 GB | 1 file per ticker |\n| Minute | 500 GB | 1 file per ticker per day |\n| Second | 1.5 TB | 1 file per ticker per day |\n| Tick | 1.5 TB | 1 file per ticker per day |",
    "table_1": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |",
    "table_2": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | 3,480 | 2,640 |\n| Hour | 3,480 | 2,640 |\n| Minute | Contact us | 2,640 |\n| Second | Contact us | 2,640 |\n| Tick | Contact us | 2,640 |"
  },
  {
    "id": "4.4.2.4",
    "title": "US Equity Coarse Universe",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Equity Coarse Universe",
    "content": "### Introduction\n\nDownload theUS Equity Coarse Universe datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain data for every trading day.\n\nThe US Equity Coarse Universe dataset depends on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Equity Coarse Universe dataset, open thePricingpage of your organization and subscribe to theUS Equity Coarse Universe History by QuantConnectdata package. If you don't already subscribe to theUS Equity Security Master by QuantConnectdata package, subscribe to it too. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US Equity Coarse Universe data, open a terminal in yourorganization workspaceand run:\n\n$ lean data download --dataset \"US Equity Coarse Universe\" --data-type \"Bulk\"\n\nTo download the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\n### Download Daily Updates\n\nAfter you bulk download the US Equity Coarse Universe dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to theUS Equity Coarse Universe Updates by QuantConnectdata package. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Equity Coarse Universe dataset, open a terminal in yourorganization workspaceand run:\n\n$ lean data download --dataset \"US Equity Coarse Universe\" --data-type \"Bulk\"\n\nTo update your local copy of the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\nAlternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script downloads the latest data when it's available:\n\nimport os\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\ndef __get_start_date() -> str:\ndir_name = f\"equity/usa/fundamental/coarse\"\nfiles = [] if not os.path.exists(dir_name) else sorted(os.listdir(dir_name))\nreturn files[-1].split(\".\")[0] if files else '19980101'\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7, 0):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:00 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\nif __name__ == \"__main__\":\nstart, end = __get_start_date(), __get_end_date()\nif start >= end:\nexit(\"Your data is already up to date.\")\n\ncommand = f'lean data download --dataset \"US Equity Coarse Universe\" --data-type \"Bulk\" --start {start} --end {end}'\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\nThe preceding script checks the date of the most recent US Equity Coarse Universe data you have. If there is new data available, it downloads the new data files.\n\n### Size and Format\n\nThe US Equity Coarse Universe dataset is 4 GB in size. We structure the data files so there is one file per day.\n\n### Price\n\nThe following table shows the price of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nAll of the historical US Equity Coarse Universe data costs $1,800. An annual subscription to daily updates costs $960/year.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Equity Coarse Universe",
      "section_number": "4.4.2.4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |"
  },
  {
    "id": "4.4.2.5",
    "title": "US Equity Options",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Equity Options",
    "content": "### Introduction\n\nDownload theUS Equity Options datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain trade, quote, and open interest data for every ticker and trading day.\n\nThe US Equity Options dataset depends on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes.\nThe US Equity Options dataset also depends on theUS Equity Option Universedataset because the US Equity Options Universe dataset contains information on the available contracts and their daily Greeks and implied volatility values.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Equity Options dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Equity Options Daily History by AlgoSeekUS Equity Options Hour History by AlgoSeekUS Equity Options Minute History by AlgoSeek\n\nIf you don't already subscribe to theUS Equity Security Master by QuantConnectdata package, subscribe to it too. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US Equity Options data, follow these steps:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\nTo download the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\n### Download Daily Updates\n\nAfter you bulk download the US Equity Options dataset, new daily updates are available at 8 PM Coordinated Universal Time (UTC) two days after each trading day. For example, the minute resolution data for Monday is available on Wednesday at 8 PM UTC. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Equity Options Daily Updates by AlgoSeekUS Equity Options Minute Updates by AlgoSeekUS Equity Options Hour Updates by AlgoSeek\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Equity Options dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. To update your local copy of the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\nAlternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"US Equity Options\" --data-type \"Bulk\" --option-style \"American\" --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\"]:\ndir_name = f\"option/usa/{resolution}/aapl\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"option/usa/{resolution}/aapl.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent minute resolution data you have for AAPL. If there is new minute data available, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size and format of the US Equity Options dataset for each resolution:\n\n[Table - 3 rows]\n\n### Price\n\nThe following table shows the price of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nThe following table shows the price of the US Equity Options dataset subscriptions:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Equity Options",
      "section_number": "4.4.2.5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 200 GB | 1 file per ticker |\n| Hour | 500 GB | 1 file per ticker |\n| Minute | 6 TB | 1 file per ticker per day |",
    "table_1": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |",
    "table_2": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | Contact us | 1,920 |\n| Hour | Contact us | 2,640 |\n| Minute | Contact us | 2,880 |"
  },
  {
    "id": "4.4.2.6",
    "title": "US Equity Option Universe",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Equity Option Universe",
    "content": "### Introduction\n\nDownload theUS Equity Option Universe datasetin bulk to get the full dataset without any selection bias.\nThe bulk dataset packages contains the available Option contracts and their daily Greeks and implied volatility values for every underlying US Equity and trading day.\n\nThe US Equity Option Universe dataset depends on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Equity Option Universe dataset, open thePricingpage of your organization and subscribe to theUS Equity Option Universe - On Premise Bulk Downloaddata package.\nIf you don't already subscribe to theUS Equity Security Master by QuantConnectdata package, subscribe to it too.\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US Equity Option Universe data, follow these steps:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\nTo download the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\n### Download Daily Updates\n\nAfter you bulk download the US Equity Option Universe dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day.\nTo unlock local access to the data updates, open thePricingpage of your organization and subscribe to theUS Equity Option Universe - On Premise Bulk Download Updatesdata package.\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Equity Option Universe dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace.\nTo update your local copy of the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\nAlternatively, instead of directly calling thelean data downloadcommand, you can place the following Python script in thedatadirectory of your organization workspace and run it to update your data files.\n\nimport os\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\ndef __get_start_date() -> str:\ndir_name = f\"option/usa/universes\"\nfiles = [] if not os.path.exists(dir_name) else sorted(os.listdir(dir_name))\nreturn files[-1].split(\".\")[0] if files else '19980101'\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7, 0):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:00 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\nif __name__ == \"__main__\":\nstart, end = __get_start_date(), __get_end_date()\nif start >= end:\nexit(\"Your data is already up to date.\")\n\ncommand = f'lean data download --dataset \"US Equity Option Universe\" --data-type \"Bulk\" --start {start} --end {end}'\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\nThe preceding script checks the date of the most recent US Equity Option Universe data you have. If there is new data available, it downloads the new data files.\n\n### Size and Format\n\nThe US Equity Option Universe dataset is 450 GB in size. We structure the data files so there is one file per underlying Equity per day.\n\n### Price\n\nThe following table shows the price of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nAll of the historical US Equity Option Universe data costs $3,960. An annual subscription to daily updates costs $1,200/year.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Equity Option Universe",
      "section_number": "4.4.2.6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |"
  },
  {
    "id": "4.4.2.7",
    "title": "US ETF Constituents",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US ETF Constituents",
    "content": "### Introduction\n\nDownload theUS ETF Constituents datasetin bulk to get the full dataset without any ETF selection bias. The bulk dataset package contains constituents data for all of thesupported ETFsfor every trading day.\n\nThe US ETF Constituents dataset depends on theUS Equity Security Masterdataset because the US Equity Security Master contains information on splits, dividends, and symbol changes.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US ETF Constituents dataset, open thePricingpage of your organization and subscribe to theUS ETF Constituents History by QuantConnectdata package. If you don't already subscribe to theUS Equity Security Master by QuantConnectdata package, subscribe to it too. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US ETF Consitutents data, open a terminal in yourorganization workspaceand run:\n\n$ lean data download --dataset \"US ETF Constituents\" --data-type \"Bulk\" --start \"20090601\" --end \"20500101\"\n\nTo download the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\n### Download Daily Updates\n\nAfter you bulk download the US ETF Constituents dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to theUS ETF Constituents Updates by QuantConnectdata package. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US ETF Constituents dataset, open a terminal in yourorganization workspaceand run:\n\n$ lean data download --dataset \"US ETF Constituents\" --data-type \"Bulk\" --start \"20090601\" --end \"20500101\"\n\nTo update your local copy of the US Equity Security Master, run:\n\n$ lean data download --dataset \"US Equity Security Master\"\n\nAlternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all of the new data that's missing from your local copy:\n\nimport os\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\ndef __get_start_date() -> str:\ndir_name = f\"equity/usa/universes/etf/spy\"\nfiles = [] if not os.path.exists(dir_name) else sorted(os.listdir(dir_name))\nreturn files[-1].split(\".\")[0] if files else '19980101'\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7, 0):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:00 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\nif __name__ == \"__main__\":\nstart, end = __get_start_date(), __get_end_date()\nif start >= end:\nexit(\"Your data is already up to date.\")\n\ncommand = f'lean data download --dataset \"US ETF Constituents\" --data-type \"Bulk\" --start {start} --end {end}'\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\nThe preceding script checks the date of the most recent SPY data you have. If there is new data available for SPY, it downloads the new data files for all of the ETFs. You may need to adjust this script to fit your needs.\n\n### Size and Format\n\nThe US ETF Constituents dataset is 50 GB in size. We structure the data files so there is one file per ETF per day.\n\n### Price\n\nThe following table shows the price of an annual subscription to the US Equity Security Master for each organization tier:\n\n[Table - 4 rows]\n\nAll of the historical US ETF Constituents data costs $3,960. An annual subscription to daily updates costs $1,200/year.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US ETF Constituents",
      "section_number": "4.4.2.7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Tier | Price ($/Year) |\n| --- | --- |\n| Quant Researcher | 600 |\n| Team | 900 |\n| Trading Firm | 1,200 |\n| Institution | 1,800 |"
  },
  {
    "id": "4.4.2.8",
    "title": "US Futures",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Futures",
    "content": "### Introduction\n\nDownload theUS Futures datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain trade, quote, and open interest data for every ticker and trading day.\n\nThe US Futures dataset depends on theUS Futures Security Masterdataset because the US Futures Security Master dataset contains information to construct continuous Futures.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Futures dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Futures Daily History by AlgoSeekUS Futures Hour History by AlgoSeekUS Futures Minute History by AlgoSeekUS Futures Second History by AlgoSeekUS Futures Tick History by AlgoSeek\n\nIf you don't already subscribe to theUS Futures Security Master by QuantConnectdata package, subscribe to it too. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, follow these steps to download the data:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the US Futures dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Futures Daily Updates by AlgoSeekUS Futures Hour Updates by AlgoSeekUS Futures Minute Updates by AlgoSeekUS Futures Second Updates by AlgoSeekUS Futures Tick Updates by AlgoSeek\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Futures dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. Alternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions and markets:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"US Futures\" --data-type \"Bulk\" --market \"CBOT\" --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\", \"second\", \"tick\"]:\ndir_name = f\"future/cbot/{resolution}/zc\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"future/cbot/{resolution}/zc.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent ZC data you have from the CBOT market for tick, second, and minute resolutions. If there is new data available for any of these resolutions, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions and markets, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size and format of the US Futures dataset for each resolution:\n\n[Table - 5 rows]\n\n### Price\n\nThe following table shows the price of the US Futures dataset subscriptions:\n\n[Table - 5 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Futures",
      "section_number": "4.4.2.8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 500 MB | 1 file per ticker |\n| Hour | 1 GB | 1 file per ticker |\n| Minute | 24 GB | 1 file per ticker per day |\n| Second | 300 GB | 1 file per ticker per day |\n| Tick | 1.5 TB | 1 file per ticker per day |",
    "table_1": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | Contact us | 1,920 |\n| Hour | Contact us | 2,640 |\n| Minute | Contact us | 2,880 |\n| Second | Contact us | 2,880 |\n| Tick | Contact us | 2,880 |"
  },
  {
    "id": "4.4.2.9",
    "title": "US Future Options",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Future Options",
    "content": "### Introduction\n\nDownload theUS Future Options datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain trade, quote, and open interest data for every ticker and trading day.\n\nThe US Future Options dataset depends on theUS Futuresdataset because the US Futures Sdataset contains data on the underlying Futures contracts.\nThe US Future Options dataset also depends on theUS Futures Security Masterdataset because the US Futures Security Master dataset contains information to construct continuous Futures.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Future Options dataset,contact us. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, follow these steps to download the data:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the US Future Options dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day. To unlock local access to the data updates,contact us. You needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Future Options dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. Alternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions and markets:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"US Future Options\" --data-type \"Bulk\"  --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\"]:\ndir_name = f\"futureoption/cme/{resolution}/es\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"futureoption/cme/{resolution}/es.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent ES data you have from the CME market for minute resolution. If there is new data available, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions and markets, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size and format of the US Future Options dataset for each resolution:\n\n[Table - 3 rows]\n\n### Price\n\nThe following table shows the price of the US Future Options dataset subscriptions:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Future Options",
      "section_number": "4.4.2.9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 1.5 GB | 1 file per ticker |\n| Hour | 11 GB | 1 file per ticker |\n| Minute | 400 GB | 1 file per ticker per day |",
    "table_1": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | Contact us | 1,920 |\n| Hour | Contact us | 2,640 |\n| Minute | Contact us | 2,880 |"
  },
  {
    "id": "4.4.2.10",
    "title": "US Index Options",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Index Options",
    "content": "### Introduction\n\nDownload theUS Index Options datasetin bulk to get the full dataset without any selection bias. The bulk dataset packages contain trade and quote data for every ticker and trading day.\n\nThe US Index Options dataset depends on theUS Index Option Universedataset because the US Index Options Universe dataset contains information on the available contracts, including their daily Greeks and implied volatility values.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Index Options dataset, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Index Options Daily Updates by AlgoSeekUS Index Options Hour History by AlgoSeekUS Index Options Minute History by AlgoSeek\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, follow these steps to download the data:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the US Index Options dataset, new daily updates are available at 8 PM Coordinated Universal Time (UTC) two days after each trading day. For example, the minute resolution data for Monday is available on Wednesday at 8 PM UTC. To unlock local access to the data updates, open thePricingpage of your organization and subscribe to at least one of the following data packages:\n\nUS Index Options Daily Updates by AlgoSeekUS Index Options Minute Updates by AlgoSeekUS Index Options Hour Updates by AlgoSeek\n\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Index Options dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace. Alternatively, instead of directly calling thelean data downloadcommand, you can place a Python script in thedatadirectory of your organization workspace and run it to update your data files. The following example script updates all data resolutions:\n\nimport os\nimport pandas as pd\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\n# Define a method to download the data\ndef __download_data(resolution, start=None, end=None):\nprint(f\"Updating {resolution} data...\")\ncommand = f'lean data download --dataset \"US Index Options\" --data-type \"Bulk\"  --resolution \"{resolution}\"'\nif start:\nend = end if end else start\ncommand += f\" --start {start} --end {end}\"\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7,30):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:30 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\ndef __download_high_frequency_data(latest_on_cloud):\nfor resolution in [\"minute\"]:\ndir_name = f\"indexoption/usa/{resolution}/spx\".lower()\nif not os.path.exists(dir_name):\n__download_data(resolution, '19980101')\ncontinue\nlatest_on_disk = sorted(os.listdir(dir_name))[-1].split('_')[0]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution, latest_on_disk, latest_on_cloud)\n\ndef __download_low_frequency_data(latest_on_cloud):\nfor resolution in [\"daily\", \"hour\"]:\nfile_name = f\"indexoption/usa/{resolution}/spx.zip\".lower()\nif not os.path.exists(file_name):\n__download_data(resolution)\ncontinue\nlatest_on_disk = str(pd.read_csv(file_name, header=None)[0].iloc[-1])[:8]\nif latest_on_disk >= latest_on_cloud:\nprint(f\"{resolution} data is already up to date.\")\ncontinue\n__download_data(resolution)\n\nif __name__ == \"__main__\":\nlatest_on_cloud = __get_end_date()\n__download_low_frequency_data(latest_on_cloud)\n__download_high_frequency_data(latest_on_cloud)\n\nThe preceding script checks the date of the most recent minute resolution data you have for SPX. If there is new minute data available, it downloads the new data files and overwrites your hourly and daily files. If you don't intend to download all resolutions, adjust this script to your needs.\n\n### Size and Format\n\nThe following table shows the size of the US Index Options dataset for each resolution:\n\n[Table - 3 rows]\n\n### Price\n\nThe following table shows the price of the US Index Options dataset subscriptions:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Index Options",
      "section_number": "4.4.2.10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Resolution | Size | Format |\n| --- | --- | --- |\n| Daily | 5 GB | 1 file per ticker |\n| Hour | 40 GB | 1 file per ticker |\n| Minute | 500 GB | 1 file per ticker per day |",
    "table_1": "| Resolution | Price of Historical Data ($) | Price of Daily Updates ($/Year) |\n| --- | --- | --- |\n| Daily | Contact us | 1,920 |\n| Hour | Contact us | 2,640 |\n| Minute | Contact us | 2,880 |"
  },
  {
    "id": "4.4.2.11",
    "title": "US Index Option Universe",
    "level": 4,
    "path": "Datasets > QuantConnect > Download in Bulk > US Index Option Universe",
    "content": "### Introduction\n\nDownload theUS Index Option Universe datasetin bulk to get the full dataset without any selection bias.\nThe bulk dataset packages contains the available Option contracts and their daily Greeks and implied volatility values for every underlying US Index and trading day.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Download History\n\nTo unlock local access to the US Index Option Universe dataset, open thePricingpage of your organization and subscribe to theUS Index Option Universe - On Premise Bulk Downloaddata package.\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to local access, to download the US Equity Option Universe data, follow these steps:\n\nLog in to the Algorithm Lab.OntheCLItab of the dataset listing, use theCLI Command Generatorto generate your download command and then copy it.TheTickerfield is irrelevant for bulk downloads because it downloads data for all the tickers in the dataset.Open a terminal in yourorganization workspaceand then run the command from theCLI Command Generator.\n\n### Download Daily Updates\n\nAfter you bulk download the US Index Option Universe dataset, new daily updates are available at 7 AM Eastern Time (ET) after each trading day.\nTo unlock local access to the data updates, open thePricingpage of your organization and subscribe to theUS Index Option Universe - On Premise Bulk Download Updatesdata package.\nYou needbilling permissionsto change the organization's subscriptions.\n\nAfter you subscribe to dataset updates, to update your local copy of the US Index Option Universe dataset, use theCLI Command Generatorto generate your download command and then run it in a terminal in yourorganization workspace.\nAlternatively, instead of directly calling thelean data downloadcommand, you can place the following Python script in thedatadirectory of your organization workspace and run it to update your data files.\n\nimport os\nfrom datetime import datetime, time, timedelta\nfrom pytz import timezone\nfrom os.path import abspath, dirname\nos.chdir(dirname(abspath(__file__)))\n\nOVERWRITE = False\n\ndef __get_start_date() -> str:\ndir_name = f\"indexoption/usa/universes\"\nfiles = [] if not os.path.exists(dir_name) else sorted(os.listdir(dir_name))\nreturn files[-1].split(\".\")[0] if files else '19980101'\n\ndef __get_end_date() -> str:\nnow = datetime.now(timezone(\"US/Eastern\"))\nif now.time() > time(7, 0):\nreturn (now - timedelta(1)).strftime(\"%Y%m%d\")\nprint('New data is available at 07:00 AM EST')\nreturn (now - timedelta(2)).strftime(\"%Y%m%d\")\n\nif __name__ == \"__main__\":\nstart, end = __get_start_date(), __get_end_date()\nif start >= end:\nexit(\"Your data is already up to date.\")\n\ncommand = f'lean data download --dataset \"US Index Option Universe\" --data-type \"Bulk\" --start {start} --end {end}'\nif OVERWRITE:\ncommand += \" --overwrite\"\nprint(command)\nos.system(command)\n\nThe preceding script checks the date of the most recent US Index Option Universe data you have. If there is new data available, it downloads the new data files.\n\n### Size and Format\n\nThe US Index Option Universe dataset is 9 GB in size. We structure the data files so there is one file per underlying Index per day.\n\n### Price\n\nAll of the historical US Index Option Universe data costs $3,960. An annual subscription to daily updates costs $1,200/year.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4.4.2",
      "breadcrumb": "Datasets > QuantConnect > Download in Bulk > US Index Option Universe",
      "section_number": "4.4.2.11",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.5",
    "title": "Brokerages",
    "level": 2,
    "path": "Datasets > Brokerages",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect, you can use data from your brokerage.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nTo view the asset classes that are available for your brokerage, follow these steps:\n\nOpen theBrokeragespage.Click the name of your brokerage.In the table of contents, clickAsset Classes.\n\nThe brokerage data providers serve raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata in local deployments,download the US Futures Security Master.\n\n### Universe Selection\n\nIn local deployments,universe selectionis available with the brokerage data provider if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nFor live trading, you'll need to periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nIn cloud deployments, QuantConnect Cloud provides the universe selection datasets.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the brokerage data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download brokerage data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical <brokerageName> --data-type <data-type> --resolution <resolution> --security-type <security-type> --ticker <tickers> --market <market> --start <YYYYMMDD> --end <YYYYMMDD> <requiredBrokerageOptions>.\n\n$ lean data download --data-provider-historical \"Interactive Brokers\" --data-type Trade --resolution Daily --security-type Equity --ticker NVDA,AMD --market USA --start 20240303 --end 20240404 --ib-user-name userName --ib-account account --ib-password password\n\n$ lean data download --data-provider-historical Binance --data-type Trade --resolution Daily --security-type Crypto --ticker BTCUSDT,ETHUSDT --start 20240303 --end 20240404 --binance-exchange-name Binance binance-api-key apiKey --binance-api-secret apiSecret\n\nTo download Coinbase data, include the--market Coinbaseoption.\n\n$ lean data download --data-provider-historical \"Coinbase Advanced Trade\" --data-type Trade --resolution hour --security-type Crypto --ticker BTCUSD --market Coinbase --start 20230101 --end 20240404 --coinbase-api-name apiName --coinbase-api-private-key apiPrivateKey\n\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access brokerage data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical <brokerageName> <requiredBrokerageOptions>.\n\n$ lean research \"My Project\" --data-provider-historical \"Interactive Brokers\" --ib-user-name userName --ib-account account --ib-password password\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with data from your brokerage, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical <brokerageName> <requiredBrokerageOptions>.\n\n$ lean backtest \"My Project\" --data-provider-historical \"Interactive Brokers\" --ib-user-name userName --ib-account account --ib-password password\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with your brokerage data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical <brokerageName> <requiredBrokerageOptions>.$ lean optimize \"My Project\" --data-provider-historical \"Interactive Brokers\" --ib-user-name userName --ib-account account --ib-password passwordFollowthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select your brokerage and run the command in non-interactive mode. If you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses your brokerage as the data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-live <dataBrokerageName> <requiredDataBrokerageOptions> --brokerage <brokerageName> <requiredBrokerageOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-live \"Interactive Brokers\" --ib-user-name userName --ib-account account --ib-password password --brokerage \"Paper Trading\"\n\nDepending on the brokerage you select, you may need to provide somerequired brokerage options. To use a different provider for historical data, include the--data-provider-historicaloption. If you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\n### Pricing\n\nTo view the prices of your brokerage data, visit their website.\n\n### Supported Brokerages\n\nThe following table shows the brokerages that provide live (--data-provider-live) and historical (--data-provider-historical) data for research, backtesting, and optimization:\n\n[Table - 24 rows]\n\nFor brokerages that exclusively provide a live data feed, see thelean live deployreference.\n\nIf you have an ARM M1, M2, or M3 chip, Interactive Brokers is not supported, see theTroubleshooting.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Brokerages",
      "section_number": "4.5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Brokerage Name | Required Options |\n| --- | --- |\n| Alpaca | --alpaca-environment |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| --binance-use-testnet |  |\n| Bitfinex | --bitfinex-api-key |\n| --bitfinex-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| --bybit-vip-level |  |\n| CharlesSchwab | --charles-schwab-account-number |\n| Coinbase Advanced Trade | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| Interactive Brokers | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| TradeStation | --trade-station-environment |\n| --trade-station-account-id |  |"
  },
  {
    "id": "4.6",
    "title": "Alpha Vantage",
    "level": 2,
    "path": "Datasets > Alpha Vantage",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect or your brokerage, you can use Alpha Vantage for historical data if you're deploying a local project.\nThis page explains our integration with their API and its functionality.\nTo use Alpha Vantage, you need toget a freeorpremium API key.\n\nTo view the implementation of the Alpha Vantage integration, see theLean.DataSource.AlphaVantage repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nThe Alpha Vantage data provider serves asset price data directly fromAlpha Vantage's Time Series Stock Data APIs.\nOur integration supportsUS Equitysecurities.\nIt only provides the security price data, so you need todownload the US Equity Security Master.\n\n### Universe Selection\n\nUniverse selectionis available with the Alpha Vantage data provider if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nFor live trading, you'll need to periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS ETF ConstituentsUS Equity Coarse Universe\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the Alpha Vantage data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download Alpha Vantage data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical AlphaVantage --data-type Trade --resolution <resolution> --security-type EQUITY --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --alpha-vantage-api-key <apiKey> --alpha-vantage-price-plan <pricePlan>.\n\n$ lean data download --data-provider-historical AlphaVantage --data-type Trade --resolution Daily --security-type Equity --ticker NVDA,AMD --start 20240303 --end 20240404 --alpha-vantage-api-key apiKey --alpha-vantage-price-plan Free\n\nThe--alpha-vantage-price-planoption must be one of the following values:Free,Plan30,Plan75,Plan150,Plan300,Plan600, orPlan1200.\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access Alpha Vantage data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical AlphaVantage --alpha-vantage-api-key <apiKey> --alpha-vantage-price-plan <pricePlan>.\n\n$ lean research \"My Project\" --data-provider-historical AlphaVantage --alpha-vantage-api-key apiKey --alpha-vantage-price-plan Free\n\nThe--alpha-vantage-price-planoption must be one of the following values:Free,Plan30,Plan75,Plan150,Plan300,Plan600, orPlan1200.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with Alpha Vantage data, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical AlphaVantage --alpha-vantage-api-key <apiKey> --alpha-vantage-price-plan <pricePlan>.\n\n$ lean backtest \"My Project\" --data-provider-historical AlphaVantage --alpha-vantage-api-key apiKey --alpha-vantage-price-plan Free\n\nThe--alpha-vantage-price-planoption must be one of the following values:Free,Plan30,Plan75,Plan150,Plan300,Plan600, orPlan1200.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with Alpha Vantage data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical AlphaVantage --alpha-vantage-api-key <apiKey> --alpha-vantage-price-plan <pricePlan>.$ lean optimize \"My Project\" --data-provider-historical AlphaVantage --alpha-vantage-api-key apiKey --alpha-vantage-price-plan FreeThe--alpha-vantage-price-planoption must be one of the following values:Free,Plan30,Plan75,Plan150,Plan300,Plan600, orPlan1200.Followthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select Alpha Vantage and run the command in non-interactive mode.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses Alpha Vantage as the historical data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-historical AlphaVantage --alpha-vantage-api-key <apiKey> --alpha-vantage-price-plan <pricePlan> --brokerage <brokerageName> <requiredBrokerageOptions>.\nAlpha Vantage doesn't support streaming live data.\nThe paper trading brokerage also doesn't provide live data, so if you select it, you need to include--data-provider-live <liveDataProviderName> <requiredLivedataProviderOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-historical AlphaVantage --alpha-vantage-api-key apiKey --alpha-vantage-price-plan Free --brokerage \"Paper Trading\" --data-provider-live \"Custom data only\"\n\nThe--alpha-vantage-price-planoption must be one of the following values:Free,Plan30,Plan75,Plan150,Plan300,Plan600, orPlan1200.\nDepending on the brokerage you select, you may need to provide someadditional required options.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\n### Pricing\n\nTo view the prices of the Alpha Vantage API packages, see thePremium API Keypage on the Alpha Vantage website.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Alpha Vantage",
      "section_number": "4.6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.7",
    "title": "FactSet",
    "level": 2,
    "path": "Datasets > FactSet",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect or your brokerage, you can use data fromFactSetif you have the autheticationJSONfile.\nThis page explains our integration with their API and its functionality.\n\nTo view the implementation of the FactSet integration, see theLean.DataSource.FactSet repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Authetication\n\nTo access FactSet data, askFactSet Supportfor your autheticationJSONfile and then save it to your local machine. When you run any of the following commands, you'll provide the path to its location using the--factset-auth-config-fileoption. This file has the followingformat:\n\n[Metadata: unknown - ]\n\n### Supported Datasets\n\nThe FactSet data provider serves asset price data directly fromFactSet's Options API.\nOur integration supportsUS Index Optionssecurities.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the FactSet data provider for research and backtesting.\n\n### Download\n\nTo download FactSet data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical FactSet --data-type <data-type> --resolution Daily --security-type IndexOption --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --factset-auth-config-file=<auth.json>.\n\n$ lean data download --data-provider-historical FactSet --data-type Trade --resolution Daily --security-type IndexOption --ticker SPX --start 20240422 --end 20240423 --factset-auth-config-file=auth.json\n\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access FactSet data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical FactSet --factset-auth-config-file <auth.json>.\n\n$ lean research \"My Project\" --data-provider-historical FactSet --factset-auth-config-file auth.json\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with FactSet data, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical FactSet --factset-auth-config-file <auth.json>.\n\n$ lean backtest \"My Project\" --data-provider-historical FactSet --factset-auth-config-file auth.json\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with FactSet data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical FactSet --factset-auth-config-file <auth.json>.$ lean optimize \"My Project\" --data-provider-historical FactSet --factset-auth-config-file auth.jsonFollowthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select Polgyon and run the command in non-interactive mode. If you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses FactSet as the historical data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-historical FactSet --factset-auth-config-file <auth.json> --brokerage <brokerageName> <requiredBrokerageOptions>.\nFactSet doesn't support streaming live data.\nThe paper trading brokerage also doesn't provide live data, so if you select it, you need to include--data-provider-live <liveDataProviderName> <requiredLivedataProviderOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-historical FactSet --factset-auth-config-file auth.json --brokerage \"Paper Trading\" --data-provider-live \"Custom data only\"\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\n### Pricing\n\nTo learn more about FactSet data solutions and pricing, see theData Solutionspage on the FactSet website.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > FactSet",
      "section_number": "4.7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.8",
    "title": "IQFeed",
    "level": 2,
    "path": "Datasets > IQFeed",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect or your brokerage, you can use IQFeed if you're deploying a local project on Windows.\nThis page explains our integration with their API and its functionality.\nTo use IQFeed, you need tocreate an accountandinstall IQFeed Client.\n\nTo view the implementation of the IQFeed integration, see theLean.DataSource.IQFeed repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nOur IQFeed integration supports securities from the following asset classes:\n\nUS EquityUS Equity OptionsForex(listed on FXCM)US Futures\n\nThe IQFeed data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata in local deployments,download the US Futures Security Master.\n\n### Universe Selection\n\nIn local deployments,universe selectionis available with the IQFeed data provider if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nFor live trading, you'll need to periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS ETF ConstituentsUS Equity Coarse UniverseUS Equity Option Universe\n\nIn cloud deployments, QuantConnect Cloud provides the universe selection datasets.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the IQFeed data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download IQFeed data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical IQFeed --data-type <data-type> --resolution <resolution> --security-type <security-type> --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --iqfeed-username <username> --iqfeed-password <password>.\n\n$ lean data download --data-provider-historical IQFeed --data-type Trade --resolution Daily --security-type Equity --ticker NVDA,AMD --start 20240303 --end 20240404 --iqfeed-username username --iqfeed-password password\n\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access IQFeed data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical IQFeed --iqfeed-username <username> --iqfeed-password <password>.\n\n$ lean research \"My Project\" --data-provider-historical IQFeed --iqfeed-username username --iqfeed-password password\n\nThelean researchcommand also accepts additionaloptionsfor IQFeed.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with IQFeed data, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical IQFeed --iqfeed-username <username> --iqfeed-password <password>.\n\n$ lean backtest \"My Project\" --data-provider-historical IQFeed --iqfeed-username username --iqfeed-password password\n\nThelean backtestcommand also accepts additionaloptionsfor IQFeed.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with IQFeed data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical IQFeed --iqfeed-username <username> --iqfeed-password <password>.$ lean optimize \"My Project\" --data-provider-historical IQFeed --iqfeed-username username --iqfeed-password passwordFollowthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select IQFeed and run the command in non-interactive mode.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses IQFeed as the data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-live IQFeed --iqfeed-username <username> --iqfeed-password <password> --brokerage <brokerageName> <requiredBrokerageOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-live IQFeed --iqfeed-username username --iqfeed-password password --brokerage \"Paper Trading\"\n\nThelean live deploycommand also accepts additionaloptionsfor IQFeed.\nDepending on the brokerage you select, you may need to provide somerequired brokerage options.\nTo use a different provider for historical data, include the--data-provider-historicaloption.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\nTo deploy the live algorithm through the interactive mode of the CLI, seeIQFeed.\n\n### Pricing\n\nTo view the prices of the IQFeed services, see theIQFeed Core Service Feespage on the DTN IQFeed Help Site.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > IQFeed",
      "section_number": "4.8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.9",
    "title": "Polygon",
    "level": 2,
    "path": "Datasets > Polygon",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect or your brokerage, you can use data fromPolygonif you have an API key. To get an API key, see theAPI Keyspage on the Polygon website\n\nTo view the implementation of the Polygon integration, see theLean.DataSource.Polygon repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nOur Polygon integration supports securities from the following asset classes:\n\nUS EquityUS Equity OptionsUS IndicesUS Index Options\n\nThe Polygon data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\n\n### Universe Selection\n\nIn local deployments,universe selectionis available with the Polygon data provider if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nFor live trading, you'll need to periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nIn cloud deployments, QuantConnect Cloud provides the universe selection datasets.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the Polygon data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download Polygon data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical Polygon --data-type <data-type> --resolution <resolution> --security-type <security-type> --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --polygon-api-key <apiKey>.\n\n$ lean data download --data-provider-historical Polygon --data-type Trade --resolution Hour --security-type Equity --ticker SOFI,TSLA,NIO --start 20200101 --end 20240404 --polygon-api-key apiKey\n\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access Polygon data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical Polygon --polygon-api-key <apiKey>.\n\n$ lean research \"My Project\" --data-provider-historical Polygon --polygon-api-key apiKey\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with Polygon data, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical Polygon --polygon-api-key <apiKey>.\n\n$ lean backtest \"My Project\" --data-provider-historical Polygon --polygon-api-key apiKey\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with Polygon data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical Polygon --polygon-api-key <apiKey>.$ lean optimize \"My Project\" --data-provider-historical Polygon --polygon-api-key apiKeyFollowthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select Polgyon and run the command in non-interactive mode.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses Polygon as the data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-live Polygon --polygon-api-key <apiKey> --brokerage <brokerageName> <requiredBrokerageOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-live Polygon --polygon-api-key apiKey --brokerage \"Paper Trading\"\n\nDepending on the brokerage you select, you may need to provide somerequired brokerage options.\nTo use a different provider for historical data, include the--data-provider-historicaloption.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\nTo deploy the algorithm in QuantConnect Cloud while still using Polygon as the data provider, runlean cloud live deploy <projectName> --data-provider-live Polygon --polygon-api-key <apiKey> --brokerage <brokerageName> <requiredBrokerageOptions> --node <nodeName> --auto-restart <enableAutoRestarts> --notify-order-events <enableOrderEventNotifications> --notify-insights <enableInsightNotifications> <requiredNotificationOptions>.\n\n$ lean cloud live deploy \"My Project\" --data-provider-live Polygon --polygon-api-key apiKey --brokerage \"Paper Trading\" --node \"My Node\" --auto-restart yes --notify-order-events no --notify-insights no\n\nTo deploy the live algorithm through the interactive mode of the CLI, seePolygon.\n\n### Pricing\n\nTo view the prices of the Polygon API packages, see theSimple Pricingpage on the Polygon website.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Polygon",
      "section_number": "4.9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.10",
    "title": "Terminal Link",
    "level": 2,
    "path": "Datasets > Terminal Link",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect, you can use data from Bloomberg EMSX through Terminal Link if you're in an organization on theInstitution tier.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nTerminal Link supports securities from the following asset classes:\n\nUS EquityUS Equity OptionsUS FuturesUS Index Options\n\nTerminal Link serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata in local deployments,download the US Futures Security Master.\n\n### Universe Selection\n\nIn local deployments,universe selectionis available with Terminal Link if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nFor live trading, you'll need to periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nIn cloud deployments, QuantConnect Cloud provides the universe selection dataset.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the Terminal Link data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download Bloomberg DAPI data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical \"Terminal Link\" --data-type <data-type> --resolution <resolution> --security-type <security-type> --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --terminal-link-connection-type DAPI --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey>.\n\n$ lean data download --data-provider-historical \"Terminal Link\" --data-type Trade --resolution Daily --security-type Equity --ticker NVDA,AMD --start 20240303 --end 20240404 --terminal-link-connection-type DAPI --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKey\n\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access Bloomberg DAPI data from the local Research Environment through Terminal Link, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey>.\n\n$ lean research \"My Project\" --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKey\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with Terminal Link that uses data from the Bloomberg DAPI, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey>.\n\n$ lean backtest \"My Project\" --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKey\n\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with data from Bloomberg DAPI through Terminal Link:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey>.$ lean optimize \"My Project\" --data-provider-historical \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKeyFollowthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select Terminal Link and run the command in non-interactive mode.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses Terminal Link as the data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-live \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-account <emsxAccount> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey> --brokerage <brokerageName> <requiredBrokerageOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-live \"Terminal Link\" --terminal-link-connection-type DAPI --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-account emsxAccount --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKey --brokerage \"Paper Trading\"\n\nDepending on the brokerage you select, you may need to provide somerequired brokerage options.\nTo use a different provider for historical data, include the--data-provider-historicaloption.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\nTo deploy the algorithm in QuantConnect Cloud while still using Terminal Link as the data provider, runlean cloud live deploy <projectName> --data-provider-live \"Terminal Link\" --terminal-link-environment <environment> --terminal-link-server-host <serverHost> --terminal-link-server-port <serverPort> --terminal-link-emsx-account <emsxAccount> --terminal-link-emsx-broker <emsxBroker> --terminal-link-openfigi-api-key <openfigiApiKey> --brokerage <brokerageName> <requiredBrokerageOptions> --node <nodeName> --auto-restart <enableAutoRestarts> --notify-order-events <enableOrderEventNotifications> --notify-insights <enableInsightNotifications> <requiredNotificationOptions>.\n\n$ lean cloud live deploy \"My Project\" --data-provider-live \"Terminal Link\" --terminal-link-environment Production --terminal-link-server-host serverHost --terminal-link-server-port serverPort --terminal-link-emsx-account emsxAccount --terminal-link-emsx-broker emsxBroker --terminal-link-openfigi-api-key openfigiApiKey --brokerage \"Paper Trading\" --node \"My Node\" --auto-restart yes --notify-order-events no --notify-insights no\n\nTo deploy the live algorithm through the interactive mode of the CLI, seeDeploy Local AlgorithmsorDeploy Cloud Algorithms.\n\n### Pricing\n\nTo view the prices of Bloomberg’s Execution Management Solutions, seeExecution Management Systemon the Bloomberg website.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Terminal Link",
      "section_number": "4.10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "4.11",
    "title": "Theta Data",
    "level": 2,
    "path": "Datasets > Theta Data",
    "content": "### Introduction\n\nInstead of using the data from QuantConnect or your brokerage, you can use Theta Data if you're deploying a local project.\nThis page explains our integration with their API and its functionality.\nTo use Theta Data, you need toinstall and launch the Theta Terminal.\n\nTo view the implementation of the Theta Data integration, see theLean.DataSource.ThetaData repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Datasets\n\nOur Theta Data integration supports securities from the following asset classes:\n\nEquityEquity OptionsIndexIndex Options\n\nThe Theta Data data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\n\n### Alternative Data\n\nIf you have licensed alternative data with QuantConnect, it works as expected with the Theta Data data provider for research, backtesting, and live trading.\n\n### Download\n\nTo download Theta Data data, open a terminal in yourorganization workspaceand then runlean data download --data-provider-historical ThetaData --data-type <data-type> --resolution <resolution> --security-type <security-type> --ticker <tickers> --start <YYYYMMDD> --end <YYYYMMDD> --thetadata-subscription-plan <plan>.\n\n$ lean data download --data-provider-historical ThetaData --data-type Trade --resolution Daily --security-type Option --ticker NVDA,AMD --start 20240303 --end 20240404 --thetadata-subscription-plan Standard\n\nThe--thetadata-subscription-planoption must beFree,Value,Standard, orPro.\nIf you provide your credentials, yourLean configuration filesaves them.\n\n### Research\n\nTo access Theta Data data from the local Research Environment, open a terminal in yourorganization workspaceand then runlean research <projectName> --data-provider-historical ThetaData --thetadata-subscription-plan <plan>.\n\n$ lean research \"My Project\" --data-provider-historical ThetaData --thetadata-subscription-plan Standard\n\nThe--thetadata-subscription-planoption must beFree,Value,Standard, orPro.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean research <projectName>to open the Research Environment with the same options.\n\n### Backtesting\n\nTo run a local backtest with data from Theta Data, open a terminal in yourorganization workspaceand then runlean backtest <projectName> --data-provider-historical ThetaData --thetadata-subscription-plan <plan>.\n\n$ lean backtest \"My Project\" --data-provider-historical ThetaData --thetadata-subscription-plan Standard\n\nThe--thetadata-subscription-planoption must beFree,Value,Standard, orPro.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean backtest <projectName>to run another backtest with the same options.\n\n### Optimization\n\nFollow these steps to run a local optimization job with data from Theta Data:\n\nAdd someparametersto your project.Open a terminal in yourorganization workspace.Runlean optimize <projectName> --data-provider-historical ThetaData --thetadata-subscription-plan <plan>.$ lean optimize \"My Project\" --data-provider-historical ThetaData --thetadata-subscription-plan StandardThe--thetadata-subscription-planoption must beFree,Value,Standard, orPro.Followthe steps in the interactive wizardto configure your optimization job settings.\n\nThelean optimizecommand also accepts additionaloptionsso that you can select Theta Data and run the command in non-interactive mode.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean optimize <projectName>to run another optimization job with the same options.\n\n### Live Trading\n\nTo deploy a local live algorithm that uses Theta Data as the data provider, open a terminal in yourorganization workspaceand then runlean live deploy <projectName> --data-provider-live ThetaData --thetadata-subscription-plan <plan> --brokerage <brokerageName> <requiredBrokerageOptions>.\n\n$ lean live deploy \"My Project\" --data-provider-live ThetaData --thetadata-subscription-plan Standard --brokerage \"Paper Trading\"\n\nThe--thetadata-subscription-planoption must beFree,Value,Standard, orPro.\nDepending on the brokerage you select, you may need to provide somerequired brokerage options.\nTo use a different provider for historical data, include the--data-provider-historicaloption.\nIf you provide any of the preceding options, yourLean configuration filesaves them so that you only need to runlean live deploy <projectName> --brokerage <brokerageName>to deploy another live algorithm with the same options.\n\nTo deploy the live algorithm through the interactive mode of the CLI, seeThetaData.\n\nThe CLI doesn't currently support deploying cloud algorithms with the Theta Data data provider.\n\n### Pricing\n\nTo view the prices of the Theta Data API packages, see thePricingpage on the Theta Data website.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Datasets > Theta Data",
      "section_number": "4.11",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5",
    "title": "Projects",
    "level": 1,
    "path": "Projects",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Projects",
      "section_number": "5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.1",
    "title": "Project Management",
    "level": 2,
    "path": "Projects > Project Management",
    "content": "### Introduction\n\nCreating new projects is an important feature of the Lean CLI.\nThe CLI can automatically scaffold basic Python and C# projects, creating basic algorithm files, research notebooks, and the required editor configuration.\nProjects scaffolded by the CLI are similar to the ones created on QuantConnect, making it easy to switch between your local environment and the cloud.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Create Projects\n\nFollow these steps to create a new Python project:\n\nOpen a terminal in one of yourorganization workspaces.Runlean project-create --language python \"<projectName>\"to create a new project named<projectName>.$ lean project-create --language python \"My Python Project\"\nSuccessfully created Python project 'My Python Project'This command creates the. / <projectName>directory and creates a simplemain.pyfile, a Python-based research notebook, aproject configuration file, and editor configuration for PyCharm and VS Code.\n\nFollow these steps to create a new C# project:\n\nOpen a terminal in one of yourorganization workspaces.Runlean project-create --language csharp \"<projectName>\"to create a new C# project named<projectName>.$ lean project-create --language csharp \"My CSharp Project\"\nSuccessfully created C# project 'My CSharp Project'This command creates the. / <projectName>directory and creates a simpleMain.csfile, a C#-based research notebook, aproject configuration file, and editor configuration for Visual Studio, Rider, and VS Code.\n\nThe project name must only contain-,_, letters, numbers, and spaces. The project name can't start with a space or be any of the following reserved names: CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, or LPT9.\n\nYou can provide a project name containing forward slashes to create a project in a sub-directory.\nIn case any of the given sub-directories does not exist yet, the CLI creates them for you.\n\n### Set the Default Language\n\nIt is also possible to set the default language to use when runninglean project-create:\n\nRunlean config set default-language pythonto set the default language to Python, after which you no longer need to provide the--language pythonoption to create Python projects.$ lean config set default-language python\n$ lean project-create \"My Python Project\"\nSuccessfully created Python project 'My Python Project'Runlean config set default-language csharpto set the default language to C#, after which you no longer need to provide the--language csharpoption to create C# projects.$ lean config set default-language csharp\n$ lean project-create \"My CSharp Project\"\nSuccessfully created C# project 'My CSharp Project'\n\n### Rename Projects\n\nFollow these steps to rename a project that you have on your local machine and in QuantConnect Cloud:\n\nOpen theorganization workspaceson your local machine where you store the project.Rename the project file.The project name must only contain-,_, letters, numbers, and spaces. The project name can't start with a space or be any of the following reserved names: CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, or LPT9.Log into the CLI if you haven't done so already.Open a terminal in the same organization workspace.Runlean cloud push --project \"<projectName>\".\n\n$ lean cloud push --project \"My Renamed Project\"\n[1/1] Pushing \"My Renamed Project\"\nRenaming project in the cloud from 'My Project' to 'My Renamed Project'\nSuccessfully updated name and files and libraries for 'My Project'\n\nAlternatively, you canrename the projectin QuantConnect Cloud and thenpull the projectto your local machine.\n\n### Delete Projects\n\nFollow these steps to delete a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat stores the project.Runlean project-delete \"<projectName>\".\n\n$ lean project-delete \"My Project\"\nSuccessfully deleted project 'My Project'\n\nThis command deletes the project on your local machine and in QuantConnect Cloud.\n\nIf you are a collaborator on the project, this command doesn't delete the project for the other collaborators, but it removes you as a collaborator.\n\n### Get Project Id\n\nTo get the project Id, open the<organizationWorkspace>/ <projectName> / config.jsonfile and look for the value of thelocal-idorcloud-idkey. An example project Id is 13946911.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Project Management",
      "section_number": "5.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.2",
    "title": "Cloud Synchronization",
    "level": 2,
    "path": "Projects > Cloud Synchronization",
    "content": "### Introduction\n\nCloud synchronization allows you to synchronize your projects in QuantConnect Cloud with your local drive using the Lean CLI.\nCloud synchronization makes it possible to use your local development environment when writing your algorithms while using QuantConnect's infrastructure and data library when executing them.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Pulling Cloud Projects\n\nFollow these steps to pull all the cloud projects that you store in anorganizationto your local drive:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacefrom which you want to pull projects.Runlean cloud pullto pull all your cloud projects to the current directory, creating directories where necessary.$ lean cloud pull\n[1/3] Pulling 'Creative Red Mule'\nSuccessfully pulled 'Creative Red Mule/main.py'\n[2/3] Pulling 'Determined Yellow-Green Duck'\nSuccessfully pulled 'Determined Yellow-Green Duck/main.py'\nSuccessfully pulled 'Determined Yellow-Green Duck/research.ipynb'\n[3/3] Pulling 'Halloween Strategy'\nSuccessfully pulled 'Halloween Strategy/benchmark.py'\nSuccessfully pulled 'Halloween Strategy/main.py'\nSuccessfully pulled 'Halloween Strategy/research.ipynb'Update your projects toinclude the required importsto run the projects locally and to make autocomplete work.\n\nFollow these steps to pull a single cloud project to your local drive:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat stores the project.Runlean cloud pull --project \"<projectName>\"to pull the project named \"<projectName>\" to. / <projectName>.$ lean cloud pull --project \"My Project\"\n[1/1] Pulling 'My Project'\nSuccessfully pulled 'My Project/main.py'\nSuccessfully pulled 'My Project/research.ipynb'Update your project toinclude the required importsto run the project locally and to make autocomplete work.\n\nIf you have a local copy of the project when you pull the project from the cloud, the configuration values of the cloud project overwrite theconfiguration values of your local copy.\n\nIf one of your team members creates aproject library, adds it to a project, and then adds you as a collaborator to the project, you can pull the project but not the library. To pull the library as well, your team member must add you as a collaborator on the library project.\n\n### Pushing Local Projects\n\nFollow these steps to push all the local projects in anorganization workspaceto the cloud:\n\nLog into the CLI if you haven't done so already.Open a terminal in the organization workspace.Runlean cloud pushto push all your local projects in the organization to the cloud, creating new cloud projects where necessary.$ lean cloud push\n[1/3] Pushing 'Alpha'\nSuccessfully created cloud project 'Alpha'\nSuccessfully created cloud file 'Alpha/benchmark.py'\nSuccessfully updated cloud file 'Alpha/main.py'\nSuccessfully updated cloud file 'Alpha/research.ipynb'\n[2/3] Pushing 'Buy and Hold BNBUSDT'\nSuccessfully created cloud project 'Buy and Hold BNBUSDT'\nSuccessfully updated cloud file 'Buy and Hold BNBUSDT/main.py'\nSuccessfully updated cloud file 'Buy and Hold BNBUSDT/research.ipynb'\n[3/3] Pushing 'Creative Red Mule'\nSuccessfully updated cloud file 'Creative Red Mule/main.py'\n\nFollow these steps to push a single local project to the cloud:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project you want to push.Runlean cloud push --project \"<projectName>\"to push the project stored in. / <projectName>to the cloud.$ lean cloud push --project \"My Project\"\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\n\nIf you create a project on your local machine and push it to the cloud, thelean cloud pushcommand creates the cloud version of the project in the organization that's linked to your current organization workspace.\n\nIf you have a cloud copy of the project when you push the project from your local machine, theconfiguration values of your local projectoverwrite the configuration values of your cloud copy.\n\nThe CLI only pushes thesupported file typesin your projects.\n\n### Detecting Environment\n\nSometimes it might be useful to run certain logic only when your algorithm is running locally, or when it is running in the cloud.\nYou can use the following code snippet to check where your algorithm is running (replaceComputerwith your computer's hostname):\n\nusing System;\n\nif (Environment.MachineName == \"Computer\")\n{\n// Running locally\n}\nelse\n{\n// Running in the cloud\n}import platform\n\nif platform.node() == \"Computer\":\n# Running locally\npass\nelse:\n# Running in the cloud\npass",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Cloud Synchronization",
      "section_number": "5.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.3",
    "title": "Structure",
    "level": 2,
    "path": "Projects > Structure",
    "content": "### Introduction\n\nWhen you run thelean project-createorlean cloud pullcommands, the CLI creates the basic files and folders most editors need to open your source code, provide autocomplete, and enable local debugging. This page documents exactly which files are created when you create a new local project withlean project-createorlean cloud pull.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Project Structure\n\nNew projects have the following structure:\n\n.\n├── .idea/\n│   ├── misc.xml\n│   ├── modules.xml\n│   ├── <projectName>.iml\n│   └── workspace.xml\n├── .vscode/\n│   ├── launch.json\n│   └── settings.json\n├── config.json\n├── main.py (only generated by lean project-create)\n└── research.ipynb (only generated by lean project-create)\n\n.\n├── .vscode/\n│   └── launch.json\n├── config.json\n├── <projectName>.csproj\n├── Main.cs (only generated by lean project-create)\n└── Research.ipynb (only generated by lean project-create)\n\nThese files contain the following content:\n\n[Table - 7 rows]\n\n[Table - 5 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Structure",
      "section_number": "5.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| File | Content |\n| --- | --- |\n| .idea / misc.xml,.idea / modules.xml,.idea / <projectName>.iml | These files contain PyCharm configuration so PyCharm can provide accurate autocomplete. |\n| .idea / workspace.xml | This file contains debug configuration to make debugging with PyCharm easier. |\n| .vscode / launch.json | This file contains debug configuration to make debugging with VS Code easier. |\n| .vscode / settings.json | This file contains VS Code configuration so that VS Code's Python and Pylance extensions can provide accurate autocomplete. |\n| config.json | This file contains theproject configurationof the created project. |\n| main.py | This file contains a basic Python algorithm to help you get started. |\n| research.ipynbResearch.ipynb | This file contains a Python-based research notebook that can be opened in aResearch Environment. |",
    "table_1": "| File | Content |\n| --- | --- |\n| .vscode / launch.json | This file contains debug configuration to make debugging with VS Code easier. |\n| config.json | This file contains theproject configurationof the created project. |\n| <projectName>.csproj | This file contains project configuration which Visual Studio, Rider, and VS Code can read to provide accurate C# autocomplete. |\n| Main.cs | This file contains a basic C# algorithm to help you get started. |\n| research.ipynb | This file contains a C#-based research notebook which can be opened in aresearch environment. |"
  },
  {
    "id": "5.4",
    "title": "Workflows",
    "level": 2,
    "path": "Projects > Workflows",
    "content": "### Introduction\n\nThe Lean CLI supports multiple workflows, ranging from running everything locally to just using your local development environment but keeping all execution in the cloud.\nThis page contains several examples of common workflows, but you're free to mix local and cloud features in any way you'd like.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Cloud-focused Workflow\n\nA cloud-focused workflow (local development, cloud execution) with the CLI might look like this:\n\nOpen a terminal in one of yourorganization workspaces.Runlean cloud pullto pull remotely changed files.Start programming locally and run backtests in the cloud withlean cloud backtest \"<projectName>\" --open --pushwhenever there is something to backtest. The--openflag means that the backtest results are opened in the browser when done, while the--pushflag means that local changes are pushed to the cloud before running the backtest.Whenever you want to create a new project, runlean project-create \"<projectName>\" --pushandlean cloud push --project \"<projectName>\"to create a new project containing some basic code and to push it to the cloud.When you're finished for the moment, runlean cloud pushto push all locally changed files to the cloud.\n\nThe advantage of this workflow is that you can use all the tools in your local development environment to write your code (i.e. autocomplete, auto-formatting, etc.) while using QuantConnect's computing infrastructure and data when running your code.\nThis advantage means you don't need to have a powerful computer and you don't need to have your own data, since that's all provided by us.\nThe downside to this workflow is that you need a constant internet connection because without an internet connection the CLI can't communicate with the cloud.\n\n### Locally-focused Workflow\n\nA locally-focused workflow (local development, local execution) with the CLI might look like this:\n\nOpen a terminal in one of yourorganization workspaces.Runlean project-create \"<projectName>\"to create a new project with some basic code to get you started.Work on your strategy in. / <projectName>.Runlean research \"<projectName>\"to start a Jupyter Lab session to perform research.Runlean backtest \"<projectName>\"to run a backtest whenever there's something to test. This command runs your strategy in a Docker container containing the same packages as the ones used on QuantConnect.com, but with your own data.Whenever you want to debug a strategy in your local development environment, seeDebugging.\n\nWith this workflow, you are not limited to the computing power that's available in QuantConnect's infrastructure, because everything runs locally.\nOn the other hand, this also means you must have all your required data available locally.\nTo download some of QuantConnect's data for local usage, seeDownloading Data.\n\n### Mixed Workflow\n\nA mixed workflow (local development, local debugging, and cloud execution) with the CLI might look like this:\n\nOpen a terminal in one of yourorganization workspaces.Runlean cloud pullto pull remotely changed files.Start programming on your strategies.Whenever you want to debug a strategy in your local development environment, seeDebugging.Whenever you want to backtest a strategy, runlean cloud backtest \"<projectName>\" --open --pushto push local changes to the cloud, run a backtest in the cloud, and open the results in the browser once finished.When you're finished for the moment, runlean cloud pushto push all locally changed files in the organization workspace to the cloud.\n\nThe advantage of this workflow is that you can use your local development environment and its debugging tools when writing your algorithms while using QuantConnect's infrastructure and data in backtesting and live trading.\nAlthough this does require you to have a local copy of the data that your strategy needs, it doesn't require you to maintain your own infrastructure and data feeds in live trading. To download some of QuantConnect's data for local usage, seeDownloading Data.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Workflows",
      "section_number": "5.4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.5",
    "title": "Encryption",
    "level": 2,
    "path": "Projects > Encryption",
    "content": "### Introduction\n\nYou can save encrypted versions of your project files on your local machine and in QuantConnect Cloud instead of the raw, human readable, file content. To use the encryption system, you provide your own encryption key. The encryption key file must be a txt file with at least 32 characters. It’s content can be arbitrary.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Encrypt Projects\n\nTo encrypt a local project, runlean encrypt \"<projectName>\" --key \"<keyPath>\".\n\n$ lean encrypt \"My Project\" --key \"C:\\Users\\john\\qc-encryption-key.txt\"\nLocal files encrypted successfully with key C:\\Users\\john\\qc-encryption-key.txt\n\nTopushan encrypted version of a local project to QuantConnect Cloud,add your encryption key to your browserand then runlean cloud push --project \"<projectName>\" --encrypt --key \"<keyPath>\".\nIf your local project is unencrypted when you run this command, the project sent to QuantConnect Cloud is encrypted but the project on your local machine remains unencrypted.\nIf your local project is unencrypted and has alibrarywhen you run this command, the project sent to QuantConnect Cloud is encrypted but the library sent to QuantConnect Cloud remains unencrypted.\n\n$ lean cloud push --project \"My Project\" --encrypt --key \"C:\\Users\\john\\qc-encryption-key.txt\"\n[1/1] Pushing 'My Project'\nSuccessfully created cloud project 'My Project' in organization 'd6d62db48592c72e67b534553413b691'\nSuccessfully updated name, files, and libraries for 'My Project'\n\nTopullan encrypted version of a project in QuantConnect Cloud to your local machine, runlean cloud pull --project \"<projectName>\" --encrypt --key \"<keyPath>\". If your cloud project isn't encrypted when you run this command, the project you pull to your local machine is encrypted but the project in the cloud remains unencrypted.\n\n$ lean cloud pull --project \"My Project\" --encrypt --key \"C:\\Users\\john\\qc-encryption-key.txt\"\n[1/1] Pulling 'My Project'\nSuccessfully pulled 'My Project/main.py'\nSuccessfully pulled 'My Project/research.ipynb'\n\n### Decrypt Projects\n\nTo decrypt a local project, runlean decrypt \"<projectName>\" --key \"<keyPath>\".\n\n$ lean decrypt \"My Project\" --key \"C:\\Users\\john\\qc\\encryption-key.txt\"\nSuccessfully decrypted project C:\\Users\\john\\qc\\workspaces\\AI Capital\\My Project\n\nTopulla decrypted version of a project in QuantConnect Cloud to your local machine, runlean cloud pull --project \"<projectName>\" --decrypt --key \"<keyPath>\". If your cloud project is encrypted when you run this command, the project you pull to your local machine is decrypted but the project in the cloud remains encrypted.\n\n$ lean cloud pull --project \"My Project\" --decrypt --key \"C:\\Users\\john\\qc\\encryption-key.txt\"\n[1/1] Pulling 'My Project'\nSuccessfully pulled 'My Project/main.py'\nSuccessfully pulled 'My Project/research.ipynb'\n\nTopusha decrypted version of a local project to QuantConnect Cloud, runlean cloud push --project \"<projectName>\" --decrypt --key \"<keyPath>\". If your local project is encrypted when you run this command, the project you push to the cloud is decrypted but the project on your local machine remains encrypted.\n\n$ lean cloud push --project \"My Project\" --decrypt --key \"C:\\Users\\john\\qc\\encryption-key.txt\"\n[1/1] Pushing 'My Project'\nSuccessfully created cloud project 'My Project' in organization 'd6d62db48592c72e67b534553413b691'\nSuccessfully updated name, files, and libraries for 'My Project'\n\n### Collaboration Support\n\nEncryption isn’t available for projects that havecollaborators.\n\n### Libraries\n\nEncrypted projects can uselibrariesencrypted with the same project key or unencrypted libraries. However, you cannot use a library encrypted with a different project encryption key.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Encryption",
      "section_number": "5.5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.6",
    "title": "Configuration",
    "level": 2,
    "path": "Projects > Configuration",
    "content": "### Introduction\n\nProject-specific configuration is stored in the project directory in theconfig.jsonfile.\nThis file is automatically generated when you runlean project-createorlean cloud pull.\nJust like the global and Lean configuration files, the project configuration is stored as JSON but without support for comments.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Properties\n\nThe following properties are stored in theconfig.jsonfile:\n\n[Table - 12 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Configuration",
      "section_number": "5.6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Property | Description |\n| --- | --- |\n| description | This property contains the project's description, which is displayed in backtest reports. It must always be a string. |\n| parameters | This property is a key/value object containing the project's parameters. Both the keys and the values must be strings. To load parameter values into your algorithm, seeGet Parameters. The parameter values are sent to your algorithm when you deploy the algorithm, so it's not possible to change the parameter values while the algorithm runs. |\n| cloud-id | This property is set automatically after the project has been pulled from or pushed to the cloud. It contains the id of the project's counterpart in the cloud and must not be modified or removed manually. |\n| local-id | This property is set automatically when the CLI needs to uniquely identify the current project. It contains a unique id that is specific to the project and must not be modified or removed manually. |\n| libraries | This property is set automatically when you add aproject libraryto the project. It contains a list of dictionaries that hold the name and path of each library. |\n| organization-id | This property is set automatically after the project has been pulled from or pushed to the cloud. It contains the Id of the organization that the project is saved to in the cloud. |\n| algorithm-language | This property contains the language of the project. It is automatically set when the project is created and must not be modified or removed manually. |\n| docker | This property is a key/value object containing the docker instance's \"environment\" and \"ports\" command line run arguments. For example, to expose host port 999 to internal port 6006, write\"docker\": { \"ports\": { \"999\": \"6006\"} }. |\n| lean-engine | This property is the version number of theLEAN Engine versionthat the project uses. |\n| python-venv | This property is an integer that represents thePython environmentthat the project uses. |\n| encrypted | This property is automatically set when you encrypt or decrypt a project. It's a boolean that represents if the local project is currently encrypted. |\n| encryption-key-path | This property is automatically set when the local project is currently encrypted. It's a string that represents the path to the file that contains the encryption key. |"
  },
  {
    "id": "5.7",
    "title": "Autocomplete",
    "level": 2,
    "path": "Projects > Autocomplete",
    "content": "### Introduction\n\nLocal autocomplete is an important feature of the Lean CLI, making you more productive in your local development environment.\nThe CLI automatically generates the necessary editor configuration when creating new projects to make local autocomplete almost seamless for most popular editors.\nHowever, not everything can be configured automatically.\nThis page explains how to make local autocomplete work for Python and C# with all editors supported by the CLI.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Python and PyCharm\n\nFollow these steps to set up local autocomplete for Python in PyCharm:\n\nOpen a project directory, generated by the CLI, with PyCharm and wait for the project to load.Wait for PyCharm to index all packages and autocomplete starts working.Update your project toinclude the required imports.\n\n### Python and VS Code\n\nFollow these steps to set up local autocomplete for Python in VS Code:\n\nInstall thePythonandPylanceextensions in VS Code.Open a project directory, generated by the CLI, with VS Code and Python autocomplete works automatically.Update your project toinclude the required imports.\n\n### C# and Visual Studio\n\nFollow these steps to set up local autocomplete for C# in Visual Studio:\n\nMake sure the .NET 6.0 Runtime is installed in the Visual Studio Installer by clickingModifyin the installed Visual Studio version and opening theIndividual componentstab on the window that shows up.ClickOpen a project or solutionon Visual Studio's home screen and open the.csprojfile in one of the project directories generated by the CLI. Visual Studio automatically downloads the required dependencies and indexes them to provide autocomplete.Update your project toinclude the required imports.\n\n### C# and Rider\n\nFollow these steps to set up local autocomplete for C# in Rider:\n\nMake sure the.NET 6.0 Runtimeis installed.Open the.csprojfile in a project directory, generated by the CLI, with Rider and wait for the project to load. Rider automatically downloads the required dependencies and indexes them to provide autocomplete.Update your project toinclude the required imports.\n\n### C# and VS Code\n\nFollow these steps to set up local autocomplete for C# in VS Code:\n\nMake sure the.NET 6.0 Runtimeis installed.Install theC#extension in VS Code.Open a project directory, generated by the CLI, with VS Code and wait for the project to load.ClickRestoreif a pop-up shows in the bottom-right telling you there are dependencies to restore.Update your project toinclude the required imports.\n\n### Imports\n\nSome imports are automatically added to your files when you run them in the cloud.\nThis does not happen locally, so in your local environment, you need to manually import all the classes that you use.\nYou can copy the following code snippet to the top of every file to have the same imports as the ones used in the cloud:\n\nusing System;\nusing System.Collections;\nusing System.Collections.Generic;\nusing System.Drawing;\nusing System.Globalization;\nusing System.Linq;\nusing QuantConnect;\nusing QuantConnect.Parameters;\nusing QuantConnect.Benchmarks;\nusing QuantConnect.Brokerages;\nusing QuantConnect.Util;\nusing QuantConnect.Interfaces;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Algorithm.Framework;\nusing QuantConnect.Algorithm.Framework.Selection;\nusing QuantConnect.Algorithm.Framework.Alphas;\nusing QuantConnect.Algorithm.Framework.Portfolio;\nusing QuantConnect.Algorithm.Framework.Execution;\nusing QuantConnect.Algorithm.Framework.Risk;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Data.Custom;\nusing QuantConnect.Data.Fundamental;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.UniverseSelection;\nusing QuantConnect.Notifications;\nusing QuantConnect.Orders;\nusing QuantConnect.Orders.Fees;\nusing QuantConnect.Orders.Fills;\nusing QuantConnect.Orders.Slippage;\nusing QuantConnect.Scheduling;\nusing QuantConnect.Securities;\nusing QuantConnect.Securities.Equity;\nusing QuantConnect.Securities.Forex;\nusing QuantConnect.Securities.Interfaces;\nusing QuantConnect.Python;\nusing QuantConnect.Storage;from AlgorithmImports import *\n\n### Staying Up-to-date\n\nFollow these steps to update Python autocomplete to be aware of the latest changes to LEAN:\n\nOpen a terminal.Runpip install --upgrade quantconnect-stubsto update the Python autocomplete.$ pip install --upgrade quantconnect-stubs\nCollecting quantconnect-stubs\nInstalling collected packages: quantconnect-stubs\nSuccessfully installed quantconnect-stubs-11657\n\nFollow these steps to update C# autocomplete to be aware of the latest changes to LEAN:\n\nOpen a terminal in one of yourorganization workspaces.Rundotnet add \"<projectName>\" package QuantConnect.Leanto update the C# autocomplete for the project in. / <projectName>.$ dotnet add \"My Project\" package QuantConnect.Lean\ninfo : Adding PackageReference for package 'QuantConnect.Lean' into project '/home/john/My Project/My Project.csproj'.\ninfo : PackageReference for package 'QuantConnect.Lean' version '2.5.11800' updated in file '/home/john/My Project/My Project.csproj'.Additionally, you can also update C# autocomplete by updating the version of the QuantConnect.Lean package reference in the C# project file (the file ending with.csproj).\nThis can be done manually or through your editor's built-in NuGet tooling if your editor has such a feature.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Autocomplete",
      "section_number": "5.7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.8",
    "title": "Libraries",
    "level": 2,
    "path": "Projects > Libraries",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Libraries",
      "section_number": "5.8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.8.1",
    "title": "Third-Party Libraries",
    "level": 3,
    "path": "Projects > Libraries > Third-Party Libraries",
    "content": "### Introduction\n\nThe Lean CLI supports using dozens of open source packages in your algorithms.\nThese packages are reviewed by our security team, and when approved, can be used in backtesting, live trading, and research.\nTo use these packages in your algorithm, you will need to add the relevantusingimportstatement at the top of your code file.\n\nBy default, only the libraries in the official LEAN Docker images can be referenced in your algorithms.\nHowever, the CLI also supports using custom libraries.\nThis makes it possible to use a library that is not available in the official LEAN Docker images or to use a newer version of an existing library.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Supported Libraries for AMD64 Systems\n\nThe CLI supports many of the most popular C# and Python open-source libraries.\nOn AMD64-based systems, the CLI supports the same C# and Python libraries as are supported on QuantConnect.\nIf you're unsure about the architecture of your system, it's most likely AMD64.\nThe following libraries are available on AMD64-based systems:\n\nabsl-py                                 2.1.0\naccelerate                              0.34.2\nadagio                                  0.2.6\naesara                                  2.9.4\naiohappyeyeballs                        2.4.4\naiohttp                                 3.11.10\naiosignal                               1.3.1\naiosqlite                               0.20.0\nalembic                                 1.14.0\nalibi-detect                            0.12.0\nalphalens-reloaded                      0.4.5\naltair                                  5.5.0\nanaconda-anon-usage                     0.4.4\nannotated-types                         0.7.0\nanyio                                   4.7.0\naplr                                    10.8.0\nappdirs                                 1.4.4\napricot-select                          0.6.1\narch                                    7.2.0\narchspec                                0.2.3\nargon2-cffi                             23.1.0\nargon2-cffi-bindings                    21.2.0\narrow                                   1.3.0\narviz                                   0.20.0\nastropy                                 7.0.0\nastropy-iers-data                       0.2024.12.9.0.36.21\nasttokens                               3.0.0\nastunparse                              1.6.3\nasync-lru                               2.0.4\nattrs                                   24.2.0\nAuthlib                                 1.3.2\nautograd                                1.7.0\nautograd-gamma                          0.5.0\nautokeras                               2.0.0\nautoray                                 0.7.0\nax-platform                             0.4.3\nbabel                                   2.16.0\nbayesian-optimization                   2.0.0\nbeautifulsoup4                          4.12.3\nbleach                                  6.2.0\nblinker                                 1.9.0\nblis                                    0.7.11\nblosc2                                  2.7.1\nbokeh                                   3.6.2\nboltons                                 23.0.0\nbotorch                                 0.12.0\nBottleneck                              1.4.2\nBrotli                                  1.0.9\ncachetools                              5.5.0\ncaptum                                  0.7.0\ncatalogue                               2.0.10\ncatboost                                1.2.7\ncategory-encoders                       2.6.4\ncausal-conv1d                           1.5.0.post8\ncertifi                                 2024.8.30\ncesium                                  0.12.1\ncffi                                    1.17.1\nchardet                                 5.2.0\ncharset-normalizer                      3.3.2\ncheck-shapes                            1.1.1\nchronos-forecasting                     1.4.1\nclarabel                                0.9.0\nclick                                   8.1.7\nclikit                                  0.6.2\ncloudpathlib                            0.20.0\ncloudpickle                             3.1.0\ncmdstanpy                               1.2.4\ncolorama                                0.4.6\ncolorcet                                3.1.0\ncolorlog                                6.9.0\ncolorlover                              0.3.0\ncolour                                  0.1.5\ncomm                                    0.2.2\nconda                                   24.9.2\nconda-content-trust                     0.2.0\nconda-libmamba-solver                   24.9.0\nconda-package-handling                  2.3.0\nconda_package_streaming                 0.10.0\nconfection                              0.1.5\ncons                                    0.4.6\ncontourpy                               1.3.1\ncontrol                                 0.10.1\ncopulae                                 0.7.9\ncopulas                                 0.12.0\ncoreforecast                            0.0.15\ncramjam                                 2.9.0\ncrashtest                               0.3.1\ncreme                                   0.6.1\ncryptography                            43.0.0\ncucim-cu12                              24.8.0\ncuda-python                             12.6.2.post1\ncudf-cu12                               24.8.3\ncufflinks                               0.17.3\ncugraph-cu12                            24.8.0\ncuml-cu12                               24.8.0\ncuproj-cu12                             24.8.0\ncupy-cuda12x                            13.3.0\ncuspatial-cu12                          24.8.0\ncuvs-cu12                               24.8.0\ncuxfilter-cu12                          24.8.0\ncvxopt                                  1.3.2\ncvxportfolio                            1.4.0\ncvxpy                                   1.6.0\ncycler                                  0.12.1\ncymem                                   2.0.10\nCython                                  3.0.11\ndarts                                   0.31.0\ndash                                    2.9.3\ndash-core-components                    2.0.0\ndash_cytoscape                          1.0.2\ndash-html-components                    2.0.0\ndash-table                              5.0.0\ndask                                    2024.7.1\ndask-cuda                               24.8.2\ndask-cudf-cu12                          24.8.3\ndask-expr                               1.1.9\ndatabricks-sdk                          0.38.0\ndataclasses-json                        0.6.7\ndatasets                                2.21.0\ndatashader                              0.16.3\ndeap                                    1.4.1\ndebugpy                                 1.8.9\ndecorator                               5.1.1\ndeepmerge                               2.0\ndefusedxml                              0.7.1\nDeprecated                              1.2.15\ndeprecation                             2.1.0\ndgl                                     2.1.0\ndill                                    0.3.8\ndimod                                   0.12.17\ndirtyjson                               1.0.8\ndiskcache                               5.6.3\ndistributed                             2024.7.1\ndistributed-ucxx-cu12                   0.39.1\ndistro                                  1.9.0\ndm-tree                                 0.1.8\ndocker                                  7.1.0\ndocutils                                0.21.2\nDoubleML                                0.9.0\ndropstackframe                          0.1.1\ndtreeviz                                2.2.2\ndtw-python                              1.5.3\ndwave-cloud-client                      0.13.1\ndwave-drivers                           0.4.4\ndwave-gate                              0.3.2\ndwave-greedy                            0.3.0\ndwave-hybrid                            0.6.12\ndwave-inspector                         0.5.1\ndwave-inspectorapp                      0.3.3\ndwave-neal                              0.6.0\ndwave_networkx                          0.8.15\ndwave-ocean-sdk                         8.0.1\ndwave-optimization                      0.3.0\ndwave-preprocessing                     0.6.6\ndwave-samplers                          1.3.0\ndwave-system                            1.26.0\ndwave-tabu                              0.5.0\ndwavebinarycsp                          0.3.0\necos                                    2.0.14\neinops                                  0.8.0\neinx                                    0.3.0\nEMD-signal                              1.6.4\nempyrical-reloaded                      0.5.11\nen-core-web-md                          3.7.1\nen-core-web-sm                          3.7.1\net_xmlfile                              2.0.0\netuples                                 0.3.9\nexchange_calendars                      4.6\nexecuting                               2.1.0\nfaiss-cpu                               1.9.0.post1\nFarama-Notifications                    0.0.4\nfastai                                  2.7.18\nfastai2                                 0.0.30\nfastcore                                1.7.26\nfastdownload                            0.0.7\nfasteners                               0.19\nfastjsonschema                          2.21.1\nfastparquet                             2024.11.0\nfastprogress                            1.0.3\nfastrlock                               0.8.2\nfasttext                                0.9.3\nfeature-engine                          1.6.2\nfeaturetools                            1.31.0\nfilelock                                3.16.1\nfiletype                                1.2.0\nfindiff                                 0.10.2\nFixedEffectModel                        0.0.5\nFlagEmbedding                           1.2.11\nFlask                                   3.1.0\nflatbuffers                             24.3.25\nfonttools                               4.55.2\nformulaic                               1.0.2\nfqdn                                    1.5.1\nfrozendict                              2.4.2\nfrozenlist                              1.5.0\nfs                                      2.4.16\nfsspec                                  2024.6.1\nfugue                                   0.9.1\nfuture                                  1.0.0\nfuzzy-c-means                           1.7.2\ngast                                    0.6.0\ngatspy                                  0.3\ngensim                                  4.3.3\ngeopandas                               1.0.1\ngevent                                  24.11.1\ngitdb                                   4.0.11\nGitPython                               3.1.43\ngluonts                                 0.16.0\ngoogle-ai-generativelanguage            0.6.10\ngoogle-api-core                         2.24.0\ngoogle-api-python-client                2.154.0\ngoogle-auth                             2.36.0\ngoogle-auth-httplib2                    0.2.0\ngoogle-generativeai                     0.8.3\ngoogle-pasta                            0.2.0\ngoogleapis-common-protos                1.66.0\ngpflow                                  2.9.2\ngplearn                                 0.4.2\ngpytorch                                1.13\ngraphene                                3.4.3\ngraphql-core                            3.2.5\ngraphql-relay                           3.2.0\ngraphviz                                0.20.3\ngreenlet                                3.1.1\ngrpcio                                  1.68.1\ngrpcio-status                           1.68.1\ngunicorn                                23.0.0\ngym                                     0.26.2\ngym-notices                             0.0.8\ngymnasium                               1.0.0\nh11                                     0.14.0\nh2o                                     3.46.0.6\nh5netcdf                                1.4.1\nh5py                                    3.12.1\nhmmlearn                                0.3.3\nholidays                                0.62\nholoviews                               1.20.0\nhomebase                                1.0.1\nhopcroftkarp                            1.2.5\nhtml5lib                                1.1\nhttpcore                                1.0.7\nhttplib2                                0.22.0\nhttpstan                                4.13.0\nhttpx                                   0.28.1\nhuggingface-hub                         0.26.5\nhurst                                   0.0.5\nhvplot                                  0.11.1\nhyperopt                                0.2.7\nibm-cloud-sdk-core                      3.22.0\nibm-platform-services                   0.59.0\nidna                                    3.7\niisignature                             0.24\nijson                                   3.3.0\nimageio                                 2.36.1\nimbalanced-learn                        0.12.4\nimmutabledict                           4.2.1\nimportlib_metadata                      8.5.0\nimportlib_resources                     6.4.5\niniconfig                               2.0.0\ninjector                                0.22.0\ninterface-meta                          1.3.0\ninterpret                               0.6.7\ninterpret-core                          0.6.7\nipykernel                               6.29.5\nipympl                                  0.9.4\nipython                                 8.30.0\nipython-genutils                        0.2.0\nipywidgets                              8.1.5\nisoduration                             20.11.0\nitsdangerous                            2.2.0\njax                                     0.4.35\njaxlib                                  0.4.35\njaxtyping                               0.2.19\njedi                                    0.19.2\nJinja2                                  3.1.4\njiter                                   0.8.2\njoblib                                  1.3.2\njson5                                   0.10.0\njsonpatch                               1.33\njsonpath-ng                             1.7.0\njsonpointer                             2.1\njsonschema                              4.23.0\njsonschema-specifications               2024.10.1\njupyter                                 1.1.1\njupyter_ai                              2.28.2\njupyter_ai_magics                       2.28.3\njupyter_bokeh                           4.0.5\njupyter_client                          8.6.3\njupyter-console                         6.6.3\njupyter_core                            5.7.2\njupyter-events                          0.10.0\njupyter-lsp                             2.2.5\njupyter-resource-usage                  1.1.0\njupyter_server                          2.14.2\njupyter_server_proxy                    4.4.0\njupyter_server_terminals                0.5.3\njupyterlab                              4.3.2\njupyterlab_pygments                     0.3.0\njupyterlab_server                       2.27.3\njupyterlab_widgets                      3.0.13\nkagglehub                               0.3.4\nkaleido                                 0.2.1\nkeras                                   3.7.0\nkeras-hub                               0.18.1\nkeras-nlp                               0.18.1\nkeras-rl                                0.4.2\nkeras-tcn                               3.5.0\nkeras-tuner                             1.4.7\nkiwisolver                              1.4.7\nkmapper                                 2.1.0\nkorean-lunar-calendar                   0.3.1\nkt-legacy                               1.0.5\nlangchain                               0.2.17\nlangchain-community                     0.2.19\nlangchain-core                          0.2.43\nlangchain-text-splitters                0.2.4\nlangcodes                               3.5.0\nlangsmith                               0.1.147\nlanguage_data                           1.3.0\nlark                                    1.2.2\nlazy_loader                             0.4\nlazypredict                             0.2.14a1\nlibclang                                18.1.1\nlibmambapy                              1.5.8\nlibucx-cu12                             1.15.0.post2\nlifelines                               0.30.0\nlightgbm                                4.5.0\nlightning                               2.4.0\nlightning-utilities                     0.11.9\nlime                                    0.2.0.1\nline_profiler                           4.2.0\nlinear-operator                         0.5.3\nlinkify-it-py                           2.0.3\nlivelossplot                            0.5.5\nllama-cloud                             0.1.6\nllama-index                             0.12.2\nllama-index-agent-openai                0.4.0\nllama-index-cli                         0.4.0\nllama-index-core                        0.12.5\nllama-index-embeddings-openai           0.3.1\nllama-index-indices-managed-llama-cloud 0.6.3\nllama-index-legacy                      0.9.48.post4\nllama-index-llms-openai                 0.3.3\nllama-index-multi-modal-llms-openai     0.3.0\nllama-index-program-openai              0.3.1\nllama-index-question-gen-openai         0.3.0\nllama-index-readers-file                0.4.1\nllama-index-readers-llama-parse         0.4.0\nllama-parse                             0.5.17\nllvmlite                                0.42.0\nlocket                                  1.0.0\nlogical-unification                     0.4.6\nloguru                                  0.7.3\nlxml                                    5.3.0\nlz4                                     4.3.3\nMako                                    1.3.8\nmamba-ssm                               2.2.4\nMAPIE                                   0.9.1\nmarisa-trie                             1.2.1\nMarkdown                                3.7\nmarkdown-it-py                          3.0.0\nMarkupSafe                              3.0.2\nmarshmallow                             3.23.1\nmatplotlib                              3.7.5\nmatplotlib-inline                       0.1.7\nmdit-py-plugins                         0.4.2\nmdurl                                   0.1.2\nmenuinst                                2.1.2\nmgarch                                  0.3.0\nminiKanren                              1.0.3\nminorminer                              0.2.15\nmistune                                 3.0.2\nml-dtypes                               0.4.1\nmlflow                                  2.18.0\nmlflow-skinny                           2.18.0\nmlforecast                              0.15.1\nmljar-scikit-plot                       0.3.12\nmljar-supervised                        1.1.9\nmlxtend                                 0.23.3\nmmh3                                    2.5.1\nmodin                                   0.26.1\nmplfinance                              0.12.10b0\nmpmath                                  1.3.0\nmsgpack                                 1.1.0\nmultidict                               6.1.0\nmultipledispatch                        1.0.0\nmultiprocess                            0.70.16\nmultitasking                            0.0.11\nmurmurhash                              1.0.11\nmypy-extensions                         1.0.0\nnamex                                   0.0.8\nnarwhals                                1.17.0\nnbclient                                0.10.1\nnbconvert                               7.16.4\nnbformat                                5.10.4\nndindex                                 1.9.2\nnest-asyncio                            1.6.0\nnetworkx                                3.4.2\nneural-tangents                         0.6.5\nneuralprophet                           0.9.0\nnfoursid                                1.0.1\nngboost                                 0.5.1\nninja                                   1.11.1.2\nnixtla                                  0.6.4\nnltk                                    3.9.1\nnolds                                   0.6.1\nnose                                    1.3.7\nnotebook                                7.3.1\nnotebook_shim                           0.2.4\nnumba                                   0.59.1\nnumerapi                                2.19.1\nnumexpr                                 2.10.2\nnumpy                                   1.26.4\nnvidia-cublas-cu12                      12.4.5.8\nnvidia-cuda-cupti-cu12                  12.4.127\nnvidia-cuda-nvrtc-cu12                  12.4.127\nnvidia-cuda-runtime-cu12                12.4.127\nnvidia-cudnn-cu12                       9.3.0.75\nnvidia-cufft-cu12                       11.2.1.3\nnvidia-curand-cu12                      10.3.5.147\nnvidia-cusolver-cu12                    11.6.1.9\nnvidia-cusparse-cu12                    12.3.1.170\nnvidia-nccl-cu12                        2.21.5\nnvidia-nvjitlink-cu12                   12.4.127\nnvidia-nvtx-cu12                        12.4.127\nnvtx                                    0.2.10\nnx-cugraph-cu12                         24.8.0\noauthlib                                3.2.2\nopenai                                  1.57.0\nopencv-contrib-python-headless          4.10.0.84\nopencv-python                           4.10.0.84\nopenpyxl                                3.1.5\nopentelemetry-api                       1.28.2\nopentelemetry-sdk                       1.28.2\nopentelemetry-semantic-conventions      0.49b2\nopt_einsum                              3.4.0\noptree                                  0.13.1\noptuna                                  4.1.0\norjson                                  3.10.12\nortools                                 9.9.3963\nosqp                                    0.6.7.post3\noverrides                               7.7.0\npackaging                               24.1\npandas                                  2.1.4\npandas-flavor                           0.6.0\npandas_market_calendars                 4.4.2\npandas_ta                               0.3.14b0\npandocfilters                           1.5.1\npanel                                   1.5.4\nparam                                   2.1.1\nparso                                   0.8.4\npartd                                   1.4.2\npastel                                  0.2.1\npathos                                  0.3.2\npatsy                                   1.0.1\npbr                                     6.1.0\npeewee                                  3.17.3\npeft                                    0.13.2\npenaltymodel                            1.1.0\nPennyLane                               0.39.0\nPennyLane_Lightning                     0.39.0\nPennyLane-qiskit                        0.36.0\npersim                                  0.3.7\npexpect                                 4.9.0\npgmpy                                   0.1.26\npillow                                  10.4.0\npingouin                                0.5.5\npip                                     24.2\nplatformdirs                            3.10.0\nplotly                                  5.24.1\nplotly-resampler                        0.10.0\nplucky                                  0.4.3\npluggy                                  1.5.0\nply                                     3.11\npmdarima                                2.0.4\npolars                                  1.16.0\npomegranate                             1.1.1\nPOT                                     0.9.5\npox                                     0.3.5\nppft                                    1.7.6.9\npprofile                                2.2.0\npreshed                                 3.0.9\nprometheus_client                       0.21.1\nprompt_toolkit                          3.0.48\npropcache                               0.2.1\nprophet                                 1.1.6\nproto-plus                              1.25.0\nprotobuf                                5.29.1\npsutil                                  5.9.8\nptyprocess                              0.7.0\nPuLP                                    2.9.0\npure_eval                               0.2.3\npy-cpuinfo                              9.0.0\npy-heat                                 0.0.6\npy-heat-magic                           0.0.2\npy_lets_be_rational                     1.0.1\npy_vollib                               1.0.1\npy4j                                    0.10.9.7\npyaml                                   24.9.0\npyarrow                                 16.1.0\npyasn1                                  0.6.1\npyasn1_modules                          0.4.1\npybind11                                2.13.6\npycaret                                 3.3.2\npycosat                                 0.6.6\npycparser                               2.21\npyct                                    0.5.0\npydantic                                2.9.2\npydantic_core                           2.23.4\nPyDMD                                   2024.12.1\npyerfa                                  2.0.1.5\npyfolio-reloaded                        0.9.8\nPygments                                2.18.0\nPyJWT                                   2.10.1\npykalman                                0.9.7\npylev                                   1.4.0\npylibcugraph-cu12                       24.8.0\npylibraft-cu12                          24.8.1\npyluach                                 2.2.0\npymannkendall                           1.4.3\npymc                                    5.19.0\npymdptoolbox                            4.0b3\npynndescent                             0.5.13\npynvjitlink-cu12                        0.4.0\npynvml                                  11.4.1\npyod                                    2.0.2\npyogrio                                 0.10.0\nPyomo                                   6.8.2\npyparsing                               3.2.0\npypdf                                   5.1.0\npyportfolioopt                          1.5.6\npyproj                                  3.7.0\nPyQt6                                   6.7.1\nPyQt6-Qt6                               6.7.3\nPyQt6_sip                               13.9.0\npyrb                                    1.0.1\npyre-extensions                         0.0.32\npyro-api                                0.1.2\npyro-ppl                                1.9.1\npysimdjson                              6.0.2\nPySocks                                 1.7.1\npyspnego                                0.11.2\npystan                                  3.10.0\npytensor                                2.26.4\npytest                                  8.3.4\npytest-runner                           6.0.1\npython-dateutil                         2.9.0.post0\npython-json-logger                      2.0.7\npython-statemachine                     2.5.0\npytorch-forecasting                     1.2.0\npytorch-ignite                          0.5.1\npytorch-lightning                       2.4.0\npytorch-tabnet                          4.1.0\npytz                                    2024.2\npyvinecopulib                           0.6.5\npyviz_comms                             3.0.3\nPyWavelets                              1.7.0\nPyYAML                                  6.0.2\npyzmq                                   26.2.0\nqdldl                                   0.1.7.post4\nqiskit                                  1.2.4\nqiskit-aer                              0.15.1\nqiskit-ibm-provider                     0.11.0\nqiskit-ibm-runtime                      0.34.0\nquadprog                                0.1.13\nquantecon                               0.7.2\nQuantLib                                1.36\nQuantStats                              0.0.64\nraft-dask-cu12                          24.8.1\nrapids-dask-dependency                  24.8.0\nrauth                                   0.7.3\nray                                     2.40.0\nRbeast                                  0.1.23\nreferencing                             0.35.1\nregex                                   2024.11.6\nrequests                                2.32.3\nrequests_ntlm                           1.3.0\nrequests-oauthlib                       1.3.1\nrequests-toolbelt                       1.0.0\nrfc3339-validator                       0.1.4\nrfc3986-validator                       0.1.1\nrich                                    13.9.4\nripser                                  0.6.10\nRiskfolio-Lib                           6.1.1\nriskparityportfolio                     0.6.0\nriver                                   0.21.0\nrmm-cu12                                24.8.2\nrpds-py                                 0.22.3\nrsa                                     4.9\nruamel.yaml                             0.18.6\nruamel.yaml.clib                        0.2.8\nruptures                                1.1.9\nrustworkx                               0.15.1\nsafetensors                             0.4.5\nSALib                                   1.5.1\nschemdraw                               0.15\nscikeras                                0.13.0\nscikit-base                             0.7.8\nscikit-image                            0.22.0\nscikit-learn                            1.4.2\nscikit-learn-extra                      0.3.0\nscikit-optimize                         0.10.2\nscikit-plot                             0.3.7\nscikit-tda                              1.1.1\nscipy                                   1.11.4\nscs                                     3.2.7\nsdeint                                  0.3.0\nseaborn                                 0.13.2\nSend2Trash                              1.8.3\nsentence-transformers                   3.3.1\nsetuptools                              73.0.1\nsetuptools-scm                          8.1.0\nshap                                    0.46.0\nshapely                                 2.0.6\nShimmy                                  2.0.0\nsimpervisor                             1.0.0\nsimplejson                              3.19.3\nsimpy                                   4.1.1\nsix                                     1.17.0\nsklearn-json                            0.1.0\nsktime                                  0.26.0\nslicer                                  0.0.8\nsmart-open                              7.0.5\nsmmap                                   5.0.1\nsniffio                                 1.3.1\nsortedcontainers                        2.4.0\nsoupsieve                               2.6\nspacy                                   3.7.5\nspacy-legacy                            3.0.12\nspacy-loggers                           1.0.5\nSQLAlchemy                              2.0.36\nsqlparse                                0.5.3\nsrsly                                   2.5.0\nssm                                     0.0.1\nstable_baselines3                       2.4.0\nstack-data                              0.6.3\nstanio                                  0.5.1\nstatsforecast                           2.0.0\nstatsmodels                             0.14.4\nstevedore                               5.4.0\nstochastic                              0.6.0\nstockstats                              0.6.2\nstopit                                  1.1.2\nstriprtf                                0.0.26\nstumpy                                  1.13.0\nsymengine                               0.13.0\nsympy                                   1.13.1\nta                                      0.11.0\nta-lib                                  0.5.1\ntables                                  3.10.1\ntabulate                                0.8.10\ntadasets                                0.2.1\ntbats                                   1.1.3\ntblib                                   3.0.0\ntenacity                                8.5.0\ntensorboard                             2.18.0\ntensorboard-data-server                 0.7.2\ntensorboardX                            2.6.2.2\ntensorflow                              2.18.0\ntensorflow-addons                       0.23.0\ntensorflow_decision_forests             1.11.0\ntensorflow-io-gcs-filesystem            0.37.1\ntensorflow-probability                  0.25.0\ntensorflow-text                         2.18.0\ntensorly                                0.9.0\ntensorrt                                10.7.0\ntensorrt_cu12                           10.7.0\ntensorrt-cu12-bindings                  10.7.0\ntensorrt-cu12-libs                      10.7.0\ntensortrade                             1.0.3\ntermcolor                               2.5.0\nterminado                               0.18.1\ntf_keras                                2.18.0\ntf2jax                                  0.3.6\nthinc                                   8.2.5\nthreadpoolctl                           3.5.0\nthundergbm                              0.3.17\ntifffile                                2024.9.20\ntigramite                               5.2.6.7\ntiktoken                                0.8.0\ntinycss2                                1.4.0\ntinygrad                                0.10.0\ntokenizers                              0.20.3\ntoml                                    0.10.2\ntoolz                                   0.12.1\ntorch                                   2.5.1\ntorch_cluster                           1.6.3\ntorch-geometric                         2.6.1\ntorch_scatter                           2.1.2\ntorch_sparse                            0.6.18\ntorch_spline_conv                       1.2.2\ntorchdata                               0.10.0\ntorchmetrics                            1.6.0\ntorchvision                             0.20.1\ntornado                                 6.4.2\nTPOT                                    0.12.2\ntqdm                                    4.66.5\ntraitlets                               5.14.3\ntransformers                            4.46.3\ntreelite                                4.3.0\ntriad                                   0.9.8\ntriton                                  3.1.0\ntruststore                              0.8.0\ntsdownsample                            0.1.3\ntsfel                                   0.1.9\ntsfresh                                 0.20.2\ntslearn                                 0.6.3\ntweepy                                  4.14.0\ntypeguard                               2.13.3\ntyper                                   0.9.4\ntyper-config                            1.4.2\ntypes-python-dateutil                   2.9.0.20241206\ntyping_extensions                       4.12.2\ntyping-inspect                          0.9.0\ntzdata                                  2024.2\nuc-micro-py                             1.0.3\nucx-py-cu12                             0.39.2\nucxx-cu12                               0.39.1\numap-learn                              0.5.7\nupdate-checker                          0.18.0\nuri-template                            1.3.0\nuritemplate                             4.1.1\nurllib3                                 2.2.3\nutilsforecast                           0.2.10\nwasabi                                  1.1.3\nwcwidth                                 0.2.13\nweasel                                  0.4.1\nwebargs                                 8.6.0\nwebcolors                               24.11.1\nwebencodings                            0.5.1\nwebsocket-client                        1.8.0\nwebsockets                              14.1\nWerkzeug                                3.1.3\nwheel                                   0.44.0\nwidgetsnbextension                      4.0.13\nwindow_ops                              0.0.15\nwoodwork                                0.31.0\nwordcloud                               1.9.4\nwrapt                                   1.16.0\nwurlitzer                               3.1.1\nx-transformers                          1.42.24\nxarray                                  2024.11.0\nxarray-einstats                         0.8.0\nxgboost                                 2.1.3\nxlrd                                    2.0.1\nXlsxWriter                              3.2.0\nxxhash                                  3.5.0\nxyzservices                             2024.9.0\nyarl                                    1.18.3\nydf                                     0.9.0\nyellowbrick                             1.5\nyfinance                                0.2.50\nzict                                    3.0.0\nzipp                                    3.21.0\nzope.event                              5.0\nzope.interface                          7.2\nzstandard                               0.23.0Accord                               3.6.0\nAccord.Fuzzy                         3.6.0\nAccord.MachineLearning               3.6.0\nAccord.Math                          3.6.0\nAccord.Statistics                    3.6.0\nCloneExtensions                      1.3.0\nCommon.Logging                       3.4.1\nCommon.Logging.Core                  3.4.1\nCsvHelper                            19.0.0\nDeedle                               2.1.0\nDotNetZip                            1.16.0\nDynamicInterop                       0.9.1\nfasterflect                          3.0.0\nMathNet.Numerics                     5.0.0\nMcMaster.Extensions.CommandLineUtils 2.6.0\nMicrosoft.IO.RecyclableMemoryStream  2.3.2\nMicrosoft.NET.Test.Sdk               16.9.4\nMicrosoft.TestPlatform.ObjectModel   16.9.4\nMoq                                  4.16.1\nNetMQ                                4.0.1.6\nNewtonsoft.Json                      13.0.2\nNodaTime                             3.0.5\nNUnit                                4.2.2\nNUnit3TestAdapter                    4.6.0\nprotobuf-net                         3.1.3\nQLNet                                1.13.0\nQuantConnect.pythonnet               2.0.42\nRestSharp                            106.12.0\nSharpZipLib                          1.3.3\nSystem.ComponentModel.Composition    6.0.0\n\n### Supported Libraries for ARM64 Systems\n\nOn ARM64-based systems, the list of available libraries is a bit shorter because ARM64 is not as well supported as AMD64.\nThe following libraries are available on ARM64-based systems:\n\n// Name                                    Version\nAccord                                     3.5.0\nAccord.Fuzzy                               3.5.0\nAccord.MachineLearning                     3.5.0\nAccord.Math                                3.5.0\nAccord.Math.Core                           3.5.0\nAccord.Statistics                          3.5.0\nAsyncIO                                    0.1.26.0\nCloneExtensions                            1.3.0\nCoinAPI.WebSocket.V1                       1.6.0\nCommon.Logging                             3.4.1\nCommon.Logging.Core                        3.4.1\nCSharpAPI                                  1.0.0.0\nCsvHelper                                  19.0.0\nDotNetZip                                  1.13.3.506\nDynamicInterop                             0.9.0\nFasterflect                                3.0.0.0\nFSharp.Core                                4.5.0.0\nICSharpCode.SharpZipLib                    1.2.0\nIQFeed.CSharpApiClient                     2.5.1\nLaunchDarkly.EventSource                   3.3.2\nMathNet.Numerics                           4.15.0\nMcMaster.Extensions.CommandLineUtils       2.6.0\nMicrosoft.IO.RecyclableMemoryStream        1.3.5.0\nMicrosoft.Win32.SystemEvents               3.1.0\nNetMQ                                      4.0.0.1\nNewtonsoft.Json                            12.0.3\nNodaTime                                   3.0.5\nprotobuf-net                               3.0.29\nprotobuf-net.Core                          3.0.29\nPython.Runtime                             2.0.1.0\nQLNet                                      1.11.3\nQuantConnect.Algorithm                     2.5.0.0\nQuantConnect.Algorithm.CSharp              2.5.0.0\nQuantConnect.Algorithm.Framework           2.5.0.0\nQuantConnect.AlgorithmFactory              2.5.0.0\nQuantConnect.Api                           2.5.0.0\nQuantConnect.Brokerages                    2.5.0.0\nQuantConnect.Common                        2.5.0.0\nQuantConnect.Compression                   2.5.0.0\nQuantConnect.Configuration                 2.5.0.0\nQuantConnect.IBAutomater.exe               2.0.17\nQuantConnect.Indicators                    2.5.0.0\nQuantConnect.Lean.Engine                   2.5.0.0\nQuantConnect.Lean.Launcher.exe             2.5.0.0\nQuantConnect.Logging                       2.5.0.0\nQuantConnect.Messaging                     2.5.0.0\nQuantConnect.Queues                        2.5.0.0\nQuantConnect.Research                      2.5.0.0\nQuantConnect.ToolBox.exe                   2.5.0.0\nRDotNet                                    1.9.0\nRestSharp                                  106.6.10\nSuperSocket.ClientEngine                   0.10.0.0\nSystem.ComponentModel.Composition          5.0.0\nSystem.Configuration.ConfigurationManager  3.1.0\nSystem.Drawing.Common                      4.6.26919.02\nSystem.Private.ServiceModel                3.1.0\nSystem.Security.Cryptography.Pkcs          4.6.26515.06\nSystem.Security.Cryptography.ProtectedData 3.1.0\nSystem.Security.Cryptography.Xml           4.6.26515.06\nSystem.Security.Permissions                3.1.0\nSystem.ServiceModel                        3.1.0\nSystem.ServiceModel.Primitives             3.1.0\nSystem.Windows.Extensions                  3.1.0\nUtf8Json                                   1.3.7.0\nWebSocket4Net                              0.15.2.11# Name                    Version                   Build  Channel\n_openmp_mutex             4.5                       1_gnu    conda-forge\nabsl-py                   0.12.0                   pypi_0    pypi\nalembic                   1.6.2                    pypi_0    pypi\nappdirs                   1.4.4                    pypi_0    pypi\nargon2-cffi               20.1.0           py36h269c3a8_2    conda-forge\nasync_generator           1.10                       py_0    conda-forge\nattrs                     21.1.0             pyhd8ed1ab_0    conda-forge\nauto-ks                   0.1                      pypi_0    pypi\nautograd                  1.3                      pypi_0    pypi\nbackcall                  0.2.0              pyh9f0ad1d_0    conda-forge\nbackports                 1.0                        py_2    conda-forge\nbackports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\nbayesian-optimization     1.2.0                    pypi_0    pypi\nbeautifulsoup4            4.9.0                    pypi_0    pypi\nbleach                    3.3.0              pyh44b312d_0    conda-forge\nboto3                     1.17.72                  pypi_0    pypi\nbotocore                  1.20.72                  pypi_0    pypi\nbrotlipy                  0.7.0           py36h269c3a8_1001    conda-forge\nca-certificates           2020.12.5            h4fd8a4c_0    conda-forge\ncertifi                   2020.12.5        py36h704843e_1    conda-forge\ncffi                      1.14.4           py36hcfd9a06_0    conda-forge\nchardet                   4.0.0            py36h704843e_1    conda-forge\nclick                     8.0.0                    pypi_0    pypi\ncliff                     3.7.0                    pypi_0    pypi\ncloudpickle               1.3.0                    pypi_0    pypi\ncmaes                     0.8.2                    pypi_0    pypi\ncmd2                      1.5.0                    pypi_0    pypi\ncmdstanpy                 0.4.0                    pypi_0    pypi\ncolorama                  0.4.4                    pypi_0    pypi\ncolorlog                  5.0.1                    pypi_0    pypi\ncolorlover                0.3.0                    pypi_0    pypi\nconda                     4.10.1           py36h704843e_0    conda-forge\nconda-package-handling    1.7.3            py36h269c3a8_0    conda-forge\ncontextvars               2.4                      pypi_0    pypi\ncopulalib                 1.1.0                    pypi_0    pypi\ncopulas                   0.3.3                    pypi_0    pypi\ncryptography              3.4.7            py36h70ab5b5_0    conda-forge\ncufflinks                 0.17.3                   pypi_0    pypi\ncycler                    0.10.0                     py_2    conda-forge\ncython                    0.29.17          py36h831f99a_0    conda-forge\ndask                      2021.3.0                 pypi_0    pypi\ndataclasses               0.8                      pypi_0    pypi\ndatashape                 0.5.2                    pypi_0    pypi\ndeap                      1.3.1                    pypi_0    pypi\ndecorator                 4.4.2                    pypi_0    pypi\ndefusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\ndill                      0.3.1.1                  pypi_0    pypi\ndistributed               2.20.0                   pypi_0    pypi\ndocutils                  0.14                     pypi_0    pypi\ndtw-python                1.0.5                    pypi_0    pypi\ndx                        0.1.2                    pypi_0    pypi\nentrypoints               0.3             pyhd8ed1ab_1003    conda-forge\nfasttext                  0.9.2                    pypi_0    pypi\nfeature-selector          1.0.0                    pypi_0    pypi\nfeaturetools              0.14.0                   pypi_0    pypi\nfindiff                   0.8.5                    pypi_0    pypi\nfreetype                  2.10.4               hdf53a3c_1    conda-forge\nfrozendict                2.0.2                    pypi_0    pypi\nfuture                    0.18.2                   pypi_0    pypi\ngluonts                   0.4.3                    pypi_0    pypi\ngplearn                   0.4.1                    pypi_0    pypi\ngreenlet                  1.1.0                    pypi_0    pypi\ngym                       0.17.2                   pypi_0    pypi\nh2o                       3.30.0.3                 pypi_0    pypi\nheapdict                  1.0.1                    pypi_0    pypi\nhmmlearn                  0.2.3                    pypi_0    pypi\nholidays                  0.9.12                   pypi_0    pypi\nhyperopt                  0.2.5                    pypi_0    pypi\nicu                       64.2                 h4c5d2ac_1    conda-forge\nidna                      2.10               pyh9f0ad1d_0    conda-forge\nimmutables                0.15                     pypi_0    pypi\nimportlib-metadata        4.0.1            py36h704843e_0    conda-forge\niniconfig                 1.1.1                    pypi_0    pypi\nipykernel                 5.5.4            py36h103942d_0    conda-forge\nipython                   7.16.1           py36h0e46ebc_2    conda-forge\nipython_genutils          0.2.0                      py_1    conda-forge\nipywidgets                7.5.1                    pypi_0    pypi\njax                       0.1.68                   pypi_0    pypi\njedi                      0.17.2           py36h704843e_1    conda-forge\njinja2                    2.11.3             pyh44b312d_0    conda-forge\njmespath                  0.10.0                   pypi_0    pypi\njoblib                    1.0.1                    pypi_0    pypi\njson5                     0.9.5              pyh9f0ad1d_0    conda-forge\njsonschema                3.2.0              pyhd8ed1ab_3    conda-forge\njupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge\njupyter_core              4.7.1            py36h704843e_0    conda-forge\njupyterlab                2.1.2                      py_0    conda-forge\njupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\njupyterlab_server         1.2.0                      py_0    conda-forge\nkiwisolver                1.3.1            py36h72e8208_1    conda-forge\nld_impl_linux-aarch64     2.35.1               h02ad14f_2    conda-forge\nlibblas                   3.9.0                8_openblas    conda-forge\nlibcblas                  3.9.0                8_openblas    conda-forge\nlibffi                    3.2.1             h4c5d2ac_1007    conda-forge\nlibgcc-ng                 9.3.0               he1ea209_19    conda-forge\nlibgfortran-ng            7.5.0               h6d8ffed_18    conda-forge\nlibgfortran4              7.5.0               h6d8ffed_18    conda-forge\nlibgomp                   9.3.0               he1ea209_19    conda-forge\nliblapack                 3.9.0                8_openblas    conda-forge\nlibopenblas               0.3.12          pthreads_hb3c22a3_1    conda-forge\nlibpng                    1.6.37               hbd635b3_2    conda-forge\nlibsodium                 1.0.18               hb9de7d4_1    conda-forge\nlibstdcxx-ng              9.3.0               h1ed1776_19    conda-forge\nlightgbm                  2.3.0                    pypi_0    pypi\nmako                      1.1.4                    pypi_0    pypi\nmarkupsafe                1.1.1            py36h269c3a8_3    conda-forge\nmatplotlib                3.2.1                         0    conda-forge\nmatplotlib-base           3.2.1            py36h0f30586_0    conda-forge\nmistune                   0.8.4           py36h269c3a8_1003    conda-forge\nmpi                       1.0                     openmpi    conda-forge\nmplfinance                0.12.4a0                 pypi_0    pypi\nmsgpack                   1.0.0                    pypi_0    pypi\nmultipledispatch          0.6.0                    pypi_0    pypi\nmxnet                     1.6.0                    pypi_0    pypi\nnbclient                  0.5.3              pyhd8ed1ab_0    conda-forge\nnbconvert                 6.0.7            py36h704843e_3    conda-forge\nnbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\nncurses                   6.2                  h7fd3ca4_4    conda-forge\nnest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\nnetworkx                  2.5.1                    pypi_0    pypi\nneural-tangents           0.2.1                    pypi_0    pypi\nnltk                      3.4.5                    pypi_0    pypi\nnotebook                  6.3.0            py36h704843e_0    conda-forge\nnumpy                     1.18.1           py36h3849536_1    conda-forge\nnvidia-ml-py3             7.352.0                  pypi_0    pypi\noauthlib                  3.1.0                    pypi_0    pypi\nodo                       0+unknown                pypi_0    pypi\nopenmpi                   4.0.3                hd49bf07_1    conda-forge\nopenssl                   1.1.1k               hf897c2e_0    conda-forge\nopt-einsum                3.3.0                    pypi_0    pypi\noptuna                    2.3.0                    pypi_0    pypi\npackaging                 20.9               pyh44b312d_0    conda-forge\npandas                    0.25.3           py36h59fbc97_0    conda-forge\npandas-market-calendars   1.7                      pypi_0    pypi\npandocfilters             1.4.2                      py_1    conda-forge\nparso                     0.7.1              pyh9f0ad1d_0    conda-forge\npbr                       5.6.0                    pypi_0    pypi\npennylane                 0.9.0                    pypi_0    pypi\npexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\npickleshare               0.7.5                   py_1003    conda-forge\npip                       21.1.1             pyhd8ed1ab_0    conda-forge\nplotly                    4.7.1                    pypi_0    pypi\npluggy                    0.13.1                   pypi_0    pypi\nppscore                   0.0.2                    pypi_0    pypi\nprettytable               2.1.0                    pypi_0    pypi\nprometheus_client         0.10.1             pyhd8ed1ab_0    conda-forge\nprompt-toolkit            3.0.18             pyha770c72_0    conda-forge\npsutil                    5.8.0                    pypi_0    pypi\nptvsd                     4.3.2                    pypi_0    pypi\nptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\npulp                      1.6.8                    pypi_0    pypi\npy                        1.10.0                   pypi_0    pypi\npyaml                     20.4.0                   pypi_0    pypi\npybind11                  2.6.2                    pypi_0    pypi\npycosat                   0.6.3           py36h269c3a8_1006    conda-forge\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\npydantic                  1.8.2                    pypi_0    pypi\npydevd-pycharm            201.8538.36              pypi_0    pypi\npyglet                    1.5.0                    pypi_0    pypi\npygments                  2.9.0              pyhd8ed1ab_0    conda-forge\npykalman                  0.9.5                    pypi_0    pypi\npyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\npyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\npyperclip                 1.8.2                    pypi_0    pypi\npyro-api                  0.1.2                    pypi_0    pypi\npyro-ppl                  1.3.1                    pypi_0    pypi\npyrsistent                0.17.3           py36h269c3a8_2    conda-forge\npysocks                   1.7.1            py36h704843e_3    conda-forge\npytest                    6.2.4                    pypi_0    pypi\npython                    3.6.7           h357f687_1008_cpython    conda-forge\npython-dateutil           2.8.0                    pypi_0    pypi\npython-editor             1.0.4                    pypi_0    pypi\npython-graphviz           0.8.4                    pypi_0    pypi\npython_abi                3.6                     1_cp36m    conda-forge\npytz                      2021.1             pyhd8ed1ab_0    conda-forge\npywavelets                1.1.1                    pypi_0    pypi\npyyaml                    5.4.1                    pypi_0    pypi\npyzmq                     22.0.3           py36hfbd0944_1    conda-forge\nrauth                     0.7.3                    pypi_0    pypi\nreadline                  8.1                  h1a49cc3_0    conda-forge\nrequests                  2.25.1             pyhd3deb0d_0    conda-forge\nrequests-oauthlib         1.3.0                    pypi_0    pypi\nretrying                  1.3.3                    pypi_0    pypi\nrpy2                      3.3.6                    pypi_0    pypi\nruamel_yaml               0.15.80         py36h269c3a8_1004    conda-forge\nruptures                  1.1.3                    pypi_0    pypi\nscikit-learn              0.24.2                   pypi_0    pypi\nscikit-learn-extra        0.2.0                    pypi_0    pypi\nscikit-multiflow          0.4.1                    pypi_0    pypi\nscikit-optimize           0.7.4                    pypi_0    pypi\nscipy                     1.4.1            py36h3a855aa_3    conda-forge\nsdeint                    0.2.1                    pypi_0    pypi\nseaborn                   0.11.0                   pypi_0    pypi\nsemantic-version          2.6.0                    pypi_0    pypi\nsend2trash                1.5.0                      py_0    conda-forge\nsetuptools                49.6.0           py36h704843e_3    conda-forge\nsetuptools-git            1.2                      pypi_0    pypi\nsimpy                     4.0.1                    pypi_0    pypi\nsix                       1.16.0             pyh6c4a22f_0    conda-forge\nsklearn-contrib-py-earth  0.1.0                    pypi_0    pypi\nsklearn-json              0.1.0                    pypi_0    pypi\nsortedcontainers          2.3.0                    pypi_0    pypi\nsoupsieve                 2.2.1                    pypi_0    pypi\nsqlalchemy                1.4.15                   pypi_0    pypi\nsqlite                    3.35.5               h43e6a2a_0    conda-forge\nstatistics                1.0.3.5                  pypi_0    pypi\nstevedore                 3.3.0                    pypi_0    pypi\nta                        0.5.25                   pypi_0    pypi\ntabulate                  0.8.9                    pypi_0    pypi\ntblib                     1.7.0                    pypi_0    pypi\nterminado                 0.9.4            py36h704843e_0    conda-forge\ntestpath                  0.4.4                      py_0    conda-forge\ntheano                    1.0.4                    pypi_0    pypi\nthreadpoolctl             2.1.0                    pypi_0    pypi\ntigramite                 4.1.0                    pypi_0    pypi\ntk                        8.6.10               ha99a2a3_1    conda-forge\ntoml                      0.10.2                   pypi_0    pypi\ntoolz                     0.11.1                   pypi_0    pypi\ntorch                     1.8.1                    pypi_0    pypi\ntornado                   6.1              py36h269c3a8_1    conda-forge\ntqdm                      4.60.0             pyhd8ed1ab_0    conda-forge\ntrading-calendars         2.1.1                    pypi_0    pypi\ntraitlets                 4.3.3            py36h9f0ad1d_1    conda-forge\ntweepy                    3.8.0                    pypi_0    pypi\ntyping_extensions         3.7.4.3                    py_0    conda-forge\ntzdata                    2021a                he74cb21_0    conda-forge\ntzlocal                   2.1                      pypi_0    pypi\nujson                     1.35                     pypi_0    pypi\nurllib3                   1.26.4             pyhd8ed1ab_0    conda-forge\nwcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\nwebencodings              0.5.1                      py_1    conda-forge\nwheel                     0.36.2             pyhd3deb0d_0    conda-forge\nwidgetsnbextension        3.5.1                    pypi_0    pypi\nwrapt                     1.12.1           py36h269c3a8_3    conda-forge\nxarray                    0.15.1                   pypi_0    pypi\nxz                        5.2.5                h6dd45c4_1    conda-forge\nyaml                      0.2.5                h516909a_0    conda-forge\nzeromq                    4.3.4                h01db608_0    conda-forge\nzict                      2.0.0                    pypi_0    pypi\nzipp                      3.4.1              pyhd8ed1ab_0    conda-forge\nzlib                      1.2.11            h516909a_1009    conda-forge\n\n### Request New Libraries\n\nTo request a new library,contact us. We will add the library to the queue for review and deployment. Since the libraries run on our servers, we need to ensure they are secure and won't cause harm. The process of adding new libraries takes 2-4 weeks to complete. View the list of libraries currently under review on theIssues list of the Lean GitHub repository.\n\n### Add Libraries\n\nFollow these steps to add custom libraries to yourC#Pythonproject:\n\nFind the name of the package that you want to add onNuGet.Open a terminal in theorganization workspacethat stores the project.Runlean library add \"<projectName>\"<packageName>to add the<packageName>NuGet package to the project in. / <projectName>.$ lean library add \"My Project\" Microsoft.ML\nRetrieving latest available version from NuGet\nAdding Microsoft.ML 1.5.5 to 'My Project/My Project.csproj'\nRestoring packages in 'My Project' to provide local autocompleteThis command installs the latest version of theMicrosoft.MLpackage.\nIf you want to use a different version you can use the--version <value>option.\nAdditionally, you can pass the--no-localflag to skip restoring the packages locally.\n\nFind the name of the package that you want to add onPyPI.Open a terminal in theorganization workspacethat stores the project.Runlean library add \"<projectName>\" <packageName>to add the<packageName>PyPI package to the project in. / <projectName>.$ lean library add \"My Project\" altair\nRetrieving latest compatible version from PyPI\nAdding altair 4.1.0 to 'My Project/requirements.txt'\nInstalling altair 4.1.0 in local Python environment to provide local autocompleteThis command installs the latest version of thealtairpackage that is compatible with Python 3.11 (which is what the official LEAN Docker images use).\nIf you want to use a different version you can use the--version <value>option.\nAdditionally, you can pass the--no-localflag to skip installing the package in your local Python environment.If you are using VS Code, restart your editor for autocomplete to start working on the new library.\n\nAdditionally, you can also add custom C# libraries by modifying the C# project file (the file ending with.csproj).\nThis can be done manually or through your editor's built-in NuGet tooling if your editor has such a feature.\n\nAdditionally, you can also add custom Python libraries by modifying the project'srequirements.txtfile.\nIf you choose to do this, make sure that the library versions that you add to this file are compatible with Python 3.6, because that's what the official LEAN Docker images use.\n\n### Remove Libraries\n\nFollow these steps to remove custom libraries from yourC#Pythonproject:\n\nOpen a terminal in theorganization workspacethat stores the project.Runlean library remove \"<projectName>\" <packageName>to remove the<packageName>NuGet package from the project in. / <projectName>.$ lean library remove \"My Project\" Microsoft.ML\nRemoving Microsoft.ML from 'My Project/My Project.csproj'\nRestoring packages in 'My Project'You can pass the--no-localflag to skip restoring the packages locally.\n\nOpen a terminal in theorganization workspacethat stores the project.Runlean library remove \"<projectName>\"<packageName>to remove the<packageName>PyPI package from the project in. / <projectName>.$ lean library remove \"My Project\" altair\nRemoving altair from 'My Project/requirements.txt'\n\nAdditionally, you can also remove custom C# libraries by modifying the C# project file (the file ending with.csproj).\nThis can be done manually or through your editor's built-in NuGet tooling if your editor has such a feature.\n\nAdditionally, you can also remove custom Python libraries by modifying the project'srequirements.txtfile.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5.8",
      "breadcrumb": "Projects > Libraries > Third-Party Libraries",
      "section_number": "5.8.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.8.2",
    "title": "Project Libraries",
    "level": 3,
    "path": "Projects > Libraries > Project Libraries",
    "content": "### Introduction\n\nProject libraries are QuantConnect projects you can merge into your project to avoid duplicating code files. If you have tools that you use across several projects, create a library.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Create Libraries\n\nTo create a library, open a terminal in one of yourorganization workspacesand thencreate a projectin theLibrarydirectory.\n\n$ lean project-create \"Library/MyLibrary\"\nRestoring packages in 'Library\\MyLibrary' to provide local autocomplete\nRestored successfully\nSuccessfully created C# project 'Library/MyLibrary'\n\n$ lean project-create \"Library/MyLibrary\"\nSuccessfully created Python project 'Library/MyLibrary'\n\nThe library name can only contain letters (a-z), numbers (0-9), and underscores (_). The library name can't contain spaces or start with a number. To create a library directory, set the name toLibrary /directoryName/libraryName(for example,Library / Tools / Calculators).\n\nThelean project-createcommand creates a new project based on yourdefault programming language. To create aPythonC#library, add the--language csharp--language pythonoption.\n\n$ lean project-create \"Library/MyLibrary\" --language csharp\nSuccessfully created C# project 'Library/MyLibrary'\nRestoring packages in 'Library\\MyLibrary' to provide local autocomplete\nRestored successfully\nSuccessfully created C# project 'Library/MyLibrary'\n\n$ lean project-create \"Library/MyLibrary\" --language python\nSuccessfully created Python project 'Library/MyLibrary'\n\n### Add Libraries\n\nFollow these steps to add a library to your project:\n\nOpen a terminal in yourorganization workspacethat contains the library.Runlean library add \"<projectName>\" \"Library/<libraryName>\".$ lean library add \"My Project\" \"Library/MyLibrary\"\nAdding Lean CLI library D:\\qc\\lean-cli\\Library\\MyLibrary to project D:\\qc\\lean-cli\\My Project\nRestoring packages in 'My Project' to provide local autocomplete\nRestored successfully$ lean library add \"My Project\" \"Library/MyLibrary\"\nAdding Lean CLI library D:\\qc\\lean-cli\\Library\\MyLibrary to project D:\\qc\\lean-cli\\My ProjectIn your project files, add the library namespace to the top of the page.By default, the namespace isQuantConnect.In your project files, import the library class at the top of the page.using QuantConnect;from MyLibrary.main import MyLibraryIn general, usefrom <libraryName>.<fileNameWithoutExtension> import <memberName>.In your project files, instantiate the library class and call its methods.var x = new MyLibrary();\nvar value = x.Add(1, 2);x = MyLibrary()\nvalue = x.add(1, 2)\n\n### Rename Libraries\n\nFollow these steps to rename a library:\n\nOpen theorganization workspacethat contains the library.In theLibrarydirectory, rename the library project.The library name can only contain letters (a-z), numbers (0-9), and underscores (_). The library name can't contain spaces or start with a number. To create a library directory, set the name toLibrary /directoryName/libraryName(for example,Library / Tools / Calculators).If you have a copy of the library in QuantConnect Cloud, open a terminal in your organization workspace and push the library project.$ lean cloud push --project \"Library/MySpecialLibrary\"\n[1/1] Pushing 'Library\\MySpecialLibrary'\nRenaming project in cloud from 'Library/MyLibrary' to 'Library/MySpecialLibrary'\nSuccessfully updated name, files, and libraries for 'Library/MyLibrary'\n\n### Remove Libraries\n\nFollow these steps to remove a library from a project, open a terminal in yourorganization workspacethat stores the project and then runlean library remove \"<projectName>\" \"Library/<libraryName>\".\n\n$ lean library remove \"My Project\" \"Library/MyLibrary\"\nRemoving D:\\qc\\workspaces\\Quant Organization\\Library\\MyLibrary from 'My Project\\My Project.csproj'\nRestoring packages in 'My Project'\nDetermining projects to restore...\nRestored D:\\qc\\workspaces\\Quant Organization\\My Project\\My Project.csproj (in 399 ms).\n\n$ lean library remove \"My Project\" \"Library/MyLibrary\"\n\n### Delete Libraries\n\nTo delete a library, open a terminal in yourorganization workspacethat contains the library and then runlean project-delete \"Library/<libraryName>\".\n\n$ lean project-delete \"Library/MyLibrary\"\nSuccessfully deleted project 'Library/MyLibrary'",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5.8",
      "breadcrumb": "Projects > Libraries > Project Libraries",
      "section_number": "5.8.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.9",
    "title": "Custom Docker Images",
    "level": 2,
    "path": "Projects > Custom Docker Images",
    "content": "### Introduction\n\nBy default, the CLI uses the official LEAN Docker images when running the LEAN engine or the research environment.\nHowever, the CLI also supports custom Docker images, making it possible to use your own version of LEAN.\nTo make this feature easier to use, the CLI is also capable of building Docker images of your own version of LEAN using a single command.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Using Custom Images\n\nFollow these steps to make the CLI use custom Docker images when running the LEAN engine or the research environment:\n\nOpen a terminal.Runlean config set engine-image <value>, where<value>is the full name of your Docker image containing the LEAN engine (example:quantconnect/lean:latest).$ lean config set engine-image quantconnect/lean:latest\nSuccessfully updated the value of 'engine-image' to 'quantconnect/lean:latest'Runlean config set research-image <value>, where<value>is the full name of your Docker image containing the research environment (example:quantconnect/research:latest).$ lean config set research-image quantconnect/research:latest\nSuccessfully updated the value of 'research-image' to 'quantconnect/research:latest'\n\nFollow these steps to revert the CLI to using the default Docker images when running the LEAN engine or the research environment:\n\nOpen a terminal.Runlean config unset engine-imageto configure the CLI to use the default engine image instead of a custom one.$ lean config unset engine-image\nSuccessfully unset 'engine-image'Runlean config unset research-imageto configure the CLI to use the default research image instead of a custom one.$ lean config unset research-image\nSuccessfully unset 'research-image'\n\n### Building Custom Images\n\nFollow these steps to build custom LEAN Docker images using the CLI:\n\nCreate a new directory that will hold the LEAN repository.Clone theQuantConnect / LeanGitHub repository usinggitor download and extract the latestmaster branch archive. Save this repository to a directory calledLeanin the directory created in step 1.Make your changes to LEAN.Open a terminal in the directory created in step 1.Runlean buildto build the foundation image, compile LEAN, build the engine image, and build the research image.$ lean build\nBuilding 'lean-cli/foundation:latest' from '/home/johndoe/QuantConnect/Lean/DockerfileLeanFoundation'\nCompiling the C# code in '/home/johndoe/QuantConnect/Lean'\nBuilding 'lean-cli/engine:latest' from '/home/johndoe/QuantConnect/Lean/Dockerfile' using 'lean-cli/foundation:latest' as base image\nBuilding 'lean-cli/research:latest' from '/home/johndoe/QuantConnect/Lean/DockerfileJupyter' using 'lean-cli/engine:latest' as base image\nSetting default engine image to 'lean-cli/engine:latest'\nSetting default research image to 'lean-cli/research:latest'After running this command the CLI uses your newly built images instead of the official ones.\n\nBy default thelean buildcommand tags all custom images withlatest.\nYou can specify a different tag using the--tag <value>option.\n\nIf you haven't changed the foundation Dockerfile, the CLI automatically skips building the custom foundation image and uses the officialquantconnect/lean:foundationimage instead.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Custom Docker Images",
      "section_number": "5.9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "5.10",
    "title": "Version Control",
    "level": 2,
    "path": "Projects > Version Control",
    "content": "### Introduction\n\nVersion control is the practice of tracking and managing changes to code files. By using version control, you can save an extra back up of your project files in the cloud, keep a history of all code changes, and easily revert changes to your projects.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Create Workspace Repositories\n\nFollow these steps to set up a new version control repository for one of yourorganization workspaces:\n\nIn your version control system,create a new repositoryfor the organization workspace.Open a terminal in your organization workspace and thenclonethe new repository to a temporary directory.$ git clone https://github.com/<userName>/<repoName>.git tempMove the.gitdirectory from the temporary directory to the workspace directory.$ mv temp/.git <workspaceDirectory>/.gitDelete the temporary directory.$ rm -r temp\n\n### Push Changes to Git\n\nFollow these steps to push the changes of your organization workspace to your version control system:\n\nPull all your cloud projects, creating directories where necessary.$ lean cloud pullAdd the project directories and theLibrary.$ git add Library/\n$ git add <projectDirectory1>/\n$ git add <projectDirectory2>/Commit the changes.$ git commit -am \"Latest Updates\"Push the changes to the repository.$ git push",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "5",
      "breadcrumb": "Projects > Version Control",
      "section_number": "5.10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "6",
    "title": "Research",
    "level": 1,
    "path": "Research",
    "content": "### Introduction\n\nStarting local Jupyter Lab environments is a powerful feature of the Lean CLI.\nJupyter Lab environments allow you to work on research notebooks locally.\nThese environments contain the same features asQuantConnect's research environmentbut run on your local machine.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Start the Research Environment\n\nYou can run the Research Environment with your current configuration or an old configuration from QuantConnect.\n\nCurrent Configuration\n\nThe default Research Environment configuration is the latest master branch of LEAN. If youset a different research image, the image you set is your current configuration. To start a local research environment with your current configuration, open a terminal in one of yourorganization workspacesand then runlean research \"<projectName>\"to start a local research environment for the project in. / <projectName>on port8888.\n\n$ lean research \"My Project\"\nStarting JupyterLab, access in your browser at localhost:8888\n\nJupyterLab automatically opens in your default browser. If you intend to use PyCharm or VS Code instead of JupyterLab, include the--no-openoption to not open JupyterLab. To run the environment on a different port by providing the--port <port>option.\n\nIf your configuration is set to the master branch of LEAN, the CLI automatically checks if your image is behind master every seven days. If your image falls behind master, the CLI automatically updates your image to the lastest version. To force an update before the automatic check, add the--updateoption. To avoid updates, add the--no-updateoption.\n\nOld Configurations from QuantConnect\n\nFollow these steps to start a local Research Environment with an old research configuration from QuantConnect:\n\nView the available versions on thequantconnect/research Docker Hub tags page.Copy the name of the tag you want to run.Open a terminal in one of yourorganization workspaces.Runlean research \"<projectName>\" --image quantconnect/research:<tagFromStep2>to start a local Research Environment for the project in. / <projectName>.$ lean research \"My Project\" --image quantconnect/research:11154\nPulling quantconnect/research:11154...\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\n\nData Providers\n\nWhen you run the Research Environment, the default data provider is your local machine.\nTo use data from QuantConnect Cloud, a brokerage, or a third-party data provider, include the--data-provider-historicaloption.\nTo view what brokerages and third-party data providers are available, seethe reference page for this command.\n\n### Use JypterLab\n\nThe following sections explain how to operate the Research Environment withJupyterLab, the default IDE.\n\nOpen Notebooks\n\nFollow these steps to open a research notebook in JupyterLab:\n\nStart a local research environmentfor the project that contains the notebook.In the left navigation menu, click theFile Browsericon.In the File Browser panel, double-click the notebook file you want to open.The default notebook isresearch.ipynb.\n\nFor more information about opening files in JupyterLab, seeOpening Filesin the JupyterLab documentation.\n\nRun Notebook Cells\n\nNotebooks are a collection of cells where you can write code snippets or MarkDown. To execute a cell, pressShift+Enter.\n\nThe following describes some helpful keyboard shortcuts to speed up your research:\n\n[Table - 6 rows]\n\nFor more information about keyboard shortcuts in JupyterLab, seeKeyboard Shortcutsin the JupyterLab documentation.\n\nStop Nodes\n\nFollow these steps to stop a research node in JupyterLab:\n\nIn the left navigation menu, click theRunning Terminals and Kernelsicon.In theKernalssection of the Running Terminals and Kernels panel, right-click the name of the notebook file and then clickShut Down Kernelfrom the drop-down menu.\n\nFor more information about the Running Terminals and Kernels panel in JupyterLab, seeManaging Kernels and Terminalsin the JupyterLab documentation.\n\nAdd Notebooks\n\nFollow these steps to add notebook files to a project in JupyterLab:\n\nStart a local research environmentfor the project.In the top navigation menu, clickFile > New > Notebook.In the Select Kernel window, clickSelect.\n\nFor more information about the creating files in JupyterLab, seeCreating Files and Activitiesin the JupyterLab documentation.\n\nRename Notebooks\n\nFollow these steps to rename notebook files in JupyterLab:\n\nStart a local research environmentfor the project that contains the notebook.In the left navigation menu, click theFile Browsericon.In the File Browser panel, right-click the notebook file you want to rename and then clickRenamefrom the drop-down menu.Enter the new name.PressEnter.\n\nDelete Notebooks\n\nFollow these steps to delete notebook files in JupyterLab:\n\nStart a local research environmentfor the project that contains the notebook.In the left navigation menu, click theFile Browsericon.In the File Browser panel, right-click the notebook file you want to delete and then clickDeletefrom the drop-down menu.In the Delete window, clickDelete.\n\n### Use PyCharm\n\nThe following sections explain how to operate the Research Environment withPyCharm.\n\nOpen Notebooks\n\nFollow these steps to open a research notebook in PyCharm:\n\nStart a local research environmentfor the project that contains the notebook.Open the same project in PyCharm.In the top navigation menu of PyCharm, clickFile > Settings.In the Settings window, clickLanguage & Frameworks > Jupyter > Jupyter Servers.ClickConfigured Server.Enterhttp://localhost:8888/?token=into the field.ClickApplyto save the changes.ClickOKto exit the window.In the left navigation menu, click theProjecticon.In the Project panel, double-click the notebook file you want to open.The default notebook isresearch.ipynb.\n\nRun Notebook Cells\n\nNotebooks are a collection of cells where you can write code snippets or MarkDown. To execute a cell, pressShift+Enter.\n\nThe following describes some helpful keyboard shortcuts to speed up your research:\n\n[Table - 6 rows]\n\nFor more information about keyboard shortcuts in PyCharm, seeKeyboard Shortcutsin the PyCharm documentation.\n\nStop Nodes\n\nFollow these steps to stop a research node in PyCharm:\n\nIn the left navigation menu, click theProjecticon.In the Project panel, right-click the name of the notebook file and then clickShutdown Kernelfrom the drop-down menu.\n\nFor more information about the Jupyter notebook servers in PyCharm, seeManage Jupyter notebook serversin the PyCharm documentation.\n\nAdd Notebooks\n\nTo add notebook files to a project in PyCharm, seeCreate a notebook filein the PyCharm documentation.\n\nRename Notebooks\n\nFollow these steps to rename notebook files in PyCharm:\n\nStart a local research environmentfor the project in PyCharm.In the left navigation menu, click theProjecticon.In the Project panel, right-click the notebook file you want to rename and then clickRefactor > Renamefrom the drop-down menu.Enter the new name.PressEnter.\n\nDelete Notebooks\n\nFollow these steps to delete notebook files in PyCharm:\n\nStart a local research environmentfor the project in PyCharm.In the left navigation menu, click theProjecticon.In the Project panel, right-click the notebook file you want to rename and then clickDeletefrom the drop-down menu.In the Delete window, clickOK.\n\n### Use VS Code\n\nThe following sections explain how to operate the Research Environment with VS Code.\n\nOpen Notebooks\n\nFollow these steps to open a research notebook in VS Code:\n\nStart a local research environmentfor the project that contains the notebook.Open the same project VS Code.In the Explore panel, click the notebook file you want to open.The default notebook isresearch.ipynb.In the top-right corner of the notebook, clickSelect Kernel.In the Select Another Kernel window, clickExisting Jypter Server....Enterhttp://localhost:8888/into the field.PressEnter.(Optional)Enter a display name for the server and then pressEnter.ClickFoundation-Py-DefaultFoundation-C#-Default.\n\nRun Notebook Cells\n\nNotebooks are a collection of cells where you can write code snippets or MarkDown. To execute a cell, pressShift+Enter.\n\nThe following describes some helpful keyboard shortcuts to speed up your research:\n\n[Table - 6 rows]\n\nFor more information about keyboard shortcuts in VS Code, seeKey Bindings for Visual Studio Codein the VS Code documentation.\n\nAdd Notebooks\n\nFollow these steps to add notebook files to a project in VS Code:\n\nOpen the project.In the right navigation menu, click theExplorericon.In the Explorer panel, expand theQC (Workspace)section.Click theNew Fileicon.EnterfileName.ipynb.PressEnter.\n\nRename Notebooks\n\nFollow these steps to rename notebook files in VS Code:\n\nStart a local research environmentfor the project that contains the notebook.In the right navigation menu, click theExplorericon.In the Explorer panel, expand theQC (Workspace)section.Click theNew Fileicon.EnterfileName.ipynb.PressEnter.\n\nDelete Notebooks\n\nFollow these steps to delete notebook files in VS Code:\n\nStart a local research environmentfor the project that contains the notebook.In the right navigation menu, click theExplorericon.In the Explorer panel, right-click the notebook you want to rename and then clickRename.Enter the new name and then pressEnter.\n\n### Retrieving Local Backtests\n\nSometimes it might be useful to retrieve the results of a previously ran local backtest in the research environment.\nBy default, backtests are saved in the<projectName> / backtests / <timestamp>directory, which is also available in the research environment.\nYou can use the following code snippet to read the contents of a backtest's result file into a local variable and to print its statistics (make sure to replace the path to the backtest with your own):\n\nusing Newtonsoft.Json;\nusing QuantConnect.Packets;\n\nvar backtestPath = \"backtests/2021-03-03_23-46-43/CSharpProject.json\";\n\nvar json = File.ReadAllText(backtestPath);\nvar data = JsonConvert.DeserializeObject<BacktestResultParameters>(json);\n\nforeach (var item in data.Statistics) {\nConsole.WriteLine($\"{item.Key}: {item.Value}\");\n}import json\n\nbacktest_path = \"backtests/2021-03-03_01-57-38/main.json\"\n\nwith open(backtest_path) as file:\ndata = json.load(file)\n\nfor key, value in data[\"Statistics\"].items():\nprint(f\"{key}: {value}\")\n\n### Retrieving Cloud Backtests\n\nIf you arelogged inusinglean loginyou can also retrieve cloud backtest results in your local research environment.\nIf you know the name of the project and the backtest you can use the following code snippet to retrieve the backtest's results and to print its statistics:\n\nvar projectName = \"Python Template\";\nvar backtestName = \"Adaptable Tan Frog\";\n\nvar project = api.ListProjects().Projects.First(p => p.Name == projectName);\nvar partialBacktest = api.ListBacktests(project.ProjectId).Backtests.First(b => b.Name == backtestName);\nvar backtest = api.ReadBacktest(project.ProjectId, partialBacktest.BacktestId);\n\nforeach (var item in backtest.Statistics) {\nConsole.WriteLine($\"{item.Key}: {item.Value}\");\n}project_name = \"Python Template\"\nbacktest_name = \"Adaptable Tan Frog\"\n\nproject = next(p for p in api.list_projects().projects if p.name == project_name)\npartial_backtest = next(b for b in api.list_backtests(project.project_id).backtests if b.name == backtest_name)\nbacktest = api.read_backtest(project.project_id, partial_backtest.backtest_id)\n\nfor key in backtest.statistics.keys:\nprint(f\"{key}: {backtest.statistics[key]}\")",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Research",
      "section_number": "6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Keyboard Shortcut | Description |\n| --- | --- |\n| Shift+Enter | Run the selected cell. |\n| a | Insert a cell above the selected cell. |\n| b | Insert a cell below the selected cell. |\n| x | Cut the selected cell. |\n| v | Paste the copied or cut cell. |\n| z | Undo cell actions. |",
    "table_1": "| Keyboard Shortcut | Description |\n| --- | --- |\n| Shift+Enter | Run the selected cell. |\n| a | Insert a cell above the selected cell. |\n| b | Insert a cell below the selected cell. |\n| x | Cut the selected cell. |\n| v | Paste the copied or cut cell. |\n| z | Undo cell actions. |",
    "table_2": "| Keyboard Shortcut | Description |\n| --- | --- |\n| Shift+Enter | Run the selected cell. |\n| a | Insert a cell above the selected cell. |\n| b | Insert a cell below the selected cell. |\n| x | Cut the selected cell. |\n| v | Paste the copied or cut cell. |\n| z | Undo cell actions. |"
  },
  {
    "id": "7",
    "title": "Backtesting",
    "level": 1,
    "path": "Backtesting",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Backtesting",
      "section_number": "7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "7.1",
    "title": "Deployment",
    "level": 2,
    "path": "Backtesting > Deployment",
    "content": "### Introduction\n\nBacktesting is a way to test your algorithm on historical data.\nThe CLI makes backtesting easier by providing simple commands to backtest your algorithms locally or in QuantConnect Cloud.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Run Local Backtests\n\nBy default, local backtests run in the LEAN engine in thequantconnect/leanDocker image.\nThis Docker image contains all thelibraries available on QuantConnect, meaning your algorithm also has access to those libraries.\nIf the specified project is a C# project, it is first compiled using the same Docker image.\nSeeThird-Party Librariesto learn how to use custom libraries and seeCustom Docker Imagesto learn how to build and use custom Docker images.\n\nBecause algorithms run in a Docker container,localhostdoes not point to your computer'slocalhost.\nSubstitutelocalhostwithhost.docker.internalif your algorithm needs to connect to other services running on your computer.\nIn other words, instead of connecting tohttp://localhost:<port>/, connect tohttp://host.docker.internal:<port>/.\n\nYou can run local backtests with the regular version of the LEAN engine or a custom version.\n\nRegular LEAN Engine\n\nFollow these steps to run a local backtest with the latest version of LEAN engine:\n\nSet up your local datafor all the data required by your project.Open a terminal in theorganization workspacethat contains the project you want to backtest.Runlean backtest \"<projectName>\"to run a local backtest for the project in. / <projectName>.$ lean backtest \"My Project\"\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\nSuccessfully ran 'My Project' in the 'backtesting' environment and stored the output in 'My Project/backtests/2021-03-22_18-51-28'View the result in the<projectName> / backtests / <timestamp>directory.\nResults are stored in JSON files and can be analyzed in alocal research environment.\nYou can save results to a different directory by providing the--output <path>option in step 3.$ lean backtest \"My Project\" --output \"My Project/custom-output\"\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\nSuccessfully ran 'My Project' in the 'backtesting' environment and stored the output in 'My Project/custom-output'\n\nCustom LEAN Engine\n\nFollow these steps to run a local backtest with a custom version of the LEAN engine:\n\nSet up your local datafor all the data required by your project.View the available versions on thequantconnect/lean Docker Hub tags page.Copy the name of the tag that you want to run.Runlean backtest \"<projectName> --image quantconnect/lean:<tagFromStep2>\"to run a local backtest for the project in. / <projectName>.$ lean backtest \"My Project\" --image quantconnect/lean:11154\nPulling quantconnect/lean:11154...\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\n\nData Providers\n\nWhen you run a local backtest, the default data provider is your local machine.\nTo use data fromQuantConnect Cloud, a brokerage, or a third-party data provider, include the--data-provider-historicaloption.\nTo view what brokerages and third-party data providers are available, seethe reference page for this command.\n\nRequired Datasets\n\nTo run backtests with Equity or Equity Option data, download thedownload the US Equity Security Master.\n\nTo run backtests with Futures data,download the US Futures Security Master.\n\nUS Equity Options Algorithms\n\nFollow these steps to run a local US Equity Options backtest:\n\nDownload theUS Equity Security Masterdataset.$ lean data download --dataset \"US Equity Security Master\"Download minute resolution trade data from theUS Equitydataset.$ lean data download --dataset \"US Equities\" --data-type \"Trade\" --ticker \"SPY\" --resolution \"Minute\" --start \"20210101\" --end \"20210720\"Download minute resolution trade and quote data from theUS Equity Optionsdataset.$ lean data download --dataset \"US Equity Options\" --data-type \"Trade\" --option-style \"American\" --ticker \"SPY\" --resolution \"Minute\" --start \"20210101\" --end \"20210720\"\n\n$ lean data download --dataset \"US Equity Options\" --data-type \"Quote\" --option-style \"American\" --ticker \"SPY\" --resolution \"Minute\" --start \"20210101\" --end \"20210720\"Create a new local project.$ lean project-create --language python \"<projectName>\"You can use the following example algorithm:\n\nIf you have the latest version of LEAN and you get differentoverall statisticswhen you run the algorithm on your local machine versus in the cloud, delete yourlocal data filesandre-download them. Some of your local files may be outdated and the preceding download commands didn't update them.\n\nThe following table shows a breakdown of the data costs for this example algorithm:\n\n[Table - 3 rows]\n\n### Run Cloud Backtests\n\nWhen you run a backtest in QuantConnect Cloud, it uses the data from theDataset Market.\nFollow these steps to run a cloud backtest:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project you want to backtest.Runlean cloud backtest \"<projectName>\" --push --opento push. / <projectName>to the cloud, run a cloud backtest for the project, and open the results in the browser.$ lean cloud backtest \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'\nStarted backtest named 'Muscular Black Chinchilla' for project 'My Project'Inspect the result in the browser, which opens automatically after the backtest finishes.\n\n### Download Datasets During Backtests\n\nAn alternative to manually downloading all the data you need before you run a backtest is to use theApiDataProviderin LEAN.\nThis data provider automatically downloads the required data files when your backtest requests them.\nAfter it downloads a data file, it stores it in your localdatadirectory so that in future runs, it won't have to download it again.\nIf the files contain data for multiple days (for example, daily Equity price data files), theApiDataProviderre-downloads the files if your local files are at least 7 days old.\nTo adjust this setting, update thedownloader-data-update-periodvalue in yourLean configurationfile.\n\nFollow these steps to use theApiDataProviderto automatically download the data you need:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project you want to backtest.Runlean backtest \"<projectName>\" --download-datato run a local backtest for the project in. / <projectName>and update the Lean configuration to use theApiDataProvider.$ lean backtest \"My Project\" --download-data\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\nSuccessfully ran 'My Project' in the 'backtesting' environment and stored the output in 'My Project/backtests/2021-03-22_18-51-28'Setting the--download-dataflag updates your Lean configuration.\nThis means that you only need to use the flag once, all future backtests will automatically use theApiDataProvider.\n\nFollow these steps to revert the Lean configuration changes so that it uses only local data again:\n\nOpen a terminal in yourorganization workspace.Runlean backtest \"<projectName>\" --data-provider-historical Localto run a local backtest for the project in. / <projectName>and update the Lean configuration to only use local data.$ lean backtest \"My Project\" --data-provider-historical Local\n20210322 17:27:46.658 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 17:27:46.664 TRACE:: Engine.Main(): Started 5:27 PM\nSuccessfully ran 'My Project' in the 'backtesting' environment and stored the output in 'My Project/backtests/2021-03-22_18-51-28'The--data-provider-historicaloption updates yourLean configuration.\nThis means that you only need to use the option once, all future backtests will automatically use the newly configured data provider.\n\nBy default theApiDataProviderdoes not have a spending limit and will keep downloading files until your QuantConnect organization runs out of QuantConnect Credit (QCC).\nYou can use the--data-purchase-limit <value>option to set the QCC spending limit for the backtest.\n\nAll the options documented above are also available on thelean researchcommand.\n\n### Get Backtest Id\n\nTo get the Id of a local backtest, check the name of the<organizationWorkspace>/ <projectName> / <deploymentTimestamp> / <backtestId>.jsonfile. An example local backtest Id is 1710698424.\n\nTo get the Id of a cloud backtest, check the output of thelean cloud backtestcommand in the terminal. If you no longer have the output,get the backtest Id from the Algorithm Lab. An example cloud backtest Id is 8b16cec0c44f75188d82f9eadb310e17.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "7",
      "breadcrumb": "Backtesting > Deployment",
      "section_number": "7.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Dataset | Initial Cost (USD) | Update Cost (USD) |\n| --- | --- | --- |\n| US Equity Security Master | $1,200/year | $1,200/year |\n| US Equity | $7.05 | $0.05/day |\n| US Equity Options | $41.70 | $0.30/day |"
  },
  {
    "id": "7.2",
    "title": "Debugging",
    "level": 2,
    "path": "Backtesting > Debugging",
    "content": "### Introduction\n\nDebugging is an important part of writing any algorithm.\nThe CLI makes it easy to use the builtin debugger of the most popular editors to debug LEAN algorithms.\nThis page explains how to start local debugging for Python and C# with all editors supported by the CLI.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Python and PyCharm\n\nLocal debugging for Python in PyCharm requires PyCharm's remote debugging functionality, which is only available in PyCharm Professional.\nAfter making sure you are running the Professional edition, follow these steps to start local debugging for Python in PyCharm:\n\nFollow theHow to set up local autocomplete for Python in PyCharmtutorial.Open the directory containing themain.pyfile in a new PyCharm window. It is important that you open the project directory itself, not yourorganization workspace.Start debugging using theDebug with Lean CLIrun configuration (this configuration is created when you create a new project with the CLI).Open a terminal in your organization workspace and runlean backtest \"<projectName>\" --debug pycharm.$ lean backtest \"My Project\" --debug pycharm\n20210322 18:58:23.355 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20210322 18:58:23.360 TRACE:: Engine.Main(): Started 6:58 PMTerminate the debugger in PyCharm once LEAN has exited.\n\nAfter finishing Python debugging with PyCharm, you will see a message saying \"Connection to Python debugger failed\".\nYou can safely ignore this message.\n\n### Python and VS Code\n\nFollow these steps to start local debugging for Python in VS Code:\n\nFollow theHow to set up local autocomplete for Python in VS Codetutorial.Open the directory containing themain.pyfile in a new VS Code window. It is important that you open the project directory itself, not yourorganization workspace.Open a terminal in your organization workspace, runlean backtest \"<projectName>\" --debug debugpy, and then wait until the CLI tells you to attach to the debugger.$ lean backtest \"My Project\" --debug debugpy\n20240507 20:35:54.970 TRACE:: Engine.Main(): LEAN ALGORITHMIC TRADING ENGINE v2.5.0.0 Mode: DEBUG (64bit)\n20240507 20:35:55.272 TRACE:: Engine.Main(): Started 8:35 PM\n20240507 20:36:01.104 TRACE:: DebuggerHelper.Initialize(): debugpy waiting for attach at port 5678...In VS Code, open theRuntab and run the configuration calledDebug with Lean CLI(this configuration is created when you create a new project with the CLI).\n\n### C# and Visual Studio\n\nFollow these steps to start local debugging for C# in Visual Studio:\n\nFollow theHow to set up local autocomplete for C# in Visual Studiotutorial.Open the project containing theMain.csfile in a new Visual Studio window. It is important that you open the project directory itself, not yourorganization workspace.Open a terminal in your organization workspace, runlean backtest \"<projectName>\" --debug vsdbg, and wait until the CLI tells you to attach to the debugger.$ lean backtest \"My Project\" --debug vsdbg\n20210423 13:50:54.634 TRACE:: DebuggerHelper.Initialize(): waiting for debugger to attach...In Visual Studio, open the process selector usingDebug > Attach to Process....SelectDocker (Linux Container)as the connection type.Selectlean_cli_vsdbgas connection target.Double-click on the process nameddotnet.Tick the checkbox in front ofManaged (.NET Core for Unix)and clickOKto start debugging.\n\nAfter finishing C# debugging with Visual Studio you will see a message saying \"The debug adapter exited unexpectedly.\".\nYou can safely ignore this message.\n\n### C# and Rider\n\nFollow these steps to start local debugging for C# in Rider:\n\nFollow theHow to set up local autocomplete for C# in Ridertutorial.Open the project containing theMain.csfile in a new Rider window. It is important that you open the project directory itself, not yourorganization workspace.Open a terminal in your organization workspace, runlean backtest \"<projectName>\" --debug rider, and wait until the CLI tells you to attach to the debugger.$ lean backtest \"My Project\" --debug rider\n20210423 13:50:54.634 TRACE:: DebuggerHelper.Initialize(): waiting for debugger to attach...In Rider, selectRun > Attach To Remote Process....In the pop-up that opens, select the target namedroot@localhost:2222.Wait for Rider to connect and select the process nameddotnet QuantConnect.Lean.Launcher.dllwhen a selector pops up to start debugging. You may have to selectRemote debugger tools are not loaded to the remote host. Click to loadfirst.\n\n### C# and VS Code\n\nFollow these steps to start local debugging for C# in VS Code:\n\nFollow theHow to set up local autocomplete for C# in VS Codetutorial.Open the directory containing theMain.csfile in a new VS Code window. It is important that you open the project directory itself, not yourorganization workspace.Open a terminal in your organization workspace, runlean backtest \"<projectName>\" --debug vsdbg, and wait until the CLI tells you to attach to the debugger.$ lean backtest \"My Project\" --debug vsdbg\n20210423 13:50:54.634 TRACE:: DebuggerHelper.Initialize(): waiting for debugger to attach...In VS Code, open theRuntab and run the configuration calledDebug with Lean CLI(this configuration is created when you create a new project with the CLI).\n\nAfter finishing C# debugging with VS Code you will see a message saying \"The pipe program 'docker' exited unexpectedly with code 137.\".\nYou can safely ignore this message.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "7",
      "breadcrumb": "Backtesting > Debugging",
      "section_number": "7.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8",
    "title": "Live Trading",
    "level": 1,
    "path": "Live Trading",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Live Trading",
      "section_number": "8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1",
    "title": "Brokerages",
    "level": 2,
    "path": "Live Trading > Brokerages",
    "content": "Brokerages supply a connection to the exchanges so that you can automate orders using LEAN. You can use multiple data providers in live trading algorithms.QuantConnect Paper TradingEquities, FOREX, CFD, Crypto, Futures, & Future OptionsAlpacaUS Equities, Equity Options & CryptoBinanceCrypto & Crypto FuturesBitfinexCryptoBybitCrypto & Crypto FuturesCharles SchwabUS Equities, Equity Options, Index, & Index OptionsCoinbaseCryptoInteractive BrokersEquities, Options, FOREX, Futures, Future Options, & CFDKrakenCryptoSamcoIndia EquitiesTradeStationUS Equities, Equity Options & FuturesTradierEquities & OptionsTrading TechnologiesFuturesZerodhaIndia EquitiesBloomberg EMSXEquities, FOREX, Crypto, Futures, & OptionsCFD and FOREX BrokeragesCFD & FOREXSee AlsoIQ FeedPolygonTheta Data",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Live Trading > Brokerages",
      "section_number": "8.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.1",
    "title": "QuantConnect Paper Trading",
    "level": 3,
    "path": "Live Trading > Brokerages > QuantConnect Paper Trading",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the QuantConnect Paper Trading brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the QuantConnect Paper Trading brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,1.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Set your initial cash balance.$ lean live deploy \"My Project\"\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf your algorithm only uses custom data, you can select the \"Custom data only\" data provider option.\nThis data feed doesn't require any brokerage credentials, but only works if your algorithm doesn't subscribe to non-custom data.\nYour algorithm crashes if it attempts to subscribe to non-custom data with this data provider in place, including the benchmark security.\nTo avoid data issues with the benchmark security, eitherset the benchmark to the subscribed custom dataor a constant.\n\nSetBenchmark(x => 0);self.set_benchmark(lambda x: 0)\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the QuantConnect Paper Trading brokerage :\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter1to select the QuantConnect Paper Trading brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: QuantConnect Paper Trading\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: QuantConnectBrokerage\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: QuantConnect Paper Trading\nLaunched: 2021-06-09 15:10:12 UTC",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > QuantConnect Paper Trading",
      "section_number": "8.1.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.2",
    "title": "Alpaca",
    "level": 3,
    "path": "Live Trading > Brokerages > Alpaca",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Alpaca brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Alpaca brokerage integration, see theLean.Brokerages.Alpaca repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Alpaca brokerage and the Alpaca data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter16to select the Alpaca brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 16In the browser window that automatically opens, clickAllow.$ lean cloud live \"My Project\" --push --open\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=alpaca\nWill sleep 5 seconds and retry fetching authorization...Enter the environment to use.$ lean cloud live \"My Project\" --push --open\nLive or Paper environment? (live, paper): liveConfigure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter19to select the Alpaca data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 19In the browser window that automatically opens, clickAllow.$ lean cloud live \"My Project\" --push --open\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=alpaca\nWill sleep 5 seconds and retry fetching authorization...Enteryour API key and API secret.$ lean live \"My Project\"\nAlpaca Api Key: PKEFXE36AR5OEG5K5KNQ\nAlpaca Api Secret: ****************************************Verify the configured settings and confirm them to start the live deployment in the cloud.$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Alpaca\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Alpaca\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: yInspect the result in the browser, which opens automatically after the deployment starts.\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Alpaca\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Alpaca brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,16.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 16In the browser window that automatically opens, clickAllow.$ lean live \"My Project\"\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=alpaca\nWill sleep 5 seconds and retry fetching authorization...Enter the environment to use.$ lean live \"My Project\"\nLive or Paper environment? (live, paper): liveEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor information about the Alpaca data provider, seeAlpaca.\n\nIn local deployments,universe selectionis available if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nTo stay up-to-date, periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF Constituents\n\nThe Alpaca data provider serves raw Equity data. To get adjusted data in local deployments,download the US Equity Security Master.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Alpaca",
      "section_number": "8.1.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.3",
    "title": "Binance",
    "level": 3,
    "path": "Live Trading > Brokerages > Binance",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Binance or Binance US brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Binance brokerage integration, see theLean.Brokerages.Binance repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Binance brokerage and the Binance data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter7to select the Binance brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 7Enter the exchange to use.$ lean cloud live \"My Project\" --push --open\nBinance Exchange (Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures): BinanceUSEnter your Binance API key and secret.$ lean cloud live \"My Project\" --push --open\nAPI key: wL1waeOC7VD447skCFeiat9pP3r1uKXfYomGg43uyCOgzl8xsI9SZsX97AXP4zWv\nAPI secret: ****************************************************************To create new credentials, seeHow to Create API Keys on Binance.Enter the environment to use.$ lean cloud live \"My Project\" --push --open\nUse the testnet? (live, paper):Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter7to select the Binance data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 7If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Binance\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Binance\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Binance\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Binance or Binance US brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,1.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Enter the exchange to use.$ lean live \"My Project\"\nBinance Exchange (Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures): BinanceUSEnter your API key and API secret.$ lean live \"My Project\"\nAPI key: 6d3ef5ca2d2fa52e4ee55624b0471261\nAPI secret: ********************************To create new credentials, seeHow to Create API Keys on Binance.Enter the environment to use.$ lean live \"My Project\"\nUse the testnet? (live, paper): liveEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Binance",
      "section_number": "8.1.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.4",
    "title": "Bitfinex",
    "level": 3,
    "path": "Live Trading > Brokerages > Bitfinex",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Bitfinex brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Bitfinex brokerage integration, see theLean.Brokerages.Bitfinex repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Bitfinex brokerage and the Bitfinex data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter5to select the Bitfinex brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 5Enter your API key Id and secret.$ lean cloud live \"My Project\" --push --open\nAPI key: bbbMsqbxjytVM9cGvnLpKguz9rZf2T5qACxaVx7E8Mm\nSecret key: *******************************************To create new API credentials, see theAPI Management pageon the Bitfinex website.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter5to select the Bitfinex data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 5If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Bitfinex\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Bitfinex\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Bitfinex\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Bitfinex brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,5.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 5Enter your API key Id and secret.$ lean live \"My Project\"\nAPI key: bbbMsqbxjytVM9cGvnLpKguz9rZf2T5qACxaVx7E8Mm\nAPI secret: *******************************************To create new API credentials, see theAPI Management pageon the Bitfinex website.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Bitfinex",
      "section_number": "8.1.4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.5",
    "title": "Bybit",
    "level": 3,
    "path": "Live Trading > Brokerages > Bybit",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Bybit brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Bybit brokerage integration, see theLean.Brokerages.Bybit repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Bybit brokerage and the Bybit data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter14to select the Bybit brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 14Enter your API key and secret.$ lean live \"My Project\"\nAPI key: bbbMsqbxjytVM9cGvnLpKguz9rZf2T5qACxaVx7E8Mm\nAPI secret: *******************************************To generate your API credentials, seeAccount Types. Your account details are not saved on QuantConnect.Enter your VIP level.$ lean live \"My Project\"\nVIP Level (VIP0, VIP1, VIP2, VIP3, VIP4, VIP5, SupremeVIP, Pro1, Pro2, Pro3, Pro4, Pro5): VIP0For more information about VIP levels, seeFAQ — Bybit VIP Programon the Bybit website.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter17to select the Bybit data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 17If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Bybit\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Bybit\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Bybit\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Bybit brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,14.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 14Enter your API key and secret.$ lean live \"My Project\"\nAPI key: bbbMsqbxjytVM9cGvnLpKguz9rZf2T5qACxaVx7E8Mm\nAPI secret: *******************************************To generate your API credentials, seeAccount Types. Your account details are not saved on QuantConnect.Enter your VIP level.$ lean live \"My Project\"\nVIP Level (VIP0, VIP1, VIP2, VIP3, VIP4, VIP5, SupremeVIP, Pro1, Pro2, Pro3, Pro4, Pro5): VIP0For more information about VIP levels, seeFAQ — Bybit VIP Programon the Bybit website.Enter the environment to use.$ lean live \"My Project\"\nUse testnet? (live, paper): liveThe paper environment isBybit Demo Trading.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Bybit",
      "section_number": "8.1.5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.6",
    "title": "Charles Schwab",
    "level": 3,
    "path": "Live Trading > Brokerages > Charles Schwab",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Charles Schwab brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nCharles Schwab only supports authenticating one account at a time per user. If you have an algorithm running with Charles Schwab and then deploy a second one, the first algorithm stops running.\n\np>To view the implementation of the Charles Schwab brokerage integration, see the <a href='https://github.com/QuantConnect/Lean.Brokerages.CharlesSchwab' rel='nofollow' target=\"_blank\">Lean.Brokerages.CharlesSchwab repository</a>.</p\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Charles Schwab brokerage and the Charles Schwab data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter13to select the Charles Schwab brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 13In the browser window that automatically opens, clickAllow.$ lean cloud live \"My Project\" --push --open\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=charlesschwab&projectId=<projectId>\nWill sleep 5 seconds and retry fetching authorization...Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter13to select the Charles Schwab data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 13Verify the configured settings and confirm them to start the live deployment in the cloud.$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Charles Schwab\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Charles Schwab\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: yInspect the result in the browser, which opens automatically after the deployment starts.\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Charles Schwab\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Charles Schwab brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,13.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 13If your project is local-only project, LEAN CLI will prompt you to enter the ID of any cloud project of your organization to proceed with authentication, seeGet Project IDfor more information.$ lean live \"My Project\"\nPlease enter any cloud project ID to proceed with Auth0 authentication:In the browser window that automatically opens. On the Charles Schwab website, log in, and select your Schwab accounts to link. ClickAllowto grant QuantConnect access to your account information and authorization.$ lean live \"My Project\"\nPlease enter any cloud project ID to proceed with Auth0 authentication: <projectId>\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=charlesschwab&projectId=<projectId>\nWill sleep 5 seconds and retry fetching authorization...Enter the Charles Schwab account number.$ lean live \"My Project\"\nThe CharlesSchwab account number (12345678, 23456789): 12345678Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor information about the Charles Schwab data provider, seeCharles Schwab.\n\nIn local deployments,universe selectionis available if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nTo stay up-to-date, periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nThe Charles Schwab data provider serves raw Equity data. To get adjusted data in local deployments,download the US Equity Security Master.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Charles Schwab",
      "section_number": "8.1.6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.7",
    "title": "Coinbase",
    "level": 3,
    "path": "Live Trading > Brokerages > Coinbase",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Coinbase brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Coinbase brokerage integration, see theLean.Brokerages.Coinbase repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Coinbase Advanced Trade brokerage and the Coinbase Advanced Trade data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter6to select the Coinbase Advanced Trade brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 6Enter your API name and private key.$ lean live \"My Project\"\nAPI name: organizations/2c7dhs-a3a3-4acf-aa0c-f68584f34c37/apiKeys/41090ffa-asd2-8080-815f-afaf63747e35\nAPI private key: ****************************************************************************************To create new API credentials, seeAccount Types.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter6to select the Coinbase Advanced Trade data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 6If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Coinbase Advanced Trade\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Coinbase Advanced Trade\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Coinbase Advanced Trade\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Coinbase Advanced Trade brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,6.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 6Enter your API name and private key.$ lean live \"My Project\"\nAPI name: organizations/2c7dhs-a3a3-4acf-aa0c-f68584f34c37/apiKeys/41090ffa-asd2-8080-815f-afaf63747e35\nAPI private key: ****************************************************************************************To create new API credentials, seeAccount Types.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Coinbase",
      "section_number": "8.1.7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.8",
    "title": "Interactive Brokers",
    "level": 3,
    "path": "Live Trading > Brokerages > Interactive Brokers",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Interactive Brokers (IB) brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the IB brokerage integration, see theLean.Brokerages.InteractiveBrokers repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Interactive Brokers brokerage and the Interactive Brokers data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter2to select the Interactive Brokers brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 2Set up IB Key Security via IBKR Mobile. For instructions, seeIB Key Security via IBKR Mobileon the IB website.Go back to the terminal and enter your Interactive Brokers username, account id, and password.$ lean cloud live \"My Project\" --push --open\nUsername: trader777\nAccount id: DU1234567\nAccount password: ****************Enter a weekly restart time that's convenient for you.$ lean cloud live \"My Project\" --push --open\nWeekly restart UTC time (hh:mm:ss) [21:00:00]:You'll receive a notification on your IB Key device every Sunday to re-authenticate the connection between IB and your live algorithm. Enter a time on Sunday to receive the notification. If you don't re-authenticate before the timeout period, your algorithm quits executing. Ensure your IB Key device has sufficient battery for the time you expect to receive the notification. If you don't receive a notification, seeI am not receiving IBKR Mobile notificationson the IB website.Enter whether you want to use theprice data from Interactive Brokersinstead of the data from QuantConnect. Enabling this feature requires you to have active Interactive Brokers market data subscriptions for all data required by your algorithm.$ lean cloud live \"My Project\" --push --open\nDo you want to use the Interactive Brokers price data feed instead of the QuantConnect price data feed? (yes/no): yConfigure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter2to select the Interactive Brokers data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 2If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Interactive Brokers\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Interactive Brokers\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Interactive Brokers\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nIf you have an ARM M1, M2, or M3 chip, you can't deploy a local live algorithm with the IB brokerage, see theTroubleshooting.\n\nFollow these steps to start local live trading with the Interactive Brokers brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,2.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 2Set up IB Key Security via IBKR Mobile. For instructions, seeIB Key Security via IBKR Mobileon the IB website.Go back to the terminal and enter your Interactive Brokers username, account id, and password.$ lean live \"My Project\"\nUsername: trader777\nAccount id: DU1234567\nAccount password: ****************Enter a weekly restart time that's convenient for you.$ lean live \"My Project\"\nWeekly restart UTC time (hh:mm:ss) [21:00:00]:You'll receive a notification on your IB Key device every Sunday to re-authenticate the connection between IB and your live algorithm. Enter a time on Sunday to receive the notification. If you don't re-authenticate before the timeout period, your algorithm quits executing. Ensure your IB Key device has sufficient battery for the time you expect to receive the notification. If you don't receive a notification, seeI am not receiving IBKR Mobile notificationson the IB website.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor information about the IB data provider, seeInteractive Brokers.\n\nIn local deployments,universe selectionis available if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nTo stay up-to-date, periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nThe IB data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata in local deployments,download the US Futures Security Master.\n\n### Troubleshooting\n\nThe following table describes errors you may see when deploying to IB:\n\n[Table - 12 rows]\n\nTo view the description of less common errors, seeError Codesin the TWS API Documentation. If you need further support,open a new support tickerand add the live deployment with the error.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Interactive Brokers",
      "section_number": "8.1.8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Error Message(s) | Possible Cause and Fix |\n| --- | --- |\n| Login failed. | The credentials you provided are incorrect. Typically, the password contains\n                leading and/or trailing white spaces. Copy the password to a text editor to ensure\n                the password is correct. \n                If you can't log in to Trader Workstation (TWS) with your credentials, contact IB. If you can log in to TWS but can't log in to the deployment wizard,contact usand provide the algorithm Id and deployment Id. |\n| Login to the IB Gateway failed becausea user account-tasks is required. | DownloadIB Gateway, run it, and follow the instructions provided. |\n| An existing session was detected and will not be automatically disconnected.Historical Market Data Service error message: Trading TWS session is connected from a different IP address. |  |\n| IB still recognizes your previous live deployment as being partially connected.\n                It can take a minute to fully disconnect. \n                For more information, seeSecurity and Stability > Connections. |  |\n| The two factor authentication request timed out.A security dialog was detected for Code Card Authentication. |  |\n| You haven't replied to the two factor authentication requests. \n                The code card authentication is triggered when you don't reply to the IB mobile 2FA requests.\n                Ensure your IB Key device has sufficient battery for the time you expect to receive the notification. \n                If you don't receive a notification, seeI am not receiving IBKR Mobile notificationson the IB website. |  |\n| API support is not available for accounts that support free trading. | Upgrade your plan from IBKR Lite to IBKR Pro. |\n| No security definition has been found for the request. | Your algorithm added an invalid security. For example, a deslisted stock, an expired contract, or inexistent contract (invalid expiration date or strike price). If the security should be valid,contact usand provide the algorithm Id and deployment Id. |\n| Requested market data is not subscribed.Historical Market Data Service error message: No market data permissions for ... |  |\n| Your algorithm uses theInteractive Brokers Data Provider, but you don't have a subscription to it.Subscribe to the data bundle you need, contact IB, or re-deploy the algorithm with a different data provider. \n                Try theQuantConnector thehybrid QuantConnect + Interactive Brokersdata providers on QuantConnect Cloud or try a third-party provider. |  |\n| Timeout waiting for brokerage response for brokerage order id 37 lean id 31 | IB didn't respond to an order request. Stop and re-deploy the algorithm. On the next deployment, LEAN retrieves this order or the positions it opened or closed. |\n| Could not find file '/root/ibgateway/ibgateway'. | Your Docker installation has pulled the ARM platform version of the LEAN Docker image. This version doesn't include IB Gateway, because QuantConnect doesn't support Interactive Brokers integration with ARM chips (e.g.: Apple M1, M2, and M3 chips). |"
  },
  {
    "id": "8.1.9",
    "title": "Kraken",
    "level": 3,
    "path": "Live Trading > Brokerages > Kraken",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Kraken brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Kraken brokerage integration, see theLean.Brokerages.Kraken repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Kraken brokerage and the Kraken data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter12to select the Kraken brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 12Enter your API key and API secret.$ lean cloud live \"My Project\" --push --open\nAPI key:\nSecret key:To get your API credentials, see theAPI Management Settingspage on the Kraken website.Enter your verification tier.$ lean cloud live \"My Project\" --push --open\nSelect the Verification Tier (Starter, Intermediate, Pro):For more information about verification tiers, seeVerification levels explainedon the Kraken website.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter12to select the Kraken data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 12If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Kraken\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Kraken\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Kraken\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Kraken brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,12.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 12Enter your API key and API secret.$ lean live \"My Project\"\nAPI key:\nAPI secret:To get your API credentials, see theAPI Management Settingspage on the Kraken website.Enter your verification tier.$ lean live \"My Project\"\nSelect the Verification Tier (Starter, Intermediate, Pro):For more information about verification tiers, seeVerification levels explainedon the Kraken website.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Kraken",
      "section_number": "8.1.9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.10",
    "title": "Samco",
    "level": 3,
    "path": "Live Trading > Brokerages > Samco",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Samco brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Samco brokerage integration, see theLean.Brokerages.Samco repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Samco brokerage and the Samco data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter9to select the Samco brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 9Enter your Samco credentials.$ lean cloud live \"My Project\" --push --open\nClient ID:\nClient Password:Enter your year of birth.$ lean cloud live \"My Project\" --push --open\nYear of Birth:Enter the product type.$ lean cloud live \"My Project\" --push --open\nProduct type (mis, cnc, nrml):The following table describes the product types:Product TypeDescriptionmisIntraday productscncDelivery productsnrmlCarry forward productsEnter the trading segment.$ lean cloud live \"My Project\" --push --open\nTrading segment (equity, commodity):The following table describes when to use each trading segment:Trading SegmentDescriptionequityFor trading Equities on the National Stock Exchange of India (NSE) or the Bombay Stock Exchange (BSE)commodityFor trading commodities on the Multi Commodity Exchange of India (MCX)Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter9to select the Samco data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 9If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Samco\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Samco\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Samco\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Samco brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,9.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 9Enter your Samco credentials.$ lean live \"My Project\"\nClient ID:\nClient Password:Enter your year of birth.$ lean live \"My Project\"\nYear of Birth:Enter the product type.$ lean live \"My Project\"\nProduct type (mis, cnc, nrml):The following table describes the product types:Product TypeDescriptionmisIntraday productscncDelivery productsnrmlCarry forward productsEnter the trading segment.$ lean live \"My Project\"\nTrading segment (equity, commodity):The following table describes when to use each trading segment:Trading SegmentDescriptionequityFor trading Equities on the National Stock Exchange of India (NSE) or the Bombay Stock Exchange (BSE)commodityFor trading commodities on the Multi Commodity Exchange of India (MCX)Enter8to select the Samco data provider.$ lean live deploy \"My Project\"\nSelect a live data feed:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma: 8View the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor more information about the Samco data provider, seeSamco.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Samco",
      "section_number": "8.1.10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.11",
    "title": "TradeStation",
    "level": 3,
    "path": "Live Trading > Brokerages > TradeStation",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the TradeStation brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the TradeStation brokerage integration, see theLean.Brokerages.TradeStation repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the TradeStation brokerage and the TradeStation data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter15to select the TradeStation brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 15In the browser window that automatically opens, log in to your TradeStation account.$ lean cloud live \"My Project\" --push --open\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=tradestation\nWill sleep 5 seconds and retry fetching authorization...Enter the TradeStation account ID.$ lean cloud live \"My Project\" --push --open\nThe TradeStation account Id (11810357, 210NKH33, SIM2829935F, SIM2829934M): SIM2829935FConfigure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter18to select the TradeStation data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 18In the browser window that automatically opens, log in to your TradeStation account.$ lean cloud live \"My Project\" --push --open\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=tradestation\nWill sleep 5 seconds and retry fetching authorization...Verify the configured settings and confirm them to start the live deployment in the cloud.$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: TradeStation\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: TradeStation\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: yInspect the result in the browser, which opens automatically after the deployment starts.\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: TradeStation\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the TradeStation brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,15.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 15LEAN CLI opens your browser for authorization. Login to TradeStation.$ lean live \"My Project\"\nPlease open the following URL in your browser to authorize the LEAN CLI.\nhttps://www.quantconnect.com/api/v2/live/auth0/authorize?brokerage=tradestation\nWill sleep 5 seconds and retry fetching authorization...Enter the TradeStation account ID.$ lean live \"My Project\"\nThe TradeStation account Id (11810357, 210NKH33, SIM2829935F, SIM2829934M): SIM2829935FEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor information about the TradeStation data provider, seeTradeStation.\n\nIn local deployments,universe selectionis available if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nTo stay up-to-date, periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF ConstituentsUS Index Option Universe\n\nThe TradeStation data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata,download the US Futures Security Master.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > TradeStation",
      "section_number": "8.1.11",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.12",
    "title": "Tradier",
    "level": 3,
    "path": "Live Trading > Brokerages > Tradier",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Tradier brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Tradier brokerage integration, see theLean.Brokerages.Tradier repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Tradier brokerage and the Tradier data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter3to select the Tradier brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 3Enter your Tradier account Id and access token.$ lean cloud live \"My Project\" --push --open\nAccount id: VA000001\nAccess token: ****************To get these credentials, see yourSettings/API Access pageon the Tradier website.Enter whether the developer sandbox should be used.$ lean cloud live \"My Project\" --push --open\nUse the developer sandbox? (live, paper):Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter3to select the Tradier data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 3In the demo environment, Tradier doesn't offer streaming market data due to exchange restrictions related to delayed data.Verify the configured settings and confirm them to start the live deployment in the cloud.$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Tradier\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Tradier\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: yInspect the result in the browser, which opens automatically after the deployment starts.\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Tradier\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Tradier brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,3.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 3Enter your Tradier account Id and access token.$ lean live \"My Project\"\nAccount id: VA000001\nAccess token: ****************To get these credentials, see yourSettings/API Access pageon the Tradier website.Enter whether the developer sandbox should be used.$ lean live \"My Project\"\nUse the developer sandbox? (live, paper): liveEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIn the demo environment, Tradier doesn't offer streaming market data due to exchange restrictions related to delayed data.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor information about the Tradier data provider, seeTradier.\n\nIn local deployments,universe selectionis available if you download the data from theDataset Market.\nThe dataset listings show how to download the universe selection data with the CLI.\nTo stay up-to-date, periodically download the new data from QuantConnect Cloud, which you can automate with Python scripts.\nFor example, the following tutorials explain how to download historical data and download daily updates:\n\nUS Equity Coarse UniverseUS Equity Option UniverseUS ETF Constituents\n\nThe Tradier data provider serves raw Equity data. To get adjusted data in local deployments,download the US Equity Security Master.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Tradier",
      "section_number": "8.1.12",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.13",
    "title": "Trading Technologies",
    "level": 3,
    "path": "Live Trading > Brokerages > Trading Technologies",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Trading Technologies brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Trading Technologies integration, see theLean.Brokerages.TradingTechnologies repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Trading Technologies brokerage and the Trading Technologies data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter11to select the Trading Technologies brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 11Enteryour Trading Technologies credentials.$ lean cloud live \"My Project\" --push --open\nUser name: john\nSession password: ****************\nAccount name: janeEnter theREST configuration.$ lean cloud live \"My Project\" --push --open\nREST app key: my-rest-app-key\nREST app secret: ******************\nREST environment: my-environmentEnter theorder routing configuration.$ lean cloud live \"My Project\" --push --open\nOrder routing sender comp id:Our TT integration routes orders via the TT FIX 4.4 Connection.Contact your TT representativeto set the exchange where you would like your orders sent. Your account details are not saved on QuantConnect.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter11to select the Trading Technologies data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 11If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Trading Technologies\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Trading Technologies\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Trading Technologies\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Trading Technologies brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,11.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 11Enteryour Trading Technologies credentials.$ lean live \"My Project\"\nUser name: john\nSession password: ****************\nAccount name: janeEnter theREST configuration.$ lean live \"My Project\"\nREST app key: my-rest-app-key\nREST app secret: ******************\nREST environment: my-environmentEnter the market data configuration.$ lean live \"My Project\"\nMarket data sender comp id:\nMarket data target comp id:\nMarket data host:\nMarket data port:Enter the order routing configuration.$ lean live \"My Project\"\nOrder routing sender comp id:\nOrder routing target comp id:\nOrder routing host:\nOrder routing port:Enter whether FIX messages must be logged.$ lean live \"My Project\"\nLog FIX messages (yes/no): yesSet your initial cash balance.$ lean live deploy \"My Project\"\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nEnter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Trading Technologies",
      "section_number": "8.1.13",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.14",
    "title": "Zerodha",
    "level": 3,
    "path": "Live Trading > Brokerages > Zerodha",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Zerodha brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the Zerodha brokerage integration, see theLean.Brokerages.Zerodha repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Zerodha brokerage and the Zerodha data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter8to select the Zerodha brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 8Enter yourKite ConnectAPI key and access token.$ lean cloud live \"My Project\" --push --open\nAPI key: hp9erb9ct0lqaxpm\nAccess token: ********************Enter the product type.$ lean cloud live \"My Project\" --push --open\nProduct type (mis, cnc, nrml):The following table describes the product types:Product TypeDescriptionmisIntraday productscncDelivery productsnrmlCarry forward productsEnter the trading segment.$ lean cloud live \"My Project\" --push --open\nTrading segment (equity, commodity):The following table describes when to use each trading segment:Trading SegmentDescriptionequityFor trading Equities on the National Stock Exchange of India (NSE) or the Bombay Stock Exchange (BSE)commodityFor trading commodities on the Multi Commodity Exchange of India (MCX)Enter whether you have a history API subscription.$ lean live \"My Project\"\nDo you have a history API subscription? (true, false): trueConfigure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter8to select the Zerodha data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 8If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Zerodha\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Zerodha\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Zerodha\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Zerodha brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,8.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 8Enter yourKite ConnectAPI key and access token.$ lean live \"My Project\"\nAPI key: hp9erb9ct0lqaxpm\nAccess token: ********************Enter the product type.$ lean live \"My Project\"\nProduct type (mis, cnc, nrml):The following table describes the product types:Product TypeDescriptionmisIntraday productscncDelivery productsnrmlCarry forward productsEnter the trading segment.$ lean live \"My Project\"\nTrading segment (equity, commodity):The following table describes when to use each trading segment:Trading SegmentDescriptionequityFor trading Equities on the National Stock Exchange of India (NSE) or the Bombay Stock Exchange (BSE)commodityFor trading commodities on the Multi Commodity Exchange of India (MCX)Enter7to select the Zerodha data provider.$ lean live deploy \"My Project\"\nSelect a live data feed:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma: 7Enter whether you have a history API subscription.$ lean live \"My Project\"\nDo you have a history API subscription? (true, false): trueView the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Data Provider\n\nFor more information about the Zerodha data provider, seeZerodha.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Zerodha",
      "section_number": "8.1.14",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1.15",
    "title": "Bloomberg EMSX",
    "level": 3,
    "path": "Live Trading > Brokerages > Bloomberg EMSX",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the Terminal Link brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nThe LEAN CLI integrates with the Bloomberg Desktop API (DAPI) to get data for research, backtests, optimization, and live trading or through your existing Bloomberg data subscriptions. In addition, you can route live trading strategies and and UAT paper trading through Bloomberg order routing via the EMSX network.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Asset Classes\n\nTerminal Link supports trading the following asset classes:\n\nEquitiesEquity OptionsFuturesIndex Options\n\n### Data Feeds\n\nTerminal Link with the LEAN CLI lets you source historical data from Bloomberg and save it onto your desktop computer for backtesting as within your license permissions from Bloomberg. The Bloomberg API includes up to six months of history in low resolutions like second and minute resolutions.\n\n### Orders\n\nTerminal Link enables you to create and manage Bloomberg™ orders. You can also use the LEAN CLI with the Terminal Link integration to test paper trading with LEAN. In this case, LEAN models order fills using the live tick data feed from Bloomberg™.\n\nOrder Types\n\nThe following table describes the available order types for each asset class that Terminal Link supports:\n\n[Table - 4 rows]\n\nTime In Force\n\nTerminal Link supports the followingTimeInForceinstructions:\n\nDayDAYGoodTilCanceledGOOD_TIL_CANCELEDGoodTilDategood_til_date\n\nGet Open Orders\n\nTerminal Link lets youaccess open orders.\n\nMonitor Fills\n\nTerminal Link allows you to monitor orders as they fill throughorder events.\n\nUpdates\n\nTerminal Link doesn't supportorder updates.\n\nCancellations\n\nTerminal Link enables you tocancel open orders.\n\nHandling Splits\n\nIf you're using rawdata normalizationand you have active orders with a limit, stop, or trigger price in the market for a US Equity when astock splitoccurs, the following properties of your orders automatically adjust to reflect the stock split:\n\nQuantityLimit priceStop priceTrigger price\n\n### Fees\n\nOrders filled with Terminal Link are subject to the fees of the Bloomberg™ Execution Management System and your prime brokerage destination. To view how we model their fees, seeFees.\n\n### Historical Data\n\nWhen LEAN taps into Bloomberg™ via Terminal Link, it can run backtests and research notebooks with rich historical data sourced from the Bloomberg™ Terminal. LEAN provides accurate slippage, spread, and transaction fee models for realistic backtesting. All models are customizable to adapt to your strategy requirements. Historical data is cached locally in an efficient format for quick backtesting in the LEAN engine. If you request intraday historical data, you can request data from within the last 6 months. Historical open interest and custom data isn't available.\n\n### Compliance\n\nBloomberg™ is not affiliated with QuantConnect, nor does it endorse Terminal Link. QuantConnect requires a Trading Firm or Institutional license to use the Terminal Link integration.\n\nThe following rules apply:\n\nAll users of the integration must hold a Bloomberg License to be defined as an \"Entitled User\".All data accessed via the Bloomberg Desktop API must remain on the host computer. The Bloomberg Terminal and the LEAN instance must be on the same computer.\n\nThe following table shows the activities each of the Bloomberg technologies support:\n\n[Table - 2 rows]\n\n### CLI Commands\n\nExecute theCLIcommands in the following sections to interact with Terminal Link. If you need further assistance, see theCLI Reference.\n\nRun Local Backtests\n\nLaunch local backtests with data from the Bloomberg Terminal Desktop API. Lean automatically fetches the data required for your backtest.\n\n$ lean backtest \"<projectName>\" --data-provider-historical \"Terminal Link\"\n\nLaunch Research Notebooks\n\nStart Jupyter Research Notebooks, tapping into the entire QuantConnect API with the data sourced from a Bloomberg Terminal.\n\n$ lean research \"<projectName>\" --data-provider-historical \"Terminal Link\"\n\nDeploy Live Algorithms\n\nLaunch live trading algorithms to trade with any of the 1300+ routing destinations in the Bloomberg EMSX network.\n\n$ lean live \"<projectName>\" --brokerage \"Terminal Link\" --data-provider-live \"Terminal Link\"\n\n### Deploy Cloud Algorithms\n\nYou need toset up the Bloomberg SAPIbefore you can deploy cloud algorithms with Terminal Link.\n\nFollow these steps to start live trading a project in the cloud with the Terminal Link brokerage and the Terminal Link data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter10to select the Terminal Link brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 10Enter your unique user identifier (UUID).$ lean cloud live \"My Project\" --push --open\nConfigure credentials for Terminal Link\nUsing 'SAPI' Connection Type\nServer Auth ID:The UUID is a unique integer identifier that's assigned to each Bloomberg Anywhere user. If you don't know your UUID, contact Bloomberg.Enter the environment to use.$ lean cloud live \"My Project\" --push --open\nEnvironment (Production, Beta):Enter the SAPI host and port.$ lean cloud live \"My Project\" --push --open\nServer host:\nServer port:The default port is 8194.Enter the EMSX broker to use.$ lean cloud live \"My Project\" --push --open\nEMSX broker:Enter the account to which LEAN should route orders.$ lean cloud live \"My Project\" --push --open\nEMSX account []:Enter your OpenFIGI API key.$ lean cloud live \"My Project\" --push --open\nOpenFIGI API key:Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter10to select the Terminal Link data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 10If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Terminal Link\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Terminal Link\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Terminal Link\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nYou need toinstall the Bloomberg Terminal and the BBComm componentfrom the Bloomberg website before you can deploy local algorithms with Terminal Link.\n\nFollow these steps to start local live trading with the Terminal Link brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,10.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 10Enter the environment to use.$ lean live \"My Project\"\nEnvironment (Production, Beta): ProductionEnter the host and port of the Bloomberg server.$ lean live \"My Project\"\nServer host: 127.0.0.1\nServer port: 8194Enter your EMSX configuration$ lean live \"My Project\"\nEMSX broker: someValue\nEMSX account:Enter your Open FIGI API key.$ lean live \"My Project\"\nOpen FIGI API key:Enter9to select the Terminal Link live data provider.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma: 9View the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > Bloomberg EMSX",
      "section_number": "8.1.15",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Order Type | Equity | Equity Options | Futures | Index Options |\n| --- | --- | --- | --- | --- |\n| MarketOrder |  |  |  |  |\n| LimitOrder |  |  |  |  |\n| StopMarketOrder |  |  |  |  |\n| StopLimitOrder |  |  |  |  |",
    "table_1": "| Technology | Research | Backtesting | Paper Trading | Live Trading |\n| --- | --- | --- | --- | --- |\n| Desktop API |  |  |  |  |\n| B.PIPE |  |  |  |  |"
  },
  {
    "id": "8.1.16",
    "title": "CFD and FOREX Brokerages",
    "level": 3,
    "path": "Live Trading > Brokerages > CFD and FOREX Brokerages",
    "content": "### Introduction\n\nThe Lean CLI supports live trading on your local machine or in QuantConnect Cloud, which makes the transfer from backtesting to live trading as seamless as possible. You mustlog inusing your QuantConnect account to deply your algorithm on your local machine or in QuantConnect Cloud. This page contains instructions on how to start live trading with the OANDA brokerage. If theLean Configuration filein yourorganization workspacecontains values for some of the command options, the CLI skips some of the prompts.\n\nTo view the implementation of the OANDA brokerage integration, see theLean.Brokerages.OANDA repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the Oanda brokerage and the Oanda data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter4to select the Oanda brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 4Enter the environment to use. EnterTradefor fxTrade orPracticefor fxTrade Practice.$ lean cloud live \"My Project\" --push --open\nEnvironment? (Practice, Trade):Enter your OANDA account ID.$ lean cloud live \"My Project\" --push --open\nAccount id: 001-011-5838423-001To get your account ID, see yourAccount Statement pageon the OANDA website.Enter your OANDA API token.$ lean cloud live \"My Project\" --push --open\nAPI token: ****************To create a token, see theManage API Access pageon the OANDA website.Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySet your initial cash balance.$ lean cloud live deploy \"My Project\" --push --open\nPrevious cash balance: [{'currency': 'USD', 'amount': 100000.0}]\nDo you want to set a different initial cash balance? [y/N]: y\nSetting initial cash balance...\nCurrency: USD\nAmount: 95800\nCash balance: [{'currency': 'USD', 'amount': 95800.0}]\nDo you want to add more currency? [y/N]: nSet your initial portfolio holdings.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to set the initial portfolio holdings? [y/N]: y\nDo you want to use the last portfolio holdings? [] [y/N]: n\nSetting custom initial portfolio holdings...\nSymbol: GOOG\nSymbol ID: GOOCV VP83T1ZUHROL\nQuantity: 10\nAverage Price: 50\nPortfolio Holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nDo you want to add more holdings? [y/N]: nSelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter4to select the Oanda data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 4If you select one of the following data providers, see the respective page for more instructions:\n\nPolygon\n\n$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: Oanda\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Oanda\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nInitial live cash balance: [{'currency': 'USD', 'amount': 95800.0}]\nInitial live portfolio holdings: [{'symbol': 'GOOG', 'symbolId': 'GOOCV VP83T1ZUHROL', 'quantity': 10, 'averagePrice': 50.0}]\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: y\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: Oanda\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Oanda brokerage:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter  the brokerage number,4.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 4Enter the environment to use. EnterTradefor fxTrade orPracticefor fxTrade Practice.$ lean live \"My Project\"\nEnvironment? (Practice, Trade): TradeEnter your OANDA account ID.$ lean live \"My Project\"\nAccount id: 001-011-5838423-001To get your account ID, see yourAccount Statement pageon the OANDA website.Enter your OANDA API token.$ lean live \"My Project\"\nAPI token: ****************To create a token, see theManage API Access pageon the OANDA website.Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:If you select one of the following data providers, see the respective page for more instructions:\n\nIQFeedPolygonTheta Data\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.1",
      "breadcrumb": "Live Trading > Brokerages > CFD and FOREX Brokerages",
      "section_number": "8.1.16",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2",
    "title": "Data Providers",
    "level": 2,
    "path": "Live Trading > Data Providers",
    "content": "Data providers supply data to run your live algorithm using LEAN. You can use multiple data providers in live trading algorithms.IQFeedUS Equities, US Options, Forex, & FuturesPolygonUS Equities, US Equity Options, US Indices, & US Index OptionsTheta DataUS Equities, US Equity Options, US Indices, & US Index OptionsSee AlsoBrokerages",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Live Trading > Data Providers",
      "section_number": "8.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.1",
    "title": "IQFeed",
    "level": 3,
    "path": "Live Trading > Data Providers > IQFeed",
    "content": "### Introduction\n\nInstead of using the data from your brokerage, you can also use IQFeed if you're on Windows.\nUsing IQFeed requires you to have an IQFeed developer account and you need to have the IQFeed client installed locally.\nThis tutorial demonstrates how to set up theIQFeed data providerwith the QuantConnect Paper Trading brokerage.\n\nTo view the implementation of the IQFeed integration, see theLean.DataSource.IQFeed repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the IQ Feed data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter a brokerage number.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:Enter the path to the IQConnect binary.The default path isC: / Program Files (x86) / DTN / IQFeed / iqconnect.exeif you used the default settings when installing the IQFeed client.$ lean live \"My Project\"\nIQConnect binary location [C:/Program Files (x86)/DTN/IQFeed/iqconnect.exe]:Enter your IQFeed username and password.$ lean live \"My Project\"\nUsername: 123456\nPassword: **********If you have an IQFeed developer account, enter the product Id and version of your account.$ lean live \"My Project\"\nProduct id: <yourID>\nProduct version: 1.0If you don't have an IQFeed developer account, openiqlink.exe, log in to IQLink with your username and password, and then enter random numbers for the product id and version.$ lean live \"My Project\"\nProduct id: 123\nProduct version: 1.0View the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Deploy Cloud Algorithms\n\nThe CLI doesn't currently support deploying cloud algorithms with the IQFeed data provider.\n\n### Supported Assets\n\nOur IQFeed integration supports securities from the following asset classes:\n\nUS EquityUS Equity OptionsForex(listed on FXCM)US Futures\n\nThe IQFeed data provider serves raw data.\nTo get adjusted Equity data in local deployments,download the US Equity Security Master.\nTo getcontinuous Futuresdata in local deployments,download the US Futures Security Master.\n\n### Mutiple Data Providers\n\nWhen youdeploy a live algorithm, you can add multiple data providers.\nIf you use multiple data providers, the order you select them in defines their order of precedence in Lean.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Live Trading > Data Providers > IQFeed",
      "section_number": "8.2.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.2",
    "title": "Polygon",
    "level": 3,
    "path": "Live Trading > Data Providers > Polygon",
    "content": "### Introduction\n\nInstead of using the data from your brokerage, you can also use Polygon. This tutorial demonstrates how to set up thePolygon data providerwith the QuantConnect Paper Trading brokerage.\n\nTo view the implementation of the Polygon integration, see theLean.DataSource.Polygon repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the Polygon data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter a brokerage number.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:Enter your Polygon API key.$ lean live \"My Project\"\nConfigure credentials for Polygon\n\nYour Polygon API Key:To get your API key, see theAPI Keys pageon the Polygon website.View the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Deploy Cloud Algorithms\n\nFollow these steps to start live trading a project in the cloud with the QuantConnect Paper Trading brokerage and the Polygon data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud live deploy \"<projectName>\" --push --opento push. / <projectName>. to the cloud, start a live deployment wizard, and open the results in the browser once the deployment starts.$ lean cloud live deploy \"My Project\" --push --open\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'Enter1to select the QuantConnect Paper Trading brokerage.$ lean cloud live deploy \"My Project\" --push --open\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Configure your notification settings.You can configure any combination of email, webhook, SMS, and Telegram notifications for order events and emitted insights.  To view the number of notification you can send for free, see theLive Trading Notification Quotas.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to send notifications on order events? [y/N]: y\nDo you want to send notifications on insights? [y/N]: y\nEmail notifications: None\nWebhook notifications: None\nSMS notifications: None\nSelect a notification method:\n1) Email\n2) Webhook\n3) SMS\n4) Telegram\nEnter an option: 1\nEmail address: john.doe@example.com\nSubject: Algorithm notification\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nDo you want to add another notification method? [y/N]: nEnable or disable automatic algorithm restarting.This feature attempts to restart your algorithm if it fails due to a runtime error, like a brokerage API disconnection.$ lean cloud live deploy \"My Project\" --push --open\nDo you want to enable automatic algorithm restarting? [Y/n]: ySelect the live node that you want to use.If you only have one idle live trading node, it is selected automatically and this step is skipped.$ lean cloud live deploy \"My Project\" --push --open\nSelect a node:\n1) L-MICRO node 89c90172 - 1 CPU @ 2.4GHz, 0.5GB Ram\n2) L-MICRO node 85a52135 - 1 CPU @ 2.4GHz, 0.5GB Ram\nEnter an option: 1Enter14to select the Polygon data provider.$ lean live \"My Project\"\nSelect a live data feed:\n1) QuantConnect\n2) Interactive Brokers\n3) Tradier\n4) Oanda\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Polygon\n15) IEX\n16) CoinApi\n17) Bybit\n18) TradeStation\n19) Alpaca\nTo enter multiple options, separate them with comma: 14Enter your Polygon API key.$ lean cloud live \"My Project\" --push --open\nConfigure credentials for Polygon\n\nYour Polygon API Key:To get your API key, see theAPI Keys pageon the Polygon website.Verify the configured settings and confirm them to start the live deployment in the cloud.$ lean cloud live deploy \"My Project\" --push --open\nBrokerage: QuantConnect Paper Trading\nProject id: 1234567\nEnvironment: Live\nServer name: L-MICRO node 89c90172\nServer type: L-MICRO\nLive Data providers: Polygon\nLEAN version: 11157\nOrder event notifications: Yes\nInsight notifications: Yes\nEmail notifications: john.doe@example.com\nWebhook notifications: None\nSMS notifications: None\nTelegram notifications: None\nAutomatic algorithm restarting: Yes\nAre you sure you want to start live trading for project 'My Project'? [y/N]: yInspect the result in the browser, which opens automatically after the deployment starts.\n\nFollow these steps to see the live status of a project:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean cloud status \"<projectName>\"to show the status of the cloud project named \"<projectName>\".$ lean cloud status \"My Project\"\nProject id: 1234567\nProject name: My Project\nProject url: https://www.quantconnect.com/project/1234567\nLive status: Running\nLive id: L-1234567a8901d234e5e678ddd9b0123c\nLive url: https://www.quantconnect.com/project/1234567/live\nBrokerage: QuantConnect Paper Trading\nLaunched: 2021-06-09 15:10:12 UTC\n\n### Supported Assets\n\nOur Polygon integration supports securities from the following asset classes:\n\nUS EquityUS Equity OptionsUS IndicesUS Index Options\n\n### Mutiple Data Providers\n\nWhen youdeploy a live algorithm, you can add multiple data providers.\nIf you use multiple data providers, the order you select them in defines their order of precedence in Lean.\nFor example, if you set Polygon as the first provider and IB as the second provider, Lean only uses the IB data provider for securities that aren't available from the Polygon data provider.\nThis configuration makes it possible to use Polygon data provider for Equity and use IB for Futures.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Live Trading > Data Providers > Polygon",
      "section_number": "8.2.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.3",
    "title": "Theta Data",
    "level": 3,
    "path": "Live Trading > Data Providers > Theta Data",
    "content": "### Introduction\n\nInstead of using the data from your brokerage, you can also use Theta Data if you're deploying a local project.\nTo use Theta Data, you need toinstall and launch the Theta Terminal.\nThis tutorial demonstrates how to set up theTheta Data data providerwith the QuantConnect Paper Trading brokerage.\n\nTo view the implementation of the Theta Data integration, see theLean.DataSource.ThetaData repository.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Deploy Local Algorithms\n\nFollow these steps to start local live trading with the ThetaData data provider:\n\nLog into the CLI if you haven't done so already.Open a terminal in theorganization workspacethat contains the project.Runlean live deploy \"<projectName>\"to start a live deployment wizard for the project in. / <projectName>and then enter a brokerage number.$ lean live deploy \"My Project\"\nSelect a brokerage:\n1) Paper Trading\n2) Interactive Brokers\n3) Tradier\n4) OANDA\n5) Bitfinex\n6) Coinbase Advanced Trade\n7) Binance\n8) Zerodha\n9) Samco\n10) Terminal Link\n11) Trading Technologies\n12) Kraken\n13) Charles Schwab\n14) Bybit\n15) TradeStation\n16) Alpaca\nEnter an option: 1Enter the number of the live data provider(s) to use and then follow the steps required for the data connection.$ lean live deploy \"My Project\"\nSelect a live data provider:\n1) Interactive Brokers\n2) Tradier\n3) Oanda\n4) Bitfinex\n5) Coinbase Advanced Trade\n6) Binance\n7) Zerodha\n8) Samco\n9) Terminal Link\n10) Trading Technologies\n11) Kraken\n12) Charles Schwab\n13) IQFeed\n14) Polygon\n15) IEX\n16) CoinApi\n17) ThetaData\n18) Custom data only\n19) Bybit\n20) TradeStation\n21) Alpaca\nTo enter multiple options, separate them with comma:(Optional) Enter the host of the ThetaData Client.The default host isws://host.docker.internal:25520/v1/eventsorhttp://host.docker.internal:25510.$ lean live \"My Project\"\nThe host of ThetaData Client [ws://host.docker.internal:25520/v1/events]:\nThe host of ThetaData Client [http://host.docker.internal:25510]:Enter your Theta Data subscription plan.$ lean live \"My Project\"\nThetaData subscription price plan (Free, Value, Standard, Pro):View the result in the<projectName> / live / <timestamp>directory.\nResults are stored in real-time in JSON format.\nYou can save results to a different directory by providing the--output <path>option in step 2.\n\nIf you already have a live environment configured in yourLean configuration file, you can skip the interactive wizard by providing the--environment <value>option in step 2.\nThe value of this option must be the name of an environment which haslive-modeset totrue.\n\n### Deploy Cloud Algorithms\n\nThe CLI doesn't currently support deploying cloud algorithms with the Theta Data data provider.\n\n### Supported Assets\n\nOur Theta Data integration supports securities from the following asset classes:\n\nEquityEquity OptionsIndexIndex Options\n\n### Mutiple Data Providers\n\nWhen you deploy a live algorithm, you can add multiple data providers.\nIf you use multiple data providers, the order you select them in defines their order of precedence in Lean.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Live Trading > Data Providers > Theta Data",
      "section_number": "8.2.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "8.3",
    "title": "Algorithm Control",
    "level": 2,
    "path": "Live Trading > Algorithm Control",
    "content": "### Introduction\n\nThe algorithm control features let you adjust your algorithm while it executes live so that you can perform actions that are not written in the project files. The control features let you intervene in the execution of your algorithm and make adjustments. The control features that are available to you depend on if you deploy the algorithm on your local machine or on the QuantConnect cloud servers.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Control Local Algorithms\n\nWhile your local algorithms run, you can add security subscriptions, submit orders, adjust orders, and stop their execution.\n\nAdd Security Subscriptions\n\nYou can manually create security subscriptions for your algorithm instead of calling theAddsecurityTypemethods in your code files. If you add security subscriptions to your algorithm, you can place manual trades without having to edit and redeploy the algorithm. To add security subscriptions, open a terminal in theorganization workspacethat contains the project and then runlean live add-security \"My Project\".\n\n$ lean live add-security \"My Project\" --ticker \"SPY\" --market \"usa\" --security-type \"equity\"\n\nFor more information about the command options, seeOptions.\n\nYou can't manually remove security subscriptions.\n\nSubmit Orders\n\nIn local deployments, you can manually place orders instead of calling the automated methods in your project files. You can use any order type that is supported by the brokerage that you used when deploying the algorithm. To view the supported order types of your brokerage, see theOrderssection of yourbrokerage model. Some example situations where it may be helpful to place manual orders instead of stopping and redeploying the algorithm include the following:\n\nYour brokerage account had holdings in it before you deployed your algorithmYour algorithm had bugs in it that caused it to purchase the wrong securityYou want to add a hedge to your portfolio without adjusting the algorithm codeYou want to rebalance your portfolio before the rebalance date\n\nTo submit orders, open a terminal in theorganization workspacethat contains the project and then runlean live submit-order \"My Project\".\n\n$ lean live submit-order \"My Project\" --ticker \"SPY\" --market \"usa\" --security-type \"equity\" --order-type \"market\" --quantity 10\n\nFor more information about the command options, seeOptions.\n\nUpdate Orders\n\nTo update an existing order, open a terminal in theorganization workspacethat contains the project and then runlean live update-order \"My Project\".\n\n$ lean live update-order \"My Project\" --order-id 1 --quantity 5\n\nFor more information about the command options, seeOptions.\n\nCancel Orders\n\nTo cancel an existing order, open a terminal in theorganization workspacethat contains the project and then runlean live cancel-order \"My Project\".\n\n$ lean live cancel-order \"My Project\" --order-id 1\n\nFor more information about the command options, seeOptions.\n\nLiquidate Positions\n\nTo liquidate a specific asset in your algorithm, open a terminal in theorganization workspacethat contains the project and then runlean live liquidate \"My Project\".\n\n$ lean live liquidate \"My Project\" --ticker \"SPY\" --market \"usa\" --security-type \"equity\"\n\nWhen you run the command, if the market is open for the asset, the algorithm liquidates it with market orders. If the market is not open, the algorithm places market on open orders.\n\nFor more information about the command options, seeOptions.\n\nStop Algorithms\n\nThelean live stopcommand immediately stops your algorithm from executing. When you stop a live algorithm, your portfolio holdings are retained. Stop your algorithm if you want to perform any of the following actions:\n\nUpdate your project's code filesUpdate the settings you entered into the deployment commandPlace manual orders through your brokerage account\n\nFurthermore, if you receive new securities in your portfolio because of a reverse merger, you also need to stop and redeploy the algorithm.\n\nLEAN actively terminates live algorithms when it detects interference outside of the algorithm's control to avoid conflicting race conditions between the owner of the account and the algorithm, so avoid manipulating your brokerage account and placing manual orders on your brokerage account while your algorithm is running. If you need to adjust your brokerage account holdings, stop the algorithm, manually place your trades, and then redeploy the algorithm.\n\nTo stop an algorithm, open a terminal in theorganization workspacethat contains the project and then runlean live stop \"My Project\".\n\n$ lean live stop \"My Project\"\n\nFor more information about the command options, seeOptions.\n\nSend Commands\n\nTo sendcommandsto your algorithm, open a terminal in theorganization workspacethat contains the project and then runlean live command \"My Project\" --data \"<payload>\".\n\n$ lean live command \"My Project\" --data \"{'ticker': 'AAPL', 'quantity': 1}\"\n\nThe preceding line will run theon_commandOnCommandmethod of your algorithm.\nIf you wrap the logic in aCommandclass in your algorithm, include a$typekey in the payload and set the value to be the name of the class.\n\n$ lean live command \"My Project\" --data \"{'$type': 'MyCommand', 'ticker': 'AAPL', 'quantity': 1}\"\n\nIf you run the command in PowerShell, use`$typeinstead of just$type.\n\n$ lean live command \"My Project\" --data \"{'`$type': 'MyCommand', 'ticker': 'AAPL', 'quantity': 1}\"\n\nFor more information about the command options, seeOptions.\n\n### Control Cloud Algorithms\n\nWhile your cloud algorithms run, you can liquidate their positions and stop their exeuction.\n\nLiquidate Positions\n\nThelean cloud live liquidatecommand acts as a \"kill switch\" to sell all of your portfolio holdings. If your algorithm has a bug in it that caused it to purchase a lot of securities that you didn't want, this command let's you easily liquidate your portfolio instead of placing many manual trades. When you run the command, if the market is open for an asset you hold, the algorithm liquidates it with market orders. If the market is not open, the algorithm places market on open orders. After the algorithm submits the liquidation orders, it stops executing.\n\nTo stop an algorithm, open a terminal in theorganization workspacethat contains the project and then runlean cloud live liquidate \"My Project\".\n\n$ lean cloud live liquidate \"My Project\"\n\nFor more information about the command options, seeOptions.\n\nStop Algorithms\n\nThelean live stopcommand immediately stops your algorithm from executing. When you stop a live algorithm, your portfolio holdings are retained. Stop your algorithm if you want to perform any of the following actions:\n\nUpdate your project's code filesUpdate the settings you entered into the deployment commandPlace manual orders through your brokerage account\n\nFurthermore, if you receive new securities in your portfolio because of a reverse merger, you also need to stop and redeploy the algorithm.\n\nLEAN actively terminates live algorithms when it detects interference outside of the algorithm's control to avoid conflicting race conditions between the owner of the account and the algorithm, so avoid manipulating your brokerage account and placing manual orders on your brokerage account while your algorithm is running. If you need to adjust your brokerage account holdings, stop the algorithm, manually place your trades, and then redeploy the algorithm.\n\nTo stop an algorithm, open a terminal in theorganization workspacethat contains the project and then runlean cloud live stop \"My Project\".\n\n$ lean cloud live stop \"My Project\"\n\nFor more information about the command options, seeOptions.\n\nSend Commands\n\nTo sendcommandsto your algorithm, open a terminal in theorganization workspacethat contains the project and then runlean cloud live cloud command \"My Project\" --data \"<payload>\".\n\n$ lean cloud live command \"My Project\" --data \"{'ticker': 'AAPL', 'quantity': 1}\"\n\nThe preceding line will run theon_commandOnCommandmethod of your algorithm.\nIf you wrap the logic in aCommandclass in your algorithm, include a$typekey in the payload and set the value to be the name of the class.\n\n$ lean cloud live command \"My Project\" --data \"{'$type': 'MyCommand', 'ticker': 'AAPL', 'quantity': 1}\"\n\nIf you run the command in PowerShell, use`$typeinstead of just$type.\n\n$ lean cloud live command \"My Project\" --data \"{'`$type': 'MyCommand', 'ticker': 'AAPL', 'quantity': 1}\"\n\nFor more information about the command options, seeOptions.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Live Trading > Algorithm Control",
      "section_number": "8.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "9",
    "title": "Reports",
    "level": 1,
    "path": "Reports",
    "content": "### Introduction\n\nThelean reportcommand in the Lean CLI is a wrapper around the LEAN Report Creator.\nThe LEAN Report Creator is a program included with LEAN which allows you to quickly generate polished, professional-grade reports of your backtests and live trading results.\nWe hope that you can use these reports to share your strategy performance with prospective investors.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Generate Reports\n\nFollow these steps to generate a report of a trading algorithm:\n\nOpen a terminal in theorganization workspacethat contains the project.Runlean reportto generate a report of the most recent backtest.$ lean report\n20210322 20:03:48.718 TRACE:: QuantConnect.Report.Main(): Parsing source files...backtest-data-source-file.json,\n20210322 20:03:51.602 TRACE:: QuantConnect.Report.Main(): Instantiating report...\nSuccessfully generated report to './report.html'By default, the generated report is saved to. / report.html, although you can change this by providing a custom path with the--report-destination <path>option.\nTo generate a report of a backtest that is not the most recent one, you can use the--backtest-results <path>option to specify the path to the backtest results JSON file to generate a report for it.Open the generated report in the browser and inspect its results.\n\nYou can also configure the following optional details:\n\n[Table - 4 rows]\n\n### Key Statistics\n\nThe top of the backtest report displays  statistics to summarize your algorithm's performance. The following table describes the key statistics in the report:\n\n[Table - 10 rows]\n\n### Returns\n\nThe backtest report displays charts to show the algorithm's returns per trade, per day, per month, per year, and the cumulative returns over the backtest.\n\nReturns per Trade\n\nThis chart displays a histogram that shows the distribution of returns per trade over the backtesting period.\n\nDaily Returns\n\nThis chart displays the returns of each day. Blue bars represent profitable days and gray bars represent unprofitable days.\n\nMonthly Returns\n\nThis chart displays the return of each month. We convert the original equity curve series into a monthly series and calculate the returns of each month. Green cells represent months with a positive return and red cells represent months with a negative return. Months that have a greater magnitude of returns are represented with darker cells. Yellow cells represent months with a relatively small gain or loss. White rectangles represent months that are not included in the backtest period. The values in the cells are percentages.\n\nAnnual Returns\n\nThis chart displays the return of each year.\nWe calculate the total return within each year and represent each year with a blue bar.\nThe red dotted line represents the average of the annual returns.\n\nCumulative Returns\n\nThis chart displays the cumulative returns of your algorithm. The blue line represents your algorithm and the gray line represents the benchmark.\n\n### Asset Allocation\n\nThis chart displays a time-weighted average of the absolute holdings value for each asset that entered your portfolio during the backtest. When an asset has a percentage that is too small to be shown in the pie chart, it is incorporated into an \"Others\" category.\n\n### Drawdown\n\nThis chart displays the peak-to-trough drawdown of your portfolio's equity throughout the backtest period. The drawdown of each day is defined as the percentage loss since the maximum equity value before the current day. The drawdowns are calculated based on daily data. The top 5 drawdown periods are marked in the chart with different colors.\n\n### Rolling Statistics\n\nThe backtest report displays time series for your portfolio's rollingbetaandSharpe ratio.\n\nRolling Portfolio Beta\n\nThis chart displays the rolling portfolio beta over trailing 6 and 12 month periods.\nThe light blue line represents the 6 month period and the dark blue line represents the 12 month period.\n\nRolling Sharpe Ratio\n\nThis chart displays the rolling portfolio Sharpe ratio over trailing 6 and 12 month periods.\nThe light blue line represents the 6 month period and the dark blue line represents the 12 month period.\n\n### Exposure\n\nThe backtest report displays time series for your portfolio's overall leverage and your portfolio's long-short exposure by asset class.\n\nLeverage\n\nThis chart displays your algorithm's utilization of leverage over time.\n\nLong-Short Exposure By Asset Class\n\nThis chart displays your algorithm's long-short exposure by asset class over time.\n\n### Crisis Events\n\nThis set of charts displays the cumulative returns of your algorithm and the benchmark during various historical periods. The blue line represents the cumulative returns of your algorithm and the grey line represents the cumulative return of the benchmark. The report only contains the crisis event that occurred during your algorithm's backtest period. The following table shows the crisis events that may be included in your backtest report:\n\n[Table - 17 rows]\n\n### Parameters\n\nThis section of the report shows the name and value of all theparametersin your project.\n\n### Customize Reports\n\nTo create custom reports, customize the HTML and CSS.\n\nCustomize the Report HTML\n\nTheReport / template.htmlfile in the LEAN GitHub repository defines the stucture of the reports you generate. To override the HTML file, add a new HTML file to your local machine. If you add it to yourorganization workspace, don't name itreport.htmlbecause that's the default name and location of the reports you generate. To include some of the information and charts that are in the default report, use the report keys in theReport / ReportKey.csfile in the LEAN GitHub repository. For example, to add theSharpe ratioof your backtest to the custom HTML file, use{{$KPI-SHARPE}}.\n\nTo include thecrisis event plotsin your report, add the{{$HTML-CRISIS-PLOTS}}key and then define the structure of the individual plots inside ofandcrisis-->. Inside of this comment, you can utilize the{{$TEXT-CRISIS-TITLE}}and{{$PLOT-CRISIS-CONTENT}}keys. For example, the following HTML is the default format for each crisis plot:\n\nTo include thealgorithm parametersin your report, add the{{$PARAMETERS}}key and then define the HTML element inside ofandparameters-->. Inside of this comment, you can use special keys{{$KEY<parameterIndex>}}and{{$VALUE<parameterIndex>}}, which represent the key and value of a single parameter. For example, the following HTML is the default format for the parameters element:\n\nIn the preceding example,{{$KEY0}}is the name of the first parameter in the algorithm and{{$VALUE0}}is its value.\n\nTo generate the report with your custom HTML file, runlean report --html <pathToCustomHTMLFile>.\n\nCustomize the Report CSS\n\nTheReport / css / report.cssfile in the LEAN GitHub repository defines the style of the reports you generate. To override the stylesheet, add a new CSS file to your local machine.\n\nTo generate the report with your custom CSS file, runlean report --css <pathToCustomCSSFile>.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Reports",
      "section_number": "9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Detail | Description |\n| --- | --- |\n| Strategy name | This name is displayed in the top-right corner of each page and can be configured using--strategy-name <value>. This value defaults to the name of the project directory. |\n| Strategy version | This version is displayed next to the strategy name and can be configured using--strategy-version <value>. |\n| Strategy description | This description is displayed underneath the \"Strategy Description\" header on the first page and can be configured using--strategy-description. This value defaults to the description stored in theproject's configuration. |\n| Live results | These results are displayed over the backtest results and can be configured using--live-results <path>. The provided path must point to a JSON file containing live results. For example,--live-results \"My Project/live/2022-03-17_10-53-12/L-3578882079.json\". |",
    "table_1": "| Statistic | Description |\n| --- | --- |\n| Runtime Days | The number of days in the backtest or live trading period. |\n| Turnover | The percentage of the algorithm's portfolio that was replaced in a given year. |\n| CAGR | The annual percentage return that would be required to grow a portfolio from its starting value to its ending value. |\n| Markets | The asset classes that the algorithm trades. |\n| Trades per day | The total number of trades during the backtest divided by the number of days in the backtest. Trades per day is an approximation of the algorithm's trading frequency. |\n| Drawdown | The largest peak to trough decline in an algorithm's equity curve. |\n| Probabilistic SR | The probability that the estimated Sharpe ratio of an algorithm is greater than a benchmark (1). |\n| Sharpe Ratio | A measure of the risk-adjusted return, developed by William Sharpe. |\n| Information Ratio | The amount of excess return from the risk-free rate per unit of systematic risk. |\n| Strategy Capacity | The maximum amount of money an algorithm can trade before its performance degrades from market impact. |",
    "table_2": "| Crisis Name | Start Date | End Date |\n| --- | --- | --- |\n| DotCom Bubble 2000 | 2/26/2000 | 9/10/2000 |\n| September 11, 2001 | 9/5/2001 | 10/10/2001 |\n| U.S. Housing Bubble 2003 | 1/1/2003 | 2/20/2003 |\n| Global Financial Crisis 2007 | 10/1/2007 | 12/1/2011 |\n| Flash Crash 2010 | 5/1/2010 | 5/22/2010 |\n| Fukushima Meltdown 2011 | 3/1/2011 | 4/22/2011 |\n| U.S. Credit Downgrade 2011 | 8/5/2011 | 9/1/2011 |\n| ECB IR Event 2012 | 9/5/2012 | 10/12/2012 |\n| European Debt Crisis 2014 | 10/1/2014 | 10/29/2014 |\n| Market Sell-Off 2015 | 8/10/2015 | 10/10/2015 |\n| Recovery 2010-2012 | 1/1/2010 | 10/1/2012 |\n| New Normal 2014-2019 | 1/1/2014 | 1/1/2019 |\n| COVID-19 Pandemic 2020 | 2/10/2020 | 9/20/2020 |\n| Post-COVID Run-up 2020-2021 | 4/1/2020 | 1/1/2022 |\n| Meme Season 2021 | 1/1/2021 | 5/15/2021 |\n| Russia Invades Ukraine 2022-2023 | 2/1/2022 | 1/1/2024 |\n| AI Boom 2022-Present | 11/30/2022 | Present |"
  },
  {
    "id": "10",
    "title": "Optimization",
    "level": 1,
    "path": "Optimization",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Optimization",
      "section_number": "10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "10.1",
    "title": "Parameters",
    "level": 2,
    "path": "Optimization > Parameters",
    "content": "### Introduction\n\nProject parameters are parameters that are defined in your project'sconfiguration file.\nThese parameters are a replacement for constants in your algorithm and can be optimized using one of LEAN's optimization strategies either locally or in the cloud.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Configure Project Parameters\n\nFollow these steps to make your algorithm use project parameters instead of constant values:\n\nOpen your project in your preferred editor.Open the project'sconfig.jsonfile.Add the required parameters in theparametersproperty. All keys and values of this object must be strings. Example:{\n\"parameters\": {\n\"ema-fast\": \"10\",\n\"ema-medium\": \"30\",\n\"ema-slow\": \"50\"\n}\n}Open your algorithm in the editor.CallQCAlgorithm.GetParameter(name)in your algorithm to retrieve the value of a parameter and use that instead of constant values.namespace QuantConnect.Algorithm.CSharp\n{\npublic class ParameterizedAlgorithm : QCAlgorithm\n{\nprivate ExponentialMovingAverage _fast;\nprivate ExponentialMovingAverage _medium;\nprivate ExponentialMovingAverage _slow;\n\npublic override void Initialize()\n{\nSetStartDate(2020, 1, 1);\nSetCash(100000);\nAddEquity(\"SPY\");\n\nvar fastPeriod = GetParameter(\"ema-fast\", 10);\nvar mediumPeriod = GetParameter(\"ema-medium\", 30);\nvar slowPeriod = GetParameter(\"ema-slow\", 50);\n\n_fast = EMA(\"SPY\", fastPeriod);\n_medium = EMA(\"SPY\", mediumPeriod);\n_slow = EMA(\"SPY\", slowPeriod);\n}\n}\n}class ParameterizedAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2020, 1, 1)\nself.set_cash(100000)\nself.add_equity(\"SPY\")\n\nfast_period = self.get_parameter(\"ema-fast\", 10)\nmedium_period = self.get_parameter(\"ema-medium\", 30)\nslow_period = self.get_parameter(\"ema-slow\", 50)\n\nself._fast = self.ema(\"SPY\", fast_period)\nself._medium = self.ema(\"SPY\", medium_period)\nself._slow = self.ema(\"SPY\", slow_period)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Optimization > Parameters",
      "section_number": "10.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "10.2",
    "title": "Deployment",
    "level": 2,
    "path": "Optimization > Deployment",
    "content": "### Introduction\n\nThe Lean CLI supports optimizing a project's parameters on your local machine or in the cloud using LEAN's powerful optimization strategies.\nOptimization is helpful when you want to find the best combination of parameters to minimize or maximize a certain statistic, like the algorithm'sSharpe ratioordrawdown. If your run optimizations in the cloud, you don't need your own powerful machine.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Run Local Optimizations\n\nFollow these steps to run a local optimization:\n\nSet up your local datafor all the data required by your project.Convert your project to use project parametersinstead of constants for all values that must be optimized.Open a terminal in theorganization workspacethat contains the project.Runlean optimize \"<projectName>\"to start optimizing the project in. / <projectName>. This command starts an interactive wizard which lets you configure the optimizer.$ lean optimize \"My Project\"\nSelect the optimization strategy to use:\n1) Grid Search\n2) Euler Search\nEnter an option:Enter the number of the optimization strategy to use. You can either choose for Grid Search, which runs through all possible combinations of parameters, or for Euler Search, which performs an Euler-like which gradually works towards smaller optimizations.$ lean optimize \"My Project\"\nSelect the optimization strategy to use:\n1) Grid Search\n2) Euler Search\nEnter an option: 1Enter the number of the optimization target to use. The target specifies what statistic you want to optimize and whether you want to minimize or maximize it.$ lean optimize \"My Project\"\nSelect an optimization target:\n1) Sharpe Ratio (min)\n2) Sharpe Ratio (max)\n3) Compounding Annual Return (min)\n4) Compounding Annual Return (max)\n5) Probabilistic Sharpe Ratio (min)\n6) Probabilistic Sharpe Ratio (max)\n7) Drawdown (min)\n8) Drawdown (max)\nEnter an option: 2For each parameter, enter whether you want to optimize it and what its values can be.$ lean optimize \"My Project\"\nShould the 'ema-fast' parameter be optimized? [Y/n]: y\nMinimum value for 'ema-fast': 5\nMaximum value for 'ema-fast': 10\nStep size for 'ema-fast' [1.0]: 1\nShould the 'ema-medium' parameter be optimized? [Y/n]: y\nMinimum value for 'ema-medium': 25\nMaximum value for 'ema-medium': 30\nStep size for 'ema-medium' [1.0]: 1\nShould the 'ema-slow' parameter be optimized? [Y/n]: y\nMinimum value for 'ema-slow': 45\nMaximum value for 'ema-slow': 50\nStep size for 'ema-slow' [1.0]: 1Enter the constraints of the optimization. An example optimization is \"Drawdown <= 0.25\", which discards all parameter combinations resulting in a drawdown higher than 25%.$ lean optimize \"My Project\"\nCurrent constraints: None\nDo you want to add a constraint? [y/N]: y\nSelect a constraint target:\n1) Sharpe Ratio\n2) Compounding Annual Return\n3) Probabilistic Sharpe Ratio\n4) Drawdown\nEnter an option: 4\nSelect a constraint operator (<value> will be asked after this):\n1) Less than <value>\n2) Less than or equal to <value>\n3) Greater than <value>\n4) Greater than or equal to <value>\n5) Equal to <value>\n6) Not equal to <value>\nEnter an option: 2\nSet the <value> for the selected operator: 0.25\nCurrent constraints: TotalPerformance.PortfolioStatistics.Drawdown <= 0.25\nDo you want to add a constraint? [y/N]: nAfter configuring the constraints the optimizer starts running.View the results in the terminal after the optimizer finished. The logs contains the optimal parameter combination.$ lean optimize \"My Project\"\n20220223 18:26:20.000 TRACE:: Program.Main(): Exiting Lean...\n20220223 18:26:20.079 TRACE:: LeanOptimizer.TriggerOnEndEvent(OID 2313bbba-9c71-4b9e-8b91-c70cc117b0c7): Optimization has ended. Result for Target: ['TotalPerformance'].['PortfolioStatistics'].['SharpeRatio'] at: 3.6205: was reached using ParameterSet: (ema-slow:47,ema-medium:26,ema-fast:5) backtestId '21c30000-dc5a-4dec-b75a-da5b1796ccba'. Constraints: (['TotalPerformance'].['PortfolioStatistics'].['Drawdown'] 'LessOrEqual' 0.25)\nOptimal parameters: ema-slow: 47, ema-medium: 26, ema-fast: 5\nSuccessfully optimized 'My Project' and stored the output in 'My Project/optimizations/2021-03-24_00-22-15'View the individual backtest results in the<project> / optimizations / <timestamp>directory.\nResults are stored in JSON files and can be analyzed in alocal research environment.\nYou can save results to a different directory by providing the--output <path>option in step 4.$ lean optimize \"My Project\" --output \"My Project/custom-output\"\n20220223 18:28:20.000 TRACE:: Program.Main(): Exiting Lean...\n20220223 18:28:20.079 TRACE:: LeanOptimizer.TriggerOnEndEvent(OID 1ac5e638-aae0-4aa9-80d4-02c51bb7b84d): Optimization has ended. Result for Target: ['TotalPerformance'].['PortfolioStatistics'].['SharpeRatio'] at: 3.6205: was reached using ParameterSet: (ema-slow:47,ema-medium:26,ema-fast:5) backtestId 'e2aa3abf-bb60-4e91-a281-59c882ada62f'. Constraints: (['TotalPerformance'].['PortfolioStatistics'].['Drawdown'] 'LessOrEqual' 0.25)\nOptimal parameters: ema-slow: 47, ema-medium: 26, ema-fast: 5\nSuccessfully optimized 'My Project' and stored the output in 'My Project/custom-output'\n\nBy default, local optimizations run in the LEAN engine in thequantconnect/leanDocker image.\nThis Docker image contains all thelibraries available on QuantConnect, meaning your algorithm also has access to those libraries.\nIf the specified project is a C# project it is first compiled using the same Docker image.\nSeeProject Librariesto learn how to use project libraries, andCustom Docker Imagesto learn how to build and use custom Docker images.\n\nWhen you run a local optimization, the default data provider is your local machine.\nTo use data from QuantConnect Cloud, a brokerage, or a third-party data provider, include the--data-provider-historicaloption.\nTo view what brokerages and third-party data providers are available, seethe reference page for this command.\n\n### Run Cloud Optimizations\n\nWhen you run an optimization in QuantConnect Cloud, it uses the data from theDataset Market.\nFollow these steps to run a cloud optimization:\n\nLog into the CLI if you haven't done so already.Convert your project to use project parametersinstead of constants for all values that must be optimized.Open a terminal in theorganization workspacethat contains the project.Runlean cloud optimize \"<projectName>\" --pushto push. / <projectName>to the cloud and start optimizing the project in the cloud.$ lean cloud optimize \"My Project\" --push\n[1/1] Pushing 'My Project'\nSuccessfully updated cloud file 'My Project/main.py'\nStarted compiling project 'My Project'\nSuccessfully compiled project 'My Project'\nSelect an optimization target:\n1) Sharpe Ratio (min)\n2) Sharpe Ratio (max)\n3) Compounding Annual Return (min)\n4) Compounding Annual Return (max)\n5) Probabilistic Sharpe Ratio (min)\n6) Probabilistic Sharpe Ratio (max)\n7) Drawdown (min)\n8) Drawdown (max)\nEnter an option:Enter the number of the optimization target to use. The target specifies what statistic you want to optimize and whether you want to minimize or maximize it.$ lean cloud optimize \"My Project\" --push\nSelect an optimization target:\n1) Sharpe Ratio (min)\n2) Sharpe Ratio (max)\n3) Compounding Annual Return (min)\n4) Compounding Annual Return (max)\n5) Probabilistic Sharpe Ratio (min)\n6) Probabilistic Sharpe Ratio (max)\n7) Drawdown (min)\n8) Drawdown (max)\nEnter an option: 2For each parameter, enter whether you want to optimize it and what its values can be.$ lean cloud optimize \"My Project\" --push\nShould the 'ema-fast' parameter be optimized? [Y/n]: y\nMinimum value for 'ema-fast': 1\nMaximum value for 'ema-fast': 10\nStep size for 'ema-fast' [1.0]: 1\nShould the 'ema-slow' parameter be optimized? [Y/n]: y\nMinimum value for 'ema-slow': 21\nMaximum value for 'ema-slow': 30\nStep size for 'ema-slow' [1.0]: 1Enter the constraints of the optimization. An example optimization is \"Drawdown <= 0.25\", which discards all parameter combinations resulting in a drawdown higher than 25%.$ lean cloud optimize \"My Project\" --push\nCurrent constraints: None\nDo you want to add a constraint? [y/N]: y\nSelect a constraint target:\n1) Sharpe Ratio\n2) Compounding Annual Return\n3) Probabilistic Sharpe Ratio\n4) Drawdown\nEnter an option: 4\nSelect a constraint operator (<value> will be asked after this):\n1) Less than <value>\n2) Less than or equal to <value>\n3) Greater than <value>\n4) Greater than or equal to <value>\n5) Equal to <value>\n6) Not equal to <value>\nEnter an option: 2\nSet the <value> for the selected operator: 0.25\nCurrent constraints: TotalPerformance.PortfolioStatistics.Drawdown <= 0.25\nDo you want to add a constraint? [y/N]: nEnter the number of the optimization node type to use.$ lean cloud optimize \"My Project\" --push\nSelect the optimization node type:\n1) O2-8 (2 cores, 8 GB RAM) @ $0.15 per hour\n2) O4-12 (4 cores, 12 GB RAM) @ $0.30 per hour\n3) O8-16 (8 cores, 16 GB RAM) @ $0.60 per hour\nEnter an option: 2Enter the number of nodes that should run in parallel.$ lean cloud optimize \"My Project\" --push\nHow many nodes should run in parallel (1-12) [6]: 10Confirm the given input to start the optimizer.$ lean cloud optimize \"My Project\" --push\nEstimated number of backtests: 100\nEstimated batch time: 8 minutes\nEstimated batch cost: $0.38\nOrganization balance: 173,368 QCC ($1,733.68)\nDo you want to start the optimization on the selected node type? [Y/n]: yInspect the optimal parameter combination and the full statistics of the backtest that ran with this combination at the bottom of the logs when the optimizer has finished.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Optimization > Deployment",
      "section_number": "10.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "11",
    "title": "Object Store",
    "level": 1,
    "path": "Object Store",
    "content": "### Introduction\n\nThe Object Store is an organization-specific key-value storage location to save and retrieve data. Similar to a dictionary or hash table, a key-value store is a storage system that saves and retrieves objects by using keys. A key is a unique string that is associated with a single record in the key-value store and a value is an object being stored. Some common use cases of the Object Store include the following:\n\nTransporting data between the backtesting environment and the research environment.Training machine learning models in the research environment before deploying them to live trading.\n\nThe Object Store is shared across the entire organization. Using the same key, you can access data across all projects in an organization.\n\nTo use the CLI, you must be a member in anorganizationon a paid tier.\n\n### Local Storage\n\nTo add files to your Object Store, add them to thestoragedirectory of yourorganization workspaceor call theSave methodsin your algorithm.\n\nTo view the contents of the Object Store, runlean object-store ls.\n\n$ lean object-store ls\n\nThis command opens File Explorer to show thestoragedirectory. You can delete and rename files in the Object Store directly from the File Explorer. To edit files, open them in a text editor.\n\n### Cloud Storage\n\nThe CLI enables you to upload files to the Object Store, view a summary of your stored files, and delete files.\n\nUpload Files\n\nTo upload files to the Object Store, runlean cloud object-store set <storage-key> <local-file-path>.\n\n$ lean cloud object-store 15737956/signals D:\\qc\\magic-signals.txt\nSetting object 15737956/signals in organization d6d62db48592c72e67b534553413b691\n\nIf the file fails to upload, you may have insufficientstorage space. If you need more,edit your storage plan.\n\nList Directory Contents\n\nTo view all of the files and folders in the root directory of the Object Store, runlean cloud object-store ls.\n\n$ lean cloud object-store ls\nKey              Bytes  Folder  Filename\n/15710069        None   True    15710069\n/15727540        None   True    15727540\n/15727540-1      None   True    15727540-1\n/15730221        89649  False   15730221\n/15730422        89748  False   15730422\n\nTo view all of the files and folders that are inside of one of the directories, runlean cloud object-store ls <folder-name>.\n\n$ lean cloud object-store ls 15710069\nKey                Bytes  Folder  Filename\n15710069/adjusted  60024  False   adjusted\n15710069/raw       60143  False   raw\n\nGet File Metadata\n\nTo view the metadata of a file in the Object Store, runlean cloud object-store properties <path/to/file>.\n\n$ lean cloud object-store properties 15710069/adjusted\nBytes  Modified             Filename           Preview\n60024  2023-08-30 23:08:23  15710069/adjusted  {\"12723264\n\nDelete Content\n\nTo delete a file or directory in the Object Storage, runlean cloud object-store delete <key>.\n\n$ lean cloud object-store delete 15710069/adjusted\n\n### Download Files\n\nPermissionedInstitutionalclients can build derivative data such as machine learning models and download it from the Object Store.Contact usto unlock this feature for your account.\n\nTo download a file or directory from the Object Store, runlean cloud object-store get <key>.\n\n$ lean cloud object-store get 15710069/adjusted\nFetching object store download url\nUnzipping object store keys values into: <Current Directory>\n\n### Bulk File Upload\n\nTo upload all files from a directory to the Object Store, run the following Python script:\n\nfrom os import listdir, path\nfrom subprocess import run\nSRC = \"\"   # Source directory\nDST = \"\"   # Destination directory (empty is root)\nif __name__ == '__main__':\n\ncommand = [ \"lean\", \"cloud\", \"object-store\", \"set\" ]\n\nfor key in listdir(SRC):\nfullname = path.join(SRC, key)\nif not path.isfile(fullname):\ncontinue\nkey = DST + '/' + key\nargs = [key, fullname]\nprint(' '.join(command + args))\nrun(command + args)\n\n### Live Trading Considerations\n\nWhen you deploy a live algorithm, you can access the data within minutes of modifying the Object Store. Ensure your algorithm is able to handle a changing dataset.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Object Store",
      "section_number": "11",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "12",
    "title": "API Reference",
    "level": 1,
    "path": "API Reference",
    "content": "The Lean CLI is a cross-platform CLI which makes it easier to develop with the LEAN engine locally and in the cloud. You can use any of the following commands. Click one to learn more.lean backtestlean buildlean cloud backtestlean cloud livelean cloud live commandlean cloud live deploylean cloud live liquidatelean cloud live stoplean cloud object-store deletelean cloud object-store getlean cloud object-store listlean cloud object-store lslean cloud object-store propertieslean cloud object-store setlean cloud optimizelean cloud pulllean cloud pushlean cloud statuslean config getlean config listlean config setlean config unsetlean create-projectlean data downloadlean data generatelean decryptlean delete-projectlean encryptlean initlean library addlean library removelean livelean live add-securitylean live cancel-orderlean live commandlean live deploylean live liquidatelean live stoplean live submit-orderlean live update-orderlean loginlean logoutlean logslean object-store deletelean object-store getlean object-store listlean object-store lslean object-store propertieslean object-store setlean optimizelean private-cloud add-computelean private-cloud startlean private-cloud stoplean project-createlean project-deletelean reportlean researchlean whoami",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "API Reference",
      "section_number": "12",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    }
  },
  {
    "id": "12.1",
    "title": "lean backtest",
    "level": 2,
    "path": "API Reference > lean backtest",
    "content": "### Introduction\n\nBacktest a project locally using Docker.\n\n$ lean backtest [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns a local backtest in a Docker container using thequantconnect/leanDocker image.\nThe logs of the backtest are shown in real-time and the full results are stored in the<project> / backtest / <timestamp>directory.\nYou can use the--outputoption to change the output directory.\n\nThe given<project>argument must be either a project directory or a file containing the algorithm to backtest.\nIf it is a project directory, the CLI looks for amain.pyorMain.csfile, assuming the first file it finds to be the algorithm to run.\n\nIf the--debugoption is given, this command configures the Docker container in such a way to allow debugging using your editor's debugger.\nThe exact ways to get local debugging to work depends on your editor and language, seeDebuggingfor more information on how to set this up.\n\nYou can use the--data-provider-historicaloption to change where the data is retrieved.\nThis option updates theLean configuration file, so you don't need to use this option multiple times for the same data provider if you are not switching between them.\nThe following table shows the available data providers and their required options in non-interactive mode:\n\n[Table - 41 rows]\n\nYou can use the--download-dataflag as an alias for--data-provider-historical QuantConnect. This data provider automatically downloads the required data files when your backtest requests them. After it downloads a data file, it stores it in your localdatadirectory so that in future runs, it won't have to download it again. If the file contain data for multiple days (for example, daily Equity price data files), theApiDataProviderre-downloads the file if your local version is at least 7 days old. To adjust this setting, update thedownloader-data-update-periodvalue in yourLean configurationfile.\n\nYou can also use the--data-purchase-limitoption to set the maximum amount ofQuantConnect Credit(QCC) to spend during the backtest when using QuantConnect as data provider.\nThe--data-purchase-limitoption is not persistent.\n\nThe Docker image that's used contains the same libraries as the onesavailable on QuantConnect.\nIf the selected project is a C# project, it is compiled before starting the backtest.\n\nBy default, the official LEAN engine image is used.\nYou can override this using the--image <value>option.\nAlternatively, you can set the default engine image for all commands usinglean config set engine-image <value>.\nThe image is pulled before running the backtest if it doesn't exist locally yet or if you pass the--updateflag.\n\n### Arguments\n\nThelean backtestcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean backtestcommand supports the following options:\n\n[Table - 61 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean backtest",
      "section_number": "12.1",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| --data-provider-historical | Required Options |\n| --- | --- |\n| Alpaca | --alpaca-environment |\n| AlphaVantage | --alpha-vantage-api-key |\n| --alpha-vantage-price-plan |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| FactSet | --factset-auth-config-file |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| IQFeed | --iqfeed-iqconnect |\n| --iqfeed-username |  |\n| --iqfeed-password |  |\n| --iqfeed-version |  |\n| --iqfeed-host |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Local | N/A |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| Polygon | --polygon-api-key |\n| QuantConnect | N/A |\n| \"Terminal Link\" | --terminal-link-connection-type |\n| --terminal-link-environment |  |\n| --terminal-link-server-host |  |\n| --terminal-link-server-port |  |\n| --terminal-link-emsx-broker |  |\n| --terminal-link-openfigi-api-key |  |\n| --terminal-link-server-auth-idif you use--terminal-link-connection-type SAPI |  |\n| ThetaData | --thetadata-subscription-plan |\n| TradeStation | N/A |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to backtest. |",
    "table_2": "| Option | Description |\n| --- | --- |\n| --output <directory> | Directory to store results in (defaults to PROJECT/backtests/TIMESTAMP) |\n| -d, --detach | Run the backtest in a detached Docker container and return immediately |\n| --debug <enum: pycharmptvsddebugpyvsdbgriderlocal-platform> | Enable a certain debugging method (see --help for more information) |\n| --data-provider-historical <enum: Interactive BrokersOandaBitfinexCoinbase Advanced TradeBinanceKrakenCharlesSchwabIQFeedPolygonFactSetAlphaVantageCoinApiThetaDataQuantConnectLocalTerminal LinkBybitTradeStationAlpaca> | Update the Lean configuration file to retrieve data from the given historical provider |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --iqfeed-iqconnect <string> | The path to the IQConnect binary |\n| --iqfeed-username <string> | Your IQFeed username |\n| --iqfeed-password <string> | Your IQFeed password |\n| --iqfeed-version <string> | The product version of your IQFeed developer account |\n| --iqfeed-host <string> | The IQFeed host address (Optional) |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --factset-auth-config-file <file> | The path to the FactSet authentication configuration file |\n| --alpha-vantage-api-key <string> | Your Alpha Vantage Api Key |\n| --alpha-vantage-price-plan <enum: FreePlan30Plan75Plan150Plan300Plan600Plan1200> | Your Alpha Vantage Premium API Key plan |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --thetadata-ws-url <string> | The ThetaData host address (Optional) |\n| --thetadata-rest-url <string> | The ThetaData host address (Optional) |\n| --thetadata-subscription-plan <enum: FreeValueStandardPro> | Your ThetaData subscription price plan |\n| --terminal-link-connection-type <enum: DAPI|SAPI> | Terminal Link Connection Type [DAPI, SAPI] |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the TerminalLink server |\n| --terminal-link-server-port <integer> | The port of the TerminalLink server |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --download-data | Update the Lean configuration file to download data from the QuantConnect API, alias for --data-provider-historical QuantConnect |\n| --data-purchase-limit <integer> | The maximum amount of QCC to spend on downloading data during the backtest when using QuantConnect as historical data provider |\n| --release | Compile C# projects in release configuration instead of debug |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --python-venv <string> | The path of the python virtual environment to be used |\n| --update | Pull the LEAN engine image before running the backtest |\n| --backtest-name <string> | Backtest name |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string. For more information https://docker- py.readthedocs.io/en/stable/containers.html |\n| --no-update | Use the local LEAN engine image instead of pulling the latest version |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean backtestcommand and exit |"
  },
  {
    "id": "12.2",
    "title": "lean build",
    "level": 2,
    "path": "API Reference > lean build",
    "content": "### Introduction\n\nBuild Docker images of your own version of LEAN.\n\n$ lean build [OPTIONS] [ROOT]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nBuilds local Docker images of a local version of LEAN and sets them up for local usage with the CLI.\nAfter running this command, all commands that run the LEAN engine or the research environment use your custom images.\nThis command performs the following actions:\n\nThelean-cli/foundation:latestimage is built fromLean / DockerfileLeanFoundation(if you're using an AMD64-based system) orLean / DockerfileLeanFoundationARM(if you're using an ARM64-based system).LEAN is compiled in a Docker container using thelean-cli/foundation:latestimage.Thelean-cli/engine:latestimage is built fromLean / Dockerfileusinglean-cli/foundation:latestas the base image.Thelean-cli/research:latestimage is built fromLean / DockerfileJupyterusinglean-cli/engine:latestas the base image.The default engine image is set tolean-cli/engine:latest.The default research image is set tolean-cli/research:latest.\n\nWhen the foundation Dockerfile is the same as the one used for the official foundation image, step 1 is skipped andquantconnect/lean:foundationis used instead oflean-cli/foundation:latest.\n\n### Arguments\n\nThelean buildcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean buildcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean build",
      "section_number": "12.2",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <lean> | The path to the directory containing theLEANrepository. Defaults to the current working directory. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --tag <string> | The tag to apply to custom images (defaults to latest) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean buildcommand and exit |"
  },
  {
    "id": "12.3",
    "title": "lean cloud backtest",
    "level": 2,
    "path": "API Reference > lean cloud backtest",
    "content": "### Introduction\n\nBacktest a project in the cloud.\n\n$ lean cloud backtest [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns a backtest for a cloud project.\nWhile running the backtest, a progress bar shows to keep you up-to-date on the status of the backtest.\nAfter running the backtest, the resulting statistics and a link to the full results on QuantConnect are logged.\nYou can use the--openoption to automatically open the full results in the browser after the backtest has finished.\n\nIf you have a local copy of the cloud project, you can use the--pushoption to push local modifications to the cloud before running the backtest.\n\n### Arguments\n\nThelean cloud backtestcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud backtestcommand supports the following options:\n\n[Table - 5 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud backtest",
      "section_number": "12.3",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the project for which to run a backtest. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --name <string> | The name of the backtest (a random one is generated if not specified) |\n| --push | Push local modifications to the cloud before running the backtest |\n| --open | Automatically open the results in the browser when the backtest is finished |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud backtestcommand and exit |"
  },
  {
    "id": "12.4",
    "title": "lean cloud live",
    "level": 2,
    "path": "API Reference > lean cloud live",
    "content": "### Introduction\n\nInteract with the QuantConnect cloud live deployments.\n\n$ lean cloud live [OPTIONS] COMMAND [ARGS]...\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean cloud livecommand supports the following options:\n\n[Table - 1 rows]\n\n### Commands\n\nThelean cloud livecommand expects the following arguments:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud live",
      "section_number": "12.4",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --help | Display the help text of thelean cloud livecommand and exit |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| command | Send a command to a running cloud live trading project |\n| deploy | Start live trading for a project in the cloud |\n| liquidate | Stops live trading and liquidates existing positions for a certain project |\n| stop | Stops live trading for a certain project without liquidating existing positions |"
  },
  {
    "id": "12.5",
    "title": "lean cloud live command",
    "level": 2,
    "path": "API Reference > lean cloud live command",
    "content": "### Introduction\n\nSend a command to a running cloud live trading project.\n\n$ lean cloud live command [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean cloud live commandcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud live command",
      "section_number": "12.5",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --data <string> | The command to send, 'str' representation of a 'dict' e.g. \"{ \\\"target\\\": \\\"BTCUSD\\\", \\\"$type\\\":\\\"MyCommand\\\" }\" |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud live commandcommand and exit |"
  },
  {
    "id": "12.6",
    "title": "lean cloud live deploy",
    "level": 2,
    "path": "API Reference > lean cloud live deploy",
    "content": "### Introduction\n\nStart live trading for a project in the cloud.\n\n$ lean cloud live deploy [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nStarts live trading for a cloud project.\nBefore starting live trading, the CLI shows an interactive wizard letting you configure the brokerage, data provider, live node, and notifications.\nAfter starting live trading, the CLI displays a URL to the live results.\nYou can use the--openflag to automatically open this URL in the browser once the deployment starts.\n\nIf you specify the--brokerageand--data-provider-liveoptions, the interactive wizard is skipped and the command runs in non-interactive mode.\nIn this mode, the command doesn't prompt for input or confirmation and reads all configuration from the provided command-line options.\nIn non-interactive mode, all options specific to the selected brokerage become required, as well as--node,--auto-restart,--notify-order-events, and--notify-insights.\nIn case a required option has not been provided, the command falls back to the property with the same name in yourLean configuration file.\nThe command aborts if this property also hasn't been set.\n\nThe following options are required for each brokerage in non-interactive mode:\n\n[Table - 56 rows]\n\nThe--data-provider-liveoption is required.\nThe following table shows the available live data providers and their required options in non-interactive mode.\nTo select multiple data providers, seperate them with a comma.\nThe order you select them in defines the order of precedence.\n\n[Table - 33 rows]\n\nIf you omit some of the required options when running in non-interactive mode, the CLI uses the option values in yourLEAN configuration file.\n\nExample non-interactive usage:\n\n$ lean cloud live deploy \"My Project\" \\\n--brokerage \"Paper Trading\" \\\n--data-provider-live QuantConnect \\\n--node \"My Node\" \\\n--auto-restart yes\n--notify-order-events no \\\n--notify-insights no \\\n--push \\\n--open\n\nIf you have a local copy of the cloud project, you can use the--pushoption to push local modifications to the cloud before starting live trading.\n\n### Arguments\n\nThelean cloud live deploycommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud live deploycommand supports the following options:\n\n[Table - 77 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud live deploy",
      "section_number": "12.6",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| --brokerage | Required Options |\n| --- | --- |\n| \"Paper Trading\" | N/A |\n| Alpaca | --alpaca-environment |\n| --alpaca-api-key |  |\n| --alpaca-api-secret |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| --binance-use-testnet |  |\n| Bitfinex | --bitfinex-api-key |\n| --bitfinex-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| --bybit-vip-level |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| \"Interactive Brokers\" | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| Samco | --samco-client-id |\n| --samco-client-password |  |\n| --samco-year-of-birth |  |\n| --samco-product-type |  |\n| --samco-trading-segment |  |\n| TDAmeritrade | --tdameritrade-api-key |\n| --tdameritrade-access-token |  |\n| --tdameritrade-account-number |  |\n| \"Terminal Link\" | --terminal-link-server-auth-id |\n| --terminal-link-environment |  |\n| --terminal-link-server-host |  |\n| --terminal-link-server-port |  |\n| --terminal-link-emsx-account |  |\n| --terminal-link-emsx-broker |  |\n| --terminal-link-openfigi-api-key |  |\n| TradeStation | --trade-station-environment |\n| --trade-station-account-type |  |\n| Tradier | --tradier-account-id |\n| --tradier-access-token |  |\n| --tradier-environment |  |\n| \"Trading Technologies\" | --tt-user-name |\n| --tt-session-password |  |\n| --tt-account-name |  |\n| --tt-rest-app-key |  |\n| --tt-rest-app-secret |  |\n| --tt-rest-environment |  |\n| --tt-order-routing-sender-comp-id |  |\n| Zerodha | --zerodha-api-key |\n| --zerodha-access-token |  |\n| --zerodha-product-type |  |\n| --zerodha-trading-segment |  |\n| --zerodha-history-subscription |  |",
    "table_1": "| --data-provider-live | Required Options |\n| --- | --- |\n| Alpaca | All options required by--brokerage Alpaca. |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bitfinex | All options required by--brokerage Bitfinex. |\n| Bybit | All options required by--brokerage Bybit. |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | All options required by--brokerage \"Interactive Brokers\". |\n| Kraken | All options required by--brokerage Kraken. |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| Polygon | --polygon-api-key |\n| QuantConnect | N/A |\n| Samco | All options required by--brokerage Samco. |\n| TDAmeritrade | All options required by--brokerage TDAmeritrade. |\n| \"Terminal Link\" | All options required by--brokerage \"Terminal Link\". |\n| TradeStation | All options required by--brokerage TradeStation. |\n| Tradier | --tradier-account-id |\n| --tradier-access-token |  |\n| \"Trading Technologies\" | --tt-user-name |\n| --tt-session-password |  |\n| --tt-account-name |  |\n| --tt-rest-app-key |  |\n| --tt-rest-app-secret |  |\n| --tt-rest-environment |  |\n| --tt-order-routing-sender-comp-id |  |\n| Zerodha | All options required by--brokerage Zerodha. |\n| --zerodha-history-subscription |  |",
    "table_2": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the project to start live trading. |",
    "table_3": "| Option | Description |\n| --- | --- |\n| --brokerage <enum: Paper TradingInteractive BrokersTradierOandaBitfinexCoinbase Advanced TradeBinanceZerodhaSamcoTerminal LinkTrading TechnologiesKrakenCharlesSchwabBybitTradeStationAlpaca> | The brokerage to use |\n| --data-provider-live <enum: QuantConnectInteractive BrokersTradierOandaBitfinexCoinbase Advanced TradeBinanceZerodhaSamcoTerminal LinkTrading TechnologiesKrakenCharlesSchwabPolygonCoinApiBybitTradeStationAlpaca> | The live data provider to use |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --tradier-account-id <string> | Your Tradier account id |\n| --tradier-access-token <string> | Your Tradier access token |\n| --tradier-environment <enum: live|paper> | Whether the developer sandbox should be used |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --binance-use-testnet <enum: live|paper> | Whether the testnet should be used |\n| --zerodha-api-key <string> | Your Kite Connect API key |\n| --zerodha-access-token <string> | Your Kite Connect access token |\n| --zerodha-product-type <enum: mis|cnc|nrml> | MIS if you are targeting intraday products, CNC if you are targeting delivery products, NRML if you are targeting carry forward products |\n| --zerodha-trading-segment <enum: equity|commodity> | EQUITY if you are trading equities on NSE or BSE, COMMODITY if you are trading commodities on MCX |\n| --zerodha-history-subscription <enum: true|false> | Whether you have a history API subscription for Zerodha |\n| --samco-client-id <string> | Your Samco account Client ID |\n| --samco-client-password <string> | Your Samco account password |\n| --samco-year-of-birth <string> | Your year of birth (YYYY) registered with Samco |\n| --samco-product-type <enum: mis|cnc|nrml> | MIS if you are targeting intraday products, CNC if you are targeting delivery products, NRML if you are targeting carry forward products |\n| --samco-trading-segment <enum: equity|commodity> | EQUITY if you are trading equities on NSE or BSE, COMMODITY if you are trading commodities on MCX |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the SAPI server |\n| --terminal-link-server-port <integer> | The port of the SAPI server |\n| --terminal-link-emsx-broker <string> | The EMSX broker to use (Optional) |\n| --terminal-link-emsx-account <string> | The EMSX account to use (Optional) |\n| --terminal-link-emsx-team <string> | The EMSX team to receive order events from (Optional) |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --tt-user-name <string> | Your Trading Technologies username |\n| --tt-session-password <string> | Your Trading Technologies session password |\n| --tt-account-name <string> | Your Trading Technologies account name |\n| --tt-rest-app-key <string> | Your Trading Technologies REST app key |\n| --tt-rest-app-secret <string> | Your Trading Technologies REST app secret |\n| --tt-rest-environment <string> | The REST environment to run in |\n| --tt-order-routing-sender-comp-id <string> | The order routing sender comp id to use |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --bybit-vip-level <enum: VIP0VIP1VIP2VIP3VIP4VIP5SupremeVIPPro1Pro2Pro3Pro4Pro5> | Your Bybit VIP Level |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --alpaca-api-key <string> | Your Alpaca Api Key |\n| --alpaca-api-secret <string> | Your Alpaca Api Secret |\n| --node <string> | The name or id of the live node to run on |\n| --auto-restart <boolean> | Whether automatic algorithm restarting must be enabled |\n| --notify-order-events <boolean> | Whether notifications must be sent for order events |\n| --notify-insights <boolean> | Whether notifications must be sent for emitted insights |\n| --notify-emails <string> | A comma-separated list of 'email:subject' pairs configuring email-notifications |\n| --notify-webhooks <string> | A comma-separated list of 'url:HEADER_1=VALUE_1:HEADER_2=VALUE_2:etc' pairs configuring webhook-notifications |\n| --notify-sms <string> | A comma-separated list of phone numbers configuring SMS-notifications |\n| --notify-telegram <string> | A comma-separated list of 'user/group Id:token(optional)' pairs configuring telegram- notifications |\n| --live-cash-balance <string> | A comma-separated list of currency:amount pairs of initial cash balance |\n| --live-holdings <string> | A comma-separated list of symbol:symbolId:quantity:averagePrice of initial portfolio holdings |\n| --push | Push local modifications to the cloud before starting live trading |\n| --open | Automatically open the live results in the browser once the deployment starts |\n| --show-secrets | Show secrets as they are input |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud live deploycommand and exit |"
  },
  {
    "id": "12.7",
    "title": "lean cloud live liquidate",
    "level": 2,
    "path": "API Reference > lean cloud live liquidate",
    "content": "### Introduction\n\nStops live trading and liquidates existing positions for a certain project.\n\n$ lean cloud live liquidate [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean cloud live liquidatecommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud live liquidatecommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud live liquidate",
      "section_number": "12.7",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the project to liquidate. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud live liquidatecommand and exit |"
  },
  {
    "id": "12.8",
    "title": "lean cloud live stop",
    "level": 2,
    "path": "API Reference > lean cloud live stop",
    "content": "### Introduction\n\nStops live trading for a certain project without liquidating existing positions.\n\n$ lean cloud live stop [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean cloud live stopcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud live stopcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud live stop",
      "section_number": "12.8",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the project to stop live trading. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud live stopcommand and exit |"
  },
  {
    "id": "12.9",
    "title": "lean cloud object-store delete",
    "level": 2,
    "path": "API Reference > lean cloud object-store delete",
    "content": "### Introduction\n\nDelete a value from the organization's cloud object store.\n\n$ lean cloud object-store delete [OPTIONS] KEY\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Arguments\n\nThelean cloud object-store deletecommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud object-store deletecommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store delete",
      "section_number": "12.9",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <key> | The key to a value in the Object Store. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store deletecommand and exit |"
  },
  {
    "id": "12.10",
    "title": "lean cloud object-store get",
    "level": 2,
    "path": "API Reference > lean cloud object-store get",
    "content": "### Introduction\n\nDownload an object store value to disk from the organization's cloud object store.\n\n$ lean cloud object-store get [OPTIONS] [KEY]...\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Arguments\n\nThelean cloud object-store getcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud object-store getcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store get",
      "section_number": "12.10",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <key> | The key to a file in the Object Store. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --destination-folder <string> | The destination folder to download the object store values, if not provided will use to current directory |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store getcommand and exit |"
  },
  {
    "id": "12.11",
    "title": "lean cloud object-store list",
    "level": 2,
    "path": "API Reference > lean cloud object-store list",
    "content": "### Introduction\n\nList all values for the given root key in the organization's cloud object store.\n\n$ lean cloud object-store list [OPTIONS] [KEY]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Arguments\n\nThelean cloud object-store listcommand expects the following arguments:\n\n[Table - 1 rows]\n\nIf you don't provide the <key>,lean cloud object-store listlists the contents of the root directory.\n\n### Options\n\nThelean cloud object-store listcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store list",
      "section_number": "12.11",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| (Optional)<key> | The path to a directory in the Object Store. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store listcommand and exit |"
  },
  {
    "id": "12.12",
    "title": "lean cloud object-store ls",
    "level": 2,
    "path": "API Reference > lean cloud object-store ls",
    "content": "### Introduction\n\nAlias for 'list'\n\n$ lean cloud object-store ls [OPTIONS] [KEY]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Arguments\n\nThelean cloud object-store lscommand expects the following arguments:\n\n[Table - 1 rows]\n\nIf you don't provide the <key>,lean cloud object-store lslists the contents of the root directory.\n\n### Options\n\nThelean cloud object-store lscommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store ls",
      "section_number": "12.12",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| (Optional)<key> | The path to a directory in the Object Store. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store lscommand and exit |"
  },
  {
    "id": "12.13",
    "title": "lean cloud object-store properties",
    "level": 2,
    "path": "API Reference > lean cloud object-store properties",
    "content": "### Introduction\n\nGet a value properties from the organization's cloud object store.\n\n$ lean cloud object-store properties [OPTIONS] KEY\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean cloud object-store propertiescommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store properties",
      "section_number": "12.13",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store propertiescommand and exit |"
  },
  {
    "id": "12.14",
    "title": "lean cloud object-store set",
    "level": 2,
    "path": "API Reference > lean cloud object-store set",
    "content": "### Introduction\n\nSets the data to the given key in the organization's cloud object store.\n\n$ lean cloud object-store set [OPTIONS] KEY PATH\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Arguments\n\nThelean cloud object-store setcommand expects the following arguments:\n\n[Table - 2 rows]\n\n### Options\n\nThelean cloud object-store setcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud object-store set",
      "section_number": "12.14",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <key> | The key under which to save the file. |\n| <path> | Path to the local file to upload. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud object-store setcommand and exit |"
  },
  {
    "id": "12.15",
    "title": "lean cloud optimize",
    "level": 2,
    "path": "API Reference > lean cloud optimize",
    "content": "### Introduction\n\nOptimize a project in the cloud.\n\n$ lean cloud optimize [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns an optimization for a cloud project.\nWhile running the optimization, a progress bar shows to keep you up-to-date on the status of the optimization.\nAfter running the optimization, the optimal parameters and the statistics of the backtest with the optimal parameters are logged.\n\nBy default, an interactive wizard is shown, letting you configure the target, the parameters, the constraints, the node type, and the number of parallel nodes.\nWhen--targetis given the command runs in non-interactive mode and does not prompt for input or confirmation.\n\nWhen--targetis given, the optimizer configuration is read from the command-line options.\nThis means the--target,--target-direction,--parameter,--node, and--parallel-nodesoptions become required.\nAdditionally, you can also use--constraintto specify optimization constraints.\n\nIn non-interactive mode, the parameters can be configured using the--parameteroption.\nThis option takes the following values: the name of the parameter, its minimum value, its maximum value, and its step size.\nYou can provide this option multiple times to configure multiple parameters.\n\nIn non-interactive mode, the constraints can be configured using the--constraintoption.\nThis option takes a \"statistic operator value\" string as value, where the statistic must be a path to a property in a backtest's output file, like \"TotalPerformance.PortfolioStatistics.SharpeRatio\".\nThis statistic can also be shortened to \"SharpeRatio\" or \"Sharpe Ratio\", in which case, the command automatically converts it to the longer version.\nThe value must be a number and the operator must be<,>,<=,>=,==, or==.\nYou can provide this option multiple times to configure multiple constraints.\n\nExample non-interactive usage:\n\n$ lean cloud optimize \"My Project\" \\\n--target \"Sharpe Ratio\" \\\n--target-direction \"max\" \\\n--parameter my-first-parameter 1 10 0.5 \\\n--parameter my-second-parameter 20 30 5 \\\n--constraint \"Drawdown < 0.5\" \\\n--constraint \"Sharpe Ratio >= 1\" \\\n--node O4-12 \\\n--parallel-nodes 12 \\\n--push\n\nIf you have a local copy of the cloud project, you can use the--pushoption to push local modifications to the cloud before starting the optimization.\n\n### Arguments\n\nThelean cloud optimizecommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud optimizecommand supports the following options:\n\n[Table - 10 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud optimize",
      "section_number": "12.15",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the project to optimize. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --target <string> | The target statistic of the optimization |\n| --target-direction <enum: min|max> | Whether the target must be minimized or maximized |\n| --parameter <<string> <float> <float> <float>>... | The 'parameter min max step' pairs configuring the parameters to optimize |\n| --constraint <string> | The 'statistic operator value' pairs configuring the constraints of the optimization |\n| --node <enum: O2-8|O4-12|O8-16> | The node type to run the optimization on |\n| --parallel-nodes <integer> | The number of nodes that may be run in parallel |\n| --name <string> | The name of the optimization (a random one is generated if not specified) |\n| --push | Push local modifications to the cloud before starting the optimization |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud optimizecommand and exit |"
  },
  {
    "id": "12.16",
    "title": "lean cloud pull",
    "level": 2,
    "path": "API Reference > lean cloud pull",
    "content": "### Introduction\n\nPull projects from QuantConnect to the local drive.\n\n$ lean cloud pull [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nPulls projects from QuantConnect to your local directory while preserving the directory structure of your projects on QuantConnect.\nThe project's files, description, and parameters are pulled from the cloud.\nBy default, all cloud projects are pulled from the organization that's linked to your currentorganization workspace. If you provide a--projectoption, you only pull a single project from the cloud.\n\nBefore pulling a cloud project, the CLI checks if the local directory with the same path already exists.\nIf it does and the local directory is not linked to the cloud project (because of an earlierlean cloud pullorlean cloud push), the CLI skips pulling the cloud project and logs a descriptive warning message.\n\nIf you have a local copy of a project when you pull it from the cloud, local files that don't exist in the cloud are not deleted, but the configuration values of your cloud project overwrite theconfiguration values of the local version. If you have renamed the project in the cloud, when you pull the project from the cloud, the local project is renamed to match the name of the cloud project.\n\nIf one of your team members creates aproject library, adds it to a project, and then adds you as a collaborator to the project, you can pull the project but not the library. To pull the library as well, your team member must add you as a collaborator on the library project.\n\n### Options\n\nThelean cloud pullcommand supports the following options:\n\n[Table - 7 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud pull",
      "section_number": "12.16",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --project <string> | Name or id of the project to pull (all cloud projects if not specified) |\n| --pull-bootcamp | Pull Boot Camp projects (disabled by default) |\n| --encrypt | Pull your cloud files and encrypt them before saving on your local drive |\n| --decrypt | Pull your cloud files and decrypt them before saving on your local drive |\n| --key <file> | Path to the encryption key to use |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud pullcommand and exit |"
  },
  {
    "id": "12.17",
    "title": "lean cloud push",
    "level": 2,
    "path": "API Reference > lean cloud push",
    "content": "### Introduction\n\nPush local projects to QuantConnect.\n\n$ lean cloud push [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nPushes local projects to QuantConnect while preserving the directory structure of your local projects.\nThe project'ssupported files, description, and parameters are pushed to the cloud.\nBy default, all local projects in your current organization workspace directory are pushed. If you provide a--projectoption, you only push a single project to the cloud.\n\nBefore pushing a local project, the CLI checks if the cloud project with the same path already exists.\nIf it does and the cloud project is not linked to the local project (because of an earlierlean cloud pullorlean cloud push), the CLI adds a 1 to the end of the name of your local project and then pushes it to the cloud.\nIf the cloud project doesn't exist yet, the CLI creates it for you and pushes the contents of the local project to the newly created cloud project.\n\nIf you have a cloud copy of a project when you push it from your local machine, files in the cloud which don't exist locally are deleted and theconfiguration values of your local projectoverwrite the configuration values of the cloud version. If you have renamed the project on your local machine or in the cloud before you push, the cloud project is renamed to match the name of the local project.\n\n### Options\n\nThelean cloud pushcommand supports the following options:\n\n[Table - 6 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud push",
      "section_number": "12.17",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --project <directory> | Path to the local project to push (all local projects if not specified) |\n| --encrypt | Push your local files and encrypt them before saving on the cloud |\n| --decrypt | Push your local files and decrypt them before saving on the cloud |\n| --key <file> | Path to the encryption key to use |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud pushcommand and exit |"
  },
  {
    "id": "12.18",
    "title": "lean cloud status",
    "level": 2,
    "path": "API Reference > lean cloud status",
    "content": "### Introduction\n\nShow the live trading status of a project in the cloud.\n\n$ lean cloud status [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nShows the live status of a cloud project.\nDisplays the project id, project name, project URL, and live status.\nIf the project has been deployed before, it also shows the deployment id, results URL, brokerage, and when it launched.\nIf the project has been stopped, it also shows when it was stopped and the error that caused it, if there is one.\n\n### Arguments\n\nThelean cloud statuscommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean cloud statuscommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean cloud status",
      "section_number": "12.18",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The name or Id of the cloud project for which to show the status. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean cloud statuscommand and exit |"
  },
  {
    "id": "12.19",
    "title": "lean config get",
    "level": 2,
    "path": "API Reference > lean config get",
    "content": "### Introduction\n\nGet the current value of a configurable option.\n\n$ lean config get [OPTIONS] KEY\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nPrints the value of the requested option or aborts if the value is not set.\n\nThis command doesn't print the values of credentials for security reasons.\nOpen thecredentialsfile in yourglobal configurationdirectory to see your stored credentials.\n\n### Arguments\n\nThelean config getcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean config getcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean config get",
      "section_number": "12.19",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <key> | The key of the value to retrieve. Runlean config listto get a list of all available keys. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean config getcommand and exit |"
  },
  {
    "id": "12.20",
    "title": "lean config list",
    "level": 2,
    "path": "API Reference > lean config list",
    "content": "### Introduction\n\nList the configurable options and their current values.\n\n$ lean config list [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nDisplays a table containing all configurable options and their current values.\nCredentials are masked with asterisks for security reasons.\n\n### Options\n\nThelean config listcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean config list",
      "section_number": "12.20",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean config listcommand and exit |"
  },
  {
    "id": "12.21",
    "title": "lean config set",
    "level": 2,
    "path": "API Reference > lean config set",
    "content": "### Introduction\n\nSet a configurable option.\n\n$ lean config set [OPTIONS] KEY VALUE\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nUpdates the value of a configurable option in yourglobal configurationdirectory.\nThe command aborts with a descriptive error message if the given value is invalid for the given key.\n\nThe following keys can be set:\n\n[Table - 5 rows]\n\n### Arguments\n\nThelean config setcommand expects the following arguments:\n\n[Table - 2 rows]\n\n### Options\n\nThelean config setcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean config set",
      "section_number": "12.21",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Key | Description |\n| --- | --- |\n| user-id | The user Id used when making authenticated requests to the QuantConnect API. |\n| api-token | The API token used when making authenticated requests to the QuantConnect API. |\n| default-language | The default language used when creating new projects (must be eitherpythonorcsharp). |\n| engine-image | The Docker image used when running the LEAN engine (quantconnect/lean:latestif not set). |\n| research-image | The Docker image used when running the research environment (quantconnect/research:latestif not set). |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| <key> | The key of the option to update. |\n| <value> | The new value for the option with the given key. |",
    "table_2": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean config setcommand and exit |"
  },
  {
    "id": "12.22",
    "title": "lean config unset",
    "level": 2,
    "path": "API Reference > lean config unset",
    "content": "### Introduction\n\nUnset a configurable option.\n\n$ lean config unset [OPTIONS] KEY\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nUnsets the value of a configurable option in yourglobal configurationdirectory.\nThe command aborts with a descriptive error message if the given value is invalid for the given key.\n\n### Arguments\n\nThelean config unsetcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean config unsetcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean config unset",
      "section_number": "12.22",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <key> | The key of the option to unset. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean config unsetcommand and exit |"
  },
  {
    "id": "12.23",
    "title": "lean create-project",
    "level": 2,
    "path": "API Reference > lean create-project",
    "content": "### Introduction\n\nAlias for 'project-create'\n\n$ lean create-project [OPTIONS] NAME\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nCreates a new project with some basic starter code.\nIf the language is set topython, this generates amain.pyfile, a Python-based research notebook, aproject configurationfile, and editor configuration files for PyCharm and VS Code.\n\nIf the language is set tocsharpthis generates aMain.csfile, a C#-based research notebook, aproject configurationfile, and editor configuration files for Visual Studio, Rider, and VS Code.\n\nA full list of the created files can be found on theProjects > Structurepage.\n\nIf no--languageis given, the default language saved in theglobal configurationis used.\nYou can update the default language to Python by runninglean config set default-language pythonor to C# by runninglean config set default-language csharp.\n\nIf the given project name contains slashes, the name is parsed as a path and the project is created in a subdirectory.\nAny subdirectories that don't exist yet are created automatically.\n\n### Arguments\n\nThelean create-projectcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean create-projectcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean create-project",
      "section_number": "12.23",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <name> | The name of the project to create. This name may contain slashes to create a project in a subdirectory.\n                The project name must only contain-,_, letters, numbers, and spaces. The project name can't start with a space or be any of the following reserved names: CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, or LPT9.\n                If the project is a Python library, the library name can only contain letters (a-z), numbers (0-9), and underscores (_). Python library names can't contain spaces or start with a number. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| -l, --language <enum: python|csharp> | The language of the project to create |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean create-projectcommand and exit |"
  },
  {
    "id": "12.24",
    "title": "lean data download",
    "level": 2,
    "path": "API Reference > lean data download",
    "content": "### Introduction\n\nPurchase and download data directly from QuantConnect or download from supported data providers\n\n$ lean data download [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nLets you purchase and download historical data from theQuantConnect Dataset Market, a brokerage, or a third-party data provider.\n\nDownload from QuantConnect\n\nWhen you download data from the QuantConnect Dataset Market, this command performs the following actions:\n\nAn interactive wizard is shown allowing you to configure exactly which data you want to download.You are asked to accept theCLI API Access and Data Agreementin your web browser.You are asked to confirm the purchase one last time.The CLI downloads the requested files while charging the organization that's linked to your current organization workspace.\n\nData from the Dataset Market is priced on a per-file per-download basis, meaning you pay a certain number ofQuantConnect Credits(QCC) for each file you download.\nThe required QCC is deducted from your organization's QCC balance when a file is downloaded.\nIf you force-quit the command before it downloaded all requested files, you are not charged for the files you didn't download.\n\nWhen--datasetis given, the command runs in non-interactive mode and several steps in the preceding list are skipped.\nInstead, the command reads the downloading configuration from the given command-line options.\nIn this mode, the--datasetoption is required, as well as all options specific to the selected dataset.\n\nExample non-interactive usage:\n\n$ lean data download \\\n--dataset \"Bitfinex Crypto Price Data\" \\\n--data-type \"Trade\" \\\n--ticker \"BTCUSDT\" \\\n--resolution \"Daily\" \\\n--start \"20201208\" \\\n--end \"20221208\"\n\nIn case the local data already exists, a warning is logged and you are given the choice of whether you want to enable overwriting existing data or not.\nUse the--overwriteflag to override this behavior and enable overwriting existing data in all such cases.\n\nTo automatically confirm payment confirmation prompts, use the--yesflag.\n\nDownload from Brokerages and Third-Party Providers\n\nTo download data from a brokerage or third-party data provider, run this command and follow the prompts to select the data you need.\nTo view all the available data providers, see the--data-provider-historicaloptiondescription.\nAfter you know what options you need to provide to download data from your specific brokerage or third-party data provider, you can run the command in a script to automate the process of downloading new data.\n\n### Options\n\nThelean data downloadcommand supports the following options:\n\n[Table - 62 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean data download",
      "section_number": "12.24",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --data-provider-historical <enum: Interactive BrokersOandaBitfinexCoinbase Advanced TradeBinanceKrakenCharlesSchwabIQFeedPolygonFactSetAlphaVantageCoinApiThetaDataQuantConnectLocalTerminal LinkBybitTradeStationAlpaca> | The name of the downloader data provider |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --iqfeed-iqconnect <string> | The path to the IQConnect binary |\n| --iqfeed-username <string> | Your IQFeed username |\n| --iqfeed-password <string> | Your IQFeed password |\n| --iqfeed-version <string> | The product version of your IQFeed developer account |\n| --iqfeed-host <string> | The IQFeed host address (Optional) |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --factset-auth-config-file <file> | The path to the FactSet authentication configuration file |\n| --alpha-vantage-api-key <string> | Your Alpha Vantage Api Key |\n| --alpha-vantage-price-plan <enum: FreePlan30Plan75Plan150Plan300Plan600Plan1200> | Your Alpha Vantage Premium API Key plan |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --thetadata-ws-url <string> | The ThetaData host address (Optional) |\n| --thetadata-rest-url <string> | The ThetaData host address (Optional) |\n| --thetadata-subscription-plan <enum: FreeValueStandardPro> | Your ThetaData subscription price plan |\n| --terminal-link-connection-type <enum: DAPI|SAPI> | Terminal Link Connection Type [DAPI, SAPI] |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the TerminalLink server |\n| --terminal-link-server-port <integer> | The port of the TerminalLink server |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --dataset <string> | The name of the dataset to download non-interactively |\n| --overwrite | Overwrite existing local data |\n| -y, --yes | Automatically confirm payment confirmation prompts |\n| --data-type <enum: TradeQuoteBulkUniverseOpenInterest> | Specify the type of historical data |\n| --resolution <enum: TickSecondMinuteHourDaily> | Specify the resolution of the historical data |\n| --security-type <enum: EquityIndexForexCfdFutureCryptoCryptoFutureOptionIndexOptionCommodityFutureOption> | Specify the security type of the historical data |\n| --market <string> | Specify the market name for tickers (e.g., 'USA', 'NYMEX', 'Binance') (if not provided or empty the default market for the requested security type will be used) |\n| --ticker <string> | Specify comma separated list of tickers to use for historical data request |\n| --start <string> | Specify the start date for the historical data request in the format yyyyMMdd |\n| --end <string> | Specify the end date for the historical data request in the format yyyyMMdd. (defaults to today) |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --update | Pull the LEAN engine image before running the Downloader Data Provider |\n| --no-update | Use the local LEAN engine image instead of pulling the latest version |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean data downloadcommand and exit |"
  },
  {
    "id": "12.25",
    "title": "lean data generate",
    "level": 2,
    "path": "API Reference > lean data generate",
    "content": "### Introduction\n\nGenerate random market data.\n\n$ lean data generate [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns the random data generator in the LEAN ToolBox to generate realistic market data using a Brownian motion model.\nRequires--start <yyyyMMdd>and--symbol-count <amount>to be set. The rest of the options have default values.\n\nIf--end <yyyyMMdd>isn't set, data is generated from the start date until the current date.\nIf the--endoption is set, data is generated between the given--startand--endvalues (inclusive).\n\nBy default, dense data is generated, which means the generated data contains at least one data point per resolution step.\nYou can use--data-density Sparseto change this to at least one data point per 5 resolution steps, or--data-density VerySparseto change it to at least one data point per 50 resolution steps.\n\nIf the security type is set toEquity, this command will automatically generate map files, factor files, and coarse universe data. To not generate coarse universe data, set the--include-coarseoption tofalse.\n\nThe following combinations of security types and resolutions are supported:\n\n[Table - 6 rows]\n\nBy default, the official LEAN engine image is used.\nYou can override this using the--image <value>option.\nAlternatively, you can set the default engine image for all commands usinglean config set engine-image <value>.\nThe image is pulled before running the random data generator if it doesn't exist locally yet or if you pass the--updateflag.\n\n### Options\n\nThelean data generatecommand supports the following options:\n\n[Table - 24 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean data generate",
      "section_number": "12.25",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Security Type | Supported Resolutions |\n| --- | --- |\n| Equity |  |\n| Forex |  |\n| CFD |  |\n| Future |  |\n| Crypto |  |\n| Option |  |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --start <yyyyMMdd> | [required] |\n| --end <yyyyMMdd> | End date for the data to generate in yyyyMMdd format (defaults to today) |\n| --symbol-count <integer> <range> | [x>=0] |\n| --tickers <string> | Comma separated list of tickers to use for generated data |\n| --security-type <enum: EquityForexCfdFutureCryptoOption> | The security type to generate data for (defaults to Equity) |\n| --resolution <enum: TickSecondMinuteHourDaily> | The resolution of the generated data (defaults to Minute) |\n| --data-density <enum: Dense|Sparse|VerySparse> | The density of the generated data (defaults to Dense) |\n| --include-coarse <boolean> | Whether coarse universe data should be generated for Equity data (defaults to True) |\n| --market <string> | The market to generate data for (defaults to standard market for the security type) |\n| --quote-trade-ratio <float> | The ratio of generated quotes to generated trades. Values larger than 1 mean more quotes than trades. Only used for Option, Future and Crypto (defaults to 1) |\n| --random-seed <integer> <range> | The random number generator seed. Defaults to None, which means no seed will be used [x>=0] |\n| --ipo-percentage <float> | The probability each equity generated will have an IPO event. Note that this is not the total probability for all symbols generated. Only used for Equity (defaults to 5.0) |\n| --rename-percentage <float> | The probability each equity generated will have a rename event. Note that this is not the total probability for all symbols generated. Only used for Equity (defaults to 30.0) |\n| --splits-percentage <float> | The probability each equity generated will have a stock split event. Note that this is not the total probability for all symbols generated. Only used for Equity (defaults to 15.0) |\n| --dividends-percentage <float> | The probability each equity generated will have dividends. Note that this is not the probability for all symbols genearted. Only used for Equity (defaults to 60.0) |\n| --dividend-every-quarter-percentage <float> | The probability each equity generated will have a dividend event every quarter. Note that this is not the total probability for all symbols generated. Only used for Equity (defaults to 30.0) |\n| --option-price-engine <string> | The stochastic process, and returns new pricing engine to run calculations for that option (defaults to BaroneAdesiWhaleyApproximationEngine) |\n| --volatility-model-resolution <enum: TickSecondMinuteHourDaily> | The volatility model period span (defaults to Daily) |\n| --chain-symbol-count <integer> <range> | [x>=0] |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --update | Pull the LEAN engine image before running the generator |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean data generatecommand and exit |"
  },
  {
    "id": "12.26",
    "title": "lean decrypt",
    "level": 2,
    "path": "API Reference > lean decrypt",
    "content": "### Introduction\n\nDecrypt your local project using the specified decryption key.\n\n$ lean decrypt [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean decryptcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean decrypt",
      "section_number": "12.26",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --key <file> | Path to the decryption key to use |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean decryptcommand and exit |"
  },
  {
    "id": "12.27",
    "title": "lean delete-project",
    "level": 2,
    "path": "API Reference > lean delete-project",
    "content": "### Introduction\n\nAlias for 'project-delete'\n\n$ lean delete-project [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nDeletes a project from your local machine and in the cloud. If you are a collaborator on the project, this command doesn't delete the project for the other collaborators, but it removes you as a collaborator.\n\n### Options\n\nThelean delete-projectcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean delete-project",
      "section_number": "12.27",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean delete-projectcommand and exit |"
  },
  {
    "id": "12.28",
    "title": "lean encrypt",
    "level": 2,
    "path": "API Reference > lean encrypt",
    "content": "### Introduction\n\nEncrypt your local project using the specified encryption key.\n\n$ lean encrypt [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean encryptcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean encrypt",
      "section_number": "12.28",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --key <file> | Path to the encryption key to use |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean encryptcommand and exit |"
  },
  {
    "id": "12.29",
    "title": "lean init",
    "level": 2,
    "path": "API Reference > lean init",
    "content": "### Introduction\n\nScaffold a Lean configuration file and data directory.\n\n$ lean init [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nFills the current directory with all the files needed to get going.\nIt'll create a Lean configuration file and a data directory containing some sample data.\nTo view a full list of the created files, seeDirectory Structure.\n\n### Options\n\nThelean initcommand supports the following options:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean init",
      "section_number": "12.29",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --organization <string> | The name or id of the organization the Lean CLI will be scaffolded for |\n| -l, --language <enum: python|csharp> | The default language to use for new projects |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean initcommand and exit |"
  },
  {
    "id": "12.30",
    "title": "lean library add",
    "level": 2,
    "path": "API Reference > lean library add",
    "content": "### Introduction\n\nAdd a custom library to a project.\n\n$ lean library add [OPTIONS] PROJECT NAME\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nAdds athird-partyorproject libraryto a project so you can use it in local backtesting, local live trading, local optimizations, and the local research environment.\nAdditionally, this command updates your local environment so you get autocomplete on the libraries.\n\nC# libraries are added to your C# project file (the file ending in.csproj).\nIfdotnetis on yourPATHand--no-localis not given, the CLI also restores all dependencies usingdotnet restoreto make local autocomplete work.\n\nThird-party Python libraries are added to your project'srequirements.txtfile.\nIfpipis on yourPATHand--no-localis not given, the CLI also installs the Python package in your local Python environment to make local autocomplete work.\n\nIf--versionis not given, the package is pinned to the latest compatible version.\nFor C# projects, this is the latest available version.\nFor Python projects, this is the latest version compatible with Python 3.11 (which is what the Docker images use).\n\nIf--versionis given and the project is a Python project, the CLI will additionally check whether the given version is compatible with Python 3.6.\nIf this is not the case, the command aborts because libraries incompatible with Python 3.11 cannot be installed in the official Docker images.\n\nIf a project isencrypted, you can only add a project library to it if the project library is unencrypted or is encrypted with the same key as the project. When you add a project library to a project, the name and path of the library is added to theproject configuration file.\n\n### Arguments\n\nThelean library addcommand expects the following arguments:\n\n[Table - 2 rows]\n\n### Options\n\nThelean library addcommand supports the following options:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean library add",
      "section_number": "12.30",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory. |\n| <name> | For third-party C# libraries, the name of the NuGet package to add. For third-party Python libraries, the name of the PyPI package to add. For project libraries, the path to the library in theLibrarydirectory of yourorganization workspace. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --version <string> | The version of the library to add (defaults to latest compatible version) |\n| --no-local | Skip making changes to your local environment |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean library addcommand and exit |"
  },
  {
    "id": "12.31",
    "title": "lean library remove",
    "level": 2,
    "path": "API Reference > lean library remove",
    "content": "### Introduction\n\nRemove a custom library from a project.\n\n$ lean library remove [OPTIONS] PROJECT NAME\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRemoves a library from a project.\nThis command can remove libraries that are added usinglean library add, as well as libraries that were manually added to the C# project file or a Python project'srequirements.txtfile.\n\nC# libraries are removed from your C# project file (the file ending in.csproj).\nIfdotnetis on yourPATHand--no-localis not given, the CLI also restores all dependencies usingdotnet restore.\n\nThird-party Python libraries are removed from your project'srequirements.txtfile.\n\nProject libraries are removed from yourproject configuration file.\n\n### Arguments\n\nThelean library removecommand expects the following arguments:\n\n[Table - 2 rows]\n\n### Options\n\nThelean library removecommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean library remove",
      "section_number": "12.31",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory. |\n| <name> | For third-party C# libraries, the name of the NuGet package to remove. For third-party Python libraries, the name of the PyPI package to remove. For project libraries, the path to the library in theLibrarydirectory of yourorganization workspace. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --no-local | Skip making changes to your local environment |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean library removecommand and exit |"
  },
  {
    "id": "12.32",
    "title": "lean live",
    "level": 2,
    "path": "API Reference > lean live",
    "content": "### Introduction\n\nInteract with the local machine.\n\n$ lean live [OPTIONS] COMMAND [ARGS]...\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean livecommand supports the following options:\n\n[Table - 1 rows]\n\n### Commands\n\nThelean livecommand expects the following arguments:\n\n[Table - 8 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live",
      "section_number": "12.32",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --help | Display the help text of thelean livecommand and exit |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| add-security | Represents a command to add a security to the algorithm |\n| cancel-order | Represents a command to cancel a specific order by id |\n| command | Send a command to a local running live trading project |\n| deploy | Start live trading a project locally using Docker |\n| liquidate | Liquidate the given symbol from the latest deployment of the given project |\n| stop | Stop an already running local live trading project |\n| submit-order | Represents a command to submit an order to the algorithm |\n| update-order | Represents a command to update a specific order by id |"
  },
  {
    "id": "12.33",
    "title": "lean live add-security",
    "level": 2,
    "path": "API Reference > lean live add-security",
    "content": "### Introduction\n\nRepresents a command to add a security to the algorithm.\n\n$ lean live add-security [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live add-securitycommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live add-securitycommand supports the following options:\n\n[Table - 10 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live add-security",
      "section_number": "12.33",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to which you want to add the security. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --ticker <string> | [required] |\n| --market <string> | [required] |\n| --security-type <string> | [required] |\n| --resolution <string> | The resolution of the symbol to add |\n| --fill-data-forward | The fill forward behavior, true to fill forward, false otherwise - defaults to true |\n| --leverage <float> | The leverage for the security, defaults to 2 for equity, 50 for forex, and 1 for everything else |\n| --extended-market-hours | The extended market hours flag, true to allow pre/post market data, false for only in market data |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live add-securitycommand and exit |"
  },
  {
    "id": "12.34",
    "title": "lean live cancel-order",
    "level": 2,
    "path": "API Reference > lean live cancel-order",
    "content": "### Introduction\n\nRepresents a command to cancel a specific order by id.\n\n$ lean live cancel-order [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live cancel-ordercommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live cancel-ordercommand supports the following options:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live cancel-order",
      "section_number": "12.34",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file that contains the order you want to cancel. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --order-id <integer> | [required] |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live cancel-ordercommand and exit |"
  },
  {
    "id": "12.35",
    "title": "lean live command",
    "level": 2,
    "path": "API Reference > lean live command",
    "content": "### Introduction\n\nSend a command to a local running live trading project.\n\n$ lean live command [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean live commandcommand supports the following options:\n\n[Table - 4 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live command",
      "section_number": "12.35",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --data <string> | The command to send, 'str' representation of a 'dict' e.g. \"{ \\\"target\\\": \\\"BTCUSD\\\", \\\"$type\\\":\\\"MyCommand\\\" }\" |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live commandcommand and exit |"
  },
  {
    "id": "12.36",
    "title": "lean live deploy",
    "level": 2,
    "path": "API Reference > lean live deploy",
    "content": "### Introduction\n\nStart live trading a project locally using Docker.\n\n$ lean live deploy [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nStarts local live trading in a Docker container using thequantconnect/leanDocker image.\nThe logs of the algorithm are shown in real-time and the full results are stored in the<project> / live / <timestamp>directory.\nYou can use the--outputoption to change the output directory.\n\nThe given<project>argument must be either a project directory or a file containing the algorithm to backtest.\nIf it is a project directory, the CLI looks for amain.pyorMain.csfile, assuming the first file it finds to contain the algorithm to run.\n\nBy default, an interactive wizard is shown letting you configure the brokerage and data provider to use.\nWhen you provide--environmentor both--brokerageand--data-provider-live, the command runs in non-interactive mode and does not prompt for input.\n\nWhen the--environmentoption is given, the environment with the given name is used.\nThe given environment must be one of the live environments stored in yourLean configuration file.\nThis means the environment must have thelive-modeproperty set totrue.\n\nWhen--brokerageand--data-provider-liveis given, the live configuration is read from the command-line options.\nIn case a required option has not been provided, the command falls back to the property with the same name in your Lean configuration file.\nThe command aborts if this property also hasn't been set.\nThe required options depend on the selected brokerage or data provider.\n\nThe following options are required for each brokerage in non-interactive mode:\n\n[Table - 64 rows]\n\nThe--data-provider-liveoption is required.\nThe following table shows the available live data providers and their required options in non-interactive mode.\nTo select multiple data providers, seperate them with a comma.\nThe order you select them in defines the order of precedence.\n\n[Table - 40 rows]\n\nThe--data-provider-historicaloption specifies the source of historical data. The following table shows the available historical data providers and their required options in non-interactive mode. If the live data provider you set also provides historical data and you omit the--data-provider-historicaloption, it defaults to the same value as the--data-provider-liveoption. If the live data provider you set doesn't provide historical data and you omit the--data-provider-historicaloption, it defaults to theLocaldata provider.\n\n[Table - 31 rows]\n\nIf you omit some of the required brokerage or data provider options when running in non-interactive mode, the CLI uses the option values in yourLEAN configuration file.\n\nExample non-interactive usage:\n\n$ lean live deploy \"My Project\" \\\n--brokerage \"Paper Trading\" \\\n--data-provider-live \"Interactive Brokers\" \\\n--ib-user-name trader777 \\\n--ib-account DU1234567 \\\n--ib-password hunter2 \\\n--ib-enable-delayed-streaming-data yes\n\nThe Docker image that is used contains the same libraries as the onesavailable on QuantConnect.\nIf the selected project is a C# project, it is compiled before starting live trading.\n\nBy default, the official LEAN engine image is used.\nYou can override this using the--image <value>option.\nAlternatively, you can set the default engine image for all commands usinglean config set engine-image <value>.\nThe image is pulled before starting the local live trading if it doesn't exist locally yet or if you pass the--updateflag.\n\n### Arguments\n\nThelean live deploycommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live deploycommand supports the following options:\n\n[Table - 102 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live deploy",
      "section_number": "12.36",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| --brokerage | Required Options |\n| --- | --- |\n| \"Paper Trading\" | N/A |\n| Alpaca | --alpaca-environment |\n| --alpaca-api-key |  |\n| --alpaca-api-secret |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| --binance-use-testnet |  |\n| Bitfinex | --bitfinex-api-key |\n| --bitfinex-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| --bybit-vip-level |  |\n| --bybit-use-testnet |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| \"Interactive Brokers\" | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| Samco | --samco-client-id |\n| --samco-client-password |  |\n| --samco-year-of-birth |  |\n| --samco-product-type |  |\n| --samco-trading-segment |  |\n| TDAmeritrade | --tdameritrade-api-key |\n| --tdameritrade-access-token |  |\n| --tdameritrade-account-number |  |\n| \"Terminal Link\" | --terminal-link-connection-type |\n| --terminal-link-environment |  |\n| --terminal-link-server-host |  |\n| --terminal-link-server-port |  |\n| --terminal-link-emsx-account |  |\n| --terminal-link-emsx-broker |  |\n| --terminal-link-openfigi-api-key |  |\n| --terminal-link-server-auth-idif you use--terminal-link-connection-type SAPI |  |\n| TradeStation | --trade-station-environment |\n| --trade-station-account-type |  |\n| Tradier | --tradier-account-id |\n| --tradier-access-token |  |\n| --tradier-environment |  |\n| \"Trading Technologies\" | --tt-user-name |\n| --tt-session-password |  |\n| --tt-account-name |  |\n| --tt-rest-app-key |  |\n| --tt-rest-app-secret |  |\n| --tt-rest-environment |  |\n| --tt-market-data-sender-comp-id |  |\n| --tt-market-data-target-comp-id |  |\n| --tt-market-data-host |  |\n| --tt-market-data-port |  |\n| --tt-order-routing-sender-comp-id |  |\n| --tt-order-routing-target-comp-id |  |\n| --tt-order-routing-host |  |\n| --tt-order-routing-port |  |\n| Zerodha | --zerodha-api-key |\n| --zerodha-access-token |  |\n| --zerodha-product-type |  |\n| --zerodha-trading-segment |  |",
    "table_1": "| --data-provider-live | Required Options |\n| --- | --- |\n| Alpaca | All options required by--brokerage Alpaca. |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bitfinex | All options required by--brokerage Bitfinex. |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| --bybit-vip-level |  |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | All options required by--brokerage \"Coinbase Advanced Trade\". |\n| \"Custom data only\" | N/A |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | All options required by--brokerage \"Interactive Brokers\". |\n| --ib-enable-delayed-streaming-data |  |\n| IQFeed | --iqfeed-iqconnect |\n| --iqfeed-username |  |\n| --iqfeed-password |  |\n| --iqfeed-version |  |\n| --iqfeed-host |  |\n| Kraken | All options required by--brokerage Kraken. |\n| Oanda | All options required by--brokerage Oanda. |\n| Polygon | --polygon-api-key |\n| Samco | All options required by--brokerage Samco. |\n| TDAmeritrade | All options required by--brokerage TDAmeritrade. |\n| \"Terminal Link\" | All options required by--brokerage \"Terminal Link\". |\n| ThetaData | --thetadata-subscription-plan |\n| TradeStation | All options required by--brokerage TradeStation. |\n| Tradier | --tradier-account-id |\n| --tradier-access-token |  |\n| \"Trading Technologies\" | --tt-user-name |\n| --tt-session-password |  |\n| --tt-account-name |  |\n| --tt-rest-app-key |  |\n| --tt-rest-app-secret |  |\n| --tt-rest-environment |  |\n| --tt-order-routing-sender-comp-id |  |\n| Zerodha | All options required by--brokerage Zerodha. |\n| --zerodha-history-subscription |  |",
    "table_2": "| --data-provider-historical | Required Options |\n| --- | --- |\n| Alpaca | All options required by--brokerage Alpaca. |\n| AlphaVantage | --alpha-vantage-api-key |\n| --alpha-vantage-price-plan |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bitfinex | All options required by--brokerage Bitfinex. |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| --bybit-vip-level |  |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | All options required by--brokerage \"Coinbase Advanced Trade\". |\n| FactSet | --factset-auth-config-file |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | All options required by--brokerage \"Interactive Brokers\". |\n| IQFeed | --iqfeed-iqconnect |\n| --iqfeed-username |  |\n| --iqfeed-password |  |\n| --iqfeed-version |  |\n| --iqfeed-host |  |\n| Kraken | All options required by--brokerage Kraken. |\n| Local | N/A |\n| Oanda | All options required by--brokerage Oanda. |\n| Polygon | --polygon-api-key |\n| QuantConnect | N/A |\n| ThetaData | --thetadata-subscription-plan |\n| TradeStation | All options required by--brokerage TradeStation. |\n| Zerodha | All options required by--brokerage Zerodha. |\n| --zerodha-history-subscription |  |",
    "table_3": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to start local live trading. |",
    "table_4": "| Option | Description |\n| --- | --- |\n| --environment <string> | The environment to use |\n| --output <directory> | Directory to store results in (defaults to PROJECT/live/TIMESTAMP) |\n| -d, --detach | Run the live deployment in a detached Docker container and return immediately |\n| --brokerage <enum: Paper TradingInteractive BrokersTradierOandaBitfinexCoinbase Advanced TradeBinanceZerodhaSamcoTerminal LinkTrading TechnologiesKrakenCharlesSchwabBybitTradeStationAlpaca> | The brokerage to use |\n| --data-provider-live <enum: Interactive BrokersTradierOandaBitfinexCoinbase Advanced TradeBinanceZerodhaSamcoTerminal LinkTrading TechnologiesKrakenCharlesSchwabIQFeedPolygonCoinApiThetaDataCustom data onlyBybitTradeStationAlpaca> | The live data provider to use |\n| --data-provider-historical <enum: Interactive BrokersOandaBitfinexCoinbase Advanced TradeBinanceKrakenCharlesSchwabIQFeedPolygonFactSetAlphaVantageCoinApiThetaDataQuantConnectLocalBybitTradeStationAlpaca> | Update the Lean configuration file to retrieve data from the given historical provider |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --tradier-account-id <string> | Your Tradier account id |\n| --tradier-access-token <string> | Your Tradier access token |\n| --tradier-environment <enum: live|paper> | Whether the developer sandbox should be used |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --binance-use-testnet <enum: live|paper> | Whether the testnet should be used |\n| --zerodha-api-key <string> | Your Kite Connect API key |\n| --zerodha-access-token <string> | Your Kite Connect access token |\n| --zerodha-product-type <enum: mis|cnc|nrml> | MIS if you are targeting intraday products, CNC if you are targeting delivery products, NRML if you are targeting carry forward products |\n| --zerodha-trading-segment <enum: equity|commodity> | EQUITY if you are trading equities on NSE or BSE, COMMODITY if you are trading commodities on MCX |\n| --zerodha-history-subscription <enum: true|false> | Whether you have a history API subscription for Zerodha |\n| --samco-client-id <string> | Your Samco account Client ID |\n| --samco-client-password <string> | Your Samco account password |\n| --samco-year-of-birth <string> | Your year of birth (YYYY) registered with Samco |\n| --samco-product-type <enum: mis|cnc|nrml> | MIS if you are targeting intraday products, CNC if you are targeting delivery products, NRML if you are targeting carry forward products |\n| --samco-trading-segment <enum: equity|commodity> | EQUITY if you are trading equities on NSE or BSE, COMMODITY if you are trading commodities on MCX |\n| --terminal-link-connection-type <enum: DAPI|SAPI> | Terminal Link Connection Type [DAPI, SAPI] |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the TerminalLink server |\n| --terminal-link-server-port <integer> | The port of the TerminalLink server |\n| --terminal-link-emsx-broker <string> | The EMSX broker to use (Optional) |\n| --terminal-link-emsx-account <string> | The EMSX account to use (Optional) |\n| --terminal-link-emsx-team <string> | The EMSX team to receive order events from (Optional) |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --tt-user-name <string> | Your Trading Technologies username |\n| --tt-session-password <string> | Your Trading Technologies session password |\n| --tt-account-name <string> | Your Trading Technologies account name |\n| --tt-rest-app-key <string> | Your Trading Technologies REST app key |\n| --tt-rest-app-secret <string> | Your Trading Technologies REST app secret |\n| --tt-rest-environment <string> | The REST environment to run in |\n| --tt-order-routing-sender-comp-id <string> | The order routing sender comp id to use |\n| --tt-market-data-sender-comp-id <string> | The market data sender comp id to use |\n| --tt-market-data-target-comp-id <string> | The market data target comp id to use |\n| --tt-market-data-host <string> | The host of the market data server |\n| --tt-market-data-port <string> | The port of the market data server |\n| --tt-order-routing-target-comp-id <string> | The order routing target comp id to use |\n| --tt-order-routing-host <string> | The host of the order routing server |\n| --tt-order-routing-port <string> | The port of the order routing server |\n| --tt-log-fix-messages <boolean> | Whether FIX messages should be logged (Optional) |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --bybit-vip-level <enum: VIP0VIP1VIP2VIP3VIP4VIP5SupremeVIPPro1Pro2Pro3Pro4Pro5> | Your Bybit VIP Level |\n| --bybit-use-testnet <enum: live|paper> | Whether the testnet should be used |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --ib-enable-delayed-streaming-data <boolean> | Whether delayed data may be used when your algorithm subscribes to a security you don't have a market data subscription for (Optional) |\n| --charles-schwab-enable-delayed-streaming-data <boolean> | Whether delayed data may be used when your algorithm subscribes to a security you don't have a market data subscription for (Optional) |\n| --iqfeed-iqconnect <string> | The path to the IQConnect binary |\n| --iqfeed-username <string> | Your IQFeed username |\n| --iqfeed-password <string> | Your IQFeed password |\n| --iqfeed-version <string> | The product version of your IQFeed developer account |\n| --iqfeed-host <string> | The IQFeed host address (Optional) |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --thetadata-ws-url <string> | The ThetaData host address (Optional) |\n| --thetadata-rest-url <string> | The ThetaData host address (Optional) |\n| --thetadata-subscription-plan <enum: FreeValueStandardPro> | Your ThetaData subscription price plan |\n| --trade-station-enable-delayed-streaming-data <boolean> | Whether delayed data may be used when your algorithm subscribes to a security you don't have a market data subscription for (Optional) |\n| --alpaca-api-key <string> | Your Alpaca Api Key |\n| --alpaca-api-secret <string> | Your Alpaca Api Secret |\n| --factset-auth-config-file <file> | The path to the FactSet authentication configuration file |\n| --alpha-vantage-api-key <string> | Your Alpha Vantage Api Key |\n| --alpha-vantage-price-plan <enum: FreePlan30Plan75Plan150Plan300Plan600Plan1200> | Your Alpha Vantage Premium API Key plan |\n| --release | Compile C# projects in release configuration instead of debug |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --python-venv <string> | The path of the python virtual environment to be used |\n| --live-cash-balance <string> | A comma-separated list of currency:amount pairs of initial cash balance |\n| --live-holdings <string> | A comma-separated list of symbol:symbolId:quantity:averagePrice of initial portfolio holdings |\n| --update | Pull the LEAN engine image before starting live trading |\n| --show-secrets | Show secrets as they are input |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string. For more information https://docker- py.readthedocs.io/en/stable/containers.html |\n| --no-update | Use the local LEAN engine image instead of pulling the latest version |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live deploycommand and exit |"
  },
  {
    "id": "12.37",
    "title": "lean live liquidate",
    "level": 2,
    "path": "API Reference > lean live liquidate",
    "content": "### Introduction\n\nLiquidate the given symbol from the latest deployment of the given project.\n\n$ lean live liquidate [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live liquidatecommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live liquidatecommand supports the following options:\n\n[Table - 6 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live liquidate",
      "section_number": "12.37",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to liquidate. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --ticker <string> | The ticker of the symbol to liquidate |\n| --market <string> | The market of the symbol to liquidate |\n| --security-type <string> | The security type of the symbol to liquidate |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live liquidatecommand and exit |"
  },
  {
    "id": "12.38",
    "title": "lean live stop",
    "level": 2,
    "path": "API Reference > lean live stop",
    "content": "### Introduction\n\nStop an already running local live trading project.\n\n$ lean live stop [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live stopcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live stopcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live stop",
      "section_number": "12.38",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to stop live trading. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live stopcommand and exit |"
  },
  {
    "id": "12.39",
    "title": "lean live submit-order",
    "level": 2,
    "path": "API Reference > lean live submit-order",
    "content": "### Introduction\n\nRepresents a command to submit an order to the algorithm.\n\n$ lean live submit-order [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live submit-ordercommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live submit-ordercommand supports the following options:\n\n[Table - 11 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live submit-order",
      "section_number": "12.39",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file in which you want to submit the order. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --ticker <string> | [required] |\n| --market <string> | [required] |\n| --security-type <string> | [required] |\n| --order-type <string> | [required] |\n| --quantity <float> | [required] |\n| --limit-price <float> | The limit price of the order be submitted |\n| --stop-price <float> | The stop price of the order to be submitted |\n| --tag <string> | The tag to be attached to the order |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live submit-ordercommand and exit |"
  },
  {
    "id": "12.40",
    "title": "lean live update-order",
    "level": 2,
    "path": "API Reference > lean live update-order",
    "content": "### Introduction\n\nRepresents a command to update a specific order by id.\n\n$ lean live update-order [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\n### Arguments\n\nThelean live update-ordercommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean live update-ordercommand supports the following options:\n\n[Table - 8 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean live update-order",
      "section_number": "12.40",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file that contains the order you want to update. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| --order-id <integer> | [required] |\n| --quantity <float> | The number of units to be updated (directional) |\n| --limit-price <float> | The limit price of the order to be updated |\n| --stop-price <float> | The stop price of the order to be updated |\n| --tag <string> | The tag to be attached to the order |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean live update-ordercommand and exit |"
  },
  {
    "id": "12.41",
    "title": "lean login",
    "level": 2,
    "path": "API Reference > lean login",
    "content": "### Introduction\n\nLog in with a QuantConnect account.\n\n$ lean login [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nLets you log in with your QuantConnect API credentials and stores the given values in thecredentialsfile in yourglobal configurationdirectory.\n\nIf--user-idor--api-tokenis not provided, an interactive prompt is shown and the missing values are read from stdin.\n\nYou canrequest your user Id and API tokenon your Account page.\n\n### Options\n\nThelean logincommand supports the following options:\n\n[Table - 5 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean login",
      "section_number": "12.41",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| -u, --user-id <string> | QuantConnect user id |\n| -t, --api-token <string> | QuantConnect API token |\n| --show-secrets | Show secrets as they are input |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean logincommand and exit |"
  },
  {
    "id": "12.42",
    "title": "lean logout",
    "level": 2,
    "path": "API Reference > lean logout",
    "content": "### Introduction\n\nLog out and remove stored credentials.\n\n$ lean logout [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRemoves the credentials stored in thecredentialsfile in yourglobal configurationdirectory.\n\n### Options\n\nThelean logoutcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean logout",
      "section_number": "12.42",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean logoutcommand and exit |"
  },
  {
    "id": "12.43",
    "title": "lean logs",
    "level": 2,
    "path": "API Reference > lean logs",
    "content": "### Introduction\n\nDisplay the most recent backtest/live/optimization logs.\n\n$ lean logs [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nDisplays the most recent backtest/live/optimization logs.\nBy default, the most recent backtest logs are shown unless--liveor--optimizationis given.\nYou can pass in a project with--project <directory>to display the most recent logs from a specific project.\n\n### Options\n\nThelean logscommand supports the following options:\n\n[Table - 7 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean logs",
      "section_number": "12.43",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --backtest | Display the most recent backtest logs (default) |\n| --live | Display the most recent live logs |\n| --optimization | Display the most recent optimization logs |\n| --project <directory> | The project to get the most recent logs from |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean logscommand and exit |"
  },
  {
    "id": "12.44",
    "title": "lean object-store delete",
    "level": 2,
    "path": "API Reference > lean object-store delete",
    "content": "### Introduction\n\nOpens the local storage directory in the file explorer.\n\n$ lean object-store delete [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store deletecommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store delete",
      "section_number": "12.44",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store deletecommand and exit |"
  },
  {
    "id": "12.45",
    "title": "lean object-store get",
    "level": 2,
    "path": "API Reference > lean object-store get",
    "content": "### Introduction\n\nOpens the local storage directory in the file explorer.\n\n$ lean object-store get [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store getcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store get",
      "section_number": "12.45",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store getcommand and exit |"
  },
  {
    "id": "12.46",
    "title": "lean object-store list",
    "level": 2,
    "path": "API Reference > lean object-store list",
    "content": "### Introduction\n\nOpens the local storage directory in the file explorer.\n\n$ lean object-store list [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store listcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store list",
      "section_number": "12.46",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store listcommand and exit |"
  },
  {
    "id": "12.47",
    "title": "lean object-store ls",
    "level": 2,
    "path": "API Reference > lean object-store ls",
    "content": "### Introduction\n\nAlias for 'list'\n\n$ lean object-store ls [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store lscommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store ls",
      "section_number": "12.47",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store lscommand and exit |"
  },
  {
    "id": "12.48",
    "title": "lean object-store properties",
    "level": 2,
    "path": "API Reference > lean object-store properties",
    "content": "### Introduction\n\nOpens the local storage directory in the file explorer.\n\n$ lean object-store properties [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store propertiescommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store properties",
      "section_number": "12.48",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store propertiescommand and exit |"
  },
  {
    "id": "12.49",
    "title": "lean object-store set",
    "level": 2,
    "path": "API Reference > lean object-store set",
    "content": "### Introduction\n\nOpens the local storage directory in the file explorer.\n\n$ lean object-store set [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean object-store setcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean object-store set",
      "section_number": "12.49",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean object-store setcommand and exit |"
  },
  {
    "id": "12.50",
    "title": "lean optimize",
    "level": 2,
    "path": "API Reference > lean optimize",
    "content": "### Introduction\n\nOptimize a project's parameters locally using Docker.\n\n$ lean optimize [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns a local optimization in a Docker container using thequantconnect/leanDocker image.\nThe logs of the optimizer are shown in real-time and the full results of the optimizer and all executed backtests are stored in the<project> / optimizations / <timestamp>directory.\nYou can use the--outputoption to change the output directory.\n\nThe given<project>argument must be either a project directory or a file containing the algorithm to optimize.\nIf it is a project directory, the CLI looks for amain.pyorMain.csfile, assuming the first file it finds to contain the algorithm to optimize.\n\nBy default, an interactive wizard is shown letting you configure the optimizer.\nWhen--optimizer-configor--strategyis given, the command runs in non-interactive mode and doesn't prompt for input.\n\nWhen the--optimizer-config <config file>option is given, the specified config file is used.\nThis option must point to a file containing a full optimizer config (thealgorithm-type-name,algorithm-languageandalgorithm-locationproperties may be omitted).\nSee theOptimizer.Launcher / config.example.jsonfile in the LEAN repository for an example optimizer configuration file, which also contains documentation on all the required properties.\n\nWhen--strategyis given, the optimizer configuration is read from the command-line options.\nThis means the--strategy,--target,--target-direction, and--parameteroptions become required.\nAdditionally, you can also use--constraintto specify optimization constraints.\n\nIn non-interactive mode, the parameters can be configured using the--parameteroption.\nThis option takes the following values: the name of the parameter, its minimum value, its maximum value, and its step size.\nYou can provide this option multiple times to configure multiple parameters.\n\nIn non-interactive mode, the constraints can be configured using the--constraintoption.\nThis option takes a \"statistic operator value\" string as value, where the statistic must be a path to a property in a backtest's output file, like \"TotalPerformance.PortfolioStatistics.SharpeRatio\".\nThis statistic can also be shortened to \"SharpeRatio\" or \"Sharpe Ratio\", in which case the command automatically converts it to the longer version.\nThe value must be a number and the operator must be<,>,<=,>=,==, or==.\nYou can provide this option multiple times to configure multiple constraints.\n\nYou can use the--data-provider-historicaloption to change where the data is retrieved.\nThis option updates theLean configuration file, so you don't need to use this option multiple times for the same data provider if you are not switching between them.\nThe following table shows the available data providers and their required options in non-interactive mode:\n\n[Table - 41 rows]\n\nYou can use the--download-dataflag as an alias for--data-provider-historical QuantConnect. This data provider automatically downloads the required data files when your backtest requests them. After it downloads a data file, it stores it in your localdatadirectory so that in future runs, it won't have to download it again. If the file contain data for multiple days (for example, daily Equity price data files), theApiDataProviderre-downloads the file if your local version is at least 7 days old. To adjust this setting, update thedownloader-data-update-periodvalue in yourLean configurationfile.\n\nExample non-interactive usage:\n\n$ lean optimize \"My Project\" \\\n--strategy \"Grid Search\" \\\n--target \"Sharpe Ratio\" \\\n--target-direction \"max\" \\\n--parameter my-first-parameter 1 10 0.5 \\\n--parameter my-second-parameter 20 30 5 \\\n--constraint \"Drawdown < 0.5\" \\\n--constraint \"Sharpe Ratio >= 1\"\n\nTo estimate the cost of running an optimization job without actually running it, add the--estimateoption to the command. You need to backtest the project at least once in order to estimate the cost of optimizing it.\n\nTo set the maximum number of concurrent backtests to run, use the--max-concurrent-backtestsoption.\n\nThe Docker image that's used contains the same libraries as the onesavailable on QuantConnect.\nIf the selected project is a C# project, it is compiled before starting the optimization.\n\nBy default, the official LEAN engine image is used.\nYou can override this using the--image <value>option.\nAlternatively, you can set the default engine image for all commands usinglean config set engine-image <value>.\nThe image is pulled before running the optimizer if it doesn't exist locally yet or if you pass the--updateflag.\n\n### Arguments\n\nThelean optimizecommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean optimizecommand supports the following options:\n\n[Table - 66 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean optimize",
      "section_number": "12.50",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| --data-provider-historical | Required Options |\n| --- | --- |\n| Alpaca | --alpaca-environment |\n| AlphaVantage | --alpha-vantage-api-key |\n| --alpha-vantage-price-plan |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| FactSet | --factset-auth-config-file |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| IQFeed | --iqfeed-iqconnect |\n| --iqfeed-username |  |\n| --iqfeed-password |  |\n| --iqfeed-version |  |\n| --iqfeed-host |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Local | N/A |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| Polygon | --polygon-api-key |\n| QuantConnect | N/A |\n| \"Terminal Link\" | --terminal-link-connection-type |\n| --terminal-link-environment |  |\n| --terminal-link-server-host |  |\n| --terminal-link-server-port |  |\n| --terminal-link-emsx-broker |  |\n| --terminal-link-openfigi-api-key |  |\n| --terminal-link-server-auth-idif you use--terminal-link-connection-type SAPI |  |\n| ThetaData | --thetadata-subscription-plan |\n| TradeStation | N/A |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory or algorithm file to optimize. |",
    "table_2": "| Option | Description |\n| --- | --- |\n| --output <directory> | Directory to store results in (defaults to PROJECT/optimizations/TIMESTAMP) |\n| -d, --detach | Run the optimization in a detached Docker container and return immediately |\n| --optimizer-config <file> | The optimizer configuration file that should be used |\n| --strategy <enum: Grid Search|Euler Search> | The optimization strategy to use |\n| --target <string> | The target statistic of the optimization |\n| --target-direction <enum: min|max> | Whether the target must be minimized or maximized |\n| --parameter <<string> <float> <float> <float>>... | The 'parameter min max step' pairs configuring the parameters to optimize |\n| --constraint <string> | The 'statistic operator value' pairs configuring the constraints of the optimization |\n| --data-provider-historical <enum: Interactive BrokersOandaBitfinexCoinbase Advanced TradeBinanceKrakenCharlesSchwabIQFeedPolygonFactSetAlphaVantageCoinApiThetaDataQuantConnectLocalTerminal LinkBybitTradeStationAlpaca> | Update the Lean configuration file to retrieve data from the given historical provider |\n| --download-data | Update the Lean configuration file to download data from the QuantConnect API, alias for --data-provider-historical QuantConnect |\n| --data-purchase-limit <integer> | The maximum amount of QCC to spend on downloading data during the backtest when using QuantConnect as historical data provider |\n| --release | Compile C# projects in release configuration instead of debug |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --update | Pull the LEAN engine image before running the optimizer |\n| --estimate | Estimate optimization runtime without running it |\n| --max-concurrent-backtests <integer> <range> | [x>=1] |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string. For more information https://docker- py.readthedocs.io/en/stable/containers.html |\n| --no-update | Use the local LEAN engine image instead of pulling the latest version |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --iqfeed-iqconnect <string> | The path to the IQConnect binary |\n| --iqfeed-username <string> | Your IQFeed username |\n| --iqfeed-password <string> | Your IQFeed password |\n| --iqfeed-version <string> | The product version of your IQFeed developer account |\n| --iqfeed-host <string> | The IQFeed host address (Optional) |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --factset-auth-config-file <file> | The path to the FactSet authentication configuration file |\n| --alpha-vantage-api-key <string> | Your Alpha Vantage Api Key |\n| --alpha-vantage-price-plan <enum: FreePlan30Plan75Plan150Plan300Plan600Plan1200> | Your Alpha Vantage Premium API Key plan |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --thetadata-ws-url <string> | The ThetaData host address (Optional) |\n| --thetadata-rest-url <string> | The ThetaData host address (Optional) |\n| --thetadata-subscription-plan <enum: FreeValueStandardPro> | Your ThetaData subscription price plan |\n| --terminal-link-connection-type <enum: DAPI|SAPI> | Terminal Link Connection Type [DAPI, SAPI] |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the TerminalLink server |\n| --terminal-link-server-port <integer> | The port of the TerminalLink server |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean optimizecommand and exit |"
  },
  {
    "id": "12.51",
    "title": "lean private-cloud add-compute",
    "level": 2,
    "path": "API Reference > lean private-cloud add-compute",
    "content": "### Introduction\n\nAdd private cloud compute\n\n$ lean private-cloud add-compute [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean private-cloud add-computecommand supports the following options:\n\n[Table - 12 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean private-cloud add-compute",
      "section_number": "12.51",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --token <string> | The master server token |\n| --master-domain, --master-ip <string> | The master server domain |\n| --master-port <integer> | The master server port |\n| --slave-domain, --slave-ip <string> | The slave server domain |\n| --update | Pull the latest image before starting |\n| --no-update | Do not update to the latest version |\n| --compute <string> | Compute configuration to use |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string |\n| --stop | Stop any existing deployment |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean private-cloud add-computecommand and exit |"
  },
  {
    "id": "12.52",
    "title": "lean private-cloud start",
    "level": 2,
    "path": "API Reference > lean private-cloud start",
    "content": "### Introduction\n\nStart a new private cloud\n\n$ lean private-cloud start [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean private-cloud startcommand supports the following options:\n\n[Table - 14 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean private-cloud start",
      "section_number": "12.52",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --master | Run in master mode |\n| --slave | Run in slave mode |\n| --token <string> | The master server token |\n| --master-domain, --master-ip <string> | The master server domain |\n| --master-port <integer> | The master server port |\n| --slave-domain, --slave-ip <string> | The slave server domain |\n| --update | Pull the latest image before starting |\n| --no-update | Do not update to the latest version |\n| --compute <string> | Compute configuration to use |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string |\n| --stop | Stop any existing deployment |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean private-cloud startcommand and exit |"
  },
  {
    "id": "12.53",
    "title": "lean private-cloud stop",
    "level": 2,
    "path": "API Reference > lean private-cloud stop",
    "content": "### Introduction\n\nStops a running private cloud\n\n$ lean private-cloud stop [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Options\n\nThelean private-cloud stopcommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean private-cloud stop",
      "section_number": "12.53",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean private-cloud stopcommand and exit |"
  },
  {
    "id": "12.54",
    "title": "lean project-create",
    "level": 2,
    "path": "API Reference > lean project-create",
    "content": "### Introduction\n\nCreate a new project containing starter code.\n\n$ lean project-create [OPTIONS] NAME\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nCreates a new project with some basic starter code.\nIf the language is set topython, this generates amain.pyfile, a Python-based research notebook, aproject configurationfile, and editor configuration files for PyCharm and VS Code.\n\nIf the language is set tocsharpthis generates aMain.csfile, a C#-based research notebook, aproject configurationfile, and editor configuration files for Visual Studio, Rider, and VS Code.\n\nA full list of the created files can be found on theProjects > Structurepage.\n\nIf no--languageis given, the default language saved in theglobal configurationis used.\nYou can update the default language to Python by runninglean config set default-language pythonor to C# by runninglean config set default-language csharp.\n\nIf the given project name contains slashes, the name is parsed as a path and the project is created in a subdirectory.\nAny subdirectories that don't exist yet are created automatically.\n\n### Arguments\n\nThelean project-createcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean project-createcommand supports the following options:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean project-create",
      "section_number": "12.54",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Argument | Description |\n| --- | --- |\n| <name> | The name of the project to create. This name may contain slashes to create a project in a subdirectory.\n                The project name must only contain-,_, letters, numbers, and spaces. The project name can't start with a space or be any of the following reserved names: CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, or LPT9.\n                If the project is a Python library, the library name can only contain letters (a-z), numbers (0-9), and underscores (_). Python library names can't contain spaces or start with a number. |",
    "table_1": "| Option | Description |\n| --- | --- |\n| -l, --language <enum: python|csharp> | The language of the project to create |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean project-createcommand and exit |"
  },
  {
    "id": "12.55",
    "title": "lean project-delete",
    "level": 2,
    "path": "API Reference > lean project-delete",
    "content": "### Introduction\n\nDelete a project locally and in the cloud if it exists.\n\n$ lean project-delete [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nDeletes a project from your local machine and in the cloud. If you are a collaborator on the project, this command doesn't delete the project for the other collaborators, but it removes you as a collaborator.\n\n### Options\n\nThelean project-deletecommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean project-delete",
      "section_number": "12.55",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean project-deletecommand and exit |"
  },
  {
    "id": "12.56",
    "title": "lean report",
    "level": 2,
    "path": "API Reference > lean report",
    "content": "### Introduction\n\nGenerate a report of a backtest.\n\n$ lean report [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns the LEAN Report Creator in a Docker container using thequantconnect/leanDocker image.\nBy default, this command generates a report of the most recent backtest.\nThis behavior can be overridden by using--backtest-results <path>and providing the path to the backtest results JSON file.\nIf--live-results <path>is also given, the generated report will contain both the backtest and the live results.\n\nThe--strategy-name,--strategy-version, and--strategy-descriptionoptions can be used to set the name, version, and description that are shown in the report.\nThe name and version are shown in the top-right corner of each page, while the description is shown on the top of the first page.\nThese fields are blank by default.\n\nWhen the given backtest results are stored in a project directory or one of its subdirectories, the default name is the name of the project directory and the default description is the description in the project'sconfig.jsonfile.\n\nBy default, the official LEAN engine image is used.\nYou can override this using the--image <value>option.\nAlternatively, you can set the default engine image for all commands usinglean config set engine-image <value>.\nThe image is pulled before running the report creator if it doesn't exist locally yet or if you pass the--updateflag.\n\nTo view the content of the default reports, seeReports. To create custom reports, seeGenerate Reports.\n\n### Options\n\nThelean reportcommand supports the following options:\n\n[Table - 16 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean report",
      "section_number": "12.56",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --backtest-results <file> | Path to the JSON file containing the backtest results |\n| --live-results <file> | Path to the JSON file containing the live trading results |\n| --report-destination <file> | Path where the generated report is stored as HTML (defaults to ./report.html) |\n| --css <file> | Path where the CSS override file is stored |\n| --html <file> | Path where the custom HTML template file is stored |\n| -d, --detach | Run the report creator in a detached Docker container and return immediately |\n| --strategy-name <string> | Name of the strategy, will appear at the top-right corner of each page |\n| --strategy-version <string> | Version number of the strategy, will appear next to the project name |\n| --strategy-description <string> | Description of the strategy, will appear under the 'Strategy Description' section |\n| --overwrite | Overwrite --report-destination if it already contains a file |\n| --image <string> | The LEAN engine image to use (defaults to quantconnect/lean:latest) |\n| --update | Pull the LEAN engine image before running the report creator |\n| --pdf | Create a PDF version along with the HTML version of the report |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean reportcommand and exit |"
  },
  {
    "id": "12.57",
    "title": "lean research",
    "level": 2,
    "path": "API Reference > lean research",
    "content": "### Introduction\n\nRun a Jupyter Lab environment locally using Docker.\n\n$ lean research [OPTIONS] PROJECT\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nRuns a local Jupyter Lab environment in a Docker container using thequantconnect/researchDocker image.\nThe project directory is mounted in the Docker container and the Jupyter Lab instance is exposed on a local port.\nAfter the Jupyter Lab instance has started, the browser automatically opens.\n\nBy default, Jupyter Lab is exposed on port 8888.\nTo use a custom port, you can use the--portoption, which is required to run two Jupyter Lab instances side-by-side.\n\nYou can use the--data-provider-historicaloption to change where the data is retrieved.\nThis option updates theLean configuration file, so you don't need to use this option multiple times for the same data provider if you are not switching between them.\nThe following table shows the available data providers and their required options in non-interactive mode:\n\n[Table - 41 rows]\n\nYou can use the--download-dataflag as an alias for--data-provider-historical QuantConnectand the--data-purchase-limitoption to set the maximum amount ofQuantConnect Credit(QCC) to spend during the research session when using QuantConnect as data provider.\nThe--data-purchase-limitoption is not persistent.\n\nIf you have previously logged in usinglean login, the CLI automatically makes your credentials available in the Jupyter Lab instance.\nIf this happens, theapivariable is automatically assigned an instance ofApiin your research notebooks, which you can use to make authenticated requests to the QuantConnect API.\n\nThe default Research Environment configuration is the latest master branch of LEAN. If youset a different research image, the image you set is your current configuration. To start the Research Environment with a different configuration than your current configuration, use the--image <value>option. If the image doesn't exist on your local machine or you pass the--updateflag, the image is pulled before starting the Research Environment. To avoid updating the image, pass the--no-updateflag.\n\n### Arguments\n\nThelean researchcommand expects the following arguments:\n\n[Table - 1 rows]\n\n### Options\n\nThelean researchcommand supports the following options:\n\n[Table - 58 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean research",
      "section_number": "12.57",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| --data-provider-historical | Required Options |\n| --- | --- |\n| Alpaca | --alpaca-environment |\n| AlphaVantage | --alpha-vantage-api-key |\n| --alpha-vantage-price-plan |  |\n| Binance | --binance-exchange-name |\n| --binance-api-keyor--binanceus-api-key |  |\n| --binance-api-secretor--binanceus-api-secret |  |\n| Bybit | --bybit-api-key |\n| --bybit-api-secret |  |\n| CoinApi | --coinapi-api-key |\n| --coinapi-product |  |\n| \"Coinbase Advanced Trade\" | --coinbase-api-name |\n| --coinbase-api-private-key |  |\n| FactSet | --factset-auth-config-file |\n| IEX | --iex-cloud-api-key |\n| --iex-price-plan |  |\n| \"Interactive Brokers\" | --ib-user-name |\n| --ib-account |  |\n| --ib-password |  |\n| IQFeed | --iqfeed-iqconnect |\n| --iqfeed-username |  |\n| --iqfeed-password |  |\n| --iqfeed-version |  |\n| --iqfeed-host |  |\n| Kraken | --kraken-api-key |\n| --kraken-api-secret |  |\n| --kraken-verification-tier |  |\n| Local | N/A |\n| Oanda | --oanda-account-id |\n| --oanda-access-token |  |\n| --oanda-environment |  |\n| Polygon | --polygon-api-key |\n| QuantConnect | N/A |\n| \"Terminal Link\" | --terminal-link-connection-type |\n| --terminal-link-environment |  |\n| --terminal-link-server-host |  |\n| --terminal-link-server-port |  |\n| --terminal-link-emsx-broker |  |\n| --terminal-link-openfigi-api-key |  |\n| --terminal-link-server-auth-idif you use--terminal-link-connection-type SAPI |  |\n| ThetaData | --thetadata-subscription-plan |\n| TradeStation | N/A |",
    "table_1": "| Argument | Description |\n| --- | --- |\n| <project> | The path to the project directory for which to run a research environment. |",
    "table_2": "| Option | Description |\n| --- | --- |\n| --port <integer> | The port to run Jupyter Lab on (defaults to 8888) |\n| --data-provider-historical <enum: Interactive BrokersOandaBitfinexCoinbase Advanced TradeBinanceKrakenCharlesSchwabIQFeedPolygonFactSetAlphaVantageCoinApiThetaDataQuantConnectLocalTerminal LinkBybitTradeStationAlpaca> | Update the Lean configuration file to retrieve data from the given historical provider |\n| --ib-user-name <string> | Your Interactive Brokers username |\n| --ib-account <string> | Your Interactive Brokers account id |\n| --ib-password <string> | Your Interactive Brokers password |\n| --ib-weekly-restart-utc-time <string> | Weekly restart UTC time (hh:mm:ss). Each week on Sunday your algorithm is restarted at this time, and will require 2FA verification. This is required by Interactive Brokers. Use this option explicitly to override the default value. (Optional) |\n| --oanda-account-id <string> | Your OANDA account id |\n| --oanda-access-token <string> | Your OANDA API token |\n| --oanda-environment <enum: Practice|Trade> | The environment to run in, Practice for fxTrade Practice, Trade for fxTrade |\n| --bitfinex-api-key <string> | Your Bitfinex API key |\n| --bitfinex-api-secret <string> | Your Bitfinex API secret |\n| --coinbase-api-name <string> | Your Coinbase Advanced Trade API name from file |\n| --coinbase-api-private-key <string> | Your Coinbase Advanced Trade API private key from file |\n| --binance-exchange-name <enum: BinanceBinanceUSBinance-USDM-FuturesBinance-COIN-Futures> | Binance exchange name [Binance, BinanceUS, Binance-USDM-Futures, Binance-COIN-Futures] |\n| --binance-api-key <string> | Your Binance API key |\n| --binanceus-api-key <string> | Your Binance API key |\n| --binance-api-secret <string> | Your Binance API secret |\n| --binanceus-api-secret <string> | Your Binance API secret |\n| --kraken-api-key <string> | Your Kraken API key |\n| --kraken-api-secret <string> | Your Kraken API secret |\n| --kraken-verification-tier <enum: Starter|Intermediate|Pro> | Your Kraken Verification Tier |\n| --charles-schwab-account-number <string> | The CharlesSchwab account number |\n| --iqfeed-iqconnect <string> | The path to the IQConnect binary |\n| --iqfeed-username <string> | Your IQFeed username |\n| --iqfeed-password <string> | Your IQFeed password |\n| --iqfeed-version <string> | The product version of your IQFeed developer account |\n| --iqfeed-host <string> | The IQFeed host address (Optional) |\n| --polygon-api-key <string> | Your Polygon.io API Key |\n| --factset-auth-config-file <file> | The path to the FactSet authentication configuration file |\n| --alpha-vantage-api-key <string> | Your Alpha Vantage Api Key |\n| --alpha-vantage-price-plan <enum: FreePlan30Plan75Plan150Plan300Plan600Plan1200> | Your Alpha Vantage Premium API Key plan |\n| --coinapi-api-key <string> | Your coinapi.io Api Key |\n| --coinapi-product <enum: FreeStartupStreamerProfessionalEnterprise> | CoinApi pricing plan (https://www.coinapi.io/market-data-api/pricing) |\n| --thetadata-ws-url <string> | The ThetaData host address (Optional) |\n| --thetadata-rest-url <string> | The ThetaData host address (Optional) |\n| --thetadata-subscription-plan <enum: FreeValueStandardPro> | Your ThetaData subscription price plan |\n| --terminal-link-connection-type <enum: DAPI|SAPI> | Terminal Link Connection Type [DAPI, SAPI] |\n| --terminal-link-environment <enum: Production|Beta> | The environment to run in |\n| --terminal-link-server-host <string> | The host of the TerminalLink server |\n| --terminal-link-server-port <integer> | The port of the TerminalLink server |\n| --terminal-link-openfigi-api-key <string> | The Open FIGI API key to use for mapping options |\n| --terminal-link-server-auth-id <string> | The Auth ID of the TerminalLink server |\n| --bybit-api-key <string> | Your Bybit API key |\n| --bybit-api-secret <string> | Your Bybit API secret |\n| --trade-station-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --trade-station-account-id <string> | The TradeStation account Id |\n| --alpaca-environment <enum: live|paper> | Whether Live or Paper environment should be used |\n| --download-data | Update the Lean configuration file to download data from the QuantConnect API, alias for --data-provider-historical QuantConnect |\n| --data-purchase-limit <integer> | The maximum amount of QCC to spend on downloading data during the research session when using QuantConnect as historical data provider |\n| -d, --detach | Run Jupyter Lab in a detached Docker container and return immediately |\n| --no-open | Don't open the Jupyter Lab environment in the browser after starting it |\n| --image <string> | The LEAN research image to use (defaults to quantconnect/research:latest) |\n| --update | Pull the LEAN research image before starting the research environment |\n| --extra-docker-config <string> | Extra docker configuration as a JSON string. For more information https://docker- py.readthedocs.io/en/stable/containers.html |\n| --no-update | Use the local LEAN research image instead of pulling the latest version |\n| --lean-config <file> | The Lean configuration file that should be used (defaults to the nearest lean.json) |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean researchcommand and exit |"
  },
  {
    "id": "12.58",
    "title": "lean whoami",
    "level": 2,
    "path": "API Reference > lean whoami",
    "content": "### Introduction\n\nDisplay who is logged in.\n\n$ lean whoami [OPTIONS]\n\nTo use the CLI, you must be a member in an\n\non a paid tier.\n\n### Description\n\nDisplays the name and the email address of the user who is currently logged in or \"You are not logged in\" if no-one is logged in.\n\n### Options\n\nThelean whoamicommand supports the following options:\n\n[Table - 2 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "12",
      "breadcrumb": "API Reference > lean whoami",
      "section_number": "12.58",
      "source_file": "Quantconnect-Lean-Cli.html",
      "document_index": 1
    },
    "table_0": "| Option | Description |\n| --- | --- |\n| --verbose | Enable debug logging |\n| --help | Display the help text of thelean whoamicommand and exit |"
  }
]