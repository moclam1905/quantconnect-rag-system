[
  {
    "id": "1",
    "title": "Key Concepts",
    "level": 1,
    "path": "Key Concepts",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Key Concepts",
      "section_number": "1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "1.1",
    "title": "Getting Started",
    "level": 2,
    "path": "Key Concepts > Getting Started",
    "content": "### Introduction\n\nThe Research Environment is aJupyter notebook-based, interactive commandline environment where you can access our data through theQuantBookclass. The environment supports both Python and C#. If you use Python, you canimport code from the code files in your project into the Research Environmentto aid development.\n\nBefore you run backtests, we recommend testing your hypothesis in the Research Environment. It's easier to perform data analysis andproduce plots in the Research Environmentthan in a backtest.\n\nBefore backtesting or live trading with machine learning models, you may find it beneficial to train them in the Research Environment, save them in the Object Store, and then load them from the Object Store into the backtesting and live trading environment\n\nIn the Research Environment, you can also use the QuantConnect API toimport your backtest resultsfor further analysis.\n\n### Example\n\nThe following snippet demonstrates how to use the Research Environment to plot the price and Bollinger Bands of the S&P 500 index ETF, SPY:\n\nThe following snippet demonstrates how to use the Research Environment to print the price of the S&P 500 index ETF, SPY:\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"# Create a QuantBook\nqb = QuantBook()\n\n# Add an asset.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Request some historical data.\nhistory = qb.history(symbol, 360, Resolution.DAILY)\n\n# Calculate the Bollinger Bands.\nbbdf = qb.indicator(BollingerBands(30, 2), symbol, 360, Resolution.DAILY)\n\n# Plot the data\nbbdf[['price', 'lowerband', 'middleband', 'upperband']].plot();\n\n#load \"../QuantConnect.csx\"\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Create a QuantBook\nvar qb = new QuantBook();\n\n// Create a security subscription\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Request some historical data\nvar history = qb.History(symbol, 70, Resolution.Daily);\n\nforeach (var tradeBar in history)\n{\nConsole.WriteLine($\"{tradeBar.EndTime} :: {tradeBar.ToString()}\");\n}\n\n### Open Notebooks\n\nThe process to open notebooks depends on if you use theAlgorithm Lab,Local Platform, or theCLI.\n\n### Run Notebook Cells\n\nNotebooks are a collection of cells where you can write code snippets or MarkDown. To execute a cell, pressShift+Enter.\n\nThe following describes some helpful keyboard shortcuts to speed up your research:\n\n[Table - 6 rows]\n\n### Stop Nodes\n\nThe process to stop Research Environment nodes depends on if you use theAlgorithm Lab,Local Platform, or theCLI.\n\n### Add Notebooks\n\nThe process to add notebook files depends on if you use theAlgorithm Lab,Local Platform, or theCLI.\n\n### Rename Notebooks\n\nThe process to rename notebook files depends on if you use theAlgorithm Lab,Local Platform, or theCLI.\n\n### Delete Notebooks\n\nThe process to delete notebooks depends on if you use theAlgorithm Lab,Local Platform, or theCLI.\n\n### Learn Jupyter\n\nThe following table lists some helpful resources to learn Jupyter:\n\n[Table - 3 rows]",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "1",
      "breadcrumb": "Key Concepts > Getting Started",
      "section_number": "1.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Keyboard Shortcut | Description |\n| --- | --- |\n| Shift+Enter | Run the selected cell. |\n| a | Insert a cell above the selected cell. |\n| b | Insert a cell below the selected cell. |\n| x | Cut the selected cell. |\n| v | Paste the copied or cut cell. |\n| z | Undo cell actions. |",
    "table_1": "| Type | Name | Producer |\n| --- | --- | --- |\n| Text | Jupyter Tutorial | tutorialspoint |\n| Text | Jupyter Notebook Tutorial: The Definitive Guide | DataCamp |\n| Text | An Introduction to DataFrame | Microsoft Developer Blogs |"
  },
  {
    "id": "1.2",
    "title": "Research Engine",
    "level": 2,
    "path": "Key Concepts > Research Engine",
    "content": "### Introduction\n\nThe Research Environment is aJupyter notebook-based, interactive commandline environment where you can access our data through theQuantBookclass. The environment supports both Python and C#. If you use Python, you canimport code from the code files in your project into the Research Environmentto aid development.\n\nBefore you run backtests, we recommend testing your hypothesis in the Research Environment. It's easier to perform data analysis andproduce plots in the Research Environmentthan in a backtest.\n\nBefore backtesting or live trading with machine learning models, you may find it beneficial to train them in the Research Environment, save them in the Object Store, and then load them from the Object Store into the backtesting and live trading environment\n\nIn the Research Environment, you can also use the QuantConnect API toimport your backtest resultsfor further analysis.\n\n### Batch vs Stream Analysis\n\nThe backtesting environment is an event-based simulation of the market. Backtests aim to provide an accurate representation of whether a strategy would have performed well in the past, but they are generally slow and aren't the most efficient way to test the foundational ideas behind strategies. You should only use backtests to verify an idea after you have already tested it with statistical analysis.\n\nThe Research Environment lets you build a strategy by starting with a central hypothesis about the market. For example, you might hypothesize that an increase in sunshine hours will increase the production of oranges, which will lead to an increase in the supply of oranges and a decrease in the price of Orange Juice Futures. You can attempt to confirm this working hypothesis by analyzing weather data, production of oranges data, and the price of Orange Juice futures. If the hypothesis is confirmed with a degree of statistical significance, you can be confident in the hypothesis and translate it into an algorithm you can backtest.\n\n### Jupyter Notebooks\n\nJupyter notebooks support interactive data science and scientific computing across various programming languages. We carry on that philosophy by providing an environment for you to perform exploratory research and brainstorm new ideas for algorithms.  A Jupyter notebook installed in QuantConnect allows you to directly explore the massive amounts of data that is available in the Dataset Market and analyze it with python or C# commands. We call this exploratory notebook environment the Research Environment.\n\nOpen Notebooks\n\nTo open a notebook, open one of the.ipynbfiles in yourcloud projectsor seeRunning Local Research Environment.\n\nExecute Code\n\nThe notebook allows you to run code in a safe and disposable environment. It's composed of independent cells where you can write, edit, and execute code. The notebooks support Python, C#, and Markdown code.\n\nKeyboard Shortcuts\n\nThe following table describes some useful keyboard shortcuts:\n\n[Table - 6 rows]\n\nTerminate Research Sessions\n\nIf you use the Research Environment in QuantConnect Cloud, to terminate a research session, stop the research node in theResources panel. If you use the local Research Environment, seeManaging Kernels and Terminalsin the JupyterLab documentation.\n\n### Your Research and LEAN\n\nTo analyze data in a research notebook, create an instance of theQuantBookclass.QuantBookis a wrapper onQCAlgorithm, which meansQuantBookallows you to access all the methods available toQCAlgorithmand some additional methods. The following table describes the helper methods of theQuantBookclass that aren't available in theQCAlgorithmclass:\n\n[Table - 4 rows]\n\nQuantBook gives you access to the vast amounts of data in the Dataset Market. Similar to backtesting, you can access that data using history calls. You can also create indicators, consolidate data, and access charting features. However, keep in mind that event-driven features available in backtesting, like universe selection and OnData events, are not available in research. After you analyze a dataset in the Research Environment, you can easily transfer the logic to the backtesting environment. For example, consider the following code in the Research Environment:\n\n// Initialize QuantBook\nvar qb = new QuantBook();\n\n// Subscribe to SPY data with QuantBook\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Make history call with QuantBook\nvar history = qb.History(symbol, TimeSpan.FromDays(10), Resolution.Daily);# Initialize QuantBook\nqb = QuantBook()\n\n# Subscribe to SPY data with QuantBook\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Make history call with QuantBook\nhistory = qb.history(symbol, timedelta(days=10), Resolution.DAILY)\n\nTo use the preceding code in a backtest, replaceQuantBook()new QuantBook()withselfthis.\n\npublic override void Initialize()\n{\n// Set qb to instance of QCAlgorithm\nvar qb = this;\n\n// Subscribe to SPY data with QCAlgorithm\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Make history call with QCAlgorithm\nvar history = qb.History(symbol, TimeSpan.FromDays(10), Resolution.Daily);\n}def initialize(self) -> None:\n\n# Set qb to instance of QCAlgorithm\nqb = self\n\n# Subscribe to SPY data with QCAlgorithm\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Make history call with QCAlgorithm\nhistory = qb.history(symbol, timedelta(days=10), Resolution.DAILY)\n\n### Import Project Code\n\nTo import code from your code files to your Research Environment session, use Python.\n\nOne of the drawbacks of using the Research Environment you may encounter is the need to rewrite code you've already written in a file in the backtesting environment. Instead of rewriting the code, you can import the methods from the backtesting environment into the Research Environment to reduce development time. For example, say you have the followinghelpers.pyfile in your project:\n\ndef add(a, b):\nreturn a+b\n\nTo import the preceding method into your research notebook, use theimportstatement.\n\nfrom helpers import Add\n\n# reuse method from helpers.py\nAdd(3, 4)\n\nIf you adjust the file that you import, restart the Research Environment session to import the latest version of the file. To restart the Research Environment,stop the research nodeand thenopen the notebookagain.\n\n### Import C# Libraries\n\nThis session is reserved for C# notebooks.\n\nFollow these steps to import the libraries that you need:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Load the necessary assembly files.#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n#r \"../Deedle.dll\"Import theQuantConnect,Plotly.NET,Accord, andDeedlepackages.using QuantConnect;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\nusing Accord.Math;\nusing Accord.Statistics;\n\nusing Deedle;\n\nIf you don't load the assemblies, the following error message is displayed:The type or namespace name '_____' could not be found (are you missing a using directive or an assembly reference?)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "1",
      "breadcrumb": "Key Concepts > Research Engine",
      "section_number": "1.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Shortcut | Description |\n| --- | --- |\n| Shift+Enter | Run the selected cell |\n| a | Insert a cell above the selected cell |\n| b | Insert a cell below the selected cell |\n| x | Cut the selected cell |\n| v | Paste the copied or cut cell |\n| z | Undo cell actions |",
    "table_1": "| Method | Description |\n| --- | --- |\n| UniverseHistory | Get historical data for a universe. |\n| FutureHistory | Get the expiration, open interest, and price data of the contracts in a Futures chain. |\n| OptionHistory | Get the strike, expiration, open interest, option right, and price data of the contracts in an Options chain. |\n| Indicator | Get the values of an indicator for an asset over time. |"
  },
  {
    "id": "2",
    "title": "Initialization",
    "level": 1,
    "path": "Initialization",
    "content": "### Introduction\n\nBefore you request and manipulate historical data in the Research Environment, you should set the notebook dates, add data subscriptions, and set the time zone.\n\n### Set Dates\n\nThe start date of yourQuantBookdetermines the latest date of data you get fromhistory requests. By default, the start date is the current day. To change the start date, call theSetStartDateset_start_datemethod.\n\nqb.set_start_date(2022, 1, 1);qb.set_start_date(2022, 1, 1)\n\nThe end date of yourQuantBookshould be greater than the end date. By default, the start date is the current day. To change the end date, call theSetEndDateset_end_datemethod.\n\nqb.set_end_date(2022, 8, 15);qb.set_end_date(2022, 8, 15)\n\n### Add Data\n\nYou can subscribe to asset, fundamental, alternative, and custom data. TheDataset Marketprovides 400TB of data that you can easily import into your notebooks.\n\nAsset Data\n\nTo subscribe to asset data, call one of the asset subscription methods likeAddEquityadd_equityorAddForexadd_forex. Each asset class has its own method to create subscriptions. For more information about how to create subscriptions for each asset class, see theCreate Subscriptionssection of an asset class in theDatasetschapter.\n\nqb.AddEquity(\"AAPL\"); // Add Apple 1 minute bars (minute by default)\nqb.AddForex(\"EURUSD\", Resolution.Second); // Add EURUSD 1 second barsqb.add_equity(\"SPY\")  # Add Apple 1 minute bars (minute by default)\nqb.add_forex(\"EURUSD\", Resolution.SECOND) # Add EURUSD 1 second bars\n\nAlternative Data\n\nTo add alternative datasets to your notebooks, call theAddDataadd_datamethod.  For a full example, seeAlternative Data.\n\nCustom Data\n\nTo add custom data to your notebooks, call theAddDataadd_datamethod. For more information about custom data, seeCustom Data.\n\nLimitations\n\nThere is no official limit to how much data you can add to your notebooks, but there are practical resource limitations. Each security subscription requires about 5MB of RAM, so larger machines let you request more data. For more information about our cloud nodes, seeResearch Nodes.\n\n### Set Time Zone\n\nThe notebook time zone determines which time zone theDateTimedatetimeobjects are in when you make ahistory requestbased on a defined period of time.When your history request returns aDataFrame, the timestamps in theDataFrameare based on thedata time zone.When your history request returns aTradeBars,QuoteBars,Ticks, orSliceobject, theTimetimeproperties of these objects are based on the notebook time zone, but theEndTimeend_timeproperties of the individualTradeBar,QuoteBar, andTickobjects are based on the data time zone.\n\nThe default time zone is Eastern Time (ET), which is UTC-4 in summer and UTC-5 in winter. To set a different time zone, call theSetTimeZoneset_time_zonemethod. This method accepts either a string following theIANA Time Zone databaseconvention or aNodaTime.DateTimeZone object. If you pass a string, the method converts it to aNodaTime.DateTimeZoneobject. TheTimeZonesclass provides the following helper attributes to createNodaTime.DateTimeZoneobjects:\n\nqb.SetTimeZone(\"Europe/London\");\nqb.SetTimeZone(NodaTime.DateTimeZone.Utc);\nqb.SetTimeZone(TimeZones.Chicago);qb.set_time_zone(\"Europe/London\")\nqb.set_time_zone(TimeZones.CHICAGO)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Initialization",
      "section_number": "2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3",
    "title": "Datasets",
    "level": 1,
    "path": "Datasets",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Datasets",
      "section_number": "3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.1",
    "title": "Key Concepts",
    "level": 2,
    "path": "Datasets > Key Concepts",
    "content": "### Introduction\n\nYou can access most of the data from the Dataset Market in the Research Environment. The data includes Equity, Crypto, Forex, and derivative data going back as far as 1998. Similar to backtesting, to access the data, create a security subscription and then make a history request.\n\n### Key History Concepts\n\nThe historical data API has many different options to give you the greatest flexibility in how to apply it to your algorithm.\n\nTime Period Options\n\nYou can request historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. If you request data in a defined period of time, theDateTimedatetimeobjects you provide are based in thenotebook time zone.\n\nReturn Formats\n\nEach asset class supports slightly different data formats. When you make a history request, consider what data returns. Depending on how you request the data, history requests return a specific data type. For example, if you don't provideSymbolobjects, you getSliceobjects that contain all of the assets you created subscriptions for in the notebook.\n\nThe most popular return type is aDataFrame. If you request aDataFrame, LEAN unpacks the data fromSliceobjects to populate theDataFrame. If you intend to use the data in theDataFrameto createTradeBarorQuoteBarobjects, request that the history request returns the data type you need. Otherwise, LEAN will waste computational resources populating theDataFrame.\n\nTime Index\n\nWhen your history request returns aDataFrame, the timestamps in theDataFrameare based on thedata time zone.When your history request returns aTradeBars,QuoteBars,Ticks, orSliceobject, theTimetimeproperties of these objects are based on the notebook time zone, but theEndTimeend_timeproperties of the individualTradeBar,QuoteBar, andTickobjects are based on thedata time zonedata time zone. TheEndTimeend_timeis the end of the sampling period and when the data is actually available. For daily US Equity data, this results in data points appearing on Saturday and skipping Monday.\n\n### Request Data\n\nThe simplest form of history request is for a known set ofSymbolobjects.\nHistory requests return slightly different data depending on the overload you call. The data that returns is in ascending order from oldest to newest.\n\nSingle Symbol History Requests\n\nTo request history for a single asset, pass the assetSymbolto theHistoryhistorymethod. The return type of the method call depends on the history request[Type]<Type>. The following table describes the return type of each request[Type]<Type>:\n\n[Table - 5 rows]\n\nEach row of the DataFrame represents the prices at a point in time. Each column of the DataFrame is a property of that price data (for example, open, high, low, and close (OHLC)). If you request a DataFrame object and passTradeBaras the first argument, the DataFrame that returns only contains the OHLC and volume columns. If you request a DataFrame object and passQuoteBaras the first argument, the DataFrame that returns contains the OHLC of the bid and ask and it contains OHLC columns, which are the respective means of the bid and ask OHLC values. If you request a DataFrame and don't passTradeBarorQuoteBaras the first arugment, the DataFrame that returns contains columns for all of the data that's available for the given resolution.\n\n# EXAMPLE 1: Requesting By Bar Count: 5 bars at the security resolution:vix_symbol = qb.add_data(CBOE, \"VIX\", Resolution.DAILY).symbol\ncboe_data = qb.history[CBOE](vix_symbol, 5)\n\nbtc_symbol = qb.add_crypto(\"BTCUSD\", Resolution.MINUTE).symbol\ntrade_bars = qb.history[TradeBar](btc_symbol, 5)\nquote_bars = qb.history[QuoteBar](btc_symbol, 5)\ntrade_bars_df = qb.history(TradeBar, btc_symbol, 5)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, 5)\ndf = qb.history(btc_symbol, 5)   # Includes trade and quote data// EXAMPLE 1: Requesting By Bar Count: 5 bars at the security resolution:var vixSymbol = qb.AddData<CBOE>(\"VIX\", Resolution.Daily).Symbol;\nvar cboeData = qb.History<CBOE>(vixSymbol, 5);\n\nvar btcSymbol = qb.AddCrypto(\"BTCUSD\", Resolution.Minute).Symbol;\nvar tradeBars = qb.History<TradeBar>(btcSymbol, 5);\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, 5);\nvar tradeBars2 = qb.History(btcSymbol, 5);# EXAMPLE 2: Requesting By Bar Count: 5 bars with a specific resolution:trade_bars = qb.history[TradeBar](btc_symbol, 5, Resolution.DAILY)\nquote_bars = qb.history[QuoteBar](btc_symbol, 5, Resolution.MINUTE)\ntrade_bars_df = qb.history(TradeBar, btc_symbol, 5, Resolution.MINUTE)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, 5, Resolution.MINUTE)\ndf = qb.history(btc_symbol, 5, Resolution.MINUTE)  # Includes trade and quote data// EXAMPLE 2: Requesting By Bar Count: 5 bars with a specific resolution:var tradeBars = qb.History<TradeBar>(btcSymbol, 5, Resolution.Daily);\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, 5, Resolution.Minute);\nvar tradeBars2 = qb.History(btcSymbol, 5, Resolution.Minute);# EXAMPLE 3: Requesting By a Trailing Period: 3 days of data at the security resolution:eth_symbol = qb.add_crypto('ETHUSD', Resolution.TICK).symbol\nticks = qb.history[Tick](eth_symbol, timedelta(days=3))\nticks_df = qb.history(eth_symbol, timedelta(days=3))\n\nvix_data = qb.history[CBOE](vix_symbol, timedelta(days=3))\ntrade_bars = qb.history[TradeBar](btc_symbol, timedelta(days=3))\nquote_bars = qb.history[QuoteBar](btc_symbol, timedelta(days=3))\ntrade_bars_df = qb.history(TradeBar, btc_symbol, timedelta(days=3))\nquote_bars_df = qb.history(QuoteBar, btc_symbol, timedelta(days=3))\ndf = qb.history(btc_symbol, timedelta(days=3))  # Includes trade and quote data// EXAMPLE 3: Requesting By a Trailing Period: 3 days of data at the security resolution:var ethSymbol = qb.AddCrypto(\"ETHUSD\", Resolution.Tick).Symbol;\nvar ticks = qb.History<Tick>(ethSymbol, TimeSpan.FromDays(3));\n\nvar cboeData = qb.History<CBOE>(vixSymbol, TimeSpan.FromDays(3));\nvar tradeBars = qb.History<TradeBar>(btcSymbol, TimeSpan.FromDays(3));\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, TimeSpan.FromDays(3));\nvar tradeBars2 = qb.History(btcSymbol, TimeSpan.FromDays(3));# EXAMPLE 4: Requesting By a Trailing Period: 3 days of data with a specific resolution:trade_bars = qb.history[TradeBar](btc_symbol, timedelta(days=3), Resolution.DAILY)\nquote_bars = qb.history[QuoteBar](btc_symbol, timedelta(days=3), Resolution.MINUTE)\nticks = qb.history[Tick](eth_symbol, timedelta(days=3), Resolution.TICK)\n\ntrade_bars_df = qb.history(TradeBar, btc_symbol, timedelta(days=3), Resolution.DAILY)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, timedelta(days=3), Resolution.MINUTE)\nticks_df = qb.history(eth_symbol, timedelta(days=3), Resolution.TICK)\ndf = qb.history(btc_symbol, timedelta(days=3), Resolution.HOUR)  # Includes trade and quote data# Important Note: Period history requests are relative to \"now\" notebook time.// EXAMPLE 4: Requesting By a Trailing Period: 3 days of data with a specific resolution:var tradeBars = qb.History<TradeBar>(btcSymbol, TimeSpan.FromDays(3), Resolution.Daily);\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, TimeSpan.FromDays(3), Resolution.Minute);\nvar ticks = qb.History<Tick>(ethSymbol, TimeSpan.FromDays(3), Resolution.Tick);\nvar tradeBars2 = qb.History(btcSymbol, TimeSpan.FromDays(3), Resolution.Minute);# EXAMPLE 5: Requesting By a Defined Period: 3 days of data at the security resolution:start_time = datetime(2022, 1, 1)\nend_time = datetime(2022, 1, 4)\n\nvix_data = qb.history[CBOE](vix_symbol, start_time, end_time)\ntrade_bars = qb.history[TradeBar](btc_symbol, start_time, end_time)\nquote_bars = qb.history[QuoteBar](btc_symbol, start_time, end_time)\nticks = qb.history[Tick](eth_symbol, start_time, end_time)\n\ntrade_bars_df = qb.history(TradeBar, btc_symbol, start_time, end_time)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, start_time, end_time)\nticks_df = qb.history(Tick, eth_symbol, start_time, end_time)\ndf = qb.history(btc_symbol, start_time, end_time)  # Includes trade and quote data// EXAMPLE 5: Requesting By a Defined Period: 3 specific days of data at the security resolution:var startTime = new DateTime(2022, 1, 1);\nvar endTime = new DateTime(2022, 1, 4);\n\nvar cboeData = qb.History<CBOE>(vixSymbol, startTime, endTime);\nvar tradeBars = qb.History<TradeBar>(btcSymbol, startTime, endTime);\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, startTime, endTime);\nvar ticks = qb.History<Tick>(ethSymbol, startTime, endTime);\nvar tradeBars2 = qb.History(btcSymbol, startTime, endTime);# EXAMPLE 6: Requesting By a Defined Period: 3 days of data with a specific resolution:trade_bars = qb.history[TradeBar](btc_symbol, start_time, end_time, Resolution.DAILY)\nquote_bars = qb.history[QuoteBar](btc_symbol, start_time, end_time, Resolution.MINUTE)\nticks = qb.history[Tick](eth_symbol, start_time, end_time, Resolution.TICK)\n\ntrade_bars_df = qb.history(TradeBar, btc_symbol, start_time, end_time, Resolution.DAILY)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, start_time, end_time, Resolution.MINUTE)\nticks_df = qb.history(eth_symbol, start_time, end_time, Resolution.TICK)\ndf = qb.history(btc_symbol, start_time, end_time, Resolution.HOUR)  # Includes trade and quote data// EXAMPLE 6: Requesting By a Defined Period: 3 days of data with a specific resolution:var tradeBars = qb.History<TradeBar>(btcSymbol, startTime, endTime, Resolution.Daily);\nvar quoteBars = qb.History<QuoteBar>(btcSymbol, startTime, endTime, Resolution.Minute);\nvar ticks = qb.History<Tick>(ethSymbol, startTime, endTime, Resolution.Tick);\nvar tradeBars2 = qb.History(btcSymbol, startTime, endTime, Resolution.Minute);\n\nMultiple Symbol History Requests\n\nTo request history for multiple symbols at a time, pass an array ofSymbolobjects to the same API methods shown in the preceding section. The return type of the method call depends on the history request[Type]<Type>. The following table describes the return type of each request[Type]<Type>:\n\n[Table - 5 rows]\n\nTheSlicereturn type provides a container that supports all data types. For example, a history request for ForexQuoteBarsand EquityTradeBarshas the Forex data underslices.QuoteBarsand the Equity data underslices.Bars.\n\n# EXAMPLE 7: Requesting By Bar Count for Multiple Symbols: 2 bars at the security resolution:vix = qb.add_data[CBOE](\"VIX\", Resolution.DAILY).symbol\nv3m = qb.add_data[CBOE](\"VIX3M\", Resolution.DAILY).symbol\ncboe_data = qb.history[CBOE]([vix, v3m], 2)\n\nibm = qb.add_equity(\"IBM\", Resolution.MINUTE).symbol\naapl = qb.add_equity(\"AAPL\", Resolution.MINUTE).symbol\ntrade_bars_list = qb.history[TradeBar]([ibm, aapl], 2)\nquote_bars_list = qb.history[QuoteBar]([ibm, aapl], 2)\n\ntrade_bars_df = qb.history(TradeBar, [ibm, aapl], 2)\nquote_bars_df = qb.history(QuoteBar, [ibm, aapl], 2)\ndf = qb.history([ibm, aapl], 2)  # Includes trade and quote data// EXAMPLE 7: Requesting By Bar Count for Multiple Symbols: 2 bars at the security resolution:var vixSymbol = qb.AddData<CBOE>(\"VIX\", Resolution.Daily).Symbol;\nvar v3mSymbol = qb.AddData<CBOE>(\"VIX3m\", Resolution.Daily).Symbol;\nvar cboeData = qb.History<CBOE>(new[] { vix, v3m }, 2);\n\nvar ibm = qb.AddEquity(\"IBM\", Resolution.Minute).Symbol;\nvar aapl = qb.AddEquity(\"AAPL\", Resolution.Minute).Symbol;\nvar tradeBarsList = qb.History<TradeBar>(new[] { ibm, aapl }, 2);\nvar quoteBarsList = qb.History<QuoteBar>(new[] { ibm, aapl }, 2);# EXAMPLE 8: Requesting By Bar Count for Multiple Symbols: 5 bars with a specific resolution:trade_bars_list = qb.history[TradeBar]([ibm, aapl], 5, Resolution.DAILY)\nquote_bars_list = qb.history[QuoteBar]([ibm, aapl], 5, Resolution.MINUTE)\n\ntrade_bars_df = qb.history(TradeBar, [ibm, aapl], 5, Resolution.DAILY)\nquote_bars_df = qb.history(QuoteBar, [ibm, aapl], 5, Resolution.MINUTE)\ndf = qb.history([ibm, aapl], 5, Resolution.DAILY)  # Includes trade data only. No quote for daily equity data// EXAMPLE 8: Requesting By Bar Count for Multiple Symbols: 5 bars with a specific resolution:var tradeBarsList = qb.History<TradeBar>(new[] { ibm, aapl }, 5, Resolution.Minute);\nvar quoteBarsList = qb.History<QuoteBar>(new[] { ibm, aapl }, 5, Resolution.Minute);# EXAMPLE 9: Requesting By Trailing Period: 3 days of data at the security resolution:ticks = qb.history[Tick]([eth_symbol], timedelta(days=3))\n\ntrade_bars = qb.history[TradeBar]([btc_symbol], timedelta(days=3))\nquote_bars = qb.history[QuoteBar]([btc_symbol], timedelta(days=3))\ntrade_bars_df = qb.history(TradeBar, [btc_symbol], timedelta(days=3))\nquote_bars_df = qb.history(QuoteBar, [btc_symbol], timedelta(days=3))\ndf = qb.history([btc_symbol], timedelta(days=3))  # Includes trade and quote data// EXAMPLE 9: Requesting By Trailing Period: 3 days of data at the security resolution:var ticks = qb.History<Tick>(new[] {ethSymbol}, TimeSpan.FromDays(3));\n\nvar tradeBars = qb.History<TradeBar>(new[] {btcSymbol}, TimeSpan.FromDays(3));\nvar quoteBars = qb.History<QuoteBar>(new[] {btcSymbol}, TimeSpan.FromDays(3));\nvar tradeBars2 = qb.History(new[] {btcSymbol}, TimeSpan.FromDays(3));# EXAMPLE 10: Requesting By Defined Period: 3 days of data at the security resolution:trade_bars = qb.history[TradeBar]([btc_symbol], start_time, end_time)\nquote_bars = qb.history[QuoteBar]([btc_symbol], start_time, end_time)\nticks = qb.history[Tick]([eth_symbol], start_time, end_time)\ntrade_bars_df = qb.history(TradeBar, btc_symbol, start_time, end_time)\nquote_bars_df = qb.history(QuoteBar, btc_symbol, start_time, end_time)\nticks_df = qb.history(Tick, eth_symbol, start_time, end_time)\ndf = qb.history([btc_symbol], start_time, end_time)  # Includes trade and quote data// EXAMPLE 10: Requesting By Defined Period: 3 days of data at the security resolution:var tradeBars = qb.History<TradeBar>(new[] {btcSymbol}, startTime, endTime);\nvar quoteBars = qb.History<QuoteBar>(new[] {btcSymbol}, startTime, endTime);\nvar ticks = qb.History<Tick>(new[] {ethSymbol}, startTime, endTime);\nvar tradeBars2 = qb.History(new[] {btcSymbol}, startTime, endTime);\n\nIf you request data for multiple securities and you use theTickTICKrequest type, eachTicksobject in the list of results only contains the last tick of each security for that particulartimeslice.\n\nAll Symbol History Requests\n\nYou can request history for all the securities you have created subscriptions for in your notebook session.  The parameters are very similar to other history method calls, but the return type is an array ofSliceobjects. TheSliceobject holds all of the results in a sorted enumerable collection that you can iterate over with a loop.\n\n# EXAMPLE 11: Requesting 5 bars for all securities at their respective resolution:# Create subscriptions\nqb.add_equity(\"IBM\", Resolution.DAILY)\nqb.add_equity(\"AAPL\", Resolution.DAILY)\n\n# Request history data and enumerate results\nslices = qb.history(5)\nfor s in slices:\nprint(str(s.time) + \" AAPL:\" + str(s.bars[\"AAPL\"].close) + \" IBM:\" + str(s.bars[\"IBM\"].close))// EXAMPLE 11: Requesting 5 bars for all securities at their respective resolution:// Set up the universe\nqb.AddEquity(\"IBM\", Resolution.Daily);\nqb.AddEquity(\"AAPL\", Resolution.Daily);\n\n// Request history data and enumerate results:\nvar slices = qb.History(5);\nforeach (var s in slices) {\nvar aaplClose = s.Bars[\"AAPL\"].Close;\nvar ibmClose = s.Bars[\"IBM\"].Close;\nConsole.WriteLine($\"{s.Time} AAPL: {aaplClose} IBM: {ibmClose}\");\n}\n\n# EXAMPLE 12: Requesting 5 minutes for all securities:slices = qb.history(timedelta(minutes=5), Resolution.MINUTE)\nfor s in slices:\nprint(str(s.time) + \" AAPL:\" + str(s.bars[\"AAPL\"].close) + \" IBM:\" + str(s.bars[\"IBM\"].close))# timedelta history requests are relative to \"now\" in notebook Time. If you request this data at 16:05, it returns an empty array because the market is closed.// EXAMPLE 12: Requesting 24 hours of hourly data for all securities:var slices = qb.History(TimeSpan.FromHours(24), Resolution.Hour);\nforeach (var s in slices) {\nvar aaplClose = s.Bars[\"AAPL\"].Close;\nvar ibmClose = s.Bars[\"IBM\"].Close;\nConsole.WriteLine($\"{s.Time} AAPL: {aaplClose} IBM: {ibmClose}\");\n}// TimeSpan history requests are relative to \"now\" in notebook Time.\n\nAssumed Default Values\n\nThe following table describes the assumptions of the History API:\n\n[Table - 2 rows]\n\nAdditional Options\n\nTheHistoryhistorymethod accepts the following additional arguments:\n\n[Table - 5 rows]\n\nfuture = qb.add_future(Futures.Currencies.BTC)\nhistory = qb.history(\ntickers=[future.symbol],\nstart=qb.time - timedelta(days=15),\nend=qb.time,\nresolution=Resolution.MINUTE,\nfill_forward=False,\nextended_market_hours=False,\ndataMappingMode=DataMappingMode.OPEN_INTEREST,\ndataNormalizationMode=DataNormalizationMode.RAW,\ncontractDepthOffset=0)var future = qb.AddFuture(Futures.Currencies.BTC);\nvar history = qb.History(\nsymbols: new[] {future.Symbol},\nstart: qb.Time - TimeSpan.FromDays(15),\nend: qb.Time,\nresolution: Resolution.Minute,\nfillForward: false,\nextendedMarketHours: false,\ndataMappingMode: DataMappingMode.OpenInterest,\ndataNormalizationMode: DataNormalizationMode.Raw,\ncontractDepthOffset: 0);\n\n### Resolutions\n\nResolution is the duration of time that's used to sample a data source. TheResolutionenumeration has the following members:\n\nThe default resolution for market data isMinuteMINUTE. To set the resolution for a security, pass theresolutionargument when you create the security subscription.\n\nqb.AddEquity(\"SPY\", Resolution.Daily);qb.add_equity(\"SPY\", Resolution.DAILY)\n\nWhen you request historical data, theHistoryhistorymethod uses the resolution of your security subscription. To get historical data with a different resolution, pass aresolutionargument to theHistoryhistorymethod.\n\nhistory = qb.history(spy, 10, Resolution.MINUTE)var history = qb.history(spy, 10, Resolution.MINUTE);\n\n### Markets\n\nThe datasets integrated into the Dataset Market cover many markets. TheMarketenumeration has the following members:\n\nLEAN can usually determine the correct market based on the ticker you provide when you create the security subscription. To manually set the market for a security, pass amarketargument when you create the security subscription.\n\nqb.AddEquity(\"SPY\", market: Market.USA);qb.add_equity(\"SPY\", market=Market.USA)\n\n### Fill Forward\n\nFill forward means if there is no data point for the current sample, LEAN uses the previous data point. Fill forward is the default data setting. To disable fill forward for a security, set thefillForwardfill_forwardargument to false when you create the security subscription.\n\nqb.AddEquity(\"SPY\", fillForward: false);qb.add_equity(\"SPY\", fill_forward=False)\n\nWhen you request historical data, theHistoryhistorymethod uses the fill forward setting of your security subscription. To get historical data with a different fill forward setting, pass afillForwardfill_forwardargument to theHistoryhistorymethod.\n\nvar history = qb.History(qb.Securities.Keys, qb.Time-TimeSpan.FromDays(10), qb.Time, fillForward: true);history = qb.history(qb.securities.keys(), qb.time-timedelta(days=10), qb.time, fillForward=True)\n\n### Extended Market Hours\n\nBy default, your security subscriptions only cover regular trading hours. To subscribe to pre and post-market trading hours for a specific asset, enable theextendedMarketHoursextended_market_hoursargument when you create the security subscription.\n\nAddEquity(\"SPY\", extendedMarketHours: true);self.add_equity(\"SPY\", extended_market_hours=True)\n\nYou only receive extended market hours data if you create the subscription with minute, second, or tick resolution. If you create the subscription with daily or hourly resolution, the bars only reflect the regular trading hours.\n\nWhen you request historical data, theHistoryhistorymethod uses the extended market hours setting of your security subscription. To get historical data with a different extended market hours setting, pass anextendedMarketHoursextended_market_hoursargument to theHistoryhistorymethod.\n\nvar history = qb.History(qb.Securities.Keys, qb.Time-TimeSpan.FromDays(10), qb.Time, extendedMarketHours: false);history = qb.history(qb.securities.keys(), qb.time-timedelta(days=10), qb.time, extended_market_hours=False)\n\n### Look-Ahead Bias\n\nIn the Research Environment, all the historical data is directly available. In backtesting, you can only access the data that is at or before the algorithm time. If you make a history request for the previous 10 days of data in the Research Environment, you get the previous 10 days of data from today's date. If you request the same data in a backtest, you get the previous 10 days of data from the algorithm time.\n\n### Consolidate Data\n\nHistory requests usually return data in one of the standardresolutions. To analyze data on custom time frames like 5-minute bars or 4-hour bars, you need to aggregate it. Consider an example where you make a history call for minute resolution data and want to create 5-minute resolution data.\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\nstart_date = datetime(2018, 4, 1)\nend_date = datetime(2018, 7, 15)\nhistory = qb.history(symbol, start_date, end_date, Resolution.MINUTE)var qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\nvar startDate = new DateTime(2018, 4, 1);\nvar endDate = new DateTime(2018, 7, 15);\nvar history = qb.History(symbol, startDate, endDate, Resolution.Minute);\nforeach (var slice in history)\n{\nforeach (var key in slice.Keys)\n{\nConsole.WriteLine($\"{slice.Time} :: {slice[key].ToString()}\");\n}\n}\n\nTo aggregate the data, use aconsolidatoror thepandasresamplemethod.\n\nTo aggregate the data, use aconsolidator.\n\nConsolidators\n\nThe following snippet demonstrates how to use a consolidator to aggregate data:\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromDays(7));\nvar window = new RollingWindow<TradeBar>(20);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}# Set up a consolidator and a RollingWindow to save the data\nconsolidator = TradeBarConsolidator(timedelta(7))\nwindow = RollingWindow[TradeBar](20)\n\n# Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\ndef on_data_consolidated(sender, bar):\nwindow.add(bar)\nconsolidator.data_consolidated += on_data_consolidated\n\n# Iterate the historical market data and feed each bar into the consolidator\nfor bar in history.itertuples():\ntradebar = TradeBar(bar.index[1], bar.index[0], bar.open, bar.high, bar.low, bar.close, bar.volume)\nconsolidator.update(tradebar)\n\nResample Method\n\nTheresamplemethod converts the frequency of a time series DataFrame into a custom frequency. The method only works on DataFrame objects that have adatetimeindex. TheHistoryhistorymethod returns a DataFrame with a multi-index. The first index is aSymbolindex for each security and the second index is a time index for the timestamps of each row of data. To make the DataFrame compatible with theresamplemethod, call thereset_indexmethod to drop theSymbolindex.\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory.reset_index(level = 0, drop = True, inplace=True)\n\nTheresamplemethod returns aResamplerobject, which needs to be downsampled using one of the pandasdownsampling computations. For example, you can use theResampler.ohlcdownsampling method to aggregate price data.\n\nWhen you resample a DataFrame with theohlcdownsampling method, it creates an OHLC row for each column in the DataFrame. To just calculate the OHLC of the close column, select the close column before you resample the DataFrame. A resample offset of 5T corresponds to a 5-minute resample. Other resampling offsets include 2D = 2 days, 5H = 5 hours, and 3S = 3 seconds.\n\nclose_prices = history[\"close\"]\n\noffset = \"5T\"\nclose_5min_ohlc = close_prices.resample(offset).ohlc()\n\n### Common Errors\n\nIf the history request returns an empty DataFrame and you try to slice it, it throws an exception. To avoid issues, check if the DataFrame contains data before slicing it.\n\ndf = qb.history(symbol, 10).close    # raises exception if the request is empty\n\ndef get_safe_history_closes(symbols):\nif not symbols:\nprint(f'No symbols')\nreturn  False, None\ndf = qb.history(symbols, 100, Resolution.DAILY)\nif df.empty:\nprint(f'Empy history for {symbols}')\nreturn  False, None\nreturn True, df.close.unstack(0)\n\nIf you run the Research Environment on your local machine and history requests return no data, check if yourdatadirectory contains the data you request. To download datasets, seeDownload.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying datasets.\n\nExample 1: Futures 5-Minute Bid-Ask\n\nThe following example studies the trend on the SP500 EMini Future contract. To study the short term supply-demand relationship, we consolidate the data into 5 minute bars and calculate the bid and ask dollar volume.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the front-month-mapped future historical data.\n// Use raw normalization mode to fairly compare the actual bid and ask dollar volume.\nvar future = qb.AddFuture(Futures.Indices.SP500EMini);\nvar history = qb.History<QuoteBar>(future.Symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute,\nfillForward: true,\nextendedMarketHours: true,\ndataMappingMode: DataMappingMode.LastTradingDay,\ndataNormalizationMode: DataNormalizationMode.Raw,\ncontractDepthOffset: 0);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new QuoteBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<QuoteBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Take the average of the highest and lowest price in the last 5 mintues as the estimated average price.\nvar askDollarVolume = window.Select(x => (x.Ask.High + x.Ask.Low) * 0.5m * x.LastAskSize).ToList();\nvar bidDollarVolume = window.Select(x => (x.Bid.High + x.Bid.Low) * 0.5m * x.LastBidSize).ToList();# Create a QuantBook\nqb = QuantBook()\n\n# Request the continuous future historical data.\n# Use raw normalization mode to fairly compare the actual bid and ask dollar volume.\nfuture = qb.add_future(Futures.Indices.SP_500_E_MINI)\nhistory = qb.history(future.symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE,\nfill_forward=True,\nextended_market_hours=True,\ndata_mapping_mode=DataMappingMode.LAST_TRADING_DAY,\ndata_normalization_mode=DataNormalizationMode.RAW,\ncontract_depth_offset=0)\n\n# Drop level 0, 1 index (Expiry, Symbol index) from the DataFrame\nhistory = history.droplevel([0, 1])\n\n# Select the required columns to calculate the estimated bid and ask size.\nhistory = history[[\"askhigh\", \"asklow\", \"asksize\", \"bidhigh\", \"bidlow\", \"bidsize\"]].resample(\"5T\").agg({\n\"askhigh\": \"max\",       # Get the highest ask price in the last 5 mintues\n\"asklow\": \"min\",        # Get the lowest ask price in the last 5 mintues\n\"asksize\": \"sum\",       # Get the total ask volume in the last 5 mintues\n\"bidhigh\": \"max\",       # Get the highest bid price in the last 5 mintues\n\"bidlow\": \"min\",        # Get the lowest bid price in the last 5 mintues\n\"bidsize\": \"sum\"        # Get the total bid volume in the last 5 mintues\n})\n# Take the average of the highest and lowest price in the last 5 mintues as the estimated average price.\nhistory[\"ask_dollar_volume\"] = (history[\"askhigh\"] + history[\"asklow\"]) * 0.5 * history[\"asksize\"]\nhistory[\"bid_dollar_volume\"] = (history[\"bidhigh\"] + history[\"bidlow\"]) * 0.5 * history[\"bidsize\"]\nhistory",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Key Concepts",
      "section_number": "3.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Request Type | Return Data Type |\n| --- | --- |\n| No argument | DataFrameList<TradeBar> |\n| TradeBar | list[TradeBars]List<TradeBar> |\n| QuoteBar | list[QuoteBars]List<QuoteBar> |\n| Tick | list[Ticks]List<Tick> |\n| alternativeDataClass(ex:CBOE) | list[alternativeDataClass](ex:list[CBOE])List<alternativeDataClass>(ex:List<CBOE>) |",
    "table_1": "| Request Type | Return Data Type |\n| --- | --- |\n| No argument | DataFrameList<Slice> |\n| TradeBar | list[TradeBars]List<TradeBars> |\n| QuoteBar | list[QuoteBars]List<QuoteBars> |\n| Tick | list[Ticks]List<Ticks> |\n| alternativeDataClass(ex:CBOE) | list[dict[Symbol,alternativeDataClass]](ex:list[dict[Symbol, CBOE]])List<Dictionary<Symbol,alternativeDataClass>>(ex:List<Dictionary<Symbol, CBOE>>) |",
    "table_2": "| Argument | Assumption |\n| --- | --- |\n| Resolution | LEAN guesses the resolution you request by looking at the securities you already have in your notebook. If you have a security subscription in your notebook with a matchingSymbol, the history request uses the same resolution as the subscription. If you don't have a security subscription in your notebook with a matchingSymbol,Resolution.MinuteResolution.MINUTEis the default. |\n| Bar type | If you don't specify a type for the history request,TradeBaris the default. If the asset you request data for doesn't haveTradeBardata, specify theQuoteBartype to receive history. |",
    "table_3": "| Argument | Data Type | Description | Default Value |\n| --- | --- | --- | --- |\n| fillForwardfill_forward | bool?bool/NoneType | True tofill forwardmissing data. Otherwise, false. If you don't provide a value, it uses the fill forward mode of the security subscription. | nullNone |\n| extendedMarketHoursextended_market_hours | bool?bool/NoneType | True to include extended market hours data. Otherwise, false. | nullNone |\n| dataMappingModedata_mapping_mode | DataMappingMode?DataMappingMode/NoneType | Thecontract mapping modeto use for the security history request. | nullNone |\n| dataNormalizationModedata_normalization_mode | DataNormalizationMode?DataNormalizationMode/NoneType | The price scaling mode to use forUS Equitiesorcontinuous Futures contracts. If you don't provide a value, it uses the data normalization mode of the security subscription. | nullNone |\n| contractDepthOffsetcontract_depth_offset | int?int/NoneType | The desired offset from the current front month forcontinuous Futures contracts. | nullNone |"
  },
  {
    "id": "3.2",
    "title": "US Equity",
    "level": 2,
    "path": "Datasets > US Equity",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical US Equity data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a US Equity security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddEquityadd_equitymethod with a ticker and then save a reference to the US EquitySymbol.var spy = qb.AddEquity(\"SPY\").Symbol;\nvar tlt = qb.AddEquity(\"TLT\").Symbol;spy = qb.add_equity(\"SPY\").symbol\ntlt = qb.add_equity(\"TLT\").symbol\n\nTo view the supported assets in the US Equities dataset, see theData Explorer.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the security dimension, you can request historical data for a single US Equity, a subset of the US Equities you created subscriptions for in your notebook, or all of the US Equities in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spy, 10);\nvar subsetHistorySlice = qb.History(new[] {spy, tlt}, 10);\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spy, 10);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spy, tlt}, 10);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, 10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spy, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spy, tlt}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);# DataFrame of trade and quote data\nsingle_history_df = qb.history(spy, 10)\nsubset_history_df = qb.history([spy, tlt], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, spy, 10)\nsubset_history_trade_bar_df = qb.history(TradeBar, [spy, tlt], 10)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), 10)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, spy, 10)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [spy, tlt], 10)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spy, 10)\nsubset_history_trade_bars = qb.history[TradeBar]([spy, tlt], 10)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), 10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spy, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([spy, tlt], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spy, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {spy, tlt}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spy, TimeSpan.FromDays(3));\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spy, tlt}, TimeSpan.FromDays(3));\nvar allHistoryTradeBars = qb.History<TradeBar>(TimeSpan.FromDays(3));\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spy, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spy, tlt}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spy, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spy, tlt}, TimeSpan.FromDays(3), Resolution.Tick);var allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of trade and quote data\nsingle_history_df = qb.history(spy, timedelta(days=3))\nsubset_history_df = qb.history([spy, tlt], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, spy, timedelta(days=3))\nsubset_history_trade_bar_df = qb.history(TradeBar, [spy, tlt], timedelta(days=3))\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, spy, timedelta(days=3))\nsubset_history_quote_bar_df = qb.history(QuoteBar, [spy, tlt], timedelta(days=3))\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spy, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([spy, tlt], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spy, timedelta(days=3))\nsubset_history_trade_bars = qb.history[TradeBar]([spy, tlt], timedelta(days=3))\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spy, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([spy, tlt], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spy, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spy, tlt], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nThe preceding calls return the most recent bars or ticks, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistoryhistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(spy, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {spy, tlt}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spy, startTime, endTime);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spy, tlt}, startTime, endTime);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spy, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spy, tlt}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spy, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spy, tlt}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of trade and quote data\nsingle_history_df = qb.history(spy, start_time, end_time)\nsubset_history_df = qb.history([spy, tlt], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, spy, start_time, end_time)\nsubset_history_trade_bar_df = qb.history(TradeBar, [spy, tlt], start_time, end_time)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, spy, start_time, end_time)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [spy, tlt], start_time, end_time)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spy, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([spy, tlt], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spy, start_time, end_time)\nsubset_history_trade_bars = qb.history[TradeBar]([spy, tlt], start_time, end_time)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), start_time, end_time)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spy, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([spy, tlt], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spy, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spy, tlt], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\nThe preceding calls return the bars or ticks that have a timestamp within the defined period of time.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Equity subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nLEAN groups all of the US Equity exchanges underMarket.USA.\n\n### Data Normalization\n\nThe data normalization mode defines how historical data is adjusted forcorporate actions. By default, LEAN adjusts US Equity data for splits and dividends to produce a smooth price curve, but the following data normalization modes are available:\n\nIf you useAdjustedADJUSTED,SplitAdjustedSPLIT_ADJUSTED, orTotalReturnTOTAL_RETURN, we use the entire split and dividend history to adjust historical prices.\nThis process ensures you get the same adjusted prices, regardless of theQuantBooktime.\nIf you useScaledRawSCALED_RAW, we use the split and dividend history before theQuantBook'sEndDateto adjust historical prices.\n\nTo set the data normalization mode for a security, pass adataNormalizationModedata_normalization_modeargument to theAddEquityadd_equitymethod.\n\nvar spy = qbAddEquity(\"SPY\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;spy = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbol\n\nWhen you request historical data, theHistoryhistorymethod uses the data normalization of your security subscription. To get historical data with a different data normalization, pass adataNormalizationModedata_normalization_modeargument to theHistoryhistorymethod.\n\nvar history = qb.History(qb.Securities.Keys, qb.Time-TimeSpan.FromDays(10), qb.Time, dataNormalizationMode: DataNormalizationMode.SplitAdjusted);history = qb.history(qb.securities.keys(), qb.time-timedelta(days=10), qb.time, dataNormalizationMode=DataNormalizationMode.SPLIT_ADJUSTED)\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded Equity Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single Equity, index thelocproperty of theDataFramewith the EquitySymbol.\n\nall_history_df.loc[spy]  # or all_history_df.loc['SPY']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[spy]['close']\n\nIf you request historical data for multiple Equities, you can transform theDataFrameso that it's a time series of close values for all of the Equities. To transform theDataFrame, select the column you want to display for each Equity and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each Equity and each row contains the close value.\n\nIf you prefer to display the ticker of eachSymbolinstead of the string representation of theSecurityIdentifier, follow these steps:\n\nCreate a dictionary where the keys are the string representations of eachSecurityIdentifierand the values are the ticker.tickers_by_id = {str(x.id): x.value for x in qb.securities.keys}Get the values of the symbol level of theDataFrameindex and create a list of tickers.tickers = set([tickers_by_id[x] for x in all_history_df.index.get_level_values('symbol')])Set the values of the symbol level of theDataFrameindex to the list of tickers.all_history_df.index.set_levels(tickers, 'symbol', inplace=True)\n\nThe newDataFrameis keyed by the ticker.\n\nall_history_df.loc[spy.value]  # or all_history_df.loc[\"SPY\"]\n\nAfter the index renaming, the unstackedDataFramehas the following format:\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[spy].EndTime)),\nnew DecimalDataFrameColumn(\"SPY Open\", history.Select(x => x[spy].Open)),\nnew DecimalDataFrameColumn(\"SPY High\", history.Select(x => x[spy].High)),\nnew DecimalDataFrameColumn(\"SPY Low\", history.Select(x => x[spy].Low)),\nnew DecimalDataFrameColumn(\"SPY Close\", history.Select(x => x[spy].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"SPY close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Equity subscriptions. To avoid issues, check if theSlicecontains data for your Equity before you index it with the EquitySymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.Bars.ContainsKey(spy))\n{\nvar tradeBar = slice.Bars[spy];\n}\nif (slice.QuoteBars.ContainsKey(spy))\n{\nvar quoteBar = slice.QuoteBars[spy];\n}\n}for slice in all_history_slice:\nif slice.bars.contains_key(spy):\ntrade_bar = slice.bars[spy]\nif slice.quote_bars.contains_key(spy):\nquote_bar = slice.quote_bars[spy]\n\n-- ---\n\nYou can also iterate through eachTradeBarandQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.Bars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.bars:\nsymbol = kvp.key\ntrade_bar = kvp.value\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachTradeBarin theSlicefor a givenSymbol.\n\nvar tradeBars = allHistorySlice.Where(slice => slice.Bars.ContainsKey(spy)).Select(slice => slice.Bars[spy]);\n\n-- ---\n\nTradeBar Objects\n\nIf theHistoryhistorymethod returnsTradeBarobjects, iterate through theTradeBarobjects to get each one.\n\nforeach (var tradeBar in singleHistoryTradeBars)\n{\nConsole.WriteLine(tradeBar);\n}for trade_bar in single_history_trade_bars:\nprint(trade_bar)\n\nIf theHistoryhistorymethod returnsTradeBars, iterate through theTradeBarsto get theTradeBarof each Equity. TheTradeBarsmay not have data for all of your Equity subscriptions. To avoid issues, check if theTradeBarsobject contains data for your security before you index it with the EquitySymbol.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nif (tradeBars.ContainsKey(spy))\n{\nvar tradeBar = tradeBars[spy];\n}\n}for trade_bars in all_history_trade_bars:\nif trade_bars.contains_key(spy):\ntrade_bar = trade_bars[spy]\n\nYou can also iterate through each of theTradeBars.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nforeach (var kvp in tradeBars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for trade_bars in all_history_trade_bars:\nfor kvp in trade_bars:\nsymbol = kvp.Key\ntrade_bar = kvp.Value\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each Equity. TheQuoteBarsmay not have data for all of your Equity subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the EquitySymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(spy))\n{\nvar quoteBar = quoteBars[spy];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(spy):\nquote_bar = quote_bars[spy]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Equity. TheTicksmay not have data for all of your Equity subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the EquitySymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(spy))\n{\nvar tick = ticks[spy];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(spy):\nticks = ticks[spy]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical Equity datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(spy, datetime(2021, 11, 23), datetime(2021, 12, 8), Resolution.DAILY).loc[spy]var history = qb.History<TradeBar>(spy, new DateTime(2021, 11, 23), new DateTime(2021, 12, 8), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestickchart.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='SPY OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init(\"SPY Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.Assign theLayoutto the chart.fig = go.Figure(data=[candlestick], layout=layout)chart.WithLayout(layout);Show the plot.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([spy, tlt], datetime(2021, 11, 23), datetime(2021, 12, 8), Resolution.DAILY)var history = qb.History<TradeBar>(new [] {spy, tlt}, new DateTime(2021, 11, 23), new DateTime(2021, 12, 8), Resolution.Daily);Select the data to plot.volume = history['volume'].unstack(level=0)var spy = history.Select(x => x[\"SPY\"]);Call theplotmethod on thepandasobject.Create aLinechart.volume.plot(title=\"Volume\", figsize=(15, 10))var chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nspy.Select(x => x.EndTime),\nspy.Select(x => x.Volume)\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Volume\");\nTitle title = Title.init(\"SPY Volume\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Assign theLayoutto the chart.chart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Common Errors\n\nSome factor files have INF split values, which indicate that the stock has so many splits that prices can't be calculated with correct numerical precision.\nTo allow history requests with these symbols, we need to move the starting date forward when reading the data or use rawdata normalization.\nIf there are numerical precision errors in the factor files for a security in your history request, LEAN throws the following error:\n\n\"Warning: when performing history requests, the start date will be adjusted if there are numerical precision errors in the factor files.\"\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the US Equity dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the SPY. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the SPY historical data.\nvar spy = qb.AddEquity(\"SPY\");\nvar history = qb.History<TradeBar>(spy.Symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<TradeBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => x.Open),\nwindow.Select(x => x.High),\nwindow.Select(x => x.Low),\nwindow.Select(x => x.Close),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{spy.Symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request SPY's historical data.\nspy = qb.add_equity(\"SPY\")\nhistory = qb.history(spy.symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{spy.symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > US Equity",
      "section_number": "3.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.3",
    "title": "Equity Fundamental Data",
    "level": 2,
    "path": "Datasets > Equity Fundamental Data",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Equity Fundamental data. Corporate fundamental data is available through theUS Fundamental Data from Morningstar.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to an Equity security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Fundamental;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddEquityadd_equitymethod with a ticker and then save a reference to the EquitySymbol.var symbols = new []\n{\n\"AAL\",  // American Airlines Group, Inc.\n\"ALGT\", // Allegiant Travel Company\n\"ALK\",  // Alaska Air Group, Inc.\n\"DAL\",  // Delta Air Lines, Inc.\n\"LUV\",  // Southwest Airlines Company\n\"SKYW\", // SkyWest, Inc.\n\"UAL\"   // United Air Lines\n}\n.Select(ticker => qb.AddEquity(ticker, Resolution.Daily).Symbol);symbols = [\nqb.add_equity(ticker, Resolution.DAILY).symbol\nfor ticker in [\n\"AAL\",   # American Airlines Group, Inc.\n\"ALGT\",  # Allegiant Travel Company\n\"ALK\",   # Alaska Air Group, Inc.\n\"DAL\",   # Delta Air Lines, Inc.\n\"LUV\",   # Southwest Airlines Company\n\"SKYW\",  # SkyWest, Inc.\n\"UAL\"    # United Air Lines\n]\n]\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical fundamental data for US Equities.\nOn the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time.\nOn the security dimension, you can request historical data for a single US Equity, a set of US Equities, or all of the US Equities in the US Fundamental dataset.\nOn the property dimension, you can call theHistoryhistorymethod to get allfundamental properties.\n\nWhen you call theHistoryhistorymethod, you can requestFundamentalorFundamentalsobjects.\nIf you useFundamental, the method returns all fundamental properties for theSymbolobject(s) you provide.\nIf you useFundamentals, the method returns all fundamental properties for all the US Equities in the US Fundamental dataset that were trading during that time period you request, including companies that no longer trade.\n\nTrailing Number of Trading Days\n\nTo get historical data for a number of trailing trading days, call theHistoryhistorymethod with the number of trading days. If you didn't useResolution.DailyResolution.DAILYwhen you subscribed to the US Equities, pass it as the last argument to theHistoryhistorymethod.\n\n// Fundamental objects\nvar singleFundamentalHistory = qb.History<Fundamental>(symbols.First(), 10);\nvar setFundamentalHistory = qb.History<Fundamental>(symbols, 10);\nvar allFundamentalHistory = qb.History<Fundamental>(qb.Securities.Keys, 10);\n\n// Fundamentals objects\nvar allFundamentalsHistory = qb.History<Fundamentals>(qb.Securities.Keys, 10);# DataFrame of fundamental data\nsingle_fundamental_df = qb.history(Fundamental, symbols[0], 10, flatten=True)\nset_fundamental_df = qb.history(Fundamental, symbols, 10, flatten=True)\nall_fundamental_df = qb.history(Fundamental, qb.securities.keys(), 10, flatten=True)\nall_fundamentals_df = qb.history(Fundamentals, 10, flatten=True)\n\n# Fundamental objects\nsingle_fundamental_history = qb.history[Fundamental](symbols[0], 10)\nset_fundamental_history = qb.history[Fundamental](symbols, 10)\nall_fundamental_history = qb.history[Fundamental](qb.securities.keys(), 10)\n\n# Fundamentals objects\nall_fundamentals_history = qb.history[Fundamentals](qb.securities.keys(), 10)\n\nThe preceding calls return fundamental data for the 10 most recent trading days.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with aTimeSpantimedeltaobject.\n\n// Fundamental objects\nvar singleFundamentalHistory = qb.History<Fundamental>(symbols.First(), TimeSpan.FromDays(10));\nvar setFundamentalHistory = qb.History<Fundamental>(symbols, TimeSpan.FromDays(10));\nvar allFundamentalHistory = qb.History<Fundamental>(qb.Securities.Keys, TimeSpan.FromDays(10));\n\n// Fundamentals objects\nvar allFundamentalsHistory = qb.History<Fundamentals>(TimeSpan.FromDays(10));# DataFrame of fundamental data\nsingle_fundamental_df = qb.history(Fundamental, symbols[0], timedelta(days=10), flatten=True)\nset_fundamental_df = qb.history(Fundamental, symbols, timedelta(days=10), flatten=True)\nall_fundamental_df = qb.history(Fundamental, qb.securities.keys(), timedelta(days=10), flatten=True)\nall_fundamentals_df = qb.history(Fundamentals, timedelta(5), flatten=True)\n\n# Fundamental objects\nsingle_fundamental_history = qb.history[Fundamental](symbols[0], timedelta(days=10))\nset_fundamental_history = qb.history[Fundamental](symbols, timedelta(days=10))\nall_fundamental_history = qb.history[Fundamental](qb.securities.keys(), timedelta(days=10))\n\n# Fundamentals objects\nall_fundamentals_history = qb.history[Fundamentals](timedelta(days=10))\n\nThe preceding calls return fundamental data for the most recent trading days.\n\nDefined Period of Time\n\nTo get the historical data of all the fundamental properties over specific period of time, call theHistoryhistorymethod with a startDateTimedatetimeand an endDateTimedatetime.\nTo view the possible fundamental properties, see theFundamentalattributes inData Point Attributes.\nThe start and end times you provide to these methods are based in thenotebook time zone.\n\nvar startDate = new DateTime(2021, 1, 1);\nvar endDate = new DateTime(2021, 2, 1);\n\n// Fundamental objects\nvar singleFundamentalHistory = qb.History<Fundamental>(symbols.First(), startDate, endDate);\nvar setFundamentalHistory = qb.History<Fundamental>(symbols, startDate, endDate);\nvar allFundamentalHistory = qb.History<Fundamental>(qb.Securities.Keys, startDate, endDate);\n\n// Fundamentals objects\nvar allFundamentalsHistory = qb.History<Fundamentals>(qb.Securities.Keys, startDate, endDate);start_date = datetime(2021, 1, 1)\nend_date = datetime(2021, 2, 1)\n\n# DataFrame of all fundamental properties\nsingle_fundamental_df = qb.history(Fundamental, symbols[0], start_date, end_date, flatten=True)\nset_fundamental_df = qb.history(Fundamental, symbols, start_date, end_date, flatten=True)\nall_fundamental_df = qb.history(Fundamental, qb.securities.keys(), start_date, end_date, flatten=True)\nall_fundamentals_df = qb.history(Fundamentals, start_date, end_date, flatten=True)\n\n# Fundamental objects\nsingle_fundamental_history = qb.history[Fundamental](symbols[0], start_date, end_date)\nset_fundamental_history = qb.history[Fundamental](symbols, start_date, end_date)\nall_fundamental_history = qb.history[Fundamental](qb.securities.keys(), start_date, end_date)\n\n# Fundamentals objects\nall_fundamentals_history = qb.history[Fundamentals](qb.securities.keys(), start_date, end_date)\n\nThe preceding method returns the fundamental property values that are timestamped within the defined period of time.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data.\n\nDataFrame Objects\n\nTheHistoryhistorymethod returns a multi-index DataFrame where the first level is the EquitySymboland the second level is theEndTimeend_timeof the trading day. The columns of the DataFrame are the names of the fundamental properties. The following image shows the first 4 columns of an example DataFrame:\n\nTo access an attribute from one of the cells in the DataFrame, select the value in the cell and then access the object's property.\n\nsingle_fundamental_df.iloc[0].companyprofile.share_class_level_shares_outstanding\n\nFundamental Objects\n\nIf you pass aSymbolto thehistory[Fundamental]History<Fundamental>method, run the following code to get the fundamental properties over time:\n\nfor fundamental in single_fundamental_history:\nsymbol = fundamental.symbol\nend_time = fundamental.end_time\npe_ratio = fundamental.valuation_ratios.pe_ratioforeach (var fundamental in singleFundamentalHistory) // Iterate trading days\n{\nvar endTime = fundamental.EndTime;\nvar peRatio = fundamental.ValuationRatios.PERatio;\n}\n\nIf you pass a list ofSymbolobjects to thehistory[Fundamental]History<Fundamental>method, run the following code to get the fundamental properties over time:\n\nfor fundamental_dict in set_fundamental_history: # Iterate trading days\nfor symbol, fundamental in fundamental_dict.items(): # Iterate Symbols\nend_time = fundamental.end_time\npe_ratio = fundamental.valuation_ratios.pe_ratioforeach (var fundamentalDict in setFundamentalHistory) // Iterate trading days\n{\nforeach (var kvp in fundamentalDict) // Iterate Symbols\n{\nvar symbol = kvp.Key;\nvar fundamental = kvp.Value;\nvar endTime = fundamental.EndTime;\nvar peRatio = fundamental.ValuationRatios.PERatio;\n}\n}\n\nFundamentals Objects\n\nIf you request all fundamental properties for all US Equities with thehistory[Fundamentals]History<Fundamentals>method, run the following code to get the fundamental properties over time:\n\nfor fundamentals_dict in all_fundamentals_history: # Iterate trading days\nfundamentals = list(fundamentals_dict.values)[0]\nend_time = fundamentals.end_time\nfor fundamental in fundamentals.data: # Iterate Symbols\nif not fundamental.has_fundamental_data:\ncontinue\nsymbol = fundamental.symbol\npe_ratio = fundamental.valuation_ratios.pe_ratioforeach (var fundamentalsDict in allFundamentalsHistory) // Iterate trading days\n{\nvar fundamentals = fundamentalsDict.Values.First().Data;\nforeach (Fundamental fundamental in fundamentals) // Iterate Symbols\n{\nif (!fundamental.HasFundamentalData)\n{\ncontinue;\n}\nvar endTime = fundamental.EndTime;\nvar symbol = fundamental.Symbol;\nvar peRatio = fundamental.ValuationRatios.PERatio;\n}\n}\n\nDataDictionary Objects\n\nTo get the fundamental data points for each Equity, iterate through the history request result.\n\nforeach (var slice in allOneAttributeHistory)\n{\nvar endTime = slice.Time;\nforeach (var symbol in symbols)\n{\nif (slice.ContainsKey(symbol))\n{\nvar peRatio = slice[symbol];\n}\n}\n}\n\nYou can also iterate through each data point in the slice.\n\nforeach (var slice in allOneAttributeHistory)\n{\nvar endTime = slice.Time;\nforeach (var kvp in slice)\n{\nvar symbol = kvp.Key;\nvar peRatio = kvp.Value;\n}\n}\n\nYou can also use LINQ to select the historical data points.\n\nvar symbol = symbols.Last();\nvar values = allOneAttributeHistory.Select(slice => slice[symbol]);\n\n### Plot Data\n\nYou need somehistorical Equity fundamental datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot line charts.\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet somehistorical data.var history = history = qb.History<Fundamental>(symbols, new DateTime(2014, 1, 1), new DateTime(2015, 1, 1));history = qb.history[Fundamental](symbols, datetime(2014, 1, 1), datetime(2015, 1, 1))Load thePlotly.NETpackage.#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;CreateLineobjects for eachSymbol.var charts = symbols.Select(\nsymbol => Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => (DateTime)x.Time),\nhistory.Select(x => (decimal)x[symbol].ValuationRatios.PERatio)),\nName: symbol.Value\n)\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"PE Ratio\");\nTitle title = Title.init(\"PE Ratios Over Time\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(charts);\nchart.WithLayout(layout);Convert to pandas DataFrame.data = {}\nfor fundamental_dict in history: # Iterate trading days\nfor symbol, fundamental in fundamental_dict.items(): # Iterate Symbols\ndatum = data.get(symbol, dict())\ndatum['index'] = datum.get('index', [])\ndatum['index'].append(fundamental.end_time)\ndatum['pe_ratio'] = datum.get('pe_ratio', [])\ndatum['pe_ratio'].append(fundamental.valuation_ratios.pe_ratio)\ndata[symbol] = datum\n\ndf = pd.DataFrame()\nfor symbol, datum in data.items():\ndf_symbol = pd.DataFrame({symbol: pd.Series(datum['pe_ratio'], index=datum['index'])})\ndf = pd.concat([df, df_symbol], axis=1)Call theplotmethod on the history DataFrame.df.plot(title='PE Ratio Over Time', figsize=(15, 8))Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Equity Fundamental Data dataset.\n\nExample 1: PE Ratio Line Chart\n\nThe following example studies the trend of PE Ratio of AAPL using a line chart.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Fundamental;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request AAPL's fundamental historical data.\nvar equity = qb.AddEquity(\"AAPL\");\nvar history = qb.History<Fundamental>(\nequity.Symbol,\nstart: qb.Time - TimeSpan.FromDays(365),\nend: qb.Time,\nresolution: Resolution.Daily\n);\n\n// Select the PE Ratio to study.\nvar peRatios = history.Select(x => x.ValuationRatios.PERatio).ToList();\nvar time = history.Select(x => x.EndTime).ToList();\n\n// Crete the Line Chart with the PE Ratios.\nvar chart = Chart2D.Chart.Line<DateTime, double, string>(\ntime,\npeRatios\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"PE Ratio\");\nTitle title = Title.init($\"PE Ratio by Time of {equity.Symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Create a QuantBook\nqb = QuantBook()\n\n# Request AAPL's fundamental historical data.\nequity = qb.add_equity(\"AAPL\")\nhistory = qb.history(\nFundamental,\nequity.symbol,\nstart=qb.time - timedelta(days=365),\nend=qb.time,\nresolution=Resolution.DAILY,\nflatten=True\n)\n\n# Select the PE Ratio to study.\npe_ratio = history.loc[equity.symbol].apply(lambda x: x.valuationratios.pe_ratio, axis=1)\n# Plot the PE Ratio line chart.\npe_ratio.plot(title=f\"PE Ratio by Time of {equity.symbol}\", ylabel=\"PE Ratio\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Equity Fundamental Data",
      "section_number": "3.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.4",
    "title": "Equity Options",
    "level": 2,
    "path": "Datasets > Equity Options",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Equity Options",
      "section_number": "3.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.4.1",
    "title": "Key Concepts",
    "level": 3,
    "path": "Datasets > Equity Options > Key Concepts",
    "content": "### Introduction\n\nEquity Options are a financial derivative that gives the holder the right (but not the obligation) to buy or sell the underlying Equity, such as Apple, at the stated exercise price.\nThis page explains the basics of Equity Option data in the Research Environment.\nTo get some data, seeUniversesorIndividual Contracts.\nFor more information about the specific datasets we use, see theUS Equity OptionsandUS Equity Option Universedataset listings.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Equity Option contract subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nLEAN groups all of the US Equity Option exchanges underMarket.USA, so you don't need to pass aMarketto theAddOptionadd_optionorAddOptionContractadd_option_contractmethods.\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. By default, LEAN doesn't adjust Equity Options data for splits and dividends of their underlying. If you change the data normalization mode, it won't change the outcome.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3.4",
      "breadcrumb": "Datasets > Equity Options > Key Concepts",
      "section_number": "3.4.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.4.2",
    "title": "Universes",
    "level": 3,
    "path": "Datasets > Equity Options > Universes",
    "content": "### Introduction\n\nThis page explains how to request historical data for a universe of Equity Option contracts.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to an Equity Option universe:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Option;\nusing QuantConnect.Data.UniverseSelection;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Subscribe to the underlying Equity with raw data normalization and save a reference to the EquitySymbol.var equitySymbol = qb.AddEquity(\"SPY\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;equity_symbol = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbolTo view the supported underlying assets in the US Equity Options dataset, see theData Explorer.Call theAddOptionadd_optionmethod with the underlying EquitySymbol.var option = qb.AddOption(equitySymbol);option = qb.add_option(equity_symbol)\n\n### Price History\n\nThecontract filterdetermines which Equity Option contracts are in your universe each trading day.\nThe default filter selects the contracts with the following characteristics:\n\nStandard type (exclude weeklys)Within 1 strike price of the underlying asset priceExpire within 35 days\n\nTo change the filter, call theSetFilterset_filtermethod.\n\n// Set the contract filter to select contracts that have the strike price\n// within 1 strike level and expire within 90 days.\noption.SetFilter(-1, 1, 0, 90);# Set the contract filter to select contracts that have the strike price\n# within 1 strike level and expire within 90 days.\noption.set_filter(-1, 1, 0, 90)\n\nTo get the prices and volumes for all of the Equity Option contracts that pass your filter during a specific period of time, call theOptionHistoryoption_historymethod with the underlying EquitySymbolobject, a startDateTimedatetime, and an endDateTimedatetime.\n\noption_history = qb.option_history(\nequity_symbol, datetime(2024, 1, 1), datetime(2024, 1, 5), Resolution.MINUTE,\nfill_forward=False, extended_market_hours=False\n)var optionHistory = qb.OptionHistory(\nequitySymbol, new DateTime(2024, 1, 1), new DateTime(2024, 1, 5), Resolution.Minute,\nfillForward: false, extendedMarketHours: false\n);\n\nTo convert theOptionHistoryobject to aDataFramethat contains the trade and quote information of each contract and the underlying, use thedata_frameproperty.\n\noption_history.data_frame\n\nTo get the expiration dates of all the contracts in anOptionHistoryobject, call theGetExpiryDatesget_expiry_datesmethod.\n\noption_history.get_expiry_dates()\n\nTo get the strike prices of all the contracts in anOptionHistoryobject, call theGetStrikesget_strikesmethod.\n\noption_history.get_strikes()\n\n### Daily Price and Greeks History\n\nTo get daily data on all the tradable contracts for a given date, call theHistory<OptionUniverse>historymethod with the canoncial Option Symbol, a start date, and an end date. This method returns the entire Option chain for each trading day, not the subset of contracts that pass your universe filter. The daily Option chains contain the prices, volume, open interest, implied volaility, and Greeks of each contract.\n\n# DataFrame format\nhistory_df = qb.history(option.symbol, datetime(2024, 1, 1), datetime(2024, 1, 5), flatten=True)\n\n# OptionUniverse objects\nhistory = qb.history[OptionUniverse](option.symbol, datetime(2024, 1, 1), datetime(2024, 1, 5))\nfor chain in history:\nend_time = chain.end_time\nfiltered_chain = [contract for contract in chain if contract.greeks.delta > 0.3]\nfor contract in filtered_chain:\nprice = contract.price\niv = contract.implied_volatilityvar history = qb.History<OptionUniverse>(option.Symbol, new DateTime(2024, 1, 1), new DateTime(2024, 1, 5));\nforeach (var chain in history)\n{\nvar endTime = chain.EndTime;\nvar filteredChain = chain.Data\n.Select(contract => contract as OptionUniverse)\n.Where(contract => contract.Greeks.Delta > 0.3m);\nforeach (var contract in filteredChain)\n{\nvar price = contract.Price;\nvar iv = contract.ImpliedVolatility;\n}\n}\n\nThe method represents each contract with anOptionUniverseobject, which have the following properties:\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Equity Options dataset.\n\nExample 1: Implied Volatility Line Chart\n\nThe following example plots a line chart on the implied volatility curve of the cloest expiring calls.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing System.Collections.Generic;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.UniverseSelection;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n// Set the date being studied.\nvar date = new DateTime(2024, 1, 4);\n\n// Subscribe to the underlying Equity with raw data normalization and save a reference to the Equity Symbol.\nvar equity = qb.AddEquity(\"SPY\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;\n// Request the option data by calling the add_option method with the underlying Equity Symbol.\nvar option = qb.AddOption(equity);\n\n// Request the historical option data to obtain the data to be calculated and compared.\nvar history = qb.History<OptionUniverse>(option.Symbol, date.AddDays(-1), date, Resolution.Daily);\nvar ivByStrike = new Dictionary<decimal, decimal>();\nforeach (var chain in history)\n{\n// Get the closest expiring calls to study.\nvar filteredChain = chain.Select(contract => contract as OptionUniverse)\n.Where(x => x.Symbol.ID.Date == date && x.Symbol.ID.OptionRight == OptionRight.Call);\n\n// Obtain the strike and IV for plotting the IV curve.\nforeach (var contract in filteredChain)\n{\nvar strike = contract.Symbol.ID.StrikePrice;\nvar iv = contract.ImpliedVolatility;\nivByStrike[strike] = iv;\n}\n}\n\n// Crete the Line Chart with the PE Ratios.\nvar chart = Chart2D.Chart.Line<decimal, decimal, string>(\nivByStrike.Keys,\nivByStrike.Values\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Strike\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Implied Volatility\");\nTitle title = Title.init($\"IV Curve of {option.Symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate a QuantBook instance.\nqb = QuantBook()\n# Set the date being studied.\ndate = datetime(2024, 1, 4)\n\n# Subscribe to the underlying Equity with raw data normalization and save a reference to the Equity Symbol.\nequity_symbol = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbol\n# Request the option data by calling the add_option method with the underlying Equity Symbol.\noption = qb.add_option(equity_symbol)\n\n# Request the historical option data to obtain the data to be calculated and compared.\nhistory_df = qb.history(option.symbol, date-timedelta(1), date, flatten=True).droplevel([0])\n\n# Include only the closest expiring calls.\nexpiry = min(x.id.date for x in history_df.index)\nhistory_df = history_df.loc[(x for x in history_df.index if x.id.date == expiry and x.id.option_right == OptionRight.CALL)]\nstrikes = [x.id.strike_price for x in history_df.index]\n\n# Plot the IV curve versus strikes.\nhistory_df.index = strikes\nhistory_df[[\"impliedvolatility\"]].plot(title=\"IV Curve\", xlabel=\"strike\", ylabel=\"implied volatility\")\n\nExample 2: COS DeltaThe following example uses Fourier-Cosine method with finite differencing under Black-Scholes framework to calculate the option Delta. Then, we plot the actual Delta and the COS-calculated Delta to study the approximation accuracy. COS method can calculate a large number of option Greeks in a continuous strike range rapidly, making it suitable for arbitration and hedge position adjustment.# Instantiate a QuantBook instance.\nqb = QuantBook()\n# Set the date being studied.\ndate = datetime(2024, 1, 4)\n\n# Subscribe to the underlying Equity with raw data normalization and save a reference to the Equity Symbol.\nequity_symbol = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbol\n# Request the option data by calling the add_option method with the underlying Equity Symbol.\noption = qb.add_option(equity_symbol)\n\n# Request the historical option data to obtain the data to be calculated and compared.\nhistory_df = qb.history(option.symbol, date-timedelta(1), date, flatten=True).droplevel([0])\n\n# Include only the furthest expiring puts.\nexpiry = max(x.id.date for x in history_df.index)\nhistory_df = history_df.loc[(x for x in history_df.index if x.id.date == expiry and x.id.option_right == OptionRight.PUT)]\nstrikes = np.array([x.id.strike_price for x in history_df.index])\n\n# Get the implied volatility of the ATM put as the forward volatility forecast.\nhistory_df[\"underlying\"] = history_df[\"underlying\"].apply(lambda x: x.price)\natm_call = sorted(history_df.iterrows(), key=lambda x: abs(x[0].id.strike_price - x[1].underlying))[0]\niv = atm_call[1].impliedvolatility\n\ndef psi_n(b1, b2, c, d, n):\n\"\"\"Calculate the psi_n function used in the COS method.\"\"\"\n# Base case for n=0.\nif n == 0:\nreturn d - c\ndelta_b = b2 - b1\n# Compute sine terms for the given range.\nsin_terms = np.sin(n * np.pi * (np.array([d]) - b1) / delta_b) - np.sin(n * np.pi * (np.array([c]) - b1) / delta_b)\nreturn (delta_b * sin_terms) / (n * np.pi)\n\ndef gamma_n(b1, b2, c, d, n):\n\"\"\"Calculate the gamma_n function used in the COS method.\"\"\"\nbase = n * np.pi / (b2 - b1)    # Scaling factor based on n\nd_ = base * (d - b1)            # Adjusted upper limit\nc_ = base * (c - b1)            # Adjusted lower limit\nexp_d = np.exp(d)               # Calculate exponential for d\nexp_c = np.exp(c)               # Calculate exponential for c\n\n# Compute cosine and sine terms for the upper and lower limits.\ncos_terms = np.cos(np.array([d_, c_]))\nsin_terms = np.sin(np.array([d_, c_]))\n\n# Numerator of the gamma_n function.\nnumerator = (cos_terms[0] * exp_d - cos_terms[1] * exp_c +\nbase * (sin_terms[0] * exp_d - sin_terms[1] * exp_c))\n\nreturn numerator / (1 + base**2)\n\ndef v_n(b1, b2, c, d, n, K):\n\"\"\"Calculate the v_n function, which combines psi_n and gamma_n.\"\"\"\nreturn 2 * K / (b2 - b1) * (psi_n(b1, b2, c, d, n) - gamma_n(b1, b2, c, d, n))\n\ndef log_char(t, S0, K, r, sigma, T):\n\"\"\"Compute the characteristic function under BS model (log normal return)\"\"\"\nterm1 = np.log(S0 / K) + (r - sigma**2 / 2) * T  # Logarithmic term\nterm2 = -sigma**2 * T * t**2 / 2  # Variance term\nreturn np.exp(1j * t * term1 + term2)\n\ndef put(N, b1, b2, c, d, S0, K, r, sigma, T):\n\"\"\"Calculate the price of a European put option using the COS method for multiple strike prices.\"\"\"\nprice = np.zeros(len(K), dtype=np.complex_)\n\n# Calculate initial price for n=0.\nprice += v_n(b1, b2, c, d, 0, K) * log_char(0, S0, K, r, sigma, T) / 2\n\n# Loop over the series expansion for n from 1 to N.\nfor i in range(1, N):\nt = i * np.pi / (b2 - b1)                           # Compute t for the current term\nlog_char_terms = log_char(t, S0, K, r, sigma, T)    # Evaluate characteristic function\nexp_term = np.exp(-1j * i * np.pi * b1 / (b2 - b1)) # Exponential decay term\nprice += log_char_terms * exp_term * v_n(b1, b2, c, d, i, K)\n\n# Return the real part of the discounted price.\nreturn np.exp(-r * T) * price.real\n\ndef option_delta(N, b1, b2, c, d, S0, K, r, sigma, T, delta_S=1e-5):\n\"\"\"Calculate the delta of a European put option using finite differencing.\"\"\"\n# Calculate option price at the current asset price.\nprice_current = put(N + 1, b1, b2, c, d, S0, K, r, sigma, T)\n\n# Calculate option price at slightly higher asset price.\nprice_up = put(N + 1, b1, b2, c, d, S0 + delta_S, K, r, sigma, T)\n\n# Calculate delta by finite differencing.\ndelta = (price_up - price_current) / delta_S\nreturn delta\n\n# Number of terms in the series expansion, the higher the more accurate.\nN = 50\n# Underlying asset price\nS = atm_call[1].underlying\n# Number of fractional years till expiry.\nT = (expiry - date + timedelta(1)).total_seconds() / 60 / 60 / 24 / 365.25\n# Get the interest rate and dividend yield to calculate the discount rate.\nr = np.log(1 + InterestRateProvider().get_interest_rate(date))      # continuous transformation\nq = DividendYieldProvider(equity_symbol).get_dividend_yield(date)\n\nc1 = r - q              # under risk-neutral measure\nc2 = T * iv**2          # Brownian variance\nc4 = 0                  # Placeholder for additional variance (not used in this context)\nL = 10                  # Parameter for the bounds\n\n# Calculate bounds for the COS method.\nb1 = c1 - L * np.sqrt(c2 + np.sqrt(c4))  # Lower bound\nb2 = c1 + L * np.sqrt(c2 + np.sqrt(c4))  # Upper bound\n\n# Calculate the put option price using the COS method.\noption_delta = option_delta(N + 1, b1, b2, b1, 0, S, strikes, r, iv, T)\n\nhistory_df.index = [x.id.strike_price for x in history_df.index]\nax = history_df.delta.plot(title=\"Delta calculation using COS method\", xlabel=\"strike\", ylabel=\"delta\", label=\"actual\", legend=True)\nax.plot(history_df.index, option_delta, label=\"COS\")\nax.legend()",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.4",
      "breadcrumb": "Datasets > Equity Options > Universes",
      "section_number": "3.4.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.4.3",
    "title": "Individual Contracts",
    "level": 3,
    "path": "Datasets > Equity Options > Individual Contracts",
    "content": "### Introduction\n\nThis page explains how to request historical data for individual Equity Option contracts.\nThehistory requestson this page only return the prices and open interest of the Option contracts, not their implied volatility or Greeks.\nFor information about history requests that return the daily implied volatility and Greeks, seeUniverses.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to individual Equity Option contracts:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Option;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Add the underlying Equitywith rawdata normalization.var underlyingSymbol = qb.AddEquity(\"SPY\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;underlying_symbol = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbolTo view the supported underlying assets in the US Equity Options dataset, see theData Explorer.Set the start dateto a date in the past that you want to use as the analysis date.qb.SetStartDate(2024, 1, 1);qb.set_start_date(2024, 1, 1)The method that you call in the next step returns data on all the contracts that were tradable on this date.Call theOptionChainoption_chainmethod with the underlyingEquitySymbol.// Get the Option contracts that were tradable on January 1st, 2024.\nvar chain = qb.OptionChain(underlyingSymbol);# Get the Option contracts that were tradable on January 1st, 2024.\nchain = qb.option_chain(underlying_symbol, flatten=True)This method returns anOptionChainobject, which represent an entire chain of Option contracts for a single underlying security.You can even format the chain data into a DataFrame where each row in the DataFrame represents a single contract.Sort and filter the data to select the specific contract(s) you want to analyze.// Select a contract.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar contractSymbol = chain\n.Where(contract =>\n// Select call contracts with the closest expiry.\ncontract.Expiry == expiry &&\ncontract.Right == OptionRight.Call &&\n// Select contracts with a 0.3-0.7 delta.\ncontract.Greeks.Delta > 0.3m &&\ncontract.Greeks.Delta < 0.7m\n)\n// Select the contract with the largest open interest.\n.OrderByDescending(contract => contract.OpenInterest)\n.First()\n// Get the Symbol of the target contract.\n.Symbol;# Get the contracts available to trade (in DataFrame format).\nchain = chain.data_frame\n\n# Select a contract.\nexpiry = chain.expiry.min()\ncontract_symbol = chain[\n# Select call contracts with the closest expiry.\n(chain.expiry == expiry) &\n(chain.right == OptionRight.CALL) &\n# Select contracts with a 0.3-0.7 delta.\n(chain.delta > 0.3) &\n(chain.delta < 0.7)\n# Select the contract with the largest open interest.\n].sort_values('openinterest').index[-1]Call theAddOptionContractadd_option_contractmethod with anOptionContractSymboland disable fill-forward.// Subscribe to the target contract.\nvar optionContract = qb.AddOptionContract(contractSymbol, fillForward: false);# Subscribe to the target contract.\noption_contract = qb.add_option_contract(contract_symbol, fill_forward=False)Disable fill-forward because there are only a fewOpenInterestdata points per day.\n\n### Trade History\n\nTradeBarobjects are price bars that consolidate individual trades from the exchanges. They contain the open, high, low, close, and volume of trading activity over a period of time.\n\nTo get trade data, call thehistoryorhistory[TradeBar]History<TradeBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<TradeBar>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var tradeBar in history)\n{\nConsole.WriteLine(tradeBar);\n}# DataFrame format\nhistory_df = qb.history(TradeBar, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# TradeBar objects\nhistory = qb.history[TradeBar](contract_symbol, timedelta(3))\nfor trade_bar in history:\nprint(trade_bar)\n\nTradeBarobjects have the following properties:\n\n### Quote History\n\nQuoteBarobjects are bars that consolidate NBBO quotes from the exchanges. They contain the open, high, low, and close prices of the bid and ask. TheOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarobject are the mean of the respective bid and ask prices. If the bid or ask portion of theQuoteBarhas no data, theOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarcopy the values of either theBidbidorAskaskinstead of taking their mean.\n\nTo get quote data, call thehistoryorhistory[QuoteBar]History<QuoteBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<QuoteBar>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var quoteBar in history)\n{\nConsole.WriteLine(quoteBar);\n}# DataFrame format\nhistory_df = qb.history(QuoteBar, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# QuoteBar objects\nhistory = qb.history[QuoteBar](contract_symbol, timedelta(3))\nfor quote_bar in history:\nprint(quote_bar)\n\nQuoteBarobjects have the following properties:\n\n### Open Interest History\n\nOpen interest is the number of outstanding contracts that haven't been settled. It provides a measure of investor interest and the market liquidity, so it's a popular metric to use for contract selection. Open interest is calculated once per day.\n\nTo get open interest data, call thehistoryorhistory[OpenInterest]History<OpenInterest>method with the contractSymbolobject(s).\n\nvar history = qb.History<OpenInterest>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var openInterest in history)\n{\nConsole.WriteLine(openInterest);\n}# DataFrame format\nhistory_df = qb.history(OpenInterest, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# OpenInterest objects\nhistory = qb.history[OpenInterest](contract_symbol, timedelta(3))\nfor open_interest in history:\nprint(open_interest)\n\nOpenInterestobjects have the following properties:\n\n### Greeks and IV History\n\nThe Greeks are measures that describe the sensitivity of an Option's price to various factors like underlying price changes (Delta), time decay (Theta), volatility (Vega), and interest rates (Rho), while Implied Volatility (IV) represents the market's expectation of the underlying asset's volatility over the life of the Option.\n\nFollow these steps to get the Greeks and IV data:\n\nCreate the mirror contractSymbol.var mirrorContractSymbol = Symbol.CreateOption(\noptionContract.Underlying.Symbol,\ncontractSymbol.ID.Market,\noptionContract.Style,\noptionContract.Right == OptionRight.Put ? OptionRight.Call : OptionRight.Put,\noptionContract.StrikePrice,\noptionContract.Expiry\n);mirror_contract_symbol = Symbol.create_option(\noption_contract.underlying.symbol, contract_symbol.id.market, option_contract.style,\nOptionRight.Call if option_contract.right == OptionRight.PUT else OptionRight.PUT,\noption_contract.strike_price, option_contract.expiry\n)Set up therisk free interest rate,dividend yield, andOption pricingmodels.Inour research, we found the Forward Tree model to be the best pricing model for indicators.risk_free_rate_model = qb.risk_free_interest_rate_model\ndividend_yield_model = DividendYieldProvider(underlying_symbol)\noption_model = OptionPricingModelType.FORWARD_TREEvar riskFreeRateModel = qb.RiskFreeInterestRateModel;\nvar dividendYieldModel = new DividendYieldProvider(underlyingSymbol);\nvar optionModel = OptionPricingModelType.ForwardTree;Define a method to return theIV & Greeks indicatorvalues for each contract.def greeks_and_iv(contracts, period, risk_free_rate_model, dividend_yield_model, option_model):\n# Get the call and put contract.\ncall, put = sorted(contracts, key=lambda s: s.id.option_right)\n\ndef get_values(indicator_class, contract, mirror_contract):\nreturn qb.indicator_history(\nindicator_class(contract, risk_free_rate_model, dividend_yield_model, mirror_contract, option_model),\n[contract, mirror_contract, contract.underlying],\nperiod\n).data_frame.current\n\nreturn pd.DataFrame({\n'iv_call': get_values(ImpliedVolatility, call, put),\n'iv_put': get_values(ImpliedVolatility, put, call),\n'delta_call': get_values(Delta, call, put),\n'delta_put': get_values(Delta, put, call),\n'gamma_call': get_values(Gamma, call, put),\n'gamma_put': get_values(Gamma, put, call),\n'rho_call': get_values(Rho, call, put),\n'rho_put': get_values(Rho, put, call),\n'vega_call': get_values(Vega, call, put),\n'vega_put': get_values(Vega, put, call),\n'theta_call': get_values(Theta, call, put),\n'theta_put': get_values(Theta, put, call),\n})Dictionary<string, IndicatorHistory> GreeksAndIV(List<Symbol> contracts, int period)\n{\n// Get the call and put contract.\nvar sortedSymbols = contracts.OrderBy(s => s.ID.OptionRight).ToArray();\nvar call = sortedSymbols[0];\nvar put = sortedSymbols[1];\n\nIndicatorHistory GetValues(OptionIndicatorBase indicator)\n{\n// Use both contracts and the underlying to update the indicator and get its value.\nreturn qb.IndicatorHistory(indicator, new[] { call, put, call.Underlying }, period);\n}\n\n// Get the values of all the IV and Greek indicators.\nreturn new Dictionary<string, IndicatorHistory>\n{\n{\"IVCall\", GetValues(new ImpliedVolatility(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"IVPut\", GetValues(new ImpliedVolatility(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"DeltaCall\", GetValues(new Delta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"DeltaPut\", GetValues(new Delta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"GammaCall\", GetValues(new Gamma(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"GammaPut\", GetValues(new Gamma(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"VegaCall\", GetValues(new Vega(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"VegaPut\", GetValues(new Vega(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"ThetaCall\", GetValues(new Theta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"ThetaPut\", GetValues(new Theta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"RhoCall\", GetValues(new Rho(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"RhoPut\", GetValues(new Rho(put, riskFreeRateModel, dividendYieldModel, call, optionModel))}\n};\n}Call the preceding method and display the results.greeks_and_iv([contract_symbol, mirror_contract_symbol], 15, risk_free_rate_model, dividend_yield_model, option_model)foreach (var (key, indicatorHistory) in GreeksAndIV(new List<Symbol> {contractSymbol, mirrorContractSymbol}, 15))\n{\nforeach (var dataPoint in indicatorHistory)\n{\nConsole.WriteLine($\"{dataPoint.EndTime} - {key}: {dataPoint.Current.Value}\");\n}\n}\n\nThe DataFrame can have NaN entries if there is no data for the contracts or the underlying asset at a moment in time.\n\n### Examples\n\nThe following examples demonstrate some common practices for analyzing individual Equity Option contracts in the Research Environment.\n\nExample 1: Contract Trade History\n\nThe following notebook plots the historical prices of an SPY Equity Option contract usingPlotlyPlotly.NET:\n\n#load \"../Initialize.csx\"\n\nimport plotly.graph_objects as go\n\n# Get the SPY Option chain for January 1, 2024.\nqb = QuantBook()\nunderlying_symbol = qb.add_equity(\"SPY\", data_normalization_mode=DataNormalizationMode.RAW).symbol\nqb.set_start_date(2024, 1, 1)\nchain = qb.option_chain(underlying_symbol, flatten=True).data_frame\n\n# Select a contract from the chain.\nexpiry = chain.expiry.min()\ncontract_symbol = chain[\n(chain.expiry == expiry) &\n(chain.right == OptionRight.CALL) &\n(chain.delta > 0.3) &\n(chain.delta < 0.7)\n].sort_values('openinterest').index[-1]\n\n# Add the target contract.\nqb.add_option_contract(contract_symbol)\n\n# Get the contract history.\nhistory = qb.history(contract_symbol, timedelta(3))\n\n# Plot the price history.\ngo.Figure(\ndata=go.Candlestick(\nx=history.index.levels[4],\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close']\n),\nlayout=go.Layout(\ntitle=go.layout.Title(text=f'{contract_symbol.value} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False\n)\n).show()#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Option;\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Get the SPY Option chain for January 1, 2024.\nvar qb = new QuantBook();\nvar underlyingSymbol = qb.AddEquity(\"SPY\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;\nqb.SetStartDate(2024, 1, 1);\nvar chain = qb.OptionChain(underlyingSymbol);\n\n// Select a contract from the chain.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar contractSymbol = chain\n.Where(contract =>\ncontract.Expiry == expiry &&\ncontract.Right == OptionRight.Call &&\ncontract.Greeks.Delta > 0.3m &&\ncontract.Greeks.Delta < 0.7m\n)\n.OrderByDescending(contract => contract.OpenInterest)\n.First()\n.Symbol;\n\n// Add the target contract.\nqb.AddOptionContract(contractSymbol);\n\n// Get the contract history.\nvar history = qb.History<TradeBar>(contractSymbol, TimeSpan.FromDays(3));\n\n// Plot the price history.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{contractSymbol} Price\");\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\nchart.WithLayout(layout);\nHTML(GenericChart.toChartHTML(chart))\n\nExample 2: Contract Open Interest History\n\nThe following notebook plots the historical open interest of a TSLA Equity Option contract usingMatplotlibPlotly.NET:\n\n#load \"../Initialize.csx\"\n\n# Get the TSLA Option chain for January 1, 2024.\nqb = QuantBook()\nunderlying_symbol = qb.add_equity(\"TSLA\", data_normalization_mode=DataNormalizationMode.RAW).symbol\nqb.set_start_date(2024, 1, 1)\nchain = qb.option_chain(underlying_symbol, flatten=True).data_frame\n\n# Select a contract from the chain.\nstrike_distance = (chain.strike - chain.underlyinglastprice).abs()\ntarget_strike_distance = strike_distance.min()\nchain = chain.loc[strike_distance[strike_distance == target_strike_distance].index]\ncontract_symbol = chain.sort_values('impliedvolatility').index[-1]\n\n# Add the target contract.\nqb.add_option_contract(contract_symbol, fill_forward=False)\n\n# Get the contract's open interest history.\nhistory = qb.history(OpenInterest, contract_symbol, timedelta(90))\nhistory.index = history.index.droplevel([0, 1, 2])\nhistory = history['openinterest'].unstack(0)[contract_symbol]\n\n# Plot the open interest history.\nhistory.plot(title=f'{contract_symbol.value} Open Interest')\nplt.show()#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Option;\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Get the TSLA Option chain for January 1, 2024.\nvar qb = new QuantBook();\nvar underlyingSymbol = qb.AddEquity(\"TSLA\", dataNormalizationMode: DataNormalizationMode.Raw).Symbol;\nqb.SetStartDate(2024, 1, 1);\nvar chain = qb.OptionChain(underlyingSymbol);\n\n// Select a contract from the chain.\nvar targetStrikeDistance = chain\n.Select(contract => Math.Abs(contract.Strike - contract.UnderlyingLastPrice))\n.Min();\nvar contractSymbol = chain\n.Where(contract => Math.Abs(contract.Strike - contract.UnderlyingLastPrice) == targetStrikeDistance)\n.OrderBy(contract => contract.ImpliedVolatility)\n.Last()\n.Symbol;\n\n// Add the target contract.\nqb.AddOptionContract(contractSymbol, fillForward: false);\n\n// Get the contract's open interest history.\nvar history = qb.History<OpenInterest>(contractSymbol, TimeSpan.FromDays(90));\n\n// Plot the open interest history.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x.EndTime),\nhistory.Select(x => x.Value)\n);\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Open Interest\");\nTitle title = Title.init($\"{contractSymbol.Value} Open Interest\");\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\nchart.WithLayout(layout);\nHTML(GenericChart.toChartHTML(chart))",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.4",
      "breadcrumb": "Datasets > Equity Options > Individual Contracts",
      "section_number": "3.4.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.5",
    "title": "Crypto",
    "level": 2,
    "path": "Datasets > Crypto",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Crypto data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a Crypto security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Crypto;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()(Optional)Set the time zoneto thedata time zone.qb.set_time_zone(TimeZones.UTC);qb.set_time_zone(TimeZones.UTC)Call theAddCryptoadd_cryptomethod with a ticker and then save a reference to the CryptoSymbol.var btcusd = qb.AddCrypto(\"BTCUSD\").Symbol;\nvar ethusd = qb.AddCrypto(\"ETHUSD\").Symbol;btcusd = qb.add_crypto(\"BTCUSD\").symbol\nethusd = qb.add_crypto(\"ETHUSD\").symbol\n\nTo view the supported assets in the Crypto datasets, see theSupported Assetssection of theCoinAPI dataset listings.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the security dimension, you can request historical data for a single Cryptocurrency, a subset of the Cryptocurrencies you created subscriptions for in your notebook, or all of the Cryptocurrencies in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, 10);\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, 10);\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, 10);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, 10);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, 10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, 10)\nsubset_history_df = qb.history([btcusd, ethusd], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, 10)\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], 10)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), 10)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, 10)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], 10)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, 10)\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], 10)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), 10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, TimeSpan.FromDays(3));\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3));\nvar allHistoryTradeBars = qb.History<TradeBar>(TimeSpan.FromDays(3));\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(btcusd, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3), Resolution.Tick);var allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, timedelta(days=3))\nsubset_history_df = qb.history([btcusd, ethusd], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, timedelta(days=3))\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], timedelta(days=3))\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, timedelta(days=3))\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], timedelta(days=3))\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(btcusd, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([btcusd, ethusd], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, timedelta(days=3))\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], timedelta(days=3))\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](btcusd, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([btcusd, ethusd], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, startTime, endTime);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, startTime, endTime);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(btcusd, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {btcusd, ethusd}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, start_time, end_time)\nsubset_history_df = qb.history([btcusd, ethusd], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, start_time, end_time)\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], start_time, end_time)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, start_time, end_time)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], start_time, end_time)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(btcusd, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([btcusd, ethusd], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, start_time, end_time)\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], start_time, end_time)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), start_time, end_time)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](btcusd, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([btcusd, ethusd], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Crypto subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe followingMarketenumeration members are available for Crypto:\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded Crypto Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single Crypto, index thelocproperty of theDataFramewith the CryptoSymbol.\n\nall_history_df.loc[btcusd]  # or all_history_df.loc['BTCUSD']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[btcusd]['close']\n\nIf you request historical data for multiple Crypto pairs, you can transform theDataFrameso that it's a time series of close values for all of the Crypto pairs. To transform theDataFrame, select the column you want to display for each Crypto pair and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each Crypto pair and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[btcusd].EndTime)),\nnew DecimalDataFrameColumn(\"BTCUSD Open\", history.Select(x => x[btcusd].Open)),\nnew DecimalDataFrameColumn(\"BTCUSD High\", history.Select(x => x[btcusd].High)),\nnew DecimalDataFrameColumn(\"BTCUSD Low\", history.Select(x => x[btcusd].Low)),\nnew DecimalDataFrameColumn(\"BTCUSD Close\", history.Select(x => x[btcusd].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"BTCUSD close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Crypto subscriptions. To avoid issues, check if theSlicecontains data for your Crypto pair before you index it with the CryptoSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.Bars.ContainsKey(btcusd))\n{\nvar tradeBar = slice.Bars[btcusd];\n}\nif (slice.QuoteBars.ContainsKey(btcusd))\n{\nvar quoteBar = slice.QuoteBars[btcusd];\n}\n}for slice in all_history_slice:\nif slice.bars.contains_key(btcusd):\ntrade_bar = slice.bars[btcusd]\nif slice.quote_bars.contains_key(btcusd):\nquote_bar = slice.quote_bars[btcusd]\n\n-- ---\n\nYou can also iterate through eachTradeBarandQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.Bars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.bars:\nsymbol = kvp.key\ntrade_bar = kvp.value\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachTradeBarin theSlicefor a givenSymbol.\n\nvar tradeBars = allHistorySlice.Where(slice => slice.Bars.ContainsKey(btcusd)).Select(slice => slice.Bars[btcusd]);\n\n-- ---\n\nTradeBar Objects\n\nIf theHistoryhistorymethod returnsTradeBarobjects, iterate through theTradeBarobjects to get each one.\n\nforeach (var tradeBar in singleHistoryTradeBars)\n{\nConsole.WriteLine(tradeBar);\n}for trade_bar in single_history_trade_bars:\nprint(trade_bar)\n\nIf theHistoryhistorymethod returnsTradeBars, iterate through theTradeBarsto get theTradeBarof each Crypto pair. TheTradeBarsmay not have data for all of your Crypto subscriptions. To avoid issues, check if theTradeBarsobject contains data for your security before you index it with the CryptoSymbol.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nif (tradeBars.ContainsKey(btcusd))\n{\nvar tradeBar = tradeBars[btcusd];\n}\n}for trade_bars in all_history_trade_bars:\nif trade_bars.contains_key(btcusd):\ntrade_bar = trade_bars[btcusd]\n\nYou can also iterate through each of theTradeBars.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nforeach (var kvp in tradeBars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for trade_bars in all_history_trade_bars:\nfor kvp in trade_bars:\nsymbol = kvp.Key\ntrade_bar = kvp.Value\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each Crypto pair. TheQuoteBarsmay not have data for all of your Crypto subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the CryptoSymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(btcusd))\n{\nvar quoteBar = quoteBars[btcusd];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(btcusd):\nquote_bar = quote_bars[btcusd]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Crypto pair. TheTicksmay not have data for all of your Crypto subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the CryptoSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(btcusd))\n{\nvar tick = ticks[btcusd];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(btcusd):\nticks = ticks[btcusd]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical Crypto datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(btcusd, datetime(2020, 12, 27), datetime(2021, 12, 21), Resolution.DAILY).loc[btcusd]var history = qb.History<TradeBar>(btcusd, new DateTime(2020, 12, 27), new DateTime(2021, 12, 21), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='BTCUSD OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{btcusd} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([btcusd, ethusd], datetime(2020, 12, 27), datetime(2021, 12, 21), Resolution.DAILY)var history = qb.History<TradeBar>(new[] {btcusd, ethusd}, new DateTime(2020, 12, 27), new DateTime(2021, 12, 21), Resolution.Daily);Select the data to plot.volume = history['volume'].unstack(level=0)Call theplotmethod on thepandasobject.volume.plot(title=\"Volume\", figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[btcusd].EndTime),\nhistory.Select(x => x[btcusd].Volume),\nName: \"BTCUSD\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[ethusd].EndTime),\nhistory.Select(x => x[ethusd].Volume),\nName: \"ETHUSD\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Volume\");\nTitle title = Title.init(\"BTCUSD & ETHUSD Volume\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Crypto dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the BTCUSD. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the BTCUSD historical data.\nvar symbol = qb.AddCrypto(\"BTCUSD\", market: Market.Coinbase).Symbol;\nvar history = qb.History<TradeBar>(symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<TradeBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => x.Open),\nwindow.Select(x => x.High),\nwindow.Select(x => x.Low),\nwindow.Select(x => x.Close),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request SPY's historical data.\nsymbol = qb.add_crypto(\"BTCUSD\", market=Market.COINBASE).symbol\nhistory = qb.history(symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Crypto",
      "section_number": "3.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.6",
    "title": "Crypto Futures",
    "level": 2,
    "path": "Datasets > Crypto Futures",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Crypto Futures data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a perpetual Crypto Futures contract:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.CryptoFuture;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()(Optional)Set the time zoneto thedata time zone.qb.set_time_zone(TimeZones.UTC);qb.set_time_zone(TimeZones.UTC)Call theAddCryptoFutureadd_crypto_futuremethod with a ticker and then save a reference to the Crypto FutureSymbol.var btcusd = qb.AddCryptoFuture(\"BTCUSD\").Symbol;\nvar ethusd = qb.AddCryptoFuture(\"ETHUSD\").Symbol;btcusd = qb.add_crypto_future(\"BTCUSD\").symbol\nethusd = qb.add_crypto_future(\"ETHUSD\").symbol\n\nTo view the supported assets in the Crypto Futures datasets, see theData Explorer.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. You can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. You can also request historical data for a single contract, a subset of the contracts you created subscriptions for in your notebook, or all of the contracts in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, 10);\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, 10);\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, 10);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, 10);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, 10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, 10)\nsubset_history_df = qb.history([btcusd, ethusd], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, 10)\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], 10)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), 10)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, 10)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], 10)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, 10)\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], 10)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), 10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, TimeSpan.FromDays(3));\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3));\nvar allHistoryTradeBars = qb.History<TradeBar>(TimeSpan.FromDays(3));\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(btcusd, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {btcusd, ethusd}, TimeSpan.FromDays(3), Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, timedelta(days=3))\nsubset_history_df = qb.history([btcusd, ethusd], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, timedelta(days=3))\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], timedelta(days=3))\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, timedelta(days=3))\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], timedelta(days=3))\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(btcusd, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([btcusd, ethusd], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, timedelta(days=3))\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], timedelta(days=3))\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](btcusd, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([btcusd, ethusd], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(btcusd, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {btcusd, ethusd}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(btcusd, startTime, endTime);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {btcusd, ethusd}, startTime, endTime);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(btcusd, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {btcusd, ethusd}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(btcusd, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {btcusd, ethusd}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of trade and quote data\nsingle_history_df = qb.history(btcusd, start_time, end_time)\nsubset_history_df = qb.history([btcusd, ethusd], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, btcusd, start_time, end_time)\nsubset_history_trade_bar_df = qb.history(TradeBar, [btcusd, ethusd], start_time, end_time)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, btcusd, start_time, end_time)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [btcusd, ethusd], start_time, end_time)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(btcusd, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([btcusd, ethusd], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](btcusd, start_time, end_time)\nsubset_history_trade_bars = qb.history[TradeBar]([btcusd, ethusd], start_time, end_time)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), start_time, end_time)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](btcusd, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([btcusd, ethusd], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](btcusd, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([btcusd, ethusd], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Crypto Futures contract subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe followingMarketenumeration members are available for Cryptofuture:\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded Crypto Future Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single Crypto Future, index thelocproperty of theDataFramewith the Crypto FutureSymbol.\n\nall_history_df.loc[btcusd]  # or all_history_df.loc['BTCUSD']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[btcusd]['close']\n\nIf you request historical data for multiple Crypto Futures contracts, you can transform theDataFrameso that it's a time series of close values for all of the Crypto Futures contracts. To transform theDataFrame, select the column you want to display for each Crypto Futures contract and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each Crypto Futures contract and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[btcusd].EndTime)),\nnew DecimalDataFrameColumn(\"BTCUSD Open\", history.Select(x => x[btcusd].Open)),\nnew DecimalDataFrameColumn(\"BTCUSD High\", history.Select(x => x[btcusd].High)),\nnew DecimalDataFrameColumn(\"BTCUSD Low\", history.Select(x => x[btcusd].Low)),\nnew DecimalDataFrameColumn(\"BTCUSD Close\", history.Select(x => x[btcusd].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"BTCUSD close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Crypto Future subscriptions. To avoid issues, check if theSlicecontains data for your Crypto Futures contract before you index it with the Crypto FutureSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.Bars.ContainsKey(btcusd))\n{\nvar tradeBar = slice.Bars[btcusd];\n}\nif (slice.QuoteBars.ContainsKey(btcusd))\n{\nvar quoteBar = slice.QuoteBars[btcusd];\n}\n}for slice in all_history_slice:\nif slice.bars.contains_key(btcusd):\ntrade_bar = slice.bars[btcusd]\nif slice.quote_bars.contains_key(btcusd):\nquote_bar = slice.quote_bars[btcusd]\n\n-- ---\n\nYou can also iterate through eachTradeBarandQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.Bars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.bars:\nsymbol = kvp.key\ntrade_bar = kvp.value\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachTradeBarin theSlicefor a givenSymbol.\n\nvar tradeBars = allHistorySlice.Where(slice => slice.Bars.ContainsKey(btcusd)).Select(slice => slice.Bars[btcusd]);\n\n-- ---\n\nTradeBar Objects\n\nIf theHistoryhistorymethod returnsTradeBarobjects, iterate through theTradeBarobjects to get each one.\n\nforeach (var tradeBar in singleHistoryTradeBars)\n{\nConsole.WriteLine(tradeBar);\n}for trade_bar in single_history_trade_bars:\nprint(trade_bar)\n\nIf theHistoryhistorymethod returnsTradeBars, iterate through theTradeBarsto get theTradeBarof each Crypto Futures contract. TheTradeBarsmay not have data for all of your Crypto Future subscriptions. To avoid issues, check if theTradeBarsobject contains data for your security before you index it with the Crypto FutureSymbol.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nif (tradeBars.ContainsKey(btcusd))\n{\nvar tradeBar = tradeBars[btcusd];\n}\n}for trade_bars in all_history_trade_bars:\nif trade_bars.contains_key(btcusd):\ntrade_bar = trade_bars[btcusd]\n\nYou can also iterate through each of theTradeBars.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nforeach (var kvp in tradeBars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for trade_bars in all_history_trade_bars:\nfor kvp in trade_bars:\nsymbol = kvp.Key\ntrade_bar = kvp.Value\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each Crypto Futures contract. TheQuoteBarsmay not have data for all of your Crypto Future subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the Crypto FutureSymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(btcusd))\n{\nvar quoteBar = quoteBars[btcusd];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(btcusd):\nquote_bar = quote_bars[btcusd]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Crypto Futures contract. TheTicksmay not have data for all of your Crypto Future subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the Crypto FutureSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(btcusd))\n{\nvar tick = ticks[btcusd];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(btcusd):\nticks = ticks[btcusd]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical Crypto Futures datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(btcusd, datetime(2021, 11, 23), datetime(2021, 12, 8), Resolution.DAILY).loc[btcusd]var history = qb.History<TradeBar>(btcusd, new DateTime(2021, 11, 23), new DateTime(2021, 12, 8), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='BTCUSD 18R OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init(\"BTCUSD 18R OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([btcusd, ethusd], datetime(2021, 11, 23), datetime(2021, 12, 8), Resolution.DAILY)var history = qb.history(new List<Symbol> { btcusd, ethusd }, new DateTime(2021, 11, 23), new DateTime(2021, 12, 8), Resolution.DAILY);Select the data to plot.volume = history['volume'].unstack(level=0)Call theplotmethod on thepandasobject.volume.plot(title=\"Volume\", figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[btcusd].EndTime),\nhistory.Select(x => x[btcusd].Volume),\nName: \"BTCUSD 18R\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[ethusd].EndTime),\nhistory.Select(x => x[ethusd].Volume),\nName: \"ETHUSD 18R\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Volume\");\nTitle title = Title.init(\"BTCUSD 18R & ETHUSD 18R Volume\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Crypto dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the BTCUSDT Future. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the BTCUSDT Future historical data.\nvar symbol = qb.AddCryptoFuture(\"BTCUSDT\", market: Market.Binance).Symbol;\nvar history = qb.History<TradeBar>(symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<TradeBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => x.Open),\nwindow.Select(x => x.High),\nwindow.Select(x => x.Low),\nwindow.Select(x => x.Close),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request the BTCUSDT Future historical data.\nsymbol = qb.add_crypto_future(\"BTCUSDT\", market=Market.BINANCE).symbol\nhistory = qb.history(symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Crypto Futures",
      "section_number": "3.6",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.7",
    "title": "Futures",
    "level": 2,
    "path": "Datasets > Futures",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Futures data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a Future security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Future;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddFutureadd_futuremethod with a ticker, resolution, andcontract rollover settings.var future = qb.AddFuture(Futures.Indices.SP500EMini, Resolution.Minute,\ndataNormalizationMode: DataNormalizationMode.BackwardsRatio,\ndataMappingMode: DataMappingMode.LastTradingDay,\ncontractDepthOffset: 0);future = qb.add_future(Futures.Indices.SP_500_E_MINI, Resolution.MINUTE,\ndata_normalization_mode = DataNormalizationMode.BACKWARDS_RATIO,\ndata_mapping_mode = DataMappingMode.LAST_TRADING_DAY,\ncontract_depth_offset = 0)To view the available tickers in the US Futures dataset, seeSupported Assets.If you omit any of the arguments after the ticker, see the following table for their default values:ArgumentDefault ValueresolutionResolution.MinuteResolution.MINUTEdataNormalizationModedata_normalization_modeDataNormalizationMode.AdjustedDataNormalizationMode.ADJUSTEDdataMappingModedata_mapping_modeDataMappingMode.OpenInterestcontractDepthOffsetcontract_depth_offset0(Optional)Set acontract filter.future.set_filter(0, 90);future.set_filter(0, 90)If you don't call theSetFilterset_filtermethod, theFutureHistoryfuture_historymethod won't return historical data.\n\nIf you want historical data on individual contracts and theirOpenInterest, follow these steps to subscribe to individual Future contracts:\n\nCall theGetFuturesContractListmethod with the underlyingFutureSymboland adatetimeDateTime.var startDate = new DateTime(2021,12,20);\nvar symbols = qb.FutureChainProvider.GetFutureContractList(future.Symbol, startDate);start_date = datetime(2021,12,20)\nsymbols = qb.future_chain_provider.get_future_contract_list(future.symbol, start_date)This method returns a list ofSymbolobjects that reference the Future contracts that were trading at the given time. If you set a contract filter withSetFilterset_filter, it doesn't affect the results ofGetFutureContractListget_future_contract_list.Select theSymbolof theFutureContractobject(s) for which you want to get historical data.For example, select theSymbolof the contract with the closest expiry.var contractSymbol = symbols.OrderBy(s => s.ID.Date).FirstOrDefault();contract_symbol = sorted(symbols, key=lambda s: s.id.date)[0]Call theAddFutureContractadd_future_contractmethod with anFutureContractSymboland disable fill-forward.qb.AddFutureContract(contractSymbol, fillForward: false);qb.add_future_contract(contract_symbol, fill_forward = False)Disable fill-forward because there are only a fewOpenInterestdata points per day.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for Futures contracts. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the contract dimension, you can request historical data for a single contract, a subset of the contracts you created subscriptions for in your notebook, or all of the contracts in your notebook.\n\nThese history requests return the prices and open interest of the Option contracts. They don't provide the implied volatility or Greeks. To get the implied volaility and Greeks, call theOptionChainoption_chainmethod or create someindicators.\n\nBefore you request historical data, call theSetStartDateset_start_datemethod with adatetimeDateTimeto reduce the risk oflook-ahead bias.\n\nqb.SetStartDate(startDate);qb.set_start_date(start_date)\n\nIf you call theSetStartDateset_start_datemethod, the date that you pass to the method is the latest date for which your history requests will return data.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with the contractSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(contractSymbol, 10);\nvar subsetHistorySlice = qb.History(new[] {contractSymbol}, 10);\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(contractSymbol, 10);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {contractSymbol}, 10);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, 10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(contractSymbol, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {contractSymbol}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);\n\n// OpenInterest objects\nvar singleHistoryOpenInterest = qb.History<OpenInterest>(contractSymbol, 400);\nvar subsetHistoryOpenInterest = qb.History<OpenInterest>(new[] {contractSymbol}, 400);\nvar allHistoryOpenInterest = qb.History<OpenInterest>(qb.Securities.Keys, 400);# DataFrame of trade and quote data\nsingle_history_df = qb.history(contract_symbol, 10)\nsubset_history_df = qb.history([contract_symbol], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, contract_symbol, 10)\nsubset_history_trade_bar_df = qb.history(TradeBar, [contract_symbol], 10)s\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), 10)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, contract_symbol, 10)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [contract_symbol], 10)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), 10)\n\n# DataFrame of open interest data\nsingle_history_open_interest_df = qb.history(OpenInterest, contract_symbol, 400)\nsubset_history_open_interest_df = qb.history(OpenInterest, [contract_symbol], 400)\nall_history_open_interest_df = qb.history(OpenInterest, qb.securities.keys(), 400)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](contract_symbol, 10)\nsubset_history_trade_bars = qb.history[TradeBar]([contract_symbol], 10)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), 10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](contract_symbol, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([contract_symbol], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\n# OpenInterest objects\nsingle_history_open_interest = qb.history[OpenInterest](contract_symbol, 400)\nsubset_history_open_interest = qb.history[OpenInterest]([contract_symbol], 400)\nall_history_open_interest = qb.history[OpenInterest](qb.securities.keys(), 400)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTo get historical data for the continous Futures contract, in the preceding history requests, replacecontract_symbolcontractSymbolwithfuture.Symbol.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with the contractSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(contractSymbol, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {contractSymbol}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(contractSymbol, TimeSpan.FromDays(3));\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {contractSymbol}, TimeSpan.FromDays(3));\nvar allHistoryTradeBars = qb.History<TradeBar>(TimeSpan.FromDays(3));\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(contractSymbol, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {contractSymbol}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History(contractSymbol, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History(new[] {contractSymbol}, TimeSpan.FromDays(3), Resolution.Tick);\nvar allHistoryTicks = qb.History(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);\n\n// OpenInterest objects\nvar singleHistoryOpenInterest = qb.History<OpenInterest>(contractSymbol, TimeSpan.FromDays(2));\nvar subsetHistoryOpenInterest = qb.History<OpenInterest>(new[] {contractSymbol}, TimeSpan.FromDays(2));\nvar allHistoryOpenInterest = qb.History<OpenInterest>(qb.Securities.Keys, TimeSpan.FromDays(2));# DataFrame of trade and quote data\nsingle_history_df = qb.history(contract_symbol, timedelta(days=3))\nsubset_history_df = qb.history([contract_symbol], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, contract_symbol, timedelta(days=3))\nsubset_history_trade_bar_df = qb.history(TradeBar, [contract_symbol], timedelta(days=3))\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, contract_symbol, timedelta(days=3))\nsubset_history_quote_bar_df = qb.history(QuoteBar, [contract_symbol], timedelta(days=3))\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of open interest data\nsingle_history_open_interest_df = qb.history(OpenInterest, contract_symbol, timedelta(days=3))\nsubset_history_open_interest_df = qb.history(OpenInterest, [contract_symbol], timedelta(days=3))\nall_history_open_interest_df = qb.history(OpenInterest, qb.securities.keys(), timedelta(days=3))\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](contract_symbol, timedelta(days=3))\nsubset_history_trade_bars = qb.history[TradeBar]([contract_symbol], timedelta(days=3))\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](contract_symbol, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([contract_symbol], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](contract_symbol, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([contract_symbol], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# OpenInterest objects\nsingle_history_open_interest = qb.history[OpenInterest](contract_symbol, timedelta(days=2))\nsubset_history_open_interest = qb.history[OpenInterest]([contract_symbol], timedelta(days=2))\nall_history_open_interest = qb.history[OpenInterest](qb.securities.keys(), timedelta(days=2))\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTo get historical data for the continous Futures contract, in the preceding history requests, replacecontract_symbolcontractSymbolwithfuture.Symbol.\n\nDefined Period of Time\n\nTo get historical data for individual Futures contracts during a specific period of time, call theHistoryhistorymethod with the Futures contractSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime.  The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 12, 1);\nvar endTime = new DateTime(2021, 12, 31);\n\n// Slice objects\nvar singleHistorySlice = qb.History(contractSymbol, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {contractSymbol}, startTime, endTime);\nvar allHistorySlice = qb.History(startTime, endTime);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(contractSymbol, startTime, endTime);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {contractSymbol}, startTime, endTime);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(contractSymbol, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {contractSymbol}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(contractSymbol, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {contractSymbol}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);\n\n// OpenInterest objects\nvar singleHistoryOpenInterest = qb.History<OpenInterest>(contractSymbol, startTime, endTime);\nvar subsetHistoryOpenInterest = qb.History<OpenInterest>(new[] {contractSymbol}, startTime, endTime);\nvar allHistoryOpenInterest = qb.History<OpenInterest>(qb.Securities.Keys, startTime, endTime);start_time = datetime(2021, 12, 1)\nend_time = datetime(2021, 12, 31)\n\n# DataFrame of trade and quote data\nsingle_history_df = qb.history(contract_symbol, start_time, end_time)\nsubset_history_df = qb.history([contract_symbol], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of trade data\nsingle_history_trade_bar_df = qb.history(TradeBar, contract_symbol, start_time, end_time)\nsubset_history_trade_bar_df = qb.history(TradeBar, [contract_symbol], start_time, end_time)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of quote data\nsingle_history_quote_bar_df = qb.history(QuoteBar, contract_symbol, start_time, end_time)\nsubset_history_quote_bar_df = qb.history(QuoteBar, [contract_symbol], start_time, end_time)\nall_history_quote_bar_df = qb.history(QuoteBar, qb.securities.keys(), start_time, end_time)\n\n# DataFrame of open interest data\nsingle_history_open_interest_df = qb.history(OpenInterest, contract_symbol, start_time, end_time)\nsubset_history_open_interest_df = qb.history(OpenInterest, [contract_symbol], start_time, end_time)\nall_history_trade_open_interest_df = qb.history(OpenInterest, qb.securities.keys(), start_time, end_time)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](contract_symbol, start_time, end_time)\nsubset_history_trade_bars = qb.history[TradeBar]([contract_symbol], start_time, end_time)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), start_time, end_time)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](contract_symbol, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([contract_symbol], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](contract_symbol, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([contract_symbol], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# OpenInterest objects\nsingle_history_open_interest = qb.history[OpenInterest](contract_symbol, start_time, end_time)\nsubset_history_open_interest = qb.history[OpenInterest]([contract_symbol], start_time, end_time)\nall_history_open_interest = qb.history[OpenInterest](qb.securities.keys(), start_time, end_time)\n\nTo get historical data for the continous Futures contract, in the preceding history requests, replacecontract_symbolcontractSymbolwithfuture.Symbol.\n\nTo get historical data for all of the Futures contracts that pass yourfilterduring a specific period of time, call theFutureHistoryfuture_historymethod with theSymbolobject of the continuous Future, a startDateTimedatetime, and an endDateTimedatetime.\n\nfuture_history = qb.future_history(future.Symbol, end_time-timedelta(days=2), end_time, Resolution.MINUTE, fill_forward=False, extended_market_hours=False)var futureHistory = qb.FutureHistory(future.Symbol, endTime-TimeSpan.FromDays(2), endTime, Resolution.Minute, fillForward: False, extendedMarketHours: False);\n\nThe preceding calls return data that have a timestamp within the defined period of time.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Futures subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe followingMarketenumeration members are available for Futures:\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request for Futures contracts. If you change the data normalization mode, it won't change the outcome.\n\nThe following data normalization modes are available forcontinuous Futures contracts:\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf your history request returns aDataFrame, theDataFramehas the following index levels:\n\nContract expiryEncoded contract SymbolTheEndTimeend_timeof the data sample\n\nThe columns of theDataFrameare the data properties. Depending on how you request data, theDataFramemay contain data for the continuous Futures contract. The continuous contract doesn't expire, so the default expiry date of December 30, 1899 doesn't have any practical meaning.\n\nTo select the rows of the contract(s) that expire at a specific time, index thelocproperty of theDataFramewith the expiry time.\n\nall_history_df.loc[datetime(2022, 3, 18, 13, 30)]\n\nIf you remove the first index level, you can index theDataFramewith just the contractSymbol, similiar to how you would with non-derivative asset classes. To remove the first index level, call thedroplevelmethod.\n\nall_history_df.index = all_history_df.index.droplevel(0)\n\nTo select the historical data of a single Futures contract, index thelocproperty of theDataFramewith the contractSymbol.\n\nall_history_df.loc[contract_symbol]\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[contract_symbol]['close']\n\nIf you request historical data for multiple Futures contracts, you can transform theDataFrameso that it's a time series of close values for all of the Futures contracts. To transform theDataFrame, select the column you want to display for each Futures contract and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each security and each row contains the close  value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[contractSymbol].EndTime)),\nnew DecimalDataFrameColumn(\" Open\", history.Select(x => x[contractSymbol].Open)),\nnew DecimalDataFrameColumn(\" High\", history.Select(x => x[contractSymbol].High)),\nnew DecimalDataFrameColumn(\" Low\", history.Select(x => x[contractSymbol].Low)),\nnew DecimalDataFrameColumn(\" Close\", history.Select(x => x[contractSymbol].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\" close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Futures subscriptions. To avoid issues, check if theSlicecontains data for your Futures contract before you index it with the FuturesSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.Bars.ContainsKey(contractSymbol))\n{\nvar tradeBar = slice.Bars[contractSymbol];\n}\nif (slice.QuoteBars.ContainsKey(contractSymbol))\n{\nvar quoteBar = slice.QuoteBars[contractSymbol];\n}\n}for slice in all_history_slice:\nif slice.bars.contains_key(contract_symbol):\ntrade_bar = slice.bars[contract_symbol]\nif slice.quote_bars.contains_key(contract_symbol):\nquote_bar = slice.quote_bars[contract_symbol]\n\n-- ---\n\nYou can also iterate through eachTradeBarandQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.Bars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.bars:\nsymbol = kvp.key\ntrade_bar = kvp.value\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachTradeBarin theSlicefor a givenSymbol.\n\nvar tradeBars = allHistorySlice.Where(slice => slice.Bars.ContainsKey(contractSymbol)).Select(slice => slice.Bars[contractSymbol]);\n\n-- ---\n\nTradeBar Objects\n\nIf theHistoryhistorymethod returnsTradeBarobjects, iterate through theTradeBarobjects to get each one.\n\nforeach (var tradeBar in singleHistoryTradeBars)\n{\nConsole.WriteLine(tradeBar);\n}for trade_bar in single_history_trade_bars:\nprint(trade_bar)\n\nIf theHistoryhistorymethod returnsTradeBars, iterate through theTradeBarsto get theTradeBarof each Futures contract. TheTradeBarsmay not have data for all of your Futures subscriptions. To avoid issues, check if theTradeBarsobject contains data for your security before you index it with the FuturesSymbol.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nif (tradeBars.ContainsKey(contractSymbol))\n{\nvar tradeBar = tradeBars[contractSymbol];\n}\n}for trade_bars in all_history_trade_bars:\nif trade_bars.contains_key(contract_symbol):\ntrade_bar = trade_bars[contract_symbol]\n\nYou can also iterate through each of theTradeBars.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nforeach (var kvp in tradeBars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for trade_bars in all_history_trade_bars:\nfor kvp in trade_bars:\nsymbol = kvp.Key\ntrade_bar = kvp.Value\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each Futures contract. TheQuoteBarsmay not have data for all of your Futures subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the FuturesSymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(contractSymbol))\n{\nvar quoteBar = quoteBars[contractSymbol];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(contract_symbol):\nquote_bar = quote_bars[contract_symbol]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Futures contract. TheTicksmay not have data for all of your Futures subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the FuturesSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(contractSymbol))\n{\nvar tick = ticks[contractSymbol];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(contract_symbol):\nticks = ticks[contract_symbol]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\nOpenInterest Objects\n\nIf theHistoryhistorymethod returnsOpenInterestobjects, iterate through theOpenInterestobjects to get each one.\n\nforeach (var openInterest in singleHistoryOpenInterest)\n{\nConsole.WriteLine(openInterest);\n}for open_interest in single_history_open_interest:\nprint(open_interest)\n\nIf theHistoryhistorymethod returns a dictionary ofOpenInterestobjects, iterate through the dictionary to get theOpenInterestof each Futures contract. The dictionary ofOpenInterestobjects may not have data for all of your Futures contract subscriptions. To avoid issues, check if the dictionary contains data for your contract before you index it with the Futures contractSymbol.\n\nforeach (var openInterestDict in allHistoryOpenInterest)\n{\nif (openInterestDict.ContainsKey(contractSymbol))\n{\nvar openInterest = openInterestDict[contractSymbol];\n}\n}for open_interest_dict in all_history_open_interest:\nif open_interest_dict.contains_key(contract_symbol):\nopen_interest = open_interest_dict[contract_symbol]\n\nYou can also iterate through each of theOpenInterestdictionaries.\n\nforeach (var openInterestDict in allHistoryOpenInterest)\n{\nforeach (var kvp in openInterestDict)\n{\nvar symbol = kvp.Key;\nvar openInterest = kvp.Value;\n}\n}for open_interest_dict in all_history_open_interest:\nfor kvp in open_interest_dict:\nsymbol = kvp.key\nopen_interest = kvp.value\n\n-- ---\n\n-- ---\n\nFutureHistory Objects\n\nTheFutureHistoryfuture_historymethod returns aFutureHistoryobject. To get eachslicein theFutureHistoryobject, iterate through it.\n\nforeach (var slice in futureHistory)\n{\nforeach (var kvp in slice.FuturesChains)\n{\nvar continuousContractSymbol = kvp.Key;\nvar chain = kvp.Value;\nforeach (var contract in chain)\n{\n\n}\n}\n}for slice in future_history:\nfor continuous_contract_symbol, chain in slice.futures_chains.items():\nfor contract in chain:\npass\n\nTo convert theFutureHistoryobject to aDataFramethat contains the trade and quote information of each contract, call theGetAllDatamethod.\n\nfuture_history.get_all_data()\n\nTo get the expiration dates of all the contracts in anFutureHistoryobject, call theGetExpiryDatesmethod.\n\nfuture_history.get_expiry_dates()\n\n### Plot Data\n\nYou need somehistorical Futures datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(contract_symbol, datetime(2021, 12, 1), datetime(2021, 12, 31), Resolution.DAILY)var history = qb.History<TradeBar>(contractSymbol, new DateTime(2021, 12, 1), new DateTime(2021, 12, 31), Resolution.Daily);Drop the first two index levels.history.index = history.index.droplevel([0, 1])Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text=f'{contract_symbol.value} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{contractSymbol} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the contract.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history(symbols, datetime(2021, 12, 1), datetime(2021, 12, 31), Resolution.DAILY)var history = qb.History<OpenInterest>(contractSymbol, new DateTime(2021, 12, 1), new DateTime(2021, 12, 31));Drop the first index level.history.index = history.index.droplevel(0)Select data to plot.closing_prices = history['close'].unstack(level=0)Rename the columns to be theSymbolof each contract.closing_prices.columns = [Symbol.get_alias(SecurityIdentifier.parse(x)) for x in closing_prices.columns]Call theplotmethod on thepandasobject.closing_prices.plot(title=\"Close\", figsize=(15, 8))CreateLinecharts.var chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x.EndTime),\nhistory.Select(x => x.Value)\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Open Interest\");\nTitle title = Title.init($\"{contractSymbol} Open Interest\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Assign theLayoutto the chart.chart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Futures dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the ES Future. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the continuous future historical data.\nvar future = qb.AddFuture(Futures.Indices.SP500EMini);\nvar history = qb.History<TradeBar>(future.Symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute,\nfillForward: true,\nextendedMarketHours: true,\ndataMappingMode: DataMappingMode.OpenInterest,\ndataNormalizationMode: DataNormalizationMode.BackwardsRatio,\ncontractDepthOffset: 0);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<QuoteBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => x.Open),\nwindow.Select(x => x.High),\nwindow.Select(x => x.Low),\nwindow.Select(x => x.Close),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{future.Symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request the continuous future historical data.\n# Use raw normalization mode to fairly compare the actual bid and ask dollar volume.\nfuture = qb.add_future(Futures.Indices.SP_500_E_MINI)\nhistory = qb.history(future.symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE,\nfill_forward=True,\nextended_market_hours=True,\ndata_mapping_mode=DataMappingMode.OPEN_INTEREST,\ndata_normalization_mode=DataNormalizationMode.BACKWARDS_RATIO,\ncontract_depth_offset=0)\n\n# Drop level 0, 1 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0, 1])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{future.symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Futures",
      "section_number": "3.7",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.8",
    "title": "Futures Options",
    "level": 2,
    "path": "Datasets > Futures Options",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Futures Options",
      "section_number": "3.8",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.8.1",
    "title": "Key Concepts",
    "level": 3,
    "path": "Datasets > Futures Options > Key Concepts",
    "content": "### Introduction\n\nFuture Option contracts give the buyer a window of opportunity to buy or sell the underlying Future contract at a specific price.\nThis page explains the basics of Future Option data in the Research Environment.\nTo get some data, seeUniversesorIndividual Contracts.\nFor more information about the specific datasets we use, see theUS Future Optionsdataset listing.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Future Option contract subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe followingMarketenumeration members are available for Future Options:\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3.8",
      "breadcrumb": "Datasets > Futures Options > Key Concepts",
      "section_number": "3.8.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.8.2",
    "title": "Universes",
    "level": 3,
    "path": "Datasets > Futures Options > Universes",
    "content": "### Introduction\n\nThis page explains how to request historical data for a universe of Future Option contracts.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a Futures Options universe:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities;\nusing QuantConnect.Data.UniverseSelection;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Add the underlying Future.var future = qb.AddFuture(Futures.Indices.SP500EMini);future = qb.add_future(Futures.Indices.SP_500_E_MINI)To view the available underlying Futures in the US Future Options dataset, seeSupported Assets.\n\n### Price History\n\nThecontract filterdetermines which Future Option contracts are in your universe each trading day.\nThe default filter selects the contracts with the following characteristics:\n\nStandard type (weeklies and non-standard contracts are not available)Within 1 strike price of the underlying asset priceExpire within 35 days\n\nTo get the prices and volumes for all of the Future Option contracts that pass your filter during a specific period of time, get the underlying Future contract and then call theOptionHistoryoption_historymethod with the Future contract'sSymbolobject, a startDateTimedatetime, and an endDateTimedatetime.\n\nstart_date = datetime(2024, 1, 1)\n\n# Select an underlying Futures contract. For example, get the front-month contract.\nfutures_contract = sorted(\nqb.future_chain_provider.get_future_contract_list(future.symbol, start_date),\nkey=lambda symbol: symbol.id.date\n)[0]\n\n# Get the Options data for the selected Futures contract.\noption_history = qb.option_history(\nfutures_contract, start_date, futures_contract.id.date, Resolution.HOUR,\nfill_forward=False, extended_market_hours=False\n)var startDate = new DateTime(2024, 1, 1);\n\n// Select an underlying Futures contract. For example, get the front-month contract.\nvar futuresContract = qb.FutureChainProvider.GetFutureContractList(future.Symbol, startDate)\n.OrderBy(symbol => symbol.ID.Date)\n.Last();\n\n// Get the Options data for the selected Futures contract.\nvar optionHistory = qb.OptionHistory(\nfuturesContract, startDate, futuresContract.ID.Date, Resolution.Hour,\nfillForward: false, extendedMarketHours: false\n);\n\nTo convert theOptionHistoryobject to aDataFramethat contains the trade and quote information of each contract and the underlying, use thedata_frameproperty.\n\noption_history.data_frame\n\nTo get the expiration dates of all the contracts in anOptionHistoryobject, call theGetExpiryDatesget_expiry_datesmethod.\n\noption_history.get_expiry_dates()\n\nTo get the strike prices of all the contracts in anOptionHistoryobject, call theGetStrikesget_strikesmethod.\n\noption_history.get_strikes()\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Future Options dataset.\n\nExample 1: Implied Volatility Line Chart\n\nThe following example plots a line chart on the implied volatility curve of the cloest expiring calls.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing System.Collections.Generic;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.UniverseSelection;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n// Set the date being studied.\nvar date = new DateTime(2024, 1, 4);\n\n// Subscribe to the underlying Future.\nvar future = qb.AddFuture(Futures.Indices.SP500EMini);\n// Select the front-month contract.\nvar futuresContract = qb.FutureChainProvider.GetFutureContractList(future.Symbol, date)\n.OrderBy(symbol => symbol.ID.Date)\n.First();\n\n// Get the Options data for the selected Futures contract at the selected date.\nvar optionHistory = qb.OptionHistory(\nfuturesContract, date.AddDays(-1), date, Resolution.Daily,\nfillForward: false, extendedMarketHours: false\n).Last();\n\nvar chain = optionHistory.OptionChains.Values.First();\n// Study the closest expiring contracts.\nvar expiry = chain.Min(x => x.Expiry);\n// Filter for the closest expiring calls to study only.\nvar filterContracts = chain.Where(x => x.Expiry == expiry && x.Right == OptionRight.Call).ToList();\n\n// Obtain the strike and IV for plotting the IV curve.\nvar ivByStrike = new Dictionary<decimal, decimal>();\nforeach (var contract in filterContracts)\n{\nvar strike = contract.Strike;\nvar iv = contract.ImpliedVolatility;\nivByStrike[strike] = iv;\n}\n\n// Crete the Line Chart with the PE Ratios.\nvar chart = Chart2D.Chart.Line<decimal, decimal, string>(\nivByStrike.Keys,\nivByStrike.Values\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Strike\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Implied Volatility\");\nTitle title = Title.init($\"IV Curve of {futuresContract}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate a QuantBook instance.\nqb = QuantBook()\n# Set the date being studied.\ndate = datetime(2024, 1, 4)\n\n# Subscribe to the underlying Future.\nfuture = qb.add_future(Futures.Indices.SP_500_E_MINI)\n# Select an underlying Futures contract. For example, get the front-month contract.\nfutures_contract = sorted(\nqb.future_chain_provider.get_future_contract_list(future.symbol, date),\nkey=lambda symbol: symbol.id.date\n)[0]\n# Get the Options data for the selected Futures contract.\noption_history = qb.option_history(\nfutures_contract, date - timedelta(1), date, Resolution.DAILY,\nfill_forward=False, extended_market_hours=False\n)\n\nchain = list(option_history)[-1].OptionChains.values()[0]\n# Study the closest expiring contracts.\nexpiry = min(x.expiry for x in chain)\n# Filter for the closest expiring calls to study only.\nfilter_contracts = [x for x in chain if x.expiry == expiry and x.right == OptionRight.CALL]\n\n# Obtain the strike and IV for plotting the IV curve.\niv_by_strike = pd.Series({x.strike: x.implied_volatility for x in filter_contracts})\niv_by_strike.plot(title=f\"IV Curve of {futures_contract}\", ylabel=\"Implied Volatility\", xlabel=\"Strike\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.8",
      "breadcrumb": "Datasets > Futures Options > Universes",
      "section_number": "3.8.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.8.3",
    "title": "Individual Contracts",
    "level": 3,
    "path": "Datasets > Futures Options > Individual Contracts",
    "content": "### Introduction\n\nThis page explains how to request historical data for individual Future Option contracts.\nThehistory requestson this page only return the prices and open interest of the Option contracts, not their implied volatility or Greeks.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to individual Futures Option contracts:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Add the underlying Futures contract.var future = qb.AddFuture(Futures.Indices.SP500EMini);\nvar startDate = new DateTime(2023, 12, 20);\nvar futuresContractSymbol = qb.FutureChainProvider.GetFutureContractList(future.Symbol, startDate)\n.OrderBy(s => s.ID.Date)\n.FirstOrDefault();\nqb.AddFutureContract(futuresContractSymbol, fillForward: false);future = qb.add_future(Futures.Indices.SP_500_E_MINI)\nstart_date = datetime(2023, 12, 20)\nfutures_contract_symbol = sorted(\nqb.future_chain_provider.get_future_contract_list(future.symbol, start_date),\nkey=lambda s: s.id.date\n)[0]\nqb.add_future_contract(futures_contract_symbol, fill_forward=False)To view the available underlying Futures in the US Future Options dataset, seeSupported Assets.Set the start dateto a date in the past that you want to use as the analysis date.qb.SetStartDate(futuresContractSymbol.ID.Date.AddDays(-5));qb.set_start_date(futures_contract_symbol.id.date - timedelta(5))The method that you call in the next step returns data on all the contracts that were tradable on this date.Call theOptionChainoption_chainmethod with the underlying Futures contractSymbol.var chain = qb.OptionChain(futuresContractSymbol);chain = qb.option_chain(futures_contract_symbol, flatten=True).data_frameThis method returns anOptionChainobject, which represent an entire chain of Option contracts for a single underlying security.You can even format the chain data into a DataFrame where each row in the DataFrame represents a single contract.Sort and filter the data to select the specific Futures Options contract(s) you want to analyze.// Select a contract.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar fopContractSymbol = chain\n.Where(contract =>\n// Select call contracts with the closest expiry.\ncontract.Expiry == expiry &&\ncontract.Right == OptionRight.Call\n)\n// Select the contract with a strike price near the middle.\n.OrderBy(contract => contract.Strike)\n.ToList()[150]\n// Get the Symbol of the target contract.\n.Symbol;# Select a contract.\nexpiry = chain.expiry.min()\nfop_contract_symbol = chain[\n# Select call contracts with the closest expiry.\n(chain.expiry == expiry) &\n(chain.right == OptionRight.CALL)\n# Select the contract with a strike price near the middle.\n].sort_values('strike').index[150]Call theAddFutureOptionContractadd_future_option_contractmethod with anOptionContractSymbol and disable fill-forward.var optionContract = qb.AddFutureOptionContract(fopContractSymbol, fillForward: false);option_contract = qb.add_future_option_contract(fop_contract_symbol, fill_forward=False)Disable fill-forward because there are only a fewOpenInterestdata points per day.\n\n### Trade History\n\nTradeBarobjects are price bars that consolidate individual trades from the exchanges. They contain the open, high, low, close, and volume of trading activity over a period of time.\n\nTo get trade data, call thehistoryorhistory[TradeBar]History<TradeBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<TradeBar>(fopContractSymbol, TimeSpan.FromDays(3));\nforeach (var tradeBar in history)\n{\nConsole.WriteLine(tradeBar);\n}# DataFrame format\nhistory_df = qb.history(TradeBar, fop_contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# TradeBar objects\nhistory = qb.history[TradeBar](fop_contract_symbol, timedelta(3))\nfor trade_bar in history:\nprint(trade_bar)\n\nTradeBarobjects have the following properties:\n\n### Quote History\n\nQuoteBarobjects are bars that consolidate NBBO quotes from the exchanges. They contain the open, high, low, and close prices of the bid and ask. TheOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarobject are the mean of the respective bid and ask prices. If the bid or ask portion of theQuoteBarhas no data, theOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarcopy the values of either theBidbidorAskaskinstead of taking their mean.\n\nTo get quote data, call thehistoryorhistory[QuoteBar]History<QuoteBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<QuoteBar>(fopContractSymbol, TimeSpan.FromDays(3));\nforeach (var quoteBar in history)\n{\nConsole.WriteLine(quoteBar);\n}# DataFrame format\nhistory_df = qb.history(QuoteBar, fop_contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# QuoteBar objects\nhistory = qb.history[QuoteBar](fop_contract_symbol, timedelta(3))\nfor quote_bar in history:\nprint(quote_bar)\n\nQuoteBarobjects have the following properties:\n\n### Open Interest History\n\nOpen interest is the number of outstanding contracts that haven't been settled. It provides a measure of investor interest and the market liquidity, so it's a popular metric to use for contract selection. Open interest is calculated once per day.\n\nTo get open interest data, call thehistoryorhistory[OpenInterest]History<OpenInterest>method with the contractSymbolobject(s).\n\nvar history = qb.History<OpenInterest>(fopContractSymbol, TimeSpan.FromDays(3));\nforeach (var openInterest in history)\n{\nConsole.WriteLine(openInterest);\n}# DataFrame format\nhistory_df = qb.history(OpenInterest, fop_contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# OpenInterest objects\nhistory = qb.history[OpenInterest](fop_contract_symbol, timedelta(3))\nfor open_interest in history:\nprint(open_interest)\n\nOpenInterestobjects have the following properties:\n\n### Greeks and IV History\n\nThe Greeks are measures that describe the sensitivity of an Option's price to various factors like underlying price changes (Delta), time decay (Theta), volatility (Vega), and interest rates (Rho), while Implied Volatility (IV) represents the market's expectation of the underlying asset's volatility over the life of the Option.\n\nFollow these steps to get the Greeks and IV data:\n\nCreate the mirror contractSymbol.var mirrorContractSymbol = Symbol.CreateOption(\noptionContract.Underlying.Symbol,\nfopContractSymbol.ID.Market,\noptionContract.Style,\noptionContract.Right == OptionRight.Put ? OptionRight.Call : OptionRight.Put,\noptionContract.StrikePrice,\noptionContract.Expiry\n);mirror_contract_symbol = Symbol.create_option(\noption_contract.underlying.symbol, fop_contract_symbol.id.market, option_contract.style,\nOptionRight.Call if option_contract.right == OptionRight.PUT else OptionRight.PUT,\noption_contract.strike_price, option_contract.expiry\n)Set up therisk free interest rate,dividend yield, andOption pricingmodels.Inour research, we found the Forward Tree model to be the best pricing model for indicators.risk_free_rate_model = qb.risk_free_interest_rate_model\ndividend_yield_model = DividendYieldProvider(futures_contract_symbol)\noption_model = OptionPricingModelType.FORWARD_TREEvar riskFreeRateModel = qb.RiskFreeInterestRateModel;\nvar dividendYieldModel = new DividendYieldProvider(futuresContractSymbol);\nvar optionModel = OptionPricingModelType.ForwardTree;Define a method to return theIV & Greeks indicatorvalues for each contract.def greeks_and_iv(contracts, period, risk_free_rate_model, dividend_yield_model, option_model):\n# Get the call and put contract.\ncall, put = sorted(contracts, key=lambda s: s.id.option_right)\n\ndef get_values(indicator_class, contract, mirror_contract):\nreturn qb.indicator_history(\nindicator_class(contract, risk_free_rate_model, dividend_yield_model, mirror_contract, option_model),\n[contract, mirror_contract, contract.underlying],\nperiod\n).data_frame.current\n\nreturn pd.DataFrame({\n'iv_call': get_values(ImpliedVolatility, call, put),\n'iv_put': get_values(ImpliedVolatility, put, call),\n'delta_call': get_values(Delta, call, put),\n'delta_put': get_values(Delta, put, call),\n'gamma_call': get_values(Gamma, call, put),\n'gamma_put': get_values(Gamma, put, call),\n'rho_call': get_values(Rho, call, put),\n'rho_put': get_values(Rho, put, call),\n'vega_call': get_values(Vega, call, put),\n'vega_put': get_values(Vega, put, call),\n'theta_call': get_values(Theta, call, put),\n'theta_put': get_values(Theta, put, call),\n})Dictionary<string, IndicatorHistory> GreeksAndIV(List<Symbol> contracts, int period)\n{\n// Get the call and put contract.\nvar sortedSymbols = contracts.OrderBy(s => s.ID.OptionRight).ToArray();\nvar call = sortedSymbols[0];\nvar put = sortedSymbols[1];\n\nIndicatorHistory GetValues(OptionIndicatorBase indicator)\n{\n// Use both contracts and the underlying to update the indicator and get its value.\nreturn qb.IndicatorHistory(indicator, new[] { call, put, call.Underlying }, period);\n}\n\n// Get the values of all the IV and Greek indicators.\nreturn new Dictionary<string, IndicatorHistory>\n{\n{\"IVCall\", GetValues(new ImpliedVolatility(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"IVPut\", GetValues(new ImpliedVolatility(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"DeltaCall\", GetValues(new Delta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"DeltaPut\", GetValues(new Delta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"GammaCall\", GetValues(new Gamma(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"GammaPut\", GetValues(new Gamma(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"VegaCall\", GetValues(new Vega(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"VegaPut\", GetValues(new Vega(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"ThetaCall\", GetValues(new Theta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"ThetaPut\", GetValues(new Theta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"RhoCall\", GetValues(new Rho(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"RhoPut\", GetValues(new Rho(put, riskFreeRateModel, dividendYieldModel, call, optionModel))}\n};\n}Call the preceding method and display the results.greeks_and_iv([fop_contract_symbol, mirror_contract_symbol], 15, risk_free_rate_model, dividend_yield_model, option_model)foreach (var (key, indicatorHistory) in GreeksAndIV(new List<Symbol> {fopContractSymbol, mirrorContractSymbol}, 15))\n{\nforeach (var dataPoint in indicatorHistory)\n{\nConsole.WriteLine($\"{dataPoint.EndTime} - {key}: {dataPoint.Current.Value}\");\n}\n}\n\nThe DataFrame can have NaN entries if there is no data for the contracts or the underlying asset at a moment in time.\n\n### Examples\n\nThe following examples demonstrate some common practices for analyzing individual Future Option contracts in the Research Environment.\n\nExample 1: Contract Mid-Price History\n\nThe following notebook plots the historical mid-prices of an E-mini S&P 500 Future Option contract usingPlotlyPlotly.NET:\n\n#load \"../Initialize.csx\"\n\nimport plotly.graph_objects as go\n\n# Add the underlying Future contract\n# (the front-month ES Future contract as of December 12, 2023).\nqb = QuantBook()\nfuture = qb.add_future(Futures.Indices.SP_500_E_MINI)\nfutures_contract_symbol = sorted(\nqb.future_chain_provider.get_future_contract_list(future.symbol, datetime(2023, 12, 20)),\nkey=lambda s: s.id.date\n)[0]\nqb.add_future_contract(futures_contract_symbol, fill_forward=False)\n\n# Get the Future Option chain as of 5 days before the underlying Future's expiry date.\nqb.set_start_date(futures_contract_symbol.id.date - timedelta(5))\nchain = qb.option_chain(futures_contract_symbol, flatten=True).data_frame\n\n# Select a Future Option contract from the chain.\nexpiry = chain.expiry.min()\nfop_contract_symbol = chain[\n(chain.expiry == expiry) & (chain.right == OptionRight.CALL)\n].sort_values('strike').index[50]\n\n# Add the target Future Option contract.\nqb.add_future_option_contract(fop_contract_symbol)\n\n# Get the Future Option contract quote history.\nhistory = qb.history(QuoteBar, fop_contract_symbol, datetime(2024, 2, 22), datetime(2024, 2, 23))\n\n# Plot the mid-price values of the quote history.\ngo.Figure(\ndata=go.Candlestick(\nx=history.index.levels[4],\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close']\n),\nlayout=go.Layout(\ntitle=go.layout.Title(text=f'{fop_contract_symbol.value} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False\n)\n).show()#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities;\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Add the underlying Future contract\n// (the front-month ES Future contract as of December 12, 2023).\nvar qb = new QuantBook();\nvar future = qb.AddFuture(Futures.Indices.SP500EMini);\nvar futuresContractSymbol = qb.FutureChainProvider\n.GetFutureContractList(future.Symbol, new DateTime(2023, 12, 20))\n.OrderBy(s => s.ID.Date)\n.FirstOrDefault();\nqb.AddFutureContract(futuresContractSymbol, fillForward: false);\n\n// Get the Future Option chain as of 5 days before the underlying Future's expiry date.\nqb.SetStartDate(futuresContractSymbol.ID.Date.AddDays(-5));\nvar chain = qb.OptionChain(futuresContractSymbol);\n\n// Select a Future Option contract from the chain.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar fopContractSymbol = chain\n.Where(contract => contract.Expiry == expiry && contract.Right == OptionRight.Call)\n.OrderBy(contract => contract.Strike)\n.ToList()[50]\n.Symbol;\n\n// Add the target Future Option contract.\nqb.AddFutureOptionContract(fopContractSymbol);\n\n// Get the Future Option contract quote history.\nvar history = qb.History<QuoteBar>(fopContractSymbol, new DateTime(2024, 2, 22), new DateTime(2024, 2, 23));\n\n// Plot the mid-price values of the quote history.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{fopContractSymbol} Price\");\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\nchart.WithLayout(layout);\nHTML(GenericChart.toChartHTML(chart))",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.8",
      "breadcrumb": "Datasets > Futures Options > Individual Contracts",
      "section_number": "3.8.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.9",
    "title": "Forex",
    "level": 2,
    "path": "Datasets > Forex",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Forex data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a Forex security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Forex;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()(Optional)Set the time zoneto thedata time zone.qb.set_time_zone(TimeZones.UTC);qb.set_time_zone(TimeZones.UTC)Call theAddForexadd_forexmethod with a ticker and then save a reference to the ForexSymbol.var eurusd = qb.AddForex(\"EURUSD\").Symbol;\nvar gbpusd = qb.AddForex(\"GBPUSD\").Symbol;eurusd = qb.add_forex(\"EURUSD\").symbol\ngbpusd = qb.add_forex(\"GBPUSD\").symbol\n\nTo view all of the available Forex pairs, seeSupported Assets.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the security dimension, you can request historical data for a single Forex pair, a subset of the pairs you created subscriptions for in your notebook, or all of the pairs in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(eurusd, 10);\nvar subsetHistorySlice = qb.History(new[] {eurusd, gbpusd}, 10);\nvar allHistorySlice = qb.History(10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(eurusd, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {eurusd, gbpusd}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);# DataFrame\nsingle_history_df = qb.history(eurusd, 10)\nsubset_history_df = qb.history([eurusd, gbpusd], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](eurusd, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([eurusd, gbpusd], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(eurusd, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {eurusd, gbpusd}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(eurusd, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {eurusd, gbpusd}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(eurusd, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {eurusd, gbpusd}, TimeSpan.FromDays(3), Resolution.Tick);var allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of quote data (Forex data doesn't have trade data)\nsingle_history_df = qb.history(eurusd, timedelta(days=3))\nsubset_history_df = qb.history([eurusd, gbpusd], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(eurusd, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([eurusd, gbpusd], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](eurusd, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([eurusd, gbpusd], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](eurusd, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([eurusd, gbpusd], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nThe preceding calls return the most recent bars or ticks, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistoryhistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(eurusd, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {eurusd, gbpusd}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(eurusd, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {eurusd, gbpusd}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(eurusd, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {eurusd, gbpusd}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of quote data (Forex data doesn't have trade data)\nsingle_history_df = qb.history(eurusd, start_time, end_time)\nsubset_history_df = qb.history([eurusd, gbpusd], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(eurusd, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([eurusd, gbpusd], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](eurusd, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([eurusd, gbpusd], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](eurusd, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([eurusd, gbpusd], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\nThe preceding calls return the bars or ticks that have a timestamp within the defined period of time.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Forex subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe only market available for Forex pairs isMarket.OandaMarket.OANDA.\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded Forex Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single Forex, index thelocproperty of theDataFramewith the ForexSymbol.\n\nall_history_df.loc[eurusd]  # or all_history_df.loc['EURUSD']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[eurusd]['close']\n\nIf you request historical data for multiple Forex pairs, you can transform theDataFrameso that it's a time series of close values for all of the Forex pairs. To transform theDataFrame, select the column you want to display for each Forex pair and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each Forex pair and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[eurusd].EndTime)),\nnew DecimalDataFrameColumn(\"EURUSD Open\", history.Select(x => x[eurusd].Open)),\nnew DecimalDataFrameColumn(\"EURUSD High\", history.Select(x => x[eurusd].High)),\nnew DecimalDataFrameColumn(\"EURUSD Low\", history.Select(x => x[eurusd].Low)),\nnew DecimalDataFrameColumn(\"EURUSD Close\", history.Select(x => x[eurusd].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"EURUSD close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Forex subscriptions. To avoid issues, check if theSlicecontains data for your Forex pair before you index it with the ForexSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.QuoteBars.ContainsKey(eurusd))\n{\nvar quoteBar = slice.QuoteBars[eurusd];\n}\n}for slice in all_history_slice:\nif slice.quote_bars.contains_key(eurusd):\nquote_bar = slice.quote_bars[eurusd]\n\n-- ---\n\nYou can also iterate through eachQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachQuoteBarin theSlicefor a givenSymbol.\n\nvar quoteBars = allHistorySlice.Where(slice => slice.QuoteBars.ContainsKey(eurusd)).Select(slice => slice.QuoteBars[eurusd]);\n\n-- ---\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each Forex pair. TheQuoteBarsmay not have data for all of your Forex subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the ForexSymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(eurusd))\n{\nvar quoteBar = quoteBars[eurusd];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(eurusd):\nquote_bar = quote_bars[eurusd]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Forex pair. TheTicksmay not have data for all of your Forex subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the ForexSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(eurusd))\n{\nvar tick = ticks[eurusd];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(eurusd):\nticks = ticks[eurusd]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical Forex datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(eurusd, datetime(2021, 11, 26), datetime(2021, 12, 8), Resolution.DAILY).loc[eurusd]var history = qb.History<QuoteBar>(eurusd, new DateTime(2021, 11, 26), new DateTime(2021, 12, 8), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='EURUSD OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{eurusd} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([eurusd, gbpusd], datetime(2021, 11, 26), datetime(2021, 12, 8), Resolution.DAILY)var history = qb.History<QuoteBar>(new [] {eurusd, gbpusd}, new DateTime(2021, 11, 26), new DateTime(2021, 12, 8), Resolution.Daily);Select the data to plot.pct_change = history['close'].unstack(0).pct_change().dropna()Call theplotmethod on thepandasobject.pct_change.plot(title=\"Close Price %Change\", figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[eurusd].EndTime),\nhistory.Select(x => x[eurusd].Close),\nName: \"EURUSD\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[gbpusd].EndTime),\nhistory.Select(x => x[gbpusd].Close),\nName: \"GBPUSD\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init(\"EURUSD & GBPUSD Close Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Forex dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the USDJPY. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot, using the mid prices.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the USDJPY historical data.\nvar symbol = qb.AddForex(\"USDJPY\").Symbol;\nvar history = qb.History<QuoteBar>(symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new QuoteBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<QuoteBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows with mid prices.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => (x.Ask.Open + x.Bid.Open) * 0.5m),\nwindow.Select(x => (x.Ask.High + x.Bid.High) * 0.5m),\nwindow.Select(x => (x.Ask.Low + x.Bid.Low) * 0.5m),\nwindow.Select(x => (x.Ask.Close + x.Bid.Close) * 0.5m),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request USDJPY's historical data.\nsymbol = qb.add_forex(\"USDJPY\").symbol\nhistory = qb.history(symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Forex",
      "section_number": "3.9",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.10",
    "title": "CFD",
    "level": 2,
    "path": "Datasets > CFD",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical CFD data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to a CFD security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Cfd;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()(Optional)Set the time zoneto thedata time zone.qb.set_time_zone(TimeZones.UTC);qb.set_time_zone(TimeZones.UTC)Call theAddCfdadd_cfdmethod with a ticker and then save a reference to the CFDSymbol.var spx = qb.AddCfd(\"SPX500USD\").Symbol;\nvar usb = qb.AddCfd(\"USB10YUSD\").Symbol;spx = qb.add_cfd(\"SPX500USD\").symbol\nusb = qb.add_cfd(\"USB10YUSD\").symbol\n\nTo view all of the available contracts, seeSupported Assets.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the security dimension, you can request historical data for a single CFD contract, a subset of the contracts you created subscriptions for in your notebook, or all of the contracts in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, 10);\nvar subsetHistorySlice = qb.History(new[] {spx, usb}, 10);\nvar allHistorySlice = qb.History(10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spx, 10);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spx, usb}, 10);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, 10);# DataFrame\nsingle_history_df = qb.history(spx, 10)\nsubset_history_df = qb.history([spx, usb], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spx, 10)\nsubset_history_quote_bars = qb.history[QuoteBar]([spx, usb], 10)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), 10)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {spx, usb}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spx, TimeSpan.FromDays(3), Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spx, usb}, TimeSpan.FromDays(3), Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spx, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spx, usb}, TimeSpan.FromDays(3), Resolution.Tick);var allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of quote data (CFD data doesn't have trade data)\nsingle_history_df = qb.history(spx, timedelta(days=3))\nsubset_history_df = qb.history([spx, usb], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spx, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([spx, usb], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spx, timedelta(days=3), Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([spx, usb], timedelta(days=3), Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), timedelta(days=3), Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spx, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spx, usb], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nThe preceding calls return the most recent bars or ticks, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistoryhistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {spx, usb}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// QuoteBar objects\nvar singleHistoryQuoteBars = qb.History<QuoteBar>(spx, startTime, endTime, Resolution.Minute);\nvar subsetHistoryQuoteBars = qb.History<QuoteBar>(new[] {spx, usb}, startTime, endTime, Resolution.Minute);\nvar allHistoryQuoteBars = qb.History<QuoteBar>(qb.Securities.Keys, startTime, endTime, Resolution.Minute);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spx, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spx, usb}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of quote data (CFD data doesn't have trade data)\nsingle_history_df = qb.history(spx, start_time, end_time)\nsubset_history_df = qb.history([spx, usb], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spx, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([spx, usb], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# QuoteBar objects\nsingle_history_quote_bars = qb.history[QuoteBar](spx, start_time, end_time, Resolution.MINUTE)\nsubset_history_quote_bars = qb.history[QuoteBar]([spx, usb], start_time, end_time, Resolution.MINUTE)\nall_history_quote_bars = qb.history[QuoteBar](qb.securities.keys(), start_time, end_time, Resolution.MINUTE)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spx, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spx, usb], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\nThe preceding calls return the bars or ticks that have a timestamp within the defined period of time.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for CFD subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe only market available for CFD contracts isMarket.OandaMarket.OANDA.\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded CFD Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single CFD, index thelocproperty of theDataFramewith the CFDSymbol.\n\nall_history_df.loc[spx]  # or all_history_df.loc['SPX500USD']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[spx]['close']\n\nIf you request historical data for multiple CFD contracts, you can transform theDataFrameso that it's a time series of close values for all of the CFD contracts. To transform theDataFrame, select the column you want to display for each CFD contract and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each CFD contract and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[spx].EndTime)),\nnew DecimalDataFrameColumn(\"SPX500USD Open\", history.Select(x => x[spx].Open)),\nnew DecimalDataFrameColumn(\"SPX500USD High\", history.Select(x => x[spx].High)),\nnew DecimalDataFrameColumn(\"SPX500USD Low\", history.Select(x => x[spx].Low)),\nnew DecimalDataFrameColumn(\"SPX500USD Close\", history.Select(x => x[spx].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"SPX500USD close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your CFD subscriptions. To avoid issues, check if theSlicecontains data for your CFD contract before you index it with the CFDSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.QuoteBars.ContainsKey(spx))\n{\nvar quoteBar = slice.QuoteBars[spx];\n}\n}for slice in all_history_slice:\nif slice.quote_bars.contains_key(spx):\nquote_bar = slice.quote_bars[spx]\n\n-- ---\n\nYou can also iterate through eachQuoteBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.QuoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\nYou can also use LINQ to select eachQuoteBarin theSlicefor a givenSymbol.\n\nvar quoteBars = allHistorySlice.Where(slice => slice.QuoteBars.ContainsKey(spx)).Select(slice => slice.QuoteBars[spx]);\n\n-- ---\n\n-- ---\n\nQuoteBar Objects\n\nIf theHistoryhistorymethod returnsQuoteBarobjects, iterate through theQuoteBarobjects to get each one.\n\nforeach (var quoteBar in singleHistoryQuoteBars)\n{\nConsole.WriteLine(quoteBar);\n}for quote_bar in single_history_quote_bars:\nprint(quote_bar)\n\nIf theHistoryhistorymethod returnsQuoteBars, iterate through theQuoteBarsto get theQuoteBarof each CFD contract. TheQuoteBarsmay not have data for all of your CFD subscriptions. To avoid issues, check if theQuoteBarsobject contains data for your security before you index it with the CFDSymbol.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nif (quoteBars.ContainsKey(spx))\n{\nvar quoteBar = quoteBars[spx];\n}\n}for quote_bars in all_history_quote_bars:\nif quote_bars.contains_key(spx):\nquote_bar = quote_bars[spx]\n\nYou can also iterate through each of theQuoteBars.\n\nforeach (var quoteBars in allHistoryQuoteBars)\n{\nforeach (var kvp in quoteBars)\n{\nvar symbol = kvp.Key;\nvar quoteBar = kvp.Value;\n}\n}for quote_bars in all_history_quote_bars:\nfor kvp in quote_bars:\nsymbol = kvp.key\nquote_bar = kvp.value\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each CFD contract. TheTicksmay not have data for all of your CFD subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the CFDSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(spx))\n{\nvar tick = ticks[spx];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(spx):\nticks = ticks[spx]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical CFD datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(spx, datetime(2021, 11, 26), datetime(2021, 12, 8), Resolution.DAILY).loc[spx]var history = qb.History<QuoteBar>(spx, new DateTime(2021, 11, 26), new DateTime(2021, 12, 8), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='SPX CFD OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{spx} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create theFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([spx, usb], datetime(2021, 11, 26), datetime(2021, 12, 8), Resolution.DAILY)var history = qb.History<QuoteBar>(new [] {spx, usb}, new DateTime(2021, 11, 26), new DateTime(2021, 12, 8), Resolution.Daily);Select the data to plot.pct_change = history['close'].unstack(0).pct_change().dropna()Call theplotmethod on thepandasobject.pct_change.plot(title=\"Close Price %Change\", figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[spx].EndTime),\nhistory.Select(x => x[spx].Close - x[spx].Open),\nName: $\"{spx}\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[usb].EndTime),\nhistory.Select(x => x[usb].Close - x[usb].Open),\nName: $\"{usb}\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{spx} & {usb} Daily Spread\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the CFD dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the XAUUSD. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot, using the mid prices.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the XAUUSD historical data.\nvar symbol = qb.AddCfd(\"XAUUSD\").Symbol;\nvar history = qb.History<QuoteBar>(symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new QuoteBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<QuoteBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows with mid prices.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => (x.Ask.Open + x.Bid.Open) * 0.5m),\nwindow.Select(x => (x.Ask.High + x.Bid.High) * 0.5m),\nwindow.Select(x => (x.Ask.Low + x.Bid.Low) * 0.5m),\nwindow.Select(x => (x.Ask.Close + x.Bid.Close) * 0.5m),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request XAUUSD's historical data.\nsymbol = qb.add_cfd(\"XAUUSD\").symbol\nhistory = qb.history(symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > CFD",
      "section_number": "3.10",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.11",
    "title": "Indices",
    "level": 2,
    "path": "Datasets > Indices",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical Index data.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to an Index security:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Index;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddIndexadd_indexmethod with a ticker and then save a reference to the IndexSymbol.var spx = qb.AddIndex(\"SPX\").Symbol;\nvar vix = qb.AddIndex(\"VIX\").Symbol;spx = qb.add_index(\"SPX\").symbol\nvix = qb.add_index(\"VIX\").symbol\n\nTo view all of the available indices, seeSupported Indices.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the security dimension, you can request historical data for a single Index, a subset of the Indices you created subscriptions for in your notebook, or all of the Indices in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, 10);\nvar subsetHistorySlice = qb.History(new[] {spx, vix}, 10);\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spx, 10);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spx, vix}, 10);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, 10);# DataFrame\nsingle_history_df = qb.history(spx, 10)\nsingle_history_trade_bar_df = qb.history(TradeBar, spx, 10)\nsubset_history_df = qb.history([spx, vix], 10)\nsubset_history_trade_bar_df = qb.history(TradeBar, [spx, vix], 10)\nall_history_df = qb.history(qb.securities.keys(), 10)\nall_history_trade_bar_df = qb.history(TradeBar, qb.securities.keys(), 10)\n\n# Slice objects\nall_history_slice = qb.history(10)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spx, 10)\nsubset_history_trade_bars = qb.history[TradeBar]([spx, vix], 10)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), 10)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {spx, vix}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spx, TimeSpan.FromDays(3));\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spx, vix}, TimeSpan.FromDays(3));\nvar allHistoryTradeBars = qb.History<TradeBar>(TimeSpan.FromDays(3));\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spx, TimeSpan.FromDays(3), Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spx, vix}, TimeSpan.FromDays(3), Resolution.Tick);var allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, TimeSpan.FromDays(3), Resolution.Tick);# DataFrame of trade data (indices don't have quote data)\nsingle_history_df = qb.history(spx, timedelta(days=3))\nsubset_history_df = qb.history([spx, vix], timedelta(days=3))\nall_history_df = qb.history(qb.securities.keys(), timedelta(days=3))\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spx, timedelta(days=3), Resolution.TICK)\nsubset_history_tick_df = qb.history([spx, usb], timedelta(days=3), Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\n# Slice objects\nall_history_slice = qb.history(timedelta(days=3))\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spx, timedelta(days=3))\nsubset_history_trade_bars = qb.history[TradeBar]([spx, vix], timedelta(days=3))\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), timedelta(days=3))\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spx, timedelta(days=3), Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spx, vix], timedelta(days=3), Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), timedelta(days=3), Resolution.TICK)\n\nThe preceding calls return the most recent bars or ticks, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistoryhistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 2, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(spx, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {spx, vix}, startTime, endTime);\nvar allHistorySlice = qb.History(qb.Securities.Keys, startTime, endTime);\n\n// TradeBar objects\nvar singleHistoryTradeBars = qb.History<TradeBar>(spx, startTime, endTime);\nvar subsetHistoryTradeBars = qb.History<TradeBar>(new[] {spx, vix}, startTime, endTime);\nvar allHistoryTradeBars = qb.History<TradeBar>(qb.Securities.Keys, startTime, endTime);\n\n// Tick objects\nvar singleHistoryTicks = qb.History<Tick>(spx, startTime, endTime, Resolution.Tick);\nvar subsetHistoryTicks = qb.History<Tick>(new[] {spx, vix}, startTime, endTime, Resolution.Tick);\nvar allHistoryTicks = qb.History<Tick>(qb.Securities.Keys, startTime, endTime, Resolution.Tick);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 2, 1)\n\n# DataFrame of trade data (indices don't have quote data)\nsingle_history_df = qb.history(spx, start_time, end_time)\nsubset_history_df = qb.history([spx, vix], start_time, end_time)\nall_history_df = qb.history(qb.securities.keys(), start_time, end_time)\n\n# DataFrame of tick data\nsingle_history_tick_df = qb.history(spx, start_time, end_time, Resolution.TICK)\nsubset_history_tick_df = qb.history([spx, vix], start_time, end_time, Resolution.TICK)\nall_history_tick_df = qb.history(qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\n# TradeBar objects\nsingle_history_trade_bars = qb.history[TradeBar](spx, start_time, end_time)\nsubset_history_trade_bars = qb.history[TradeBar]([spx, vix], start_time, end_time)\nall_history_trade_bars = qb.history[TradeBar](qb.securities.keys(), start_time, end_time)\n\n# Tick objects\nsingle_history_ticks = qb.history[Tick](spx, start_time, end_time, Resolution.TICK)\nsubset_history_ticks = qb.history[Tick]([spx, vix], start_time, end_time, Resolution.TICK)\nall_history_ticks = qb.history[Tick](qb.securities.keys(), start_time, end_time, Resolution.TICK)\n\nThe preceding calls return the bars or ticks that have a timestamp within the defined period of time.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Index subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe only market available for Indices isMarket.USA.\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded Index Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single Index, index thelocproperty of theDataFramewith the IndexSymbol.\n\nall_history_df.loc[spx]  # or all_history_df.loc['SPX']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[spx]['close']\n\nIf you request historical data for multiple Indices, you can transform theDataFrameso that it's a time series of close values for all of the Indices. To transform theDataFrame, select the column you want to display for each Index and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each Index and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[spx].EndTime)),\nnew DecimalDataFrameColumn(\"SPX Open\", history.Select(x => x[spx].Open)),\nnew DecimalDataFrameColumn(\"SPX High\", history.Select(x => x[spx].High)),\nnew DecimalDataFrameColumn(\"SPX Low\", history.Select(x => x[spx].Low)),\nnew DecimalDataFrameColumn(\"SPX Close\", history.Select(x => x[spx].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"SPX close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your Index subscriptions. To avoid issues, check if theSlicecontains data for your Index before you index it with the IndexSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.Bars.ContainsKey(spx))\n{\nvar tradeBar = slice.Bars[spx];\n}\n}for slice in all_history_slice:\nif slice.bars.contains_key(spx):\ntrade_bar = slice.bars[spx]\n\n-- ---\n\nYou can also iterate through eachTradeBarin theSlice.\n\nforeach (var slice in allHistorySlice)\n{\nforeach (var kvp in slice.Bars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for slice in all_history_slice:\nfor kvp in slice.bars:\nsymbol = kvp.key\ntrade_bar = kvp.value\n\nYou can also use LINQ to select eachTradeBarin theSlicefor a givenSymbol.\n\nvar tradeBars = allHistorySlice.Where(slice => slice.Bars.ContainsKey(spx)).Select(slice => slice.Bars[spx]);\n\n-- ---\n\nTradeBar Objects\n\nIf theHistoryhistorymethod returnsTradeBarobjects, iterate through theTradeBarobjects to get each one.\n\nforeach (var tradeBar in singleHistoryTradeBars)\n{\nConsole.WriteLine(tradeBar);\n}for trade_bar in single_history_trade_bars:\nprint(trade_bar)\n\nIf theHistoryhistorymethod returnsTradeBars, iterate through theTradeBarsto get theTradeBarof each Index. TheTradeBarsmay not have data for all of your Index subscriptions. To avoid issues, check if theTradeBarsobject contains data for your security before you index it with the IndexSymbol.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nif (tradeBars.ContainsKey(spx))\n{\nvar tradeBar = tradeBars[spx];\n}\n}for trade_bars in all_history_trade_bars:\nif trade_bars.contains_key(spx):\ntrade_bar = trade_bars[spx]\n\nYou can also iterate through each of theTradeBars.\n\nforeach (var tradeBars in allHistoryTradeBars)\n{\nforeach (var kvp in tradeBars)\n{\nvar symbol = kvp.Key;\nvar tradeBar = kvp.Value;\n}\n}for trade_bars in all_history_trade_bars:\nfor kvp in trade_bars:\nsymbol = kvp.Key\ntrade_bar = kvp.Value\n\n-- ---\n\n-- ---\n\nTick Objects\n\nIf theHistoryhistorymethod returnsTickTICKobjects, iterate through theTickTICKobjects to get each one.\n\nforeach (var tick in singleHistoryTicks)\n{\nConsole.WriteLine(tick);\n}for tick in single_history_ticks:\nprint(tick)\n\nIf theHistoryhistorymethod returnsTicks, iterate through theTicksto get theTickTICKof each Index. TheTicksmay not have data for all of your Index subscriptions. To avoid issues, check if theTicksobject contains data for your security before you index it with the IndexSymbol.\n\nforeach (var ticks in allHistoryTicks)\n{\nif (ticks.ContainsKey(spx))\n{\nvar tick = ticks[spx];\n}\n}for ticks in all_history_ticks:\nif ticks.contains_key(spx):\nticks = ticks[spx]\n\nYou can also iterate through each of theTicks.\n\nforeach (var ticks in allHistoryTicks)\n{\nforeach (var kvp in ticks)\n{\nvar symbol = kvp.Key;\nvar tick = kvp.Value;\n}\n}for ticks in all_history_ticks:\nfor kvp in ticks:\nsymbol = kvp.key\ntick = kvp.value\n\nTheTicksobjects only contain the last tick of each security for that particulartimeslice\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical Indices datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(spx, datetime(2021, 11, 24), datetime(2021, 12, 8), Resolution.DAILY).loc[spx]var history = qb.History<TradeBar>(spx, new DateTime(2021, 11, 24), new DateTime(2021, 12, 8), Resolution.Daily);Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='SPX OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{spx} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create aFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([spx, vix], datetime(2021, 11, 24), datetime(2021, 12, 8), Resolution.DAILY)var history = qb.History<TradeBar>(new [] {spx, vix}, new DateTime(2021, 11, 24), new DateTime(2021, 12, 8), Resolution.Daily);Select the data to plot.pct_change = history['close'].unstack(0).pct_change().dropna()Call theplotmethod on thepandasobject.pct_change.plot(title=\"Close Price %Change\", figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[spx].EndTime),\nhistory.Select(x => x[spx].Close - x[spx].Open),\nName: $\"{spx}\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[vix].EndTime),\nhistory.Select(x => x[vix].Close - x[vix].Open),\nName: $\"{vix}\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{spx} & {vix} Daily Spread\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the US Indices dataset.\n\nExample 1: 5-Minute Candlestick Plot\n\nThe following example studies the candlestick pattern of the SPX. To study the short term pattern, we consolidate the data into 5 minute bars and plot the 5-minute candlestick plot.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.Consolidators;\nusing QuantConnect.Indicators;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Securities;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request the SPX historical data.\nvar symbol = qb.AddIndex(\"SPX\").Symbol;\nvar history = qb.History<TradeBar>(symbol,\nstart: qb.Time - TimeSpan.FromDays(182),\nend: qb.Time,\nresolution: Resolution.Minute);\n\n// Set up a consolidator and a RollingWindow to save the data\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\nvar window = new RollingWindow<TradeBar>(10000);\n\n// Attach a consolidation handler method that saves the consolidated bars in the RollingWindow\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nwindow.Add(consolidated);\n};\n\n// Iterate the historical market data and feed each bar into the consolidator\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Crete the Candlestick chart using the 5-minute windows.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nwindow.Select(x => x.Open),\nwindow.Select(x => x.High),\nwindow.Select(x => x.Low),\nwindow.Select(x => x.Close),\nwindow.Select(x => x.EndTime)\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Import plotly library for plotting.\nimport plotly.graph_objects as go\n\n# Create a QuantBook\nqb = QuantBook()\n\n# Request SPX's historical data.\nsymbol = qb.add_index(\"SPX\").symbol\nhistory = qb.history(symbol,\nstart=qb.time - timedelta(days=182),\nend=qb.time,\nresolution=Resolution.MINUTE)\n\n# Drop level 0 index (Symbol index) from the DataFrame\nhistory = history.droplevel([0])\n\n# Select the required columns to obtain the 5-minute OHLC data.\nhistory = history[[\"open\", \"high\", \"low\", \"close\"]].resample(\"5T\").agg({\n\"open\": \"first\",\n\"high\": \"max\",\n\"low\": \"min\",\n\"close\": \"last\"\n})\n\n# Crete the Candlestick chart using the 5-minute windows.\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])\n# Create a Layout as the plot settings.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n# Create the Figure.\nfig = go.Figure(data=[candlestick], layout=layout)\n# Display the plot.\nfig.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Indices",
      "section_number": "3.11",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.12",
    "title": "Index Options",
    "level": 2,
    "path": "Datasets > Index Options",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Index Options",
      "section_number": "3.12",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.12.1",
    "title": "Key Concepts",
    "level": 3,
    "path": "Datasets > Index Options > Key Concepts",
    "content": "### Introduction\n\nIndex Options are a financial derivative that gives the holder the right (but not the obligation) to buy or sell the value of an underlying Index, such as the S&P 500 index, at the stated exercise price. No actual assets are bought or sold.\nThis page explains the basics of Index Option data in the Research Environment.\nTo get some data, seeUniversesorIndividual Contracts.\nFor more information about the specific datasets we use, see theUS Index OptionsandUS Index Option Universedataset listings.\n\n### Resolutions\n\nThe following table shows the available resolutions and data formats for Index Option contract subscriptions:\n\n[Table - 5 rows]\n\n### Markets\n\nThe only market available for Index Options isMarket.USA.\n\n### Data Normalization\n\nThe data normalization mode doesn't affect data from history request. If you change the data normalization mode, it won't change the outcome.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "3.12",
      "breadcrumb": "Datasets > Index Options > Key Concepts",
      "section_number": "3.12.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Resolution | TradeBar | QuoteBar | Trade Tick | Quote Tick |\n| --- | --- | --- | --- | --- |\n| TickTICK |  |  |  |  |\n| SecondSECOND |  |  |  |  |\n| MinuteMINUTE |  |  |  |  |\n| HourHOUR |  |  |  |  |\n| DailyDAILY |  |  |  |  |"
  },
  {
    "id": "3.12.2",
    "title": "Universes",
    "level": 3,
    "path": "Datasets > Index Options > Universes",
    "content": "### Introduction\n\nThis page explains how to request historical data for a universe of Index Option contracts.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to an Index Option universe:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Securities.Index;\nusing QuantConnect.Securities.IndexOption;\nusing QuantConnect.Data.UniverseSelection;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Add the underlying Index.var indexSymbol = qb.AddIndex(\"SPX\", Resolution.Minute).Symbol;index_symbol = qb.add_index(\"SPX\", Resolution.MINUTE).symbolTo view the available Indices, seeSupported Assets.If you do not pass a resolution argument,Resolution.MinuteResolution.MINUTEis used by default.Call theAddIndexOptionadd_index_optionmethod with the underlyingIndexSymboland, if you want non-standard Index Options, thetarget Option ticker.var option = qb.AddIndexOption(indexSymbol);option = qb.add_index_option(index_symbol)\n\n### Price History\n\nThecontract filterdetermines which Index Option contracts are in your universe each trading day.\nThe default filter selects the contracts with the following characteristics:\n\nStandard type (exclude weeklys)Within 1 strike price of the underlying asset priceExpire within 35 days\n\nTo change the filter, call theSetFilterset_filtermethod.\n\n// Set the contract filter to select contracts that have the strike price\n// within 1 strike level and expire within 90 days.\noption.SetFilter(-1, 1, 0, 90);# Set the contract filter to select contracts that have the strike price\n# within 1 strike level and expire within 90 days.\noption.set_filter(-1, 1, 0, 90)\n\nTo get the prices and volumes for all of the Index Option contracts that pass your filter during a specific period of time, call theOptionHistoryoption_historymethod with the underlying IndexSymbolobject, a startDateTimedatetime, and an endDateTimedatetime.\n\noption_history = qb.option_history(\nindex_symbol, datetime(2024, 1, 1), datetime(2024, 1, 5), Resolution.MINUTE,\nfill_forward=False, extended_market_hours=False\n)var optionHistory = qb.OptionHistory(\nindexSymbol, new DateTime(2024, 1, 1), new DateTime(2024, 1, 5), Resolution.Minute,\nfillForward: false, extendedMarketHours: false\n);\n\nTo convert theOptionHistoryobject to aDataFramethat contains the trade and quote information of each contract and the underlying, use thedata_frameproperty.\n\noption_history.data_frame\n\nTo get the expiration dates of all the contracts in anOptionHistoryobject, call theGetExpiryDatesget_expiry_datesmethod.\n\noption_history.get_expiry_dates()\n\nTo get the strike prices of all the contracts in anOptionHistoryobject, call theGetStrikesget_strikesmethod.\n\noption_history.get_strikes()\n\n### Daily Price and Greeks History\n\nTo get daily data on all the tradable contracts for a given date, call theHistory<OptionUniverse>historymethod with the canoncial Option Symbol, a start date, and an end date. This method returns the entire Option chain for each trading day, not the subset of contracts that pass your universe filter. The daily Option chains contain the prices, volume, open interest, implied volaility, and Greeks of each contract.\n\n# DataFrame format\nhistory_df = qb.history(option.symbol, datetime(2024, 1, 1), datetime(2024, 1, 5), flatten=True)\n\n# OptionUniverse objects\nhistory = qb.history[OptionUniverse](option.symbol, datetime(2024, 1, 1), datetime(2024, 1, 5))\nfor chain in history:\nend_time = chain.end_time\nfiltered_chain = [contract for contract in chain if contract.greeks.delta > 0.3]\nfor contract in filtered_chain:\nprice = contract.price\niv = contract.implied_volatilityvar history = qb.History<OptionUniverse>(option.Symbol, new DateTime(2024, 1, 1), new DateTime(2024, 1, 5));\nforeach (var chain in history)\n{\nvar endTime = chain.EndTime;\nvar filteredChain = chain.Data\n.Select(contract => contract as OptionUniverse)\n.Where(contract => contract.Greeks.Delta > 0.3m);\nforeach (var contract in filteredChain)\n{\nvar price = contract.Price;\nvar iv = contract.ImpliedVolatility;\n}\n}\n\nThe method represents each contract with anOptionUniverseobject, which have the following properties:\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Index Options dataset.\n\nExample 1: Implied Volatility Line Chart\n\nThe following example plots a line chart on the implied volatility curve of the cloest expiring calls.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing System;\nusing System.Collections.Generic;\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Data.UniverseSelection;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n// Set the date being studied.\nvar date = new DateTime(2024, 1, 4);\n\n// Subscribe to the underlying Index.\nvar index = qb.AddIndex(\"SPX\").Symbol;\n// Request the option data by calling the add_option method with the underlying Index Symbol.\nvar option = qb.AddOption(index, \"SPXW\");\noption.SetFilter((u) => u.IncludeWeeklys());\n\n// Request the historical option data to obtain the data to be calculated and compared.\nvar history = qb.History<OptionUniverse>(option.Symbol, date.AddDays(-1), date, Resolution.Daily);\nvar ivByStrike = new Dictionary<decimal, decimal>();\nforeach (var chain in history)\n{\n// Get the closest expiring calls to study.\nvar filteredChain = chain.Select(contract => contract as OptionUniverse)\n.Where(x => x.Symbol.ID.Date == date && x.Symbol.ID.OptionRight == OptionRight.Call);\n\n// Obtain the strike and IV for plotting the IV curve.\nforeach (var contract in filteredChain)\n{\nvar strike = contract.Symbol.ID.StrikePrice;\nvar iv = contract.ImpliedVolatility;\nivByStrike[strike] = iv;\n}\n}\n\n// Crete the Line Chart with the PE Ratios.\nvar chart = Chart2D.Chart.Line<decimal, decimal, string>(\nivByStrike.Keys,\nivByStrike.Values\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Strike\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Implied Volatility\");\nTitle title = Title.init($\"IV Curve of {option.Symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate a QuantBook instance.\nqb = QuantBook()\n# Set the date being studied.\ndate = datetime(2024, 1, 4)\n\n# Subscribe to the underlying Index.\nindex_symbol = qb.add_index(\"SPX\").symbol\n# Request the option data by calling the add_option method with the underlying Index Symbol.\noption = qb.add_option(index_symbol, \"SPXW\")\noption.set_filter(lambda u: u.include_weeklys())\n\n# Request the historical option data to obtain the data to be calculated and compared.\nhistory_df = qb.history(option.symbol, date-timedelta(1), date, flatten=True).droplevel([0])\n\n# Include only the closest expiring calls.\nexpiry = min(x.id.date for x in history_df.index)\nhistory_df = history_df.loc[(x for x in history_df.index if x.id.date == expiry and x.id.option_right == OptionRight.CALL)]\nstrikes = [x.id.strike_price for x in history_df.index]\n\n# Plot the IV curve versus strikes.\nhistory_df.index = strikes\nhistory_df[[\"impliedvolatility\"]].plot(title=\"IV Curve\", xlabel=\"strike\", ylabel=\"implied volatility\")\n\nExample 2: COS DeltaThe following example uses Fourier-Cosine method with finite differencing under Black-Scholes framework to calculate the option Delta. Then, we plot the actual Delta and the COS-calculated Delta to study the approximation accuracy. COS method can calculate a large number of option Greeks in a continuous strike range rapidly, making it suitable for arbitration and hedge position adjustment.# Instantiate a QuantBook instance.\nqb = QuantBook()\n# Set the date being studied.\ndate = datetime(2024, 1, 4)\n\n# Subscribe to the underlying Index.\nindex_symbol = qb.add_index(\"SPX\").symbol\n# Request the option data by calling the add_option method with the underlying Index Symbol.\noption = qb.add_option(index_symbol, \"SPXW\")\noption.set_filter(lambda u: u.include_weeklys())\n\n# Request the historical option data to obtain the data to be calculated and compared.\nhistory_df = qb.history(option.symbol, date-timedelta(7), date, flatten=True).droplevel([0])\n\n# Include only the furthest expiring puts.\nexpiry = max(x.id.date for x in history_df.index)\nhistory_df = history_df.loc[(x for x in history_df.index if x.id.date == expiry and x.id.option_right == OptionRight.PUT)]\nstrikes = np.array([x.id.strike_price for x in history_df.index])\n\n# Get the implied volatility of the ATM put as the forward volatility forecast.\nhistory_df[\"underlying\"] = history_df[\"underlying\"].apply(lambda x: x.price)\natm_call = sorted(history_df.iterrows(), key=lambda x: abs(x[0].id.strike_price - x[1].underlying))[0]\niv = atm_call[1].impliedvolatility\n\ndef psi_n(b1, b2, c, d, n):\n\"\"\"Calculate the psi_n function used in the COS method.\"\"\"\n# Base case for n=0.\nif n == 0:\nreturn d - c\ndelta_b = b2 - b1\n# Compute sine terms for the given range.\nsin_terms = np.sin(n * np.pi * (np.array([d]) - b1) / delta_b) - np.sin(n * np.pi * (np.array([c]) - b1) / delta_b)\nreturn (delta_b * sin_terms) / (n * np.pi)\n\ndef gamma_n(b1, b2, c, d, n):\n\"\"\"Calculate the gamma_n function used in the COS method.\"\"\"\nbase = n * np.pi / (b2 - b1)    # Scaling factor based on n\nd_ = base * (d - b1)            # Adjusted upper limit\nc_ = base * (c - b1)            # Adjusted lower limit\nexp_d = np.exp(d)               # Calculate exponential for d\nexp_c = np.exp(c)               # Calculate exponential for c\n\n# Compute cosine and sine terms for the upper and lower limits.\ncos_terms = np.cos(np.array([d_, c_]))\nsin_terms = np.sin(np.array([d_, c_]))\n\n# Numerator of the gamma_n function.\nnumerator = (cos_terms[0] * exp_d - cos_terms[1] * exp_c +\nbase * (sin_terms[0] * exp_d - sin_terms[1] * exp_c))\n\nreturn numerator / (1 + base**2)\n\ndef v_n(b1, b2, c, d, n, K):\n\"\"\"Calculate the v_n function, which combines psi_n and gamma_n.\"\"\"\nreturn 2 * K / (b2 - b1) * (psi_n(b1, b2, c, d, n) - gamma_n(b1, b2, c, d, n))\n\ndef log_char(t, S0, K, r, sigma, T):\n\"\"\"Compute the characteristic function under BS model (log normal return)\"\"\"\nterm1 = np.log(S0 / K) + (r - sigma**2 / 2) * T  # Logarithmic term\nterm2 = -sigma**2 * T * t**2 / 2  # Variance term\nreturn np.exp(1j * t * term1 + term2)\n\ndef put(N, b1, b2, c, d, S0, K, r, sigma, T):\n\"\"\"Calculate the price of a European put option using the COS method for multiple strike prices.\"\"\"\nprice = np.zeros(len(K), dtype=np.complex_)\n\n# Calculate initial price for n=0.\nprice += v_n(b1, b2, c, d, 0, K) * log_char(0, S0, K, r, sigma, T) / 2\n\n# Loop over the series expansion for n from 1 to N.\nfor i in range(1, N):\nt = i * np.pi / (b2 - b1)                           # Compute t for the current term\nlog_char_terms = log_char(t, S0, K, r, sigma, T)    # Evaluate characteristic function\nexp_term = np.exp(-1j * i * np.pi * b1 / (b2 - b1)) # Exponential decay term\nprice += log_char_terms * exp_term * v_n(b1, b2, c, d, i, K)\n\n# Return the real part of the discounted price.\nreturn np.exp(-r * T) * price.real\n\ndef option_delta(N, b1, b2, c, d, S0, K, r, sigma, T, delta_S=1e-5):\n\"\"\"Calculate the delta of a European put option using finite differencing.\"\"\"\n# Calculate option price at the current asset price.\nprice_current = put(N + 1, b1, b2, c, d, S0, K, r, sigma, T)\n\n# Calculate option price at slightly higher asset price.\nprice_up = put(N + 1, b1, b2, c, d, S0 + delta_S, K, r, sigma, T)\n\n# Calculate delta by finite differencing.\ndelta = (price_up - price_current) / delta_S\nreturn delta\n\n# Number of terms in the series expansion, the higher the more accurate.\nN = 50\n# Underlying asset price\nS = atm_call[1].underlying\n# Number of fractional years till expiry.\nT = (expiry - date + timedelta(1)).total_seconds() / 60 / 60 / 24 / 365.25\n# Get the interest rate and dividend yield to calculate the discount rate.\nr = np.log(1 + InterestRateProvider().get_interest_rate(date))      # continuous transformation\nq = DividendYieldProvider(index_symbol).get_dividend_yield(date)\n\nc1 = r - q              # under risk-neutral measure\nc2 = T * iv**2          # Brownian variance\nc4 = 0                  # Placeholder for additional variance (not used in this context)\nL = 10                  # Parameter for the bounds\n\n# Calculate bounds for the COS method.\nb1 = c1 - L * np.sqrt(c2 + np.sqrt(c4))  # Lower bound\nb2 = c1 + L * np.sqrt(c2 + np.sqrt(c4))  # Upper bound\n\n# Calculate the put option price using the COS method.\noption_delta = option_delta(N + 1, b1, b2, b1, 0, S, strikes, r, iv, T)\n\nhistory_df.index = [x.id.strike_price for x in history_df.index]\nax = history_df.delta.plot(title=\"Delta calculation using COS method\", xlabel=\"strike\", ylabel=\"delta\", label=\"actual\", legend=True)\nax.plot(history_df.index, option_delta, label=\"COS\")\nax.legend()",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.12",
      "breadcrumb": "Datasets > Index Options > Universes",
      "section_number": "3.12.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.12.3",
    "title": "Individual Contracts",
    "level": 3,
    "path": "Datasets > Index Options > Individual Contracts",
    "content": "### Introduction\n\nThis page explains how to request historical data for individual Index Option contracts.\nThehistory requestson this page only return the prices and open interest of the Option contracts, not their implied volatility or Greeks.\nFor information about history requests that return the daily implied volatility and Greeks, seeUniverses.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to individual Index Option contracts:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Index;\nusing QuantConnect.Securities.IndexOption;\nusing Microsoft.Data.Analysis;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Add the underlying Index.var underlyingSymbol = qb.AddIndex(\"SPX\", Resolution.Minute).Symbol;underlying_symbol = qb.add_index(\"SPX\", Resolution.MINUTE).symbolTo view the available Indices, seeSupported Assets.If you do not pass a resolution argument,Resolution.MinuteResolution.MINUTEis used by default.Set the start dateto a date in the past that you want to use as the analysis date.qb.SetStartDate(2024, 1, 1);qb.set_start_date(2024, 1, 1)The method that you call in the next step returns data on all the contracts that were tradable on this date.Call theOptionChainoption_chainmethod with the underlyingIndexSymbol.// Get the Option contracts that were tradable on January 1st, 2024.\n//   Option A: Standard contracts.\nvar chain = qb.OptionChain(\nQuantConnect.Symbol.CreateCanonicalOption(underlyingSymbol, Market.USA, \"?SPX\")\n);\n\n//   Option B: Weekly contracts.\n//var chain = qb.OptionChain(\n//    QuantConnect.Symbol.CreateCanonicalOption(underlyingSymbol, \"SPXW\", Market.USA, \"?SPXW\")\n//);# Get the Option contracts that were tradable on January 1st, 2024.\n#   Option A: Standard contracts.\nchain = qb.option_chain(\nSymbol.create_canonical_option(underlying_symbol, Market.USA, \"?SPX\"), flatten=True\n).data_frame\n\n#  Option B: Weekly contracts.\n#chain = qb.option_chain(\n#    Symbol.create_canonical_option(underlying_symbol, \"SPXW\", Market.USA, \"?SPXW\"), flatten=True\n#).data_frameThis method returns anOptionChainobject, which represent an entire chain of Option contracts for a single underlying security.You can even format the chain data into a DataFrame where each row in the DataFrame represents a single contract.Sort and filter the data to select the specific contract(s) you want to analyze.// Select a contract.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar contractSymbol = chain\n.Where(contract =>\n// Select call contracts with the closest expiry.\ncontract.Expiry == expiry &&\ncontract.Right == OptionRight.Call &&\n// Select contracts with a 0.3-0.7 delta.\ncontract.Greeks.Delta > 0.3m &&\ncontract.Greeks.Delta < 0.7m\n)\n// Select the contract with the largest open interest.\n.OrderByDescending(contract => contract.OpenInterest)\n.First()\n// Get the Symbol of the target contract.\n.Symbol;# Select a contract.\nexpiry = chain.expiry.min()\ncontract_symbol = chain[\n# Select call contracts with the closest expiry.\n(chain.expiry == expiry) &\n(chain.right == OptionRight.CALL) &\n# Select contracts with a 0.3-0.7 delta.\n(chain.delta > 0.3) &\n(chain.delta < 0.7)\n# Select the contract with the largest open interest.\n].sort_values('openinterest').index[-1]Call theAddIndexOptionContractadd_index_option_contractmethod with anOptionContractSymboland disable fill-forward.var optionContract = qb.AddIndexOptionContract(contractSymbol, fillForward: false);option_contract = qb.add_index_option_contract(contract_symbol, fill_forward=False)Disable fill-forward because there are only a fewOpenInterestdata points per day.\n\n### Trade History\n\nTradeBarobjects are price bars that consolidate individual trades from the exchanges. They contain the open, high, low, close, and volume of trading activity over a period of time.\n\nTo get trade data, call thehistoryorhistory[TradeBar]History<TradeBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<TradeBar>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var tradeBar in history)\n{\nConsole.WriteLine(tradeBar);\n}# DataFrame format\nhistory_df = qb.history(TradeBar, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# TradeBar objects\nhistory = qb.history[TradeBar](contract_symbol, timedelta(3))\nfor trade_bar in history:\nprint(trade_bar)\n\nTradeBarobjects have the following properties:\n\n### Quote History\n\nQuoteBarobjects are bars that consolidate NBBO quotes from the exchanges. They contain the open, high, low, and close prices of the bid and ask. TheOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarobject are the mean of the respective bid and ask prices. If the bid or ask portion of theQuoteBarhas no data, theOpenopen,Highhigh,Lowlow, andClosecloseproperties of theQuoteBarcopy the values of either theBidbidorAskaskinstead of taking their mean.\n\nTo get quote data, call thehistoryorhistory[QuoteBar]History<QuoteBar>method with the contractSymbolobject(s).\n\nvar history = qb.History<QuoteBar>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var quoteBar in history)\n{\nConsole.WriteLine(quoteBar);\n}# DataFrame format\nhistory_df = qb.history(QuoteBar, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# QuoteBar objects\nhistory = qb.history[QuoteBar](contract_symbol, timedelta(3))\nfor quote_bar in history:\nprint(quote_bar)\n\nQuoteBarobjects have the following properties:\n\n### Open Interest History\n\nOpen interest is the number of outstanding contracts that haven't been settled. It provides a measure of investor interest and the market liquidity, so it's a popular metric to use for contract selection. Open interest is calculated once per day.\n\nTo get open interest data, call thehistoryorhistory[OpenInterest]History<OpenInterest>method with the contractSymbolobject(s).\n\nvar history = qb.History<OpenInterest>(contractSymbol, TimeSpan.FromDays(3));\nforeach (var openInterest in history)\n{\nConsole.WriteLine(openInterest);\n}# DataFrame format\nhistory_df = qb.history(OpenInterest, contract_symbol, timedelta(3))\ndisplay(history_df)\n\n# OpenInterest objects\nhistory = qb.history[OpenInterest](contract_symbol, timedelta(3))\nfor open_interest in history:\nprint(open_interest)\n\nOpenInterestobjects have the following properties:\n\n### Greeks and IV History\n\nThe Greeks are measures that describe the sensitivity of an Option's price to various factors like underlying price changes (Delta), time decay (Theta), volatility (Vega), and interest rates (Rho), while Implied Volatility (IV) represents the market's expectation of the underlying asset's volatility over the life of the Option.\n\nFollow these steps to get the Greeks and IV data:\n\nCreate the mirror contractSymbol.var mirrorContractSymbol = Symbol.CreateOption(\noptionContract.Underlying.Symbol,\ncontractSymbol.ID.Market,\noptionContract.Style,\noptionContract.Right == OptionRight.Put ? OptionRight.Call : OptionRight.Put,\noptionContract.StrikePrice,\noptionContract.Expiry\n);mirror_contract_symbol = Symbol.create_option(\noption_contract.underlying.symbol, contract_symbol.id.market, option_contract.style,\nOptionRight.Call if option_contract.right == OptionRight.PUT else OptionRight.PUT,\noption_contract.strike_price, option_contract.expiry\n)Set up therisk free interest rate,dividend yield, andOption pricingmodels.Inour research, we found the Forward Tree model to be the best pricing model for indicators.risk_free_rate_model = qb.risk_free_interest_rate_model\ndividend_yield_model = DividendYieldProvider(underlying_symbol)\noption_model = OptionPricingModelType.FORWARD_TREEvar riskFreeRateModel = qb.RiskFreeInterestRateModel;\nvar dividendYieldModel = new DividendYieldProvider(underlyingSymbol);\nvar optionModel = OptionPricingModelType.ForwardTree;Define a method to return theIV & Greeks indicatorvalues for each contract.def greeks_and_iv(contracts, period, risk_free_rate_model, dividend_yield_model, option_model):\n# Get the call and put contract.\ncall, put = sorted(contracts, key=lambda s: s.id.option_right)\n\ndef get_values(indicator_class, contract, mirror_contract):\nreturn qb.indicator_history(\nindicator_class(contract, risk_free_rate_model, dividend_yield_model, mirror_contract, option_model),\n[contract, mirror_contract, contract.underlying],\nperiod\n).data_frame.current\n\nreturn pd.DataFrame({\n'iv_call': get_values(ImpliedVolatility, call, put),\n'iv_put': get_values(ImpliedVolatility, put, call),\n'delta_call': get_values(Delta, call, put),\n'delta_put': get_values(Delta, put, call),\n'gamma_call': get_values(Gamma, call, put),\n'gamma_put': get_values(Gamma, put, call),\n'rho_call': get_values(Rho, call, put),\n'rho_put': get_values(Rho, put, call),\n'vega_call': get_values(Vega, call, put),\n'vega_put': get_values(Vega, put, call),\n'theta_call': get_values(Theta, call, put),\n'theta_put': get_values(Theta, put, call),\n})Dictionary<string, IndicatorHistory> GreeksAndIV(List<Symbol> contracts, int period)\n{\n// Get the call and put contract.\nvar sortedSymbols = contracts.OrderBy(s => s.ID.OptionRight).ToArray();\nvar call = sortedSymbols[0];\nvar put = sortedSymbols[1];\n\nIndicatorHistory GetValues(OptionIndicatorBase indicator)\n{\n// Use both contracts and the underlying to update the indicator and get its value.\nreturn qb.IndicatorHistory(indicator, new[] { call, put, call.Underlying }, period);\n}\n\n// Get the values of all the IV and Greek indicators.\nreturn new Dictionary<string, IndicatorHistory>\n{\n{\"IVCall\", GetValues(new ImpliedVolatility(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"IVPut\", GetValues(new ImpliedVolatility(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"DeltaCall\", GetValues(new Delta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"DeltaPut\", GetValues(new Delta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"GammaCall\", GetValues(new Gamma(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"GammaPut\", GetValues(new Gamma(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"VegaCall\", GetValues(new Vega(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"VegaPut\", GetValues(new Vega(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"ThetaCall\", GetValues(new Theta(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"ThetaPut\", GetValues(new Theta(put, riskFreeRateModel, dividendYieldModel, call, optionModel))},\n{\"RhoCall\", GetValues(new Rho(call, riskFreeRateModel, dividendYieldModel, put, optionModel))},\n{\"RhoPut\", GetValues(new Rho(put, riskFreeRateModel, dividendYieldModel, call, optionModel))}\n};\n}Call the preceding method and display the results.greeks_and_iv([contract_symbol, mirror_contract_symbol], 15, risk_free_rate_model, dividend_yield_model, option_model)foreach (var (key, indicatorHistory) in GreeksAndIV(new List<Symbol> {contractSymbol, mirrorContractSymbol}, 15))\n{\nforeach (var dataPoint in indicatorHistory)\n{\nConsole.WriteLine($\"{dataPoint.EndTime} - {key}: {dataPoint.Current.Value}\");\n}\n}\n\nThe DataFrame can have NaN entries if there is no data for the contracts or the underlying asset at a moment in time.\n\n### Examples\n\nThe following examples demonstrate some common practices for analyzing individual Index Option contracts in the Research Environment.\n\nExample 1: Contract Trade History\n\nThe following notebook plots the historical prices of an SPX Index Option contract usingPlotlyPlotly.NET:\n\n#load \"../Initialize.csx\"\n\nimport plotly.graph_objects as go\n\n# Get the SPX Option chain for January 1, 2024.\nqb = QuantBook()\nunderlying_symbol = qb.add_index(\"SPX\").symbol\nqb.set_start_date(2024, 1, 1)\nchain = qb.option_chain(\nSymbol.create_canonical_option(underlying_symbol, Market.USA, \"?SPX\"), flatten=True\n).data_frame\n\n# Select a contract from the chain.\nexpiry = chain.expiry.min()\ncontract_symbol = chain[\n(chain.expiry == expiry) &\n(chain.right == OptionRight.CALL) &\n(chain.delta > 0.3) &\n(chain.delta < 0.7)\n].sort_values('openinterest').index[-1]\n\n# Add the target contract.\nqb.add_index_option_contract(contract_symbol)\n\n# Get the contract history.\nhistory = qb.history(contract_symbol, timedelta(3))\n\n# Plot the price history.\ngo.Figure(\ndata=go.Candlestick(\nx=history.index.levels[4],\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close']\n),\nlayout=go.Layout(\ntitle=go.layout.Title(text=f'{contract_symbol.value} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False\n)\n).show()#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Option;\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Get the SPX Option chain for January 1, 2024.\nvar qb = new QuantBook();\nvar underlyingSymbol = qb.AddIndex(\"SPX\").Symbol;\nqb.SetStartDate(2024, 1, 1);\nvar chain = qb.OptionChain(\nQuantConnect.Symbol.CreateCanonicalOption(underlyingSymbol, Market.USA, \"?SPX\")\n);\n\n// Select a contract from the chain.\nvar expiry = chain.Select(contract => contract.Expiry).Min();\nvar contractSymbol = chain\n.Where(contract =>\ncontract.Expiry == expiry &&\ncontract.Right == OptionRight.Call &&\ncontract.Greeks.Delta > 0.3m &&\ncontract.Greeks.Delta < 0.7m\n)\n.OrderByDescending(contract => contract.OpenInterest)\n.First()\n.Symbol;\n\n// Add the target contract.\nqb.AddIndexOptionContract(contractSymbol);\n\n// Get the contract history.\nvar history = qb.History<TradeBar>(contractSymbol, TimeSpan.FromDays(3));\n\n// Plot the price history.\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{contractSymbol} Price\");\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\nchart.WithLayout(layout);\nHTML(GenericChart.toChartHTML(chart))\n\nExample 2: Contract Open Interest History\n\nThe following notebook plots the historical open interest of a VIXW Index Option contract usingMatplotlibPlotly.NET:\n\n#load \"../Initialize.csx\"\n\n# Get the VIX weekly Option chain for January 1, 2024.\nqb = QuantBook()\nunderlying_symbol = qb.add_index(\"VIX\").symbol\nqb.set_start_date(2024, 1, 1)\nchain = qb.option_chain(\nSymbol.create_canonical_option(underlying_symbol, \"VIXW\", Market.USA, \"?VIXW\"), flatten=True\n).data_frame\n\n# Select a contract from the chain.\nstrike_distance = (chain.strike - chain.underlyinglastprice).abs()\ntarget_strike_distance = strike_distance.min()\nchain = chain.loc[strike_distance[strike_distance == target_strike_distance].index]\ncontract_symbol = chain.sort_values('openinterest').index[-1]\n\n# Add the target contract.\nqb.add_index_option_contract(contract_symbol, fill_forward=False)\n\n# Get the contract's open interest history.\nhistory = qb.history(OpenInterest, contract_symbol, timedelta(90))\nhistory.index = history.index.droplevel([0, 1, 2])\nhistory = history['openinterest'].unstack(0)[contract_symbol]\n\n# Plot the open interest history.\nhistory.plot(title=f'{contract_symbol.value} Open Interest')\nplt.show()#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Securities.Option;\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Get the VIX weekly Option chain for January 1, 2024.\nvar qb = new QuantBook();\nvar underlyingSymbol = qb.AddIndex(\"VIX\").Symbol;\nqb.SetStartDate(2024, 1, 1);\nvar chain = qb.OptionChain(\nQuantConnect.Symbol.CreateCanonicalOption(underlyingSymbol, \"VIXW\", Market.USA, \"?VIXW\")\n);\n\n// Select a contract from the chain.\nvar targetStrikeDistance = chain\n.Select(contract => Math.Abs(contract.Strike - contract.UnderlyingLastPrice))\n.Min();\nvar contractSymbol = chain\n.Where(contract => Math.Abs(contract.Strike - contract.UnderlyingLastPrice) == targetStrikeDistance)\n.OrderBy(contract => contract.OpenInterest)\n.Last()\n.Symbol;\n\n// Add the target contract.\nqb.AddIndexOptionContract(contractSymbol, fillForward: false);\n\n// Get the contract's open interest history.\nvar history = qb.History<OpenInterest>(contractSymbol, TimeSpan.FromDays(90));\n\n// Plot the open interest history.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x.EndTime),\nhistory.Select(x => x.Value)\n);\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Open Interest\");\nTitle title = Title.init($\"{contractSymbol.Value} Open Interest\");\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\nchart.WithLayout(layout);\nHTML(GenericChart.toChartHTML(chart))",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3.12",
      "breadcrumb": "Datasets > Index Options > Individual Contracts",
      "section_number": "3.12.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.13",
    "title": "Alternative Data",
    "level": 2,
    "path": "Datasets > Alternative Data",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical alternative data. This tutorial uses theVIX Daily Pricedataset from the CBOE as the example dataset.\n\n### Create Subscriptions\n\nFollow these steps to subscribe to an alternative dataset from theDataset Market:\n\nLoad the required assembly files and data types.#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.DataSource;\nusing Microsoft.Data.Analysis;Load the dynamic link library (DLL) of the dataset.To load the DLL of any dataset, type:#r \"../QuantConnect.DataSource.<nameOfAlternativeDatasetClass>.dll\"For example, to load the DLL of the CBOE dataset, type:#r \"../QuantConnect.DataSource.CBOE.dll\"Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddDataadd_datamethod with the dataset class, a ticker, and a resolution and then save a reference to the alternative dataSymbol.var vix = qb.AddData<CBOE>(\"VIX\", Resolution.Daily).Symbol;\nvar v3m = qb.AddData<CBOE>(\"VIX3M\", Resolution.Daily).Symbol;vix = qb.add_data(CBOE, \"VIX\", Resolution.DAILY).symbol\nv3m = qb.add_data(CBOE, \"VIX3M\", Resolution.DAILY).symbolTo view the arguments that theAddDataadd_datamethod accepts for each dataset, see thedataset listing.If you don't pass a resolution argument, the default resolution of the dataset is used by default. To view the supported resolutions and the default resolution of each dataset, see thedataset listing.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a dataset. On the time dimension, you can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time. On the dataset dimension, you can request historical data for a single dataset subscription, a subset of the dataset subscriptions you created in your notebook, or all of the dataset subscriptions in your notebook.\n\nTrailing Number of Bars\n\nTo get historical data for a number of trailing bars, call theHistoryhistorymethod with theSymbolobject(s) and an integer.\n\n// Slice objects\nvar singleHistorySlice = qb.History(vix, 10);\nvar subsetHistorySlice = qb.History(new[] {vix, v3m}, 10);\nvar allHistorySlice = qb.History(10);\n\n// CBOE objects\nvar singleHistoryDataObjects = qb.History<CBOE>(vix, 10);\nvar subsetHistoryDataObjects = qb.History<CBOE>(new[] {vix, v3m}, 10);\nvar allHistoryDataObjects = qb.History<CBOE>(qb.Securities.Keys, 10);# DataFrame\nsingle_history_df = qb.History(vix, 10)\nsubset_history_df = qb.History([vix, v3m], 10)\nall_history_df = qb.History(qb.Securities.Keys, 10)\n\n# Slice objects\nall_history_slice = qb.History(10)\n\n# CBOE objects\nsingle_history_data_objects = qb.History[CBOE](vix, 10)\nsubset_history_data_objects = qb.History[CBOE]([vix, v3m], 10)all_history_data_objects = qb.History[CBOE](qb.Securities.Keys, 10)\n\nThe preceding calls return the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nTo get historical data for a trailing period of time, call theHistoryhistorymethod with theSymbolobject(s) and aTimeSpantimedelta.\n\n// Slice objects\nvar singleHistorySlice = qb.History(vix, TimeSpan.FromDays(3));\nvar subsetHistorySlice = qb.History(new[] {vix, v3m}, TimeSpan.FromDays(3));\nvar allHistorySlice = qb.History(10);\n\n// CBOE objects\nvar singleHistoryDataObjects = qb.History<CBOE>(vix, TimeSpan.FromDays(3));var subsetHistoryDataObjects = qb.History<CBOE>(new[] {vix, v3m}, TimeSpan.FromDays(3));var allHistoryDataObjects = qb.History<CBOE>(TimeSpan.FromDays(3));# DataFrame\nsingle_history_df = qb.History(vix, timedelta(days=3))\nsubset_history_df = qb.History([vix, v3m], timedelta(days=3))\nall_history_df = qb.History(qb.Securities.Keys, timedelta(days=3))\n\n# Slice objects\nall_history_slice = qb.History(timedelta(days=3))\n\n# CBOE objects\nsingle_history_data_objects = qb.History[CBOE](vix, timedelta(days=3))subset_history_data_objects = qb.History[CBOE]([vix, v3m], timedelta(days=3))all_history_data_objects = qb.History[CBOE](qb.Securities.Keys, timedelta(days=3))\n\nThe preceding calls return the most recent bars or ticks, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nTo get historical data for a specific period of time, call theHistoryhistorymethod with theSymbolobject(s), a startDateTimedatetime, and an endDateTimedatetime. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2021, 1, 1);\nvar endTime = new DateTime(2021, 3, 1);\n\n// Slice objects\nvar singleHistorySlice = qb.History(vix, startTime, endTime);\nvar subsetHistorySlice = qb.History(new[] {vix, v3m}, startTime, endTime);\nvar allHistorySlice = qb.History(startTime, endTime);\n\n// CBOE objects\nvar singleHistoryDataObjects = qb.History<CBOE>(vix, startTime, endTime);var subsetHistoryDataObjects = qb.History<CBOE>(new[] {vix, v3m}, startTime, endTime);var allHistoryDataObjects = qb.History<CBOE>(qb.Securities.Keys, startTime, endTime);start_time = datetime(2021, 1, 1)\nend_time = datetime(2021, 3, 1)\n\n# DataFrame\nsingle_history_df = qb.History(vix, start_time, end_time)\nsubset_history_df = qb.History([vix, v3m], start_time, end_time)\nall_history_df = qb.History(qb.Securities.Keys, start_time, end_time)\n\n# Slice objects\nall_history_slice = qb.History(start_time, end_time)\n\n# CBOE objects\nsingle_history_data_objects = qb.History[CBOE](vix, start_time, end_time)subset_history_data_objects = qb.History[CBOE]([vix, v3m], start_time, end_time)all_history_data_objects = qb.History[CBOE](qb.Securities.Keys, start_time, end_time)\n\nThe preceding calls return the bars or ticks that have a timestamp within the defined period of time.\n\nIf you do not pass a resolution to theHistoryhistorymethod, theHistoryhistorymethod uses the resolution that theAddDataadd_datamethod used when you created thesubscription.\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. The process to manipulate the historical data depends on its data type. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data. The process to manipulate the historical data depends on its data type.\n\nDataFrame Objects\n\nIf theHistoryhistorymethod returns aDataFrame, the first level of theDataFrameindex is theencoded dataset Symboland the second level is theEndTimeend_timeof the data sample. The columns of theDataFrameare the data properties.\n\nTo select the historical data of a single dataset, index thelocproperty of theDataFramewith the datasetSymbol.\n\nall_history_df.loc[vix]  # or all_history_df.loc['VIX']\n\nTo select a column of theDataFrame, index it with the column name.\n\nall_history_df.loc[vix]['close']\n\nIf you request historical data for multiple tickers, you can transform theDataFrameso that it's a time series of close values for all of the tickers. To transform theDataFrame, select the column you want to display for each ticker and then call theunstackmethod.\n\nall_history_df['close'].unstack(level=0)\n\nTheDataFrameis transformed so that the column indices are theSymbolof each ticker and each row contains the close value.\n\nThe historical data methods don't return DataFrame objects, but you can create one for efficient vectorized data wrangling.\n\nusing Microsoft.Data.Analysis;\n\nvar columns = new DataFrameColumn[] {\nnew PrimitiveDataFrameColumn(\"Time\", history.Select(x => x[vix].EndTime)),\nnew DecimalDataFrameColumn(\"VIX Open\", history.Select(x => x[vix].Open)),\nnew DecimalDataFrameColumn(\"VIX High\", history.Select(x => x[vix].High)),\nnew DecimalDataFrameColumn(\"VIX Low\", history.Select(x => x[vix].Low)),\nnew DecimalDataFrameColumn(\"VIX Close\", history.Select(x => x[vix].Close))\n};\nvar df = new DataFrame(columns);\ndf\n\nTo select a particular column of the DataFrame, index it with the column name.\n\ndf[\"VIX close\"]\n\nSlice Objects\n\nIf theHistoryhistorymethod returnsSliceobjects, iterate through theSliceobjects to get each one. TheSliceobjects may not have data for all of your dataset subscriptions. To avoid issues, check if theSlicecontains data for your ticker before you index it with the datasetSymbol.\n\nforeach (var slice in allHistorySlice) {\nif (slice.ContainsKey(vix))\n{\nvar data = slice[vix];\n}\n}for slice in all_history_slice:\nif slice.contains_key(vix):\ndata = slice[vix]\n\n-- ---\n\n-- ---\n\n-- ---\n\n-- ---\n\n-- ---\n\n-- ---\n\n-- ---\n\n### Plot Data\n\nYou need somehistorical alternative datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nYou can only create candlestick charts for alternative datasets that have open, high, low, and close properties.\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(vix, datetime(2021, 1, 1), datetime(2021, 2, 1)).loc[vix]var history = qb.History<CBOE>(vix, new DateTime(2021, 12, 1), new DateTime(2021, 12, 31));Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text='VIX from CBOE OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{vix} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create aFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the alternative data.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nGet some historical data.history = qb.history([vix, v3m], datetime(2021, 1, 1), datetime(2021, 2, 1))var history = qb.History<CBOE>(new [] {vix, v3x}, new DateTime(2021, 1, 1), new DateTime(2021, 2, 1));Select the data to plot.values = history['close'].unstack(0)Call theplotmethod on thepandasobject.values.plot(title = 'Close', figsize=(15, 10))CreateLinecharts.var chart1 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[vix].EndTime),\nhistory.Select(x => x[vix].Close),\nName: $\"{vix}\"\n);\nvar chart2 = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x[v3m].EndTime),\nhistory.Select(x => x[v3m].Close),\nName: $\"{v3m}\"\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{vix} & {v3m} Close Price\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Combine the charts and assign theLayoutto the chart.var chart = Plotly.NET.Chart.Combine(new []{chart1, chart2});\nchart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.\n\n### Examples\n\nThe following examples demonstrate some common practices for applying the Equity Fundamental Data dataset.\n\nExample 1: PE Ratio Line Chart\n\nThe following example studies the trend of 10-year yield curve using a line chart.\n\n// Load the required assembly files and data types in a separate cell.\n#load \"../Initialize.csx\"\n\n#load \"../QuantConnect.csx\"\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.DataSource;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\n\n// Import Plotly for plotting.\n#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;\n\n// Create a QuantBook.\nvar qb = new QuantBook();\n\n// Request 10-year US Yield Curve historical data.\nvar symbol = qb.AddData<USTreasuryYieldCurveRate>(\"USTYCR\").Symbol;\nvar history = qb.History<USTreasuryYieldCurveRate>(\nsymbol,\nstart: qb.Time - TimeSpan.FromDays(365),\nend: qb.Time,\nresolution: Resolution.Daily\n);\n\n// Select the 10-year yield rate to study.\nvar y10YieldRate = history.Select(x => x.TenYear).ToList();\nvar time = history.Select(x => x.EndTime).ToList();\n\n// Crete the Line Chart with the 10-year yield rate.\nvar chart = Chart2D.Chart.Line<DateTime, double, string>(\ntime,\ny10YieldRate\n);\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"10-Year Yield Rate\");\nTitle title = Title.init($\"10-Year Yield Rate by Time of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Create a QuantBook\nqb = QuantBook()\n\n# Request 10-year US Yield Curve historical data.\nsymbol = qb.add_data(USTreasuryYieldCurveRate, \"USTYCR\").symbol\nhistory = qb.history(\nUSTreasuryYieldCurveRate,\nsymbol,\nstart=qb.time - timedelta(days=365),\nend=qb.time,\nresolution=Resolution.DAILY,\nflatten=True\n)\n\n# Select the 10-year US Yield Rate to study.\npe_ratio = history.droplevel([0]).tenyear\n# Plot the 10-year US Yield Rate line chart.\npe_ratio.plot(title=f\"10-year US Yield Rate by Time of {symbol}\", ylabel=\"Yield Rate\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Alternative Data",
      "section_number": "3.13",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "3.14",
    "title": "Custom Data",
    "level": 2,
    "path": "Datasets > Custom Data",
    "content": "### Introduction\n\nThis page explains how to request, manipulate, and visualize historical user-defined custom data.\n\n### Define Custom Data\n\nYou must format the data file into chronological order before you define the custom data class.\n\nTo define a custom data class, extend theBaseDataPythonDataclass and override theGetSourceandReadermethods.\n\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing Microsoft.Data.Analysis;\n\npublic class Nifty : BaseData\n{\npublic decimal Open;\npublic decimal High;\npublic decimal Low;\npublic decimal Close;\n\npublic Nifty()\n{\n}\n\npublic override SubscriptionDataSource GetSource(SubscriptionDataConfig config, DateTime date, bool isLiveMode)\n{\nvar url = \"http://cdn.quantconnect.com.s3.us-east-1.amazonaws.com/uploads/CNXNIFTY.csv\";\nreturn new SubscriptionDataSource(url, SubscriptionTransportMedium.RemoteFile);\n}\n\npublic override BaseData Reader(SubscriptionDataConfig config, string line, DateTime date, bool isLiveMode)\n{\nvar index = new Nifty();\nindex.Symbol = config.Symbol;\n\ntry\n{\n//Example File Format:\n//Date,       Open       High        Low       Close     Volume      Turnover\n//2011-09-13  7792.9    7799.9     7722.65    7748.7    116534670    6107.78\nvar data = line.Split(',');\nindex.Time = DateTime.Parse(data[0], CultureInfo.InvariantCulture);\nindex.EndTime = index.Time.AddDays(1);\nindex.Open = Convert.ToDecimal(data[1], CultureInfo.InvariantCulture);\nindex.High = Convert.ToDecimal(data[2], CultureInfo.InvariantCulture);\nindex.Low = Convert.ToDecimal(data[3], CultureInfo.InvariantCulture);\nindex.Close = Convert.ToDecimal(data[4], CultureInfo.InvariantCulture);\nindex.Value = index.Close;\n}\ncatch\n{\n// Do nothing\n}\nreturn index;\n}\n}class Nifty(PythonData):\n'''NIFTY Custom Data Class'''\ndef get_source(self, config: SubscriptionDataConfig, date: datetime, is_live_mode: bool) -> SubscriptionDataSource:\nurl = \"http://cdn.quantconnect.com.s3.us-east-1.amazonaws.com/uploads/CNXNIFTY.csv\"\nreturn SubscriptionDataSource(url, SubscriptionTransportMedium.REMOTE_FILE)\n\ndef reader(self, config: SubscriptionDataConfig, line: str, date: datetime, is_live_mode: bool) -> BaseData:\nif not (line.strip() and line[0].isdigit()): return None\n\n# New Nifty object\nindex = Nifty()\nindex.symbol = config.symbol\n\ntry:\n# Example File Format:\n# Date,       Open       High        Low       Close     Volume      Turnover\n# 2011-09-13  7792.9    7799.9     7722.65    7748.7    116534670    6107.78\ndata = line.split(',')\nindex.time = datetime.strptime(data[0], \"%Y-%m-%d\")\nindex.end_time = index.time + timedelta(days=1)\nindex.value = data[4]\nindex[\"Open\"] = float(data[1])\nindex[\"High\"] = float(data[2])\nindex[\"Low\"] = float(data[3])\nindex[\"Close\"] = float(data[4])\n\nexcept:\npass\n\nreturn index\n\n### Create Subscriptions\n\nYou need todefine a custom data classbefore you can subscribe to it.\n\nFollow these steps to subscribe to custom dataset:\n\nCreate aQuantBook.var qb = new QuantBook();qb = QuantBook()Call theAddDataadd_datamethod with a ticker and then save a reference to the dataSymbol.var symbol = qb.AddData<Nifty>(\"NIFTY\").Symbol;symbol = qb.add_data(Nifty, \"NIFTY\").symbolCustom data has its own resolution, so you don't need to specify it.\n\n### Get Historical Data\n\nYou need asubscriptionbefore you can request historical data for a security. You can request an amount of historical data based on a trailing number of bars, a trailing period of time, or a defined period of time.\n\nBefore you request data, callSetStartDateset_start_datemethod with adatetimeDateTimeto reduce the risk oflook-ahead bias.\n\nqb.set_start_date(2014, 7, 29);qb.set_start_date(2014, 7, 29)\n\nIf you call theSetStartDateset_start_datemethod, the date that you pass to the method is the latest date for which your history requests will return data.\n\nTrailing Number of Bars\n\nCall theHistoryhistorymethod with a symbol, integer, and resolution to request historical data based on the given number of trailing bars and resolution.\n\nvar history = qb.history(symbol, 10);history = qb.history(symbol, 10)\n\nThis method returns the most recent bars, excluding periods of time when the exchange was closed.\n\nTrailing Period of Time\n\nCall theHistoryhistorymethod with a symbol,TimeSpantimedelta, and resolution to request historical data based on the given trailing period of time and resolution.\n\nvar history = qb.History(symbol, TimeSpan.FromDays(10));history = qb.history(symbol, timedelta(days=10))\n\nThis method returns the most recent bars, excluding periods of time when the exchange was closed.\n\nDefined Period of Time\n\nCall theHistoryhistorymethod with a symbol, startDateTimedatetime, endDateTimedatetime, and resolution to request historical data based on the defined period of time and resolution. The start and end times you provide are based in thenotebook time zone.\n\nvar startTime = new DateTime(2013, 7, 29);\nvar endTime = new DateTime(2014, 7, 29);\nvar history = qb.History(symbol, startTime, endTime);start_time = datetime(2013, 7, 29)\nend_time = datetime(2014, 7, 29)\nhistory = qb.history(symbol, start_time, end_time)\n\nThis method returns the bars that are timestamped within the defined period of time.\n\nIn all of the cases above, theHistoryhistorymethod returns aDataFramewith aMultiIndex.\n\nIn all of the cases above, theHistoryhistorymethod returns anIEnumerable<Nifty>for single-security requests.\n\nDownload Method\n\nTo download the data directly from the remote file location instead of using your custom data class, call theDownloaddownloadmethod with the data URL.\n\nvar content = qb.download(\"http://cdn.quantconnect.com.s3.us-east-1.amazonaws.com/uploads/CNXNIFTY.csv\");content = qb.download(\"http://cdn.quantconnect.com.s3.us-east-1.amazonaws.com/uploads/CNXNIFTY.csv\")\n\nFollow these steps to convert the content to aDataFrame:\n\nImport theStringIOfrom theiolibrary.from io import StringIOCreate aStringIO.data = StringIO(content)Call theread_csvmethod.dataframe = pd.read_csv(data, index_col=0)\n\n### Wrangle Data\n\nYou need somehistorical datato perform wrangling operations. To displaypandasobjects, run a cell in a notebook with thepandasobject as the last line. To display other data formats, call theprintmethod.\n\nYou need somehistorical datato perform wrangling operations. Use LINQ to wrangle the data and then call theConsole.WriteLinemethod in a Jupyter Notebook to display the data.\n\nTheDataFramethat theHistoryhistorymethod returns has the following index levels:\n\nDatasetSymbolTheEndTimeend_timeof the data sample\n\nThe columns of theDataFrameare the data properties.\n\nTo select the data of a single dataset, index thelocproperty of theDataFramewith the dataSymbol.\n\nhistory.loc[symbol]\n\nTo select a column of theDataFrame, index it with the column name.\n\nhistory.loc[symbol]['close']\n\nTo get each custom data object, iterate through the result of the history request.\n\nforeach(var nifty in history)\n{\nConsole.WriteLine($\"{nifty} EndTime: {nifty.EndTime}\");\n}\n\n### Plot Data\n\nYou need somehistorical custom datato produce plots. You can usemany of thesupported plotting librariesPlot.NETpackageto visualize data in various formats. For example, you can plot candlestick and line charts.\n\nCandlestick Chart\n\nFollow these steps to plot candlestick charts:\n\nGet somehistorical data.history = qb.history(Nifty, datetime(2013, 7, 1), datetime(2014, 7, 31)).loc[symbol]var history = qb.History<Nifty>(symbol, new DateTime(2013, 7, 1), new DateTime(2014, 7, 31));Import theplotlyPlot.NETlibrary.import plotly.graph_objects as go#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create aCandlestick.candlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'])var chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nhistory.Select(x => x.Open),\nhistory.Select(x => x.High),\nhistory.Select(x => x.Low),\nhistory.Select(x => x.Close),\nhistory.Select(x => x.EndTime)\n);Create aLayout.layout = go.Layout(title=go.layout.Title(text=f'{symbol} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Create aFigure.fig = go.Figure(data=[candlestick], layout=layout)Assign theLayoutto the chart.chart.WithLayout(layout);Show theFigure.fig.show()HTML(GenericChart.toChartHTML(chart))Candlestick charts display the open, high, low, and close prices of the security.\n\nLine Chart\n\nFollow these steps to plot line charts usingbuilt-in methodsPlotly.NETpackage:\n\nSelect data to plot.values = history['value'].unstack(level=0)Call theplotmethod on thepandasobject.values.plot(title=\"Value\", figsize=(15, 10))Create aLinechart.var chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nhistory.Select(x => x.EndTime),\nhistory.Select(x => x.Close)\n);Create aLayout.LinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} Close\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);Assign theLayoutto the chart.chart.WithLayout(layout);Show the plot.plt.show()HTML(GenericChart.toChartHTML(chart))Line charts display the value of the property you selected in a time series.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "3",
      "breadcrumb": "Datasets > Custom Data",
      "section_number": "3.14",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4",
    "title": "Charting",
    "level": 1,
    "path": "Charting",
    "content": "The Research Environment is centered around analyzing and understanding data. One way to gain a more intuitive understanding of the existing relationships in our data is to visualize it using charts. There are many different libraries that allow you to chart our data in different ways. Sometimes the right chart can illuminate an interesting relationship in the data. Click one of the following libraries to learn more about it:BokehMatplotlibPlotlySeabornPlotly NETSee AlsoSupported LibrariesAlgorithm Charting",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Charting",
      "section_number": "4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4.1",
    "title": "Bokeh",
    "level": 2,
    "path": "Charting > Bokeh",
    "content": "### Introduction\n\nbokehis a Python library you can use to create interactive visualizations. It helps you build beautiful graphics, ranging from simple plots to complex dashboards with streaming datasets. Withbokeh, you can create JavaScript-powered visualizations without writing any JavaScript.\n\n### Preparation\n\nImport Libraries\n\nTo research with theBokehlibrary, import the libraries that you need.\n\n# Import the Bokeh library for plots and settings.\nfrom bokeh.plotting import figure, show\nfrom bokeh.models import BasicTicker, ColorBar, ColumnDataSource, LinearColorMapper\nfrom bokeh.palettes import Category20c\nfrom bokeh.transform import cumsum, transform\nfrom bokeh.io import output_notebook\n\n# Call the `output_notebook` method for displaying the plots in the jupyter notebook.\noutput_notebook()\n\nGet Historical Data\n\nGet some historical market datato produce the plots. For example, to get data for a bank sector ETF and some banking companies over 2021, run:\n\nqb = QuantBook()\ntickers = [\"XLF\",   # Financial Select Sector SPDR Fund\n\"COF\",   # Capital One Financial Corporation\n\"GS\",    # Goldman Sachs Group, Inc.\n\"JPM\",   # J P Morgan Chase & Co\n\"WFC\"]   # Wells Fargo & Company\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2021, 1, 1), datetime(2022, 1, 1))\n\n### Create Candlestick Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a candlestick chart that shows the open, high, low, and close prices of one of the banking securities. Follow these steps to create the candlestick chart:\n\n# Obtain the historical price data for a single symbol.\nsymbol = symbols[0]\ndata = history.loc[symbol]\n\n# Divide the data into days with positive returns and days with negative returns, since they will be plotted in different colors.\nup_days = data[data['close'] > data['open']]\ndown_days = data[data['open'] > data['close']]\n\n# Create the figure instance with the axes.\nplot = figure(title=f\"{symbol} OHLC\", x_axis_label='Date', y_axis_label='Price', x_axis_type='datetime')\n\n# Plot the high to low price each day with a vertical black line.\nplot.segment(data.index, data['high'], data.index, data['low'], color=\"black\")\n\n# Overlay the green or red box on top of the vertical line to create the candlesticks.\nwidth = 12*60*60*1000\nplot.vbar(up_days.index, width, up_days['open'], up_days['close'],\nfill_color=\"green\", line_color=\"green\")\nplot.vbar(down_days.index, width, down_days['open'], down_days['close'],\nfill_color=\"red\", line_color=\"red\")\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the candlestick chart.\n\n### Create Line Plot\n\nYou mustimport the plotting libraries and get some historical datato create line charts.\n\nIn this example, you create a line chart that shows the closing price for one of the banking securities. Follow these steps to create the line chart:\n\n# Obtain the close price series for a single symbol.\nsymbol = symbols[0]\nclose_prices = history.loc[symbol]['close']\n\n# Create the figure instance with the axis settings.\nplot = figure(title=f\"{symbol} Close Price\", x_axis_label='Date', y_axis_label='Price', x_axis_type='datetime')\n\n# Plot the line chart with the timestamps, the close price series, and some design settings.\nplot.line(close_prices.index, close_prices,\nlegend_label=symbol.value, color=\"blue\", line_width=2)\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the line plot.\n\n### Create Scatter Plot\n\nYou mustimport the plotting libraries and get some historical datato create scatter plots.\n\nIn this example, you create a scatter plot that shows the relationship between the daily returns of two banking securities. Follow these steps to create the scatter plot:\n\n# Select 2 stocks to plot the correlation between their return series.\nsymbol1 = symbols[1]\nsymbol2 = symbols[2]\nclose_price1 = history.loc[symbol1]['close']\nclose_price2 = history.loc[symbol2]['close']\ndaily_return1 = close_price1.pct_change().dropna()\ndaily_return2 = close_price2.pct_change().dropna()\n\n# Fit a linear regression model on the correlation.\nm, b = np.polyfit(daily_returns1, daily_returns2, deg=1)\n\n# Generate a prediction line upon the linear regression model.\nx = np.linspace(daily_returns1.min(), daily_returns1.max())\ny = m*x + b\n\n# Create the figure instance with the axis settings.\nplot = figure(title=f\"{symbol1} vs {symbol2} Daily Return\",\nx_axis_label=symbol1.value, y_axis_label=symbol2.value)\n\n# Call the line method with x- and y-axis values, a color, and a line width to plot the linear regression prediction line.\nplot.line(x, y, color=\"red\", line_width=2)\n\n# Call the dot method with the daily_returns1, daily_returns2, and some design settings to plot the scatter plot dots of the daily returns.\nplot.dot(daily_returns1, daily_returns2, size=20, color=\"navy\", alpha=0.5)\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the scatter plot.\n\n### Create Histogram\n\nYou mustimport the plotting libraries and get some historical datato create histograms.\n\nIn this example, you create a histogram that shows the distribution of the daily percent returns of the bank sector ETF. In addition to the bins in the histogram, you overlay a normal distribution curve for comparison. Follow these steps to create the histogram:\n\n# Obtain the daily return series for a single symbol.\nsymbol = symbols[0]\nclose_prices = history.loc[symbol]['close']\ndaily_returns = close_prices.pct_change().dropna()\n\n# Call the histogram method with the daily_returns, the density argument enabled, and a number of bins.\nhist, edges = np.histogram(daily_returns, density=True, bins=20)\n# hist: The value of the probability density function at each bin, normalized such that the integral over the range is 1.\n# edges: The x-axis value of the edges of each bin.\n\n# Create the figure instance with the axis settings.\nplot = figure(title=f\"{symbol} Daily Return Distribution\",\nx_axis_label='Return', y_axis_label='Frequency')\n\n# Call the quad method with the coordinates of the bins and some design settings to plot the histogram bins.\nplot.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\nfill_color=\"navy\", line_color=\"white\", alpha=0.5)\n\n# Get the mean and standard deviation of the returns.\nmean = daily_returns.mean()\nstd = daily_returns.std()\n# Calculate the normal distribution PDF given the mean and SD.\nx = np.linspace(-3*std, 3*std, 1000)\npdf = 1/(std * np.sqrt(2*np.pi)) * np.exp(-(x-mean)**2 / (2*std**2))\n# Plot a normal distribution PDF curve of the daily returns.\nplot.line(x, pdf, color=\"red\", line_width=4,\nalpha=0.7, legend_label=\"Normal Distribution PDF\")\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the histogram.\n\n### Create Bar Chart\n\nYou mustimport the plotting libraries and get some historical datato create bar charts.\n\nIn this example, you create a bar chart that shows the average daily percent return of the banking securities. Follow these steps to create the bar chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change() * 100\n\n# Obtain the mean of the daily return.\navg_daily_returns = daily_returns.mean()\n\n# Call the DataFrame constructor with the data Series and then call the reset_index method.\navg_daily_returns = pd.DataFrame(avg_daily_returns, columns=['avg_return']).reset_index()\n\n# Create the figure instance with the axis settings.\nplot = figure(title='Banking Stocks Average Daily % Returns', x_range=avg_daily_returns['symbol'],\nx_axis_label='%', y_axis_label='Stocks')\n\nCall thevbarmethod with theavg_daily_returns, x- and y-axis column names, and a bar width to plot the mean daily return bars.\nplot.vbar(source=avg_daily_returns, x='symbol', top='avg_return', width=0.8)\n\n# Rotate the x-axis label to display the plot axis properly.\nplot.xaxis.major_label_orientation = 0.6\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the bar chart.\n\n### Create Heat Map\n\nYou mustimport the plotting libraries and get some historical datato create heat maps.\n\nIn this example, you create a heat map that shows the correlation between the daily returns of the banking securities. Follow these steps to create the heat map:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Call the corr method to create the correlation matrix to plot.\ncorr_matrix = daily_returns.corr()\n# Set the index and columns of the corr_matrix to the ticker of each security and then set the name of the column and row indices.\ncorr_matrix.index = corr_matrix.columns = [symbol.value for symbol in symbols]\ncorr_matrix.index.name = 'symbol'\ncorr_matrix.columns.name = \"stocks\"\n\n# Call the stack, rename, and reset_index methods for ease of plotting.\ncorr_matrix = corr_matrix.stack().rename(\"value\").reset_index()\n\n# Create the figure instance with the axis settings.\nplot = figure(title=f\"Banking Stocks and Bank Sector ETF Correlation Heat Map\",\nx_range=list(corr_matrix.symbol.drop_duplicates()),\ny_range=list(corr_matrix.stocks.drop_duplicates()),\ntoolbar_location=None,\ntools=\"\",\nx_axis_location=\"above\")\n\n# Select a color palette and then call the LinearColorMapper constructor with the color pallet, the minimum correlation, and the maximum correlation to set the heatmap color.\ncolors = Category20c[len(corr_matrix.columns)]\nmapper = LinearColorMapper(palette=colors, low=corr_matrix.value.min(),\nhigh=corr_matrix.value.max())\n\n# Call the rect method with the correlation plot data and design setting to plot the heatmap.\nplot.rect(source=ColumnDataSource(corr_matrix),\nx=\"stocks\",\ny=\"symbol\",\nwidth=1,\nheight=1,\nline_color=None,\nfill_color=transform('value', mapper))\n\n# Creates a color bar to represent the correlation coefficients of the heat map cells.\n# Call the ColorBar constructor with the mapper, a location, and a BaseTicker.\ncolor_bar = ColorBar(color_mapper=mapper,\nlocation=(0, 0),\nticker=BasicTicker(desired_num_ticks=len(colors)))\n\n# Plot the color bar to the right of the heat map.\n# Call the add_layout method with the color_bar and a location.\nplot.add_layout(color_bar, 'right')\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the heat map.\n\n### Create Pie Chart\n\nYou mustimport the plotting libraries and get some historical datato create pie charts.\n\nIn this example, you create a pie chart that shows the weights of the banking securities in a portfolio if you allocate to them based on their inverse volatility. Follow these steps to create the pie chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Calculate the inverse of variances to plot with.\ninverse_variance = 1 / daily_returns.var()\ninverse_variance /= np.sum(inverse_variance)   # Normalization\ninverse_variance *= np.pi*2    # For a full circle circumference in radian\n# Call the DataFrame constructor with the inverse_variance Series and then call the reset_index method.\ninverse_variance = pd.DataFrame(inverse_variance, columns=[\"inverse variance\"]).reset_index()\n\n# Add a color column to the inverse_variance DataFrame.\ninverse_variance['color'] = Category20c[len(inverse_variance.index)]\n\n# Create the figure instance with the title settings.\nplot = figure(title=f\"Banking Stocks and Bank Sector ETF Allocation\")\n\n# Call the wedge method with design settings and the inverse_variance DataFrame to plot the pie chart.\nplot.wedge(x=0, y=1, radius=0.6, start_angle=cumsum('inverse variance', include_zero=True),\nend_angle=cumsum('inverse variance'), line_color=\"white\", fill_color='color',\nlegend_field='symbol', source=inverse_variance)\n\n# Display the plot.\nshow(plot)\n\nThe Jupyter Notebook displays the pie chart.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Charting > Bokeh",
      "section_number": "4.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4.2",
    "title": "Matplotlib",
    "level": 2,
    "path": "Charting > Matplotlib",
    "content": "### Introduction\n\nmatplotlibis the most popular 2d-charting library for python. It allows you to easily create histograms, scatter plots, and various other charts. In addition,pandasis integrated withmatplotlib, so you can seamlessly move between data manipulation and data visualization. This makesmatplotlibgreat for quickly producing a chart to visualize your data.\n\n### Preparation\n\nImport Libraries\n\nTo research with theMatplotliblibrary, import the libraries that you need.\n\n# Import the matplotlib library for plots and settings.\nimport matplotlib.pyplot as plt\nimport mplfinance       # for candlestick\nimport numpy as np\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nGet Historical Data\n\nGet some historical market datato produce the plots. For example, to get data for a bank sector ETF and some banking companies over 2021, run:\n\nqb = QuantBook()\ntickers = [\"XLF\",   # Financial Select Sector SPDR Fund\n\"COF\",   # Capital One Financial Corporation\n\"GS\",    # Goldman Sachs Group, Inc.\n\"JPM\",   # J P Morgan Chase & Co\n\"WFC\"]   # Wells Fargo & Company\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2021, 1, 1), datetime(2022, 1, 1))\n\n### Create Candlestick Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, we'll create a candlestick chart that shows the open, high, low, and close prices of one of the banking securities. Follow these steps to create the candlestick chart:\n\n# Select a symbol to plot the candlestick plot.\nsymbol = symbols[0]\n\n# Get the OHLCV data to plot.\ndata = history.loc[symbol]\ndata.columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n\n# Call the plot method with the data, chart type, style, title, y-axis label, and figure size to plot the candlesticks.\nmplfinance.plot(data,\ntype='candle',\nstyle='charles',\ntitle=f'{symbol.value} OHLC',\nylabel='Price ($)',\nfigratio=(15, 10))\n\nThe Jupyter Notebook displays the candlestick chart.\n\n### Create Line Plot\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a line chart that shows the closing price for one of the banking securities. Follow these steps to create the line chart:\n\n# Select a symbol to plot the candlestick plot.\nsymbol = symbols[0]\n\n# Obtain the close price series of the symbol to plot.\ndata = history.loc[symbol]['close']\n\n# Call the plot method with a title and figure size to plot the line chart.\ndata.plot(title=f\"{symbol} Close Price\", figsize=(15, 10))\n\nThe Jupyter Notebook displays the line plot.\n\n### Create Scatter Plot\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a scatter plot that shows the relationship between the daily returns of two banking securities. Follow these steps to create the scatter plot:\n\n# Select 2 stocks to plot the correlation between their return series.\nsymbol1 = symbols[1]\nsymbol2 = symbols[2]\n# Obtain the daily return series of the 2 stocks for plotting.\nclose_price1 = history.loc[symbol1]['close']\nclose_price2 = history.loc[symbol2]['close']\ndaily_returns1 = close_price1.pct_change().dropna()\ndaily_returns2 = close_price2.pct_change().dropna()\n\n# Fit a linear regression model on the correlation.\nm, b = np.polyfit(daily_returns1, daily_returns2, deg=1)\n# This method call returns the slope and intercept of the ordinary least squares regression line.\n\n# Generate a prediction line upon the linear regression model.\nx = np.linspace(daily_returns1.min(), daily_returns1.max())\ny = m*x + b\n\n# Call the plot method with the coordinates and color of the regression line to plot the linear regression prediction line.\nplt.plot(x, y, color='red')\n\n# In the same cell, call the plot method, call the scatter method with the 2 daily return series to plot the scatter plot dots of the daily returns.\nplt.scatter(daily_returns1, daily_returns2)\n\n# In the same cell, call the title, xlabel, and ylabel methods with a title and axis labels to decorate the plot.\nplt.title(f'{symbol1} vs {symbol2} daily returns Scatter Plot')\nplt.xlabel(symbol1.value)\nplt.ylabel(symbol2.value)\n\nThe Jupyter Notebook displays the scatter plot.\n\n### Create Histogram\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a histogram that shows the distribution of the daily percent returns of the bank sector ETF. In addition to the bins in the histogram, you overlay a normal distribution curve for comparison. Follow these steps to create the histogram:\n\n# Obtain the daily return series for a single symbol.\nsymbol = symbols[0]\nclose_prices = history.loc[symbol]['close']\ndaily_returns = close_prices.pct_change().dropna()\n\n# Get the mean and standard deviation of the returns.\nmean = daily_returns.mean()\nstd = daily_returns.std()\n# Calculate the normal distribution PDF given the mean and SD.\nx = np.linspace(-3*std, 3*std, 1000)\npdf = 1/(std * np.sqrt(2*np.pi)) * np.exp(-(x-mean)**2 / (2*std**2))\n\n# Call the plot method with the data for the normal distribution curve.\nplt.plot(x, pdf, label=\"Normal Distribution\")\n# In the same cell that you called the plot method, call the hist method with the daily return data and the number of bins to plot the histogram.\nplt.hist(daily_returns, bins=20)\n# In the same cell that you called the hist method, call the title, xlabel, and ylabel methods with a title and the axis labels to decorate the plot.\nplt.title(f'{symbol} Return Distribution')\nplt.xlabel('Daily Return')\nplt.ylabel('Count')\n\nThe Jupyter Notebook displays the histogram.\n\n### Create Bar Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a bar chart that shows the average daily percent return of the banking securities. Follow these steps to create the bar chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change() * 100\n\n# Obtain the mean of the daily return.\navg_daily_returns = daily_returns.mean()\n\n# Create the figure to plot on with the size set.\nplt.figure(figsize=(15, 10))\n\n# Call the bar method with the x-axis and y-axis values to plot the mean returns as bar chart.\nplt.bar(avg_daily_returns.index, avg_daily_returns)\n# In the same cell that you called the bar method, call the title, xlabel, and ylabel methods with a title and the axis labels to decorate the plot.\nplt.title('Banking Stocks Average Daily % Returns')\nplt.xlabel('Tickers')\nplt.ylabel('%')\n\nThe Jupyter Notebook displays the bar chart.\n\n### Create Heat Map\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a heat map that shows the correlation between the daily returns of the banking securities. Follow these steps to create the heat map:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Call the corr method to create the correlation matrix to plot.\ncorr_matrix = daily_returns.corr()\n\n# Call the imshow method with the correlation matrix, a color map, and an interpolation method to plot the heatmap.\nplt.imshow(corr_matrix, cmap='hot', interpolation='nearest')\n\n# In the same cell that you called the imshow method, call the title, xticks, and yticks, methods with a title and the axis tick labels to decorate the plot.\nplt.title('Banking Stocks and Bank Sector ETF Correlation Heat Map')\nplt.xticks(np.arange(len(tickers)), labels=tickers)\nplt.yticks(np.arange(len(tickers)), labels=tickers)\n\n# Plot the color bar to the right of the heat map.\n# In the same cell that you called the imshow method, call the colorbar method.\nplt.colorbar()\n\nThe Jupyter Notebook displays the heat map.\n\n### Create Pie Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a pie chart that shows the weights of the banking securities in a portfolio if you allocate to them based on their inverse volatility. Follow these steps to create the pie chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Calculate the inverse of variances to plot with.\ninverse_variance = 1 / daily_returns.var()\n\n# Call the pie method with the inverse_variance Series, the plot labels, and a display format to plot the pie chart.\nplt.pie(inverse_variance, labels=inverse_variance.index, autopct='%1.1f%%')\n# In the cell that you called the pie method, call the title method with a title.\nplt.title('Banking Stocks and Bank Sector ETF Allocation')\n\nThe Jupyter Notebook displays the pie chart.\n\n### Create 3D Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a 3D chart that shows the price of an asset on each dimension, i.e. the price correlation of 3 different symbols. Follow these steps to create the 3D chart:\n\n# Select the asset to plot on each dimension.\nx, y, z = symbols[:3]\n\n# Select the close price series of each symbol to plot with.\nx_hist = history.loc[x].close\ny_hist = history.loc[y].close\nz_hist = history.loc[z].close\n\n# Construct the basic 3D plot layout.\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot(projection='3d')\n\n# Call the ax.scatter method with the 3 price series to plot the 3D graph.\nax.scatter(x_hist, y_hist, z_hist)\n\n# Update the x, y, and z axis labels.\nax.set_xlabel(f\"{x} Price\")\nax.set_ylabel(f\"{y} Price\")\nax.set_zlabel(f\"{z} Price\")\n\n# Display the 3D chart. Note that you need to zoom the chart to avoid z-axis cut off.\nax.set_box_aspect(None, zoom=0.85)\nplt.show()\n\nThe Jupyter Notebook displays the pie chart.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Charting > Matplotlib",
      "section_number": "4.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4.3",
    "title": "Plotly",
    "level": 2,
    "path": "Charting > Plotly",
    "content": "### Introduction\n\nplotlyis an online charting tool with a python API. It offers the ability to create rich and interactive graphs.\n\n### Preparation\n\nImport Libraries\n\nTo research with thePlotlylibrary, import the libraries that you need.\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nGet Historical Data\n\nGet some historical market datato produce the plots. For example, to get data for a bank sector ETF and some banking companies over 2021, run:\n\nqb = QuantBook()\ntickers = [\"XLF\",   # Financial Select Sector SPDR Fund\n\"COF\",   # Capital One Financial Corporation\n\"GS\",    # Goldman Sachs Group, Inc.\n\"JPM\",   # J P Morgan Chase & Co\n\"WFC\"]   # Wells Fargo & Company\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2021, 1, 1), datetime(2022, 1, 1))\n\n### Create Candlestick Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a candlestick chart that shows the open, high, low, and close prices of one of the banking securities. Follow these steps to create the candlestick chart:\n\n# Select a symbol to plot the candlestick plot.\nsymbol = symbols[0]\n# Get the OHLCV data of the symbol to plot.\ndata = history.loc[symbol]\n\n# Call the Candlestick constructor with the time and open, high, low, and close price series to create the candlestick plot.\ncandlestick = go.Candlestick(x=data.index,\nopen=data['open'],\nhigh=data['high'],\nlow=data['low'],\nclose=data['close'])\n\n# Call the Layout constructor with a title and axes labels to set the plot layout.\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol.value} OHLC'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False)\n\n# Call the Figure constructor with the candlestick and layout.\nfig = go.Figure(data=[candlestick], layout=layout)\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the candlestick chart.\n\n### Create Line Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a line chart that shows the closing price for one of the banking securities. Follow these steps to create the line chart:\n\n# Obtain the close price series for a single symbol.\nsymbol = symbols[0]\ndata = history.loc[symbol]['close']\n\n# Call the DataFrame constructor with the data Series and then call the reset_index method to make the time column accessible to plotly.\ndata = pd.DataFrame(data).reset_index()\n\n# Call the line method with data, the column names of the x- and y-axis in data, and the plot title to plot the close price series line chart.\nfig = px.line(data, x='time', y='close', title=f'{symbol} Close price')\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the line chart.\n\n### Create Scatter Plot\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a scatter plot that shows the relationship between the daily returns of two banking securities. Follow these steps to create the scatter plot:\n\n# Select 2 stocks to plot the correlation between their return series.\nsymbol1 = symbols[1]\nsymbol2 = symbols[2]\n# Obtain the daily return series of the 2 stocks for plotting.\nclose_price1 = history.loc[symbol1]['close']\nclose_price2 = history.loc[symbol2]['close']\ndaily_returns1 = close_price1.pct_change().dropna()\ndaily_returns2 = close_price2.pct_change().dropna()\n\n# Call the scatter method with the 2 return Series, the trendline option, and axes labels to plot the correlation into a scatter plot.\nfig = px.scatter(x=daily_return1, y=daily_return2, trendline='ols',\nlabels={'x': symbol1.value, 'y': symbol2.value})\n\n# Call the update_layout method with a title to update the plot title.\nfig.update_layout(title=f'{symbol1.value} vs {symbol2.value} Daily % Returns')\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the scatter plot.\n\n### Create Histogram\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a histogram that shows the distribution of the daily percent returns of the bank sector ETF. Follow these steps to create the histogram:\n\n# Obtain the daily return series for a single symbol.\nsymbol = symbols[0]\ndata = history.loc[symbol]['close']\ndaily_returns = data.pct_change().dropna()\n\n# Call the DataFrame constructor with the data Series and then call the reset_index method.\ndaily_returns = pd.DataFrame(daily_returns).reset_index()\n\n# Call the histogram method with the daily_returns DataFrame, the x-axis label, a title, and the number of bins to plot the histogram.\nfig = px.histogram(daily_returns, x='close',\ntitle=f'{symbol} Daily Return of Close Price Distribution',\nnbins=20)\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the histogram.\n\n### Create Bar Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a bar chart that shows the average daily percent return of the banking securities. Follow these steps to create the bar chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change() * 100\n\n# Obtain the mean of the daily return.\navg_daily_returns = daily_returns.mean()\n\n# Call the DataFrame constructor with the avg_daily_returns Series and then call the reset_index method.\navg_daily_returns = pd.DataFrame(avg_daily_returns, columns=[\"avg_daily_ret\"]).reset_index()\n\n# Call the bar method with the avg_daily_returns and the axes column names to plot the bar chart.\nfig = px.bar(avg_daily_returns, x='symbol', y='avg_daily_ret')\n# Call the update_layout method with a title to decorate the plot.\nfig.update_layout(title='Banking Stocks Average Daily % Returns')\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the bar plot.\n\n### Create Heat Map\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a heat map that shows the correlation between the daily returns of the banking securities. Follow these steps to create the heat map:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Call the corr method to create the correlation matrix to plot.\ncorr_matrix = daily_returns.corr()\n\n# Call the imshow method with the corr_matrix and the axes labels to plot the heatmap.\nfig = px.imshow(corr_matrix, x=tickers, y=tickers)\n\n# ICall the update_layout method with a title to decorate the plot.\nfig.update_layout(title='Banking Stocks and bank sector ETF Correlation Heat Map')\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the heat map.\n\n### Create Pie Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a pie chart that shows the weights of the banking securities in a portfolio if you allocate to them based on their inverse volatility. Follow these steps to create the pie chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Calculate the inverse of variances to plot with.\ninverse_variance = 1 / daily_returns.var()\n\n# Call the DataFrame constructor with the inverse_variance Series and then call the reset_index method.\ninverse_variance = pd.DataFrame(inverse_variance, columns=[\"inverse variance\"]).reset_index()\n\n# Call the pie method with the inverse_variance DataFrame, the column name of the values, and the column name of the names to plot the pie chart.\nfig = px.pie(inverse_variance, values='inverse variance', names='symbol')\n# Call the update_layout method with a title to decorate the plot.\nfig.update_layout(title='Asset Allocation of bank stocks and bank sector ETF')\n\n# Display the plot.\nfig.show()\n\nThe Jupyter Notebook displays the pie chart.\n\n### Create 3D Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a 3D chart that shows the price of an asset on each dimension. Follow these steps to create the 3D chart:\n\n# Select the asset to plot on each dimension.\nx, y, z = symbols[:3]\n\n# Call the Scatter3d constructor with the data for the x, y, and z axes to create the 3D scatter plot.\nscatter = go.Scatter3d(\nx=history.loc[x].close,\ny=history.loc[y].close,\nz=history.loc[z].close,\nmode='markers',\nmarker=dict(\nsize=2,\nopacity=0.8\n)\n)\n\n# Call the Layout constructor with the axes titles and chart dimensions to create the layout of the plot.\nlayout = go.Layout(\nscene=dict(\nxaxis_title=f'{x.value} Price',\nyaxis_title=f'{y.value} Price',\nzaxis_title=f'{z.value} Price'\n),\nwidth=700,\nheight=700\n)\n\n# Call the Figure constructor with the scatter and layout variables to plot them.\nfig = go.Figure(scatter, layout)\n\n# Display the 3D chart.\nfig.show()\n\nThe Jupyter Notebook displays the 3D chart.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Charting > Plotly",
      "section_number": "4.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4.4",
    "title": "Seaborn",
    "level": 2,
    "path": "Charting > Seaborn",
    "content": "### Introduction\n\nseabornis a data visualization library based onmatplotlib. It makes it easier to create more complicated plots and allows us to create much more visually-appealing charts thanmatplotlibcharts.\n\n### Preparation\n\nImport Libraries\n\nTo research with theSeabornlibrary, import the libraries that you need.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nGet Historical Data\n\nGet some historical market datato produce the plots. For example, to get data for a bank sector ETF and some banking companies over 2021, run:\n\nqb = QuantBook()\ntickers = [\"XLF\",   # Financial Select Sector SPDR Fund\n\"COF\",   # Capital One Financial Corporation\n\"GS\",    # Goldman Sachs Group, Inc.\n\"JPM\",   # J P Morgan Chase & Co\n\"WFC\"]   # Wells Fargo & Company\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2021, 1, 1), datetime(2022, 1, 1))\n\n### Create Candlestick Chart\n\nSeaborn does not currently support candlestick charts. Use one ofthe other plotting librariesto create candlestick charts.\n\n### Create Line Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a line chart that shows the closing price for one of the banking securities. Follow these steps to create the line chart:\n\n# Select a symbol to plot the candlestick plot.\nsymbol = symbols[0]\n\n# Obtain the close price series of the symbol to plot.\ndata = history.loc[symbol]['close']\n\n# Call the plot method with a title and figure size to plot the line chart.\nplot = sns.lineplot(data=data,\nx='time',\ny='close')\n# In the same cell that you called the lineplot method, call the set method with the y-axis label and a title to update the plot settings.\nplot.set(ylabel=\"price\", title=f\"{symbol} Price Over Time\")\n\nThe Jupyter Notebook displays the line chart.\n\n### Create Scatter Plot\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a scatter plot that shows the relationship between the daily returns of two banking securities. Follow these steps to create the scatter plot:\n\n# Select 2 stocks to plot the correlation between their return series.\nsymbol1 = symbols[1]\nsymbol2 = symbols[2]\n# Select the close column of the history DataFrame, call the unstack method, and then select the symbol1 and symbol2 columns.\nclose_prices = history['close'].unstack(0)[[symbol1, symbol2]]\n# Obtain the daily return series of the 2 symbols to plot with.\ndaily_returns = close_prices.pct_change().dropna()\n\n# Call the regplot method with the daily_returns DataFrame and the column names to plot the scatter plot.\nplot = sns.regplot(data=daily_returns,\nx=daily_returns.columns[0],\ny=daily_returns.columns[1])\n# In the same cell that you called the regplot method, call the set method with the axis labels and a title to update the layout.\nplt.scatter(daily_returns1, daily_returns2)\n\n# In the same cell, call the title, xlabel, and ylabel methods with a title and axis labels to decorate the plot.\nplot.set(xlabel=f'{daily_returns.columns[0]} % Returns',\nylabel=f'{daily_returns.columns[1]} % Returns',\ntitle=f'{symbol1} vs {symbol2} Daily % Returns')\n\nThe Jupyter Notebook displays the scatter plot.\n\n### Create Histogram\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a histogram that shows the distribution of the daily percent returns of the bank sector ETF. Follow these steps to create the histogram:\n\n# Obtain the daily return series for a single symbol.\nsymbol = symbols[0]\nclose_prices = history.loc[symbol]['close']\ndaily_returns = close_prices.pct_change().dropna()\n\n# Call the DataFrame constructor with the daily_returns Series and then call the reset_index method.\ndaily_returns = pd.DataFrame(daily_returns).reset_index()\n\n# Call the histplot method with the daily_returns, the close column name, and the number of bins to plot the histogram.\nplot = sns.histplot(daily_returns, x='close', bins=20)\n# In the same cell that you called the histplot method, call the set method with the axis labels and a title to update the layout.\nplot.set(xlabel='Return',\nylabel='Frequency',\ntitle=f'{symbol} Daily Return of Close Price Distribution')\n\nThe Jupyter Notebook displays the histogram.\n\n### Create Bar Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a bar chart that shows the average daily percent return of the banking securities. Follow these steps to create the bar chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change() * 100\n\n# Obtain the mean of the daily return.\navg_daily_returns = daily_returns.mean()\n\n# Call the DataFrame constructor with the avg_daily_returns Series and then call the reset_index method.\navg_daily_returns = pd.DataFrame(avg_daily_returns, columns=[\"avg_daily_ret\"]).reset_index()\n\n# Call barplot method with the avg_daily_returns Series and the axes column names to plot the bar chart.\nplot = sns.barplot(data=avg_daily_returns, x='symbol', y='avg_daily_ret')\n# In the same cell that you called the barplot method, call the set method with the axis labels and a title to update layout.\nplot.set(xlabel='Tickers',\nylabel='%',\ntitle='Banking Stocks Average Daily % Returns')\n# In the same cell that you called the set method, call the tick_params method to rotate the x-axis labels to rotate the labels of the x-axis for visibility.\nplot.tick_params(axis='x', rotation=90)\n\nThe Jupyter Notebook displays the bar chart.\n\n### Create Heat Map\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a heat map that shows the correlation between the daily returns of the banking securities. Follow these steps to create the heat map:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Call the corr method to create the correlation matrix to plot.\ncorr_matrix = daily_returns.corr()\n\n# Call the heatmap method with the corr_matrix and the annotation argument enabled to plot the heapmap.interpolation method to plot the heatmap.\nplot = sns.heatmap(corr_matrix, annot=True)\n# In the same cell that you called the heatmap method, call the set method with a title to update the layout.\nplot.set(title='Bank Stocks and Bank Sector ETF Correlation Coefficients')\n\nThe Jupyter Notebook displays the heat map.\n\n### Create Pie Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a pie chart that shows the weights of the banking securities in a portfolio if you allocate to them based on their inverse volatility. Follow these steps to create the pie chart:\n\n# Obtain the returns of all stocks to compare their return.\nclose_prices = history['close'].unstack(level=0)\ndaily_returns = close_prices.pct_change()\n\n# Calculate the inverse of variances to plot with.\ninverse_variance = 1 / daily_returns.var()\n\n# Call the color_palette method with a palette name and then truncate the returned colors to so that you have one color for each security.\ncolors = sns.color_palette('pastel')[:len(inverse_variance.index)]\n\n# Call the pie method with the security weights, labels, and colors to plot the pie chart.\nplt.pie(inverse_variance, labels=inverse_variance.index, colors=colors, autopct='%1.1f%%')\n# In the same cell that you called the pie method, call the title method with a title to update the layout.\nplt.title(title='Banking Stocks and Bank Sector ETF Allocation')\n\nThe Jupyter Notebook displays the pie chart.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Charting > Seaborn",
      "section_number": "4.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "4.5",
    "title": "Plotly NET",
    "level": 2,
    "path": "Charting > Plotly NET",
    "content": "### Introduction\n\nPlotly.NETprovides functions for generating and rendering plotly.js charts in.NETprogramming languages. Our .NET interactive notebooks support its C# implementation.\n\n### Preparation\n\nImport Libraries\n\nTo research with thePlotly.NETlibrary, import the libraries that you need.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\nusing Accord.Math;\nusing Accord.Statistics;\n\nGet Historical Data\n\nGet some historical market datato produce the plots. For example, to get data for a bank sector ETF and some banking companies over 2021, run:\n\nvar qb = new QuantBook();\nvar tickers = new[]\n{\n\"XLF\",  // Financial Select Sector SPDR Fund\n\"COF\",  // Capital One Financial Corporation\n\"GS\",   // Goldman Sachs Group, Inc.\n\"JPM\",  // J P Morgan Chase & Co\n\"WFC\"   // Wells Fargo & Company\n};\nvar symbols = tickers.Select(ticker => qb.AddEquity(ticker, Resolution.Daily).Symbol);\nvar history = qb.History(symbols, new DateTime(2021, 1, 1), new DateTime(2022, 1, 1));\n\n### Create Candlestick Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a candlestick chart that shows the open, high, low, and close prices of one of the banking securities. Follow these steps to create the candlestick chart:\n\n// Select a symbol to plot its candlestick plot.\nvar symbol = symbols.First();\n\n// Call the Chart2D.Chart.Candlestick constructor with the time and open, high, low, and close price IEnumerable to create the candlestick plot.\nvar bars = history.Select(slice => slice.Bars[symbol]);\nvar chart = Chart2D.Chart.Candlestick<decimal, decimal, decimal, decimal, DateTime, string>(\nbars.Select(x => x.Open),\nbars.Select(x => x.High),\nbars.Select(x => x.Low),\nbars.Select(x => x.Close),\nbars.Select(x => x.EndTime)\n);\n\n// Call the Layout constructor and set the title, xaxis, and yaxis properties as the title and axes label objects to create the plot layout.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Price ($)\");\nTitle title = Title.init($\"{symbol} OHLC\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Show the plot.\nHTML(GenericChart.toChartHTML(chart));\n\nThe Jupyter Notebook displays the candlestick chart.\n\n### Create Line Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a line chart that shows the volume of a security. Follow these steps to create the chart:\n\n// Select a symbol to plot its volume as line chart.\nvar symbol = symbols.First();\n\n// Call the Chart2D.Chart.Line constructor with the timestamps and volumes to create the line chart.\nvar bars = history.Select(slice => slice.Bars[symbol]);\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\nbars.Select(x => x.EndTime),\nbars.Select(x => x.Volume)\n);\n\n// Create a Layout for the plot setting.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Volume\");\nTitle title = Title.init($\"{symbol} Volume\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Show the plot.\nHTML(GenericChart.toChartHTML(chart));\n\nThe Jupyter Notebook displays the line chart.\n\n### Create Scatter Plot\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a scatter plot that shows the relationship between the daily price of two securities. Follow these steps to create the scatter plot:\n\n// Select 2 symbols to plot their price correlation.\nvar symbol1 = symbols.First();\nvar symbol2 = symbols.Last();\n\n// Call the Chart2D.Chart.Point constructor with the closing prices of both securities to create the scatter plot.\nvar chart = Chart2D.Chart.Point<decimal, decimal, string>(\nhistory.Select(slice => slice.Bars[symbol1].Close),\nhistory.Select(slice => slice.Bars[symbol2].Close)\n);\n\n// Create a Layout as the plot setting.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", $\"{symbol1} Price ($)\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", $\"{symbol2} Price ($)\");\nTitle title = Title.init($\"{symbol1} vs {symbol2}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Show the plot.\nHTML(GenericChart.toChartHTML(chart));\n\nThe Jupyter Notebook displays the scatter plot.\n\n### Create Heat Map\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a heat map that shows the correlation between the daily returns of the banking securities. Follow these steps to create the heat map:\n\n// Compute the daily returns of the stocks to calculate the correlation later.\nvar data = history.SelectMany(x => x.Bars.Values)\n.GroupBy(x => x.Symbol)\n.Select(x =>\n{\nvar prices = x.Select(x => (double)x.Close).ToArray();\nreturn Enumerable.Range(0, prices.Length - 1)\n.Select(i => prices[i+1] / prices[i] - 1).ToArray();\n}).ToArray().Transpose();\n\n// Call the Measures.Correlation method to calculate the correlation matrix for plotting.\nvar corrMatrix = Measures.Correlation(data).Select(x => x.ToList()).ToList();\n\n// Call the Plotly.NET.Chart2D.Chart.Heatmap constructor with the correlation matrix to plot the heat map.\nvar X = Enumerable.Range(0, tickers.Length).ToList();\n\nvar heatmap = Plotly.NET.Chart2D.Chart.Heatmap<IEnumerable<double>, double, int, int, string>(\nzData: corr,\nX: X,\nY: X,\nShowScale: true,\nReverseYAxis: true\n);\n\n// Create a Layout as the plot settings.\nvar axis = new LinearAxis();\naxis.SetValue(\"tickvals\", X);\naxis.SetValue(\"ticktext\", tickers);\n\nvar layout = new Layout();\nlayout.SetValue(\"xaxis\", axis);\nlayout.SetValue(\"yaxis\", axis);\nlayout.SetValue(\"title\", Title.init(\"Banking Stocks and bank sector ETF Correlation Heat Map\"));\n\n// Assign the Layout to the chart.\nheatmap.WithLayout(layout);\n\n// Show the plot.\nHTML(GenericChart.toChartHTML(heatmap))\n\nThe Jupyter Notebook displays the heat map.\n\n### Create 3D Chart\n\nYou mustimport the plotting libraries and get some historical datato create candlestick charts.\n\nIn this example, you create a 3D chart that shows the price of an asset on each dimension, i.e. the price correlation of 3 different symbols. Follow these steps to create the 3D chart:\n\n// Select three Symbol objects to plot with.\nvar symbolList = symbols.ToList();\nvar symbol1 = symbolList[0];\nvar symbol2 = symbolList[1];\nvar symbol3 = symbolList[2];\n\n// Call the Chart3D.Chart.Point3D constructor with the closing price series of each securities to create the 3D scatter plot.\nvar chart = Chart3D.Chart.Point3D<decimal, decimal, decimal, string>(\nhistory.Select(slice => slice.Bars[symbol1].Close),\nhistory.Select(slice => slice.Bars[symbol2].Close),\nhistory.Select(slice => slice.Bars[symbol3].Close)\n);\n\n// Create a Layout to add title and axis labels as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", $\"{symbol1} Price ($)\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", $\"{symbol2} Price ($)\");\nLinearAxis zAxis = new LinearAxis();\nzAxis.SetValue(\"title\", $\"{symbol3} Price ($)\");\nTitle title = Title.init($\"{symbol1} vs {symbol2} vs {symbol3}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"zaxis\", zAxis);\nlayout.SetValue(\"title\", title);\n\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Show the plot.\nHTML(GenericChart.toChartHTML(heatmap))\n\nThe Jupyter Notebook displays the scatter plot.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "4",
      "breadcrumb": "Charting > Plotly NET",
      "section_number": "4.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "5",
    "title": "Universes",
    "level": 1,
    "path": "Universes",
    "content": "### Introduction\n\nUniverse selection is the process of selecting a basket of assets to research. Dynamic universe selection increases diversification and decreasesselection biasin your analysis.\n\n### Get Universe Data\n\nUniverses are data types. To get historical data for a universe, pass the universe data type to theUniverseHistorymethod. The object that returns contains a universe data collection for each day. With this object, you can iterate through each day and then iterate through the universe data objects of each day to analyze the universe constituents.\n\nFor example, follow these steps to get the US Equity Fundamental data for a specific universe:\n\nLoad the assembly files and data types in their own cell.#load \"../Initialize.csx\"Load the necessary assembly files.#load \"../QuantConnect.csx\"Import theQuantConnectpackage and the universe data type.using QuantConnect;\nusing QuantConnect.Research;\nusing QuantConnect.Data.Fundamental;Create aQuantBook.var qb = new QuantBook();qb = QuantBook()Define a universe.The following example defines a dynamic universe that contains the 10 Equities with the lowest PE ratios in the market. To see all theFundamentalattributes you can use to define a filter function for a Fundamental universe, seeData Point Attributes. To create the universe, call theAddUniverseadd_universemethod with the filter function.var universe = qb.AddUniverse(fundamentals =>\n{\nreturn fundamentals\n.Where(f => !double.IsNaN(f.ValuationRatios.PERatio))\n.OrderBy(f => f.ValuationRatios.PERatio)\n.Take(10)\n.Select(f => f.Symbol);\n});def filter_function(fundamentals):\nsorted_by_pe_ratio = sorted(\n[f for f in fundamentals if not np.isnan(f.valuation_ratios.pe_ratio)],\nkey=lambda fundamental: fundamental.valuation_ratios.pe_ratio\n)\nreturn [fundamental.symbol for fundamental in sorted_by_pe_ratio[:10]]\n\nuniverse = qb.add_universe(filter_function)Call theUniverseHistoryuniverse_historymethod with the universe, a start date, and an end date.var universeHistory = qb.UniverseHistory(universe, new DateTime(2023, 11, 6), new DateTime(2023, 11, 13));universe_history = qb.universe_history(universe, datetime(2023, 11, 6), datetime(2023, 11, 13))The end date arguments is optional. If you omit it, the method returnsFundamentaldata between the start date and the current day.Theuniverse_historymethod returns a Series where the multi-index is the universeSymboland the time when universe selection would occur in a backtest. Each row in the data column contains a list ofFundamentalobjects. The following image shows the first 5 rows of an example Series:To get a flat DataFrame instead of a Series, set theflattenargument toTrue.TheUniverseHistorymethod returns anIEnumerable<IEnumerable<Fundamental>>object.Iterate through the Series to access the universe data.Iterate through the result to access the universe data.universe_history = universe_history.droplevel('symbol', axis=0)\nfor date, fundamentals in universe_history.items():\nfor fundamental in fundamentals:\nsymbol = fundamental.symbol\nprice = fundamental.price\nif fundamental.has_fundamental_data:\npe_ratio = fundamental.valuation_ratios.pe_ratioforeach (var fundamentals in universeHistory)\n{\nforeach (Fundamental fundamental in fundamentals)\n{\nvar date = fundamental.Time;\nvar symbol = fundamental.Symbol;\nvar price = fundamental.Price;\nif (fundamental.HasFundamentalData)\n{\nvar peRatio = fundamental.ValuationRatios.PERatio;\n}\n}\n}\n\n### Available Universes\n\nTo get universe data for other types of universes, you usually just need to replaceFundamentalin the preceding code snippets with the universe data type.\nThe following table shows the datasets that support universe selection and their respective data type.\nFor more information, about universe selection with these datasets and the data points you can use in the filter function, see the dataset's documentation.\n\n[Table - 20 rows]\n\nTo get universe data for Futures and Options, use theFutureHistoryfuture_historyandOptionHistoryoption_historymethods, respectively.\n\n### Examples\n\nThe following examples demonstrate some common practices for universe research.\n\nExample 1: Top-Minus-Bottom PE Ratio\n\nThe below example studies the top-minus-bottom PE Ratio universe, in which the top 10 PE Ratio stocks are brought, and the bottom 10 are sold in equal weighting daily. We carry out a mini-backtest to analyze its performance.\n\n// Load the required assembly files and data types.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing System;\nusing MathNet.Numerics.Distributions;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n\n// Set start and end dates of the research to avoid look-ahead bias.\nvar start = new DateTime(2021, 1, 1);\nvar end = new DateTime(2021, 4, 1);\n\n// Request data for research purposes.\n// We are interested in the most liquid primary stocks.\nvar universe = qb.AddUniverse(\n(datum) => datum.OrderByDescending(x => x.DollarVolume)\n.Take(100)\n.Select(x => x.Symbol)\n);\n\n// Historical data call for the data to be compared and tested.\nvar universeHistory = qb.UniverseHistory(universe, start, end);\n\n// Process the historical data to generate a signal and return it for research.\nvar bottomPeRatioDict = new Dictionary<DateTime, List<Symbol>>();\nvar topPeRatioDict = new Dictionary<DateTime, List<Symbol>>();\nforeach (FundamentalUniverse fundamentals in universeHistory)\n{\nvar sortedByPeRatio = fundamentals.OrderBy(x => (x as Fundamental).ValuationRatios.PERatio).ToList();\nvar bottomPeRatio = sortedByPeRatio.Take(10)\n.Select(x => x.Symbol)\n.ToList();\nvar topPeRatio = sortedByPeRatio.TakeLast(10)\n.Select(x => x.Symbol)\n.ToList();\n\n// Study 10 stocks with the top and bottom PE Ratios.\nvar _time = fundamentals.First().Time;\nbottomPeRatioDict[_time.Date] = bottomPeRatio;\ntopPeRatioDict[_time.Date] = topPeRatio;\n}\n\n// Extract symbols from both dictionaries and remove duplicates\nvar allSymbols = bottomPeRatioDict.Values\n.SelectMany(symbols => symbols)\n.Concat(topPeRatioDict.Values.SelectMany(symbols => symbols))\n.Distinct()\n.ToList();\n// All symbols' daily prices are for return comparison.\nvar history = qb.History<TradeBar>(allSymbols, start, end, Resolution.Daily).ToList();\n\n// Iterate the history to backtest the top minus bottom performance.\nvar time = new List<DateTime>() { start };\nvar equity = new List<decimal>() { 1m };\nfor (int i = 0; i < history.Count - 2; i++)\n{\nvar bar = history[i];\nvar nextBar = history[i+1];\nvar timeStamp = bar.Values.First().EndTime;\nvar bottomReturn = bottomPeRatioDict[timeStamp.Date].Sum(x => (nextBar[x].Close - bar[x].Close) / bar[x].Close * -0.1m);\nvar topReturn = topPeRatioDict[timeStamp.Date].Sum(x => (nextBar[x].Close - bar[x].Close) / bar[x].Close * 0.1m);\n\n// Calculate the cumulative return.\ntime.Add(nextBar.Values.First().EndTime);\nequity.Add((bottomReturn + topReturn + 1m) * equity[^1]);\n}\n\n// Create line chart of the equity curve.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nequity\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Equity\");\nTitle title = Title.init($\"Equity by Time of Top-Minus-Bottom Universe\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n\n# Set start and end dates of the research to avoid look-ahead bias.\nstart = datetime(2021, 1, 1)\nend = datetime(2021, 4, 1)\nqb.set_start_date(end)\n\n# Request data for research purposes.\n# We are interested in the most liquid primary stocks.\nuniverse = qb.add_universe(\nlambda datum: [x.symbol for x in sorted(\n[f for f in datum],\nkey=lambda f: f.dollar_volume\n)[-100:]]\n)\n\n# Historical data call for the data to be compared and tested.\nuniverse_history = qb.universe_history(universe, start, end).droplevel([0])\n# All symbols' daily prices are for return comparison.\nhistory = qb.history(\n[x.symbol for x in set(\ne for datum in universe_history.values.flatten() for e in datum\n)],\nstart,\nend,\nResolution.DAILY\n).close.unstack(0)\n\n# Change the index format for matching.\nuniverse_history.index = universe_history.index.date\nhistory.index = history.index.date\n# Process the historical data to generate a signal and return it for research.\nbottom_liquid_universe_history = universe_history.apply(\nlambda datum: [x.symbol for x in sorted(\ndatum,\nkey=lambda d: d.dollar_volume\n)[:10]]\n)\ntop_liquid_universe_history = universe_history.apply(\nlambda datum: [x.symbol for x in sorted(\ndatum,\nkey=lambda d: d.dollar_volume,\nreverse=True\n)[:10]]\n)\nret = history.pct_change().dropna()\n\n# Keep the entries that have common indices for a fair comparison.\ncommon_index = list(set(ret.index).intersection(universe_history.index))\nret = ret.loc[common_index].apply(\nlambda x: x[top_liquid_universe_history.loc[x.name]].sum()*0.1\\\n- x[bottom_liquid_universe_history.loc[x.name]].sum()*0.1,\naxis=1\n)\n\n# Plot the data for visualization. It is easier to study the pattern.\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot()\n\n# Use line plot to present time series.\nax.plot(ret.sort_index())\n\n# Set axis and titles to explain the plot.\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Return\")\nax.set_title(\"Top Minus Bottom Liquidity Return\")\n\nplt.show()",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Universes",
      "section_number": "5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Dataset Name | Universe Type(s) | Documentation |\n| --- | --- | --- |\n| US ETF Constituents | ETFConstituentUniverse | Learn more |\n| US Equity Option Universe | OptionUniverse | Learn more |\n| US Index Option Universe | OptionUniverse | Learn more |\n| Binance Crypto Price Data | CryptoUniverse | Learn more |\n| Binance US Crypto Price Data | CryptoUniverse | Learn more |\n| Bitfinex Crypto Price Data | CryptoUniverse | Learn more |\n| Bybit Crypto Price Data | CryptoUniverse | Learn more |\n| Coinbase Crypto Price Data | CryptoUniverse | Learn more |\n| Kraken Crypto Price Data | CryptoUniverse | Learn more |\n| Brain Language Metrics on Company Filings | BrainCompanyFilingLanguageMetricsUniverse | \">Learn more |\n| Brain ML Stock Ranking | BrainStockRankingUniverse | \">Learn more |\n| Brain Sentiment Indicator | BrainSentimentIndicatorUniverse | \">Learn more |\n| Crypto Market Cap | CoinGeckoUniverse | \">Learn more |\n| CNBC Trading | QuiverCNBCsUniverse | \">Learn more |\n| Corporate Lobbying | QuiverLobbyingUniverse | \">Learn more |\n| Insider Trading | QuiverInsiderTradingUniverse | \">Learn more |\n| US Congress Trading | QuiverQuantCongressUniverse | \">Learn more |\n| US Government Contracts | QuiverGovernmentContractUniverse | \">Learn more |\n| WallStreetBets | QuiverWallStreetBetsUniverse | \">Learn more |\n| Corporate Buybacks | SmartInsiderIntentionUniverseSmartInsiderTransactionUniverse | \">Learn more |"
  },
  {
    "id": "6",
    "title": "Indicators",
    "level": 1,
    "path": "Indicators",
    "content": "Indicators let you analyze market data in an abstract form rather than in its raw form. For example, indicators like the RSI tell you, based on price and volume data, if the market is overbought or oversold. Because indicators can extract overall market trends from price data, sometimes, you may want to look for correlations between indicators and the market, instead of between raw price data and the market. To view all of the indicators and candlestick patterns we provide, see theSupported Indicators.Data Point IndicatorsIndicators that processIndicatorDataPointobjectsBar IndicatorsIndicators that processBarobjectsTrade Bar IndicatorsIndicators that processTradeBarobjectsCombining IndicatorsChain indicators togetherCustom IndicatorsCreate your ownCustom ResolutionsBeyond the standard resolutionsSee AlsoKey Concepts",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Indicators",
      "section_number": "6",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.1",
    "title": "Data Point Indicators",
    "level": 2,
    "path": "Indicators > Data Point Indicators",
    "content": "### Introduction\n\nThis page explains how to create, update, and visualize LEAN data-point indicators.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market dataand create an indicator in order to calculate a timeseries of indicator values. In this example, use a 20-period 2-standard-deviationBollingerBandsindicator.\n\nvar bb = new BollingerBands(20, 2);bb = BollingerBands(20, 2)\n\nYou can create the indicator timeseries with theIndicatorhelper method or you can manually create the timeseries.\n\nIndicator Helper Method\n\nTo create an indicator timeseries with the helper method, call theIndicatormethod.\n\n// Create a dataframe with a date index, and columns are indicator values.\nvar bbIndicator = qb.Indicator(bb, symbol, 50, Resolution.Daily);# Create a dataframe with a date index, and columns are indicator values.\nbb_dataframe = qb.indicator(bb, symbol, 50, Resolution.DAILY)\n\nManually Create the Indicator Timeseries\n\nFollow these steps to manually create the indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Set the indicatorWindow.Sizewindow.sizefor each attribute of the indicator to hold their values.// Set the window.size to the desired timeseries length\nbb.Window.Size=50;\nbb.LowerBand.Window.Size=50;\nbb.MiddleBand.Window.Size=50;\nbb.UpperBand.Window.Size=50;\nbb.BandWidth.Window.Size=50;\nbb.PercentB.Window.Size=50;\nbb.StandardDeviation.Window.Size=50;\nbb.Price.Window.Size=50;# Set the window.size to the desired timeseries length\nbb.window.size=50\nbb.lower_band.window.size=50\nbb.middle_band.window.size=50\nbb.upper_band.window.size=50\nbb.band_width.window.size=50\nbb.percent_b.window.size=50\nbb.standard_deviation.window.size=50\nbb.price.window.size=50Iterate through the historical market data and update the indicator.foreach (var bar in history)\n{\nbb.Update(bar.EndTime, bar.Close);\n}for bar in history:\nbb.update(bar.end_time, bar.close)Display the data.foreach (var i in Enumerable.Range(0, 5).Reverse())\n{\nConsole.WriteLine($\"{bb[i].EndTime:yyyyMMdd} {bb[i].Value:f4} {bb.LowerBand[i].Value:f4} {bb.MiddleBand[i].Value:f4} {bb.UpperBand[i].Value:f4} {bb.BandWidth[i].Value:f4} {bb.PercentB[i].Value:f4} {bb.StandardDeviation[i].Value:f4} {bb.Price[i].Value:f4}\");\n}Populate aDataFramewith the data in theIndicatorobject.bb_dataframe = pd.DataFrame({\n\"current\": pd.Series({x.end_time: x.value for x in bb}),\n\"lowerband\": pd.Series({x.end_time: x.value for x in bb.lower_band}),\n\"middleband\": pd.Series({x.end_time: x.value for x in bb.middle_band}),\n\"upperband\": pd.Series({x.end_time: x.value for x in bb.upper_band}),\n\"bandwidth\": pd.Series({x.end_time: x.value for x in bb.band_width}),\n\"percentb\": pd.Series({x.end_time: x.value for x in bb.percent_b}),\n\"standarddeviation\": pd.Series({x.end_time: x.value for x in bb.standard_deviation}),\n\"price\": pd.Series({x.end_time: x.value for x in bb.price})\n}).sort_index()\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot data point indicators.\n\nYou need tocreate an indicator timeseriesto plot the indicator values.\n\nFollow these steps to plot the indicator values:\n\nSelect the columns/features to plot.bb_plot = bb_indicator[[\"upperband\", \"middleband\", \"lowerband\", \"price\"]]Call theplotmethod.bb_plot.plot(figsize=(15, 10), title=\"SPY BB(20,2)\"))Show the plots.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with data point indicators.\n\nExample 1: Quick Backtest On Bollinger Band\n\nThe following example demonstrates a quick backtest to testify the effectiveness of a Bollinger Band mean-reversal under the research enviornment.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Create the Bollinger Band indicator with parameters to be studied.\nvar bb = new BollingerBands(20, 2);\n\n// Get the history of SPY to update the indicator and trade.\nvar history = qb.History<TradeBar>(symbol, 252, Resolution.Daily).ToList();\n\n// Obtain the cumulative return curve as a mini-backtest.\nvar equity = new List<decimal>() { 1m };\nvar time = new List<DateTime>() { history[0].EndTime };\nfor (int i = 0; i < history.Count - 1; i++)\n{\nvar bar = history[i];\nvar nextBar = history[i+1];\n// Update the indicator value.\nbb.Update(bar.EndTime, bar.Close);\n\n// Get 1-day forward return.\nvar pctChg = (nextBar.Close - bar.Close) / bar.Close;\n\n// Buy if the asset is underprice (below the lower band), sell if overpriced (above the upper band)\nvar order = bar.Close < bb.LowerBand ? 1 : (bar.Close > bb.UpperBand ? -1 : 0);\nvar equityChg = order * pctChg;\n\nequity.Add((1m + equityChg) * equity[^1]);\ntime.Add(nextBar.EndTime);\n}\n\n// Create line chart of the equity curve.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nequity\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Equity\");\nTitle title = Title.init($\"Equity by Time of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Create the Bollinger Band indicator with parameters to be studied.\nbb = BollingerBands(20, 2)\n\n# Get the indicator history of the indicator.\nbb_dataframe = qb.indicator(bb, symbol, 252, Resolution.DAILY)\n\n# Create a order record and return column.\n# Buy if the asset is underprice (below the lower band), sell if overpriced (above the upper band)\nbb_dataframe[\"position\"] = bb_dataframe.apply(lambda x: 1 if x.price < x.lowerband else -1 if x.price > x.upperband else 0, axis=1)\n# Get the 1-day forward return.\nbb_dataframe[\"return\"] = bb_dataframe[\"price\"].pct_change().shift(-1).fillna(0)\nbb_dataframe[\"return\"] = bb_dataframe[\"position\"] * bb_dataframe[\"return\"]\n\n# Obtain the cumulative return curve as a mini-backtest.\nequity_curve = (bb_dataframe[\"return\"] + 1).cumprod()\nequity_curve.plot(title=\"Equity Curve on BBand Mean Reversal\", ylabel=\"Equity\", xlabel=\"time\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Data Point Indicators",
      "section_number": "6.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.2",
    "title": "Bar Indicators",
    "level": 2,
    "path": "Indicators > Bar Indicators",
    "content": "### Introduction\n\nThis page explains how to create, update, and visualize LEAN bar indicators.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market dataand create an indicator in order to calculate a timeseries of indicator values. In this example, use a 20-periodAverageTrueRangeindicator.\n\nvar atr = new AverageTrueRange(20);atr = AverageTrueRange(20)\n\nYou can create the indicator timeseries with theIndicatorhelper method or you can manually create the timeseries.\n\nIndicator Helper Method\n\nTo create an indicator timeseries with the helper method, call theIndicatormethod.\n\n// Create a dataframe with a date index, and columns are indicator values.\nvar atrIndicator = qb.Indicator(atr, symbol, 50, Resolution.Daily);# Create a dataframe with a date index, and columns are indicator values.\natr_dataframe = qb.indicator(atr, symbol, 50, Resolution.DAILY)\n\nManually Create the Indicator Timeseries\n\nFollow these steps to manually create the indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Set the indicatorWindow.Sizewindow.sizefor each attribute of the indicator to hold their values.// Set the window.size to the desired timeseries length\natr.Window.Size = 50;\natr.TrueRange.Window.Size = 50;# Set the window.size to the desired timeseries length\natr.window.size = 50\natr.true_range.window.size = 50Iterate through the historical market data and update the indicator.foreach (var bar in history)\n{\natr.Update(bar);\n}for bar in history:\natr.update(bar)Display the data.foreach (var i in Enumerable.Range(0, 5).Reverse())\n{\nConsole.WriteLine($\"{atr[i].EndTime:yyyyMMdd} {atr[i].Value:f4} {atr.TrueRange[i].Value:f4}\");\n}Populate aDataFramewith the data in theIndicatorobject.atr_dataframe = pd.DataFrame({\n\"current\": pd.Series({x.end_time: x.value for x in atr}),\n\"truerange\": pd.Series({x.end_time: x.value for x in atr.true_range})\n}).sort_index()\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot bar indicators.\n\nYou need tocreate an indicator timeseriesto plot the indicator values.\n\nFollow these steps to plot the indicator values:\n\nCall theplotmethod.atr_indicator.plot(title=\"SPY ATR(20)\", figsize=(15, 10))Show the plots.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with bar indicators.\n\nExample 1: Quick Backtest On William Percent Ratio\n\nThe following example demonstrates a quick backtest to testify the effectiveness of a William Percent Ratio mean-reversal under the research enviornment.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Create the William %R indicator with parameters to be studied.\nvar indicator = new WilliamsPercentR(20);\n\n// Get the history of SPY to update the indicator and trade.\nvar history = qb.History<TradeBar>(symbol, 252, Resolution.Daily).ToList();\n\n// Obtain the cumulative return curve as a mini-backtest.\nvar equity = new List<decimal>() { 1m };\nvar time = new List<DateTime>() { history[0].EndTime };\nfor (int i = 0; i < history.Count - 1; i++)\n{\nvar bar = history[i];\nvar nextBar = history[i+1];\n// Update the indicator value.\nindicator.Update(bar);\n\n// Get 1-day forward return.\nvar pctChg = (nextBar.Close - bar.Close) / bar.Close;\n\n// Buy if the asset is underprice (below -80), sell if overpriced (above -20)\nvar order = indicator < -80 ? 1 : (indicator > -20 ? -1 : 0);\nvar equityChg = order * pctChg;\n\nequity.Add((1m + equityChg) * equity[^1]);\ntime.Add(nextBar.EndTime);\n}\n\n// Create line chart of the equity curve.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nequity\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Equity\");\nTitle title = Title.init($\"Equity by Time of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Get the historical data for trading.\nhistory = qb.history(symbol, 252, Resolution.DAILY).close.unstack(0).iloc[:, 0]\n\n# Create the William %R indicator with parameters to be studied.\nindicator = WilliamsPercentR(20)\n\n# Get the indicator history of the indicator.\nindicator_dataframe = qb.indicator(indicator, symbol, 252, Resolution.DAILY)\n\n# Create a order record and return column.\n# Buy if the asset is underprice (below -80), sell if overpriced (above -20)\nindicator_dataframe[\"position\"] = indicator_dataframe.apply(lambda x: 1 if x.current < -80 else -1 if x.current > -20 else 0, axis=1)\n# Get the 1-day forward return.\nindicator_dataframe[\"return\"] = history.pct_change().shift(-1).fillna(0)\nindicator_dataframe[\"return\"] = indicator_dataframe[\"position\"] * indicator_dataframe[\"return\"]\n\n# Obtain the cumulative return curve as a mini-backtest.\nequity_curve = (indicator_dataframe[\"return\"] + 1).cumprod()\nequity_curve.plot(title=\"Equity Curve\", ylabel=\"Equity\", xlabel=\"time\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Bar Indicators",
      "section_number": "6.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.3",
    "title": "Trade Bar Indicators",
    "level": 2,
    "path": "Indicators > Trade Bar Indicators",
    "content": "### Introduction\n\nThis page explains how to create, update, and visualize LEANTradeBarindicators.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market dataand create an indicator in order to calculate a timeseries of indicator values. In this example, use a 20-periodVolumeWeightedAveragePriceIndicatorindicator.\n\nvar vwap = new VolumeWeightedAveragePriceIndicator(20);vwap = VolumeWeightedAveragePriceIndicator(20)\n\nYou can create the indicator timeseries with theIndicatorhelper method or you can manually create the timeseries.\n\nIndicator Helper Method\n\nTo create an indicator timeseries with the helper method, call theIndicatormethod.\n\n// Create a dataframe with a date index, and columns are indicator values.\nvar vwapIndicator = qb.Indicator(vwap, symbol, 50, Resolution.Daily);# Create a dataframe with a date index, and columns are indicator values.\nvwap_dataframe = qb.indicator(vwap, symbol, 50, Resolution.DAILY)\n\nManually Create the Indicator Timeseries\n\nFollow these steps to manually create the indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Set the indicatorWindow.Sizewindow.sizefor each attribute of the indicator to hold their values.// Set the window.size to the desired timeseries length\nvwap.Window.Size = 50;# Set the window.size to the desired timeseries length\nvwap.window.size = 50Iterate through the historical market data and update the indicator.foreach (var bar in history)\n{\nvwap.Update(bar);\n}for bar in history:\nvwap.update(bar)Display the data.foreach (var i in Enumerable.Range(0, 5).Reverse())\n{\nConsole.WriteLine($\"{vwap[i].EndTime:yyyyMMdd} {vwap[i].Value:f4}\");\n}Populate aDataFramewith the data in theIndicatorobject.vwap_dataframe = pd.DataFrame({\n\"current\": pd.Series({x.end_time: x.value for x in vwap}))\n}).sort_index()\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot TradeBar indicators.\n\nFollow these steps to plot the indicator values:\n\nCall theplotmethod.vwap_indicator.plot(title=\"SPY VWAP(20)\", figsize=(15, 10))Show the plots.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with trade bar indicators.\n\nExample 1: Quick Backtest On MoneyFlowIndex\n\nThe following example demonstrates a quick backtest to testify the effectiveness of a Money Flow Index mean-reversal under the research enviornment.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Create the Money Flow Index indicator with parameters to be studied.\nvar indicator = new MoneyFlowIndex(20);\n\n// Get the history of SPY to update the indicator and trade.\nvar history = qb.History<TradeBar>(symbol, 252, Resolution.Daily).ToList();\n\n// Obtain the cumulative return curve as a mini-backtest.\nvar equity = new List<decimal>() { 1m };\nvar time = new List<DateTime>() { history[0].EndTime };\nfor (int i = 0; i < history.Count - 1; i++)\n{\nvar bar = history[i];\nvar nextBar = history[i+1];\n// Update the indicator value.\nindicator.Update(bar);\n\n// Get 1-day forward return.\nvar pctChg = (nextBar.Close - bar.Close) / bar.Close;\n\n// Buy if the asset is underprice (below 20), sell if overpriced (above 80)\nvar order = indicator < 20 ? 1 : (indicator > 80 ? -1 : 0);\nvar equityChg = order * pctChg;\n\nequity.Add((1m + equityChg) * equity[^1]);\ntime.Add(nextBar.EndTime);\n}\n\n// Create line chart of the equity curve.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nequity\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Equity\");\nTitle title = Title.init($\"Equity by Time of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Get the historical data for trading.\nhistory = qb.history(symbol, 252, Resolution.DAILY).close.unstack(0).iloc[:, 0]\nhistory = history.groupby(history.index.date).sum()\n\n# Create the Money Flow Index with parameters to be studied.\nindicator = MoneyFlowIndex(10)\n\n# Get the indicator history of the indicator.\nindicator_dataframe = qb.indicator(indicator, symbol, 252, Resolution.DAILY)\nindicator_dataframe = indicator_dataframe.groupby(indicator_dataframe.index.date).sum()\n\n# Match index.\ncommon_ix = sorted(set(indicator_dataframe.index).intersection(set(history.index)))\nhistory = history.loc[common_ix]\nindicator_dataframe = indicator_dataframe.loc[common_ix]\n\n# Create a order record and return column.\n# Buy if the asset is underprice (below 20), sell if overpriced (above 80)\nindicator_dataframe[\"position\"] = indicator_dataframe.apply(lambda x: 1 if x.current < 20 else -1 if x.current > 80 else 0, axis=1)\n# Get the 1-day forward return.\nindicator_dataframe[\"return\"] = history.pct_change().shift(-1).fillna(0)\nindicator_dataframe[\"return\"] = indicator_dataframe[\"position\"] * indicator_dataframe[\"return\"]\n\n# Obtain the cumulative return curve as a mini-backtest.\nequity_curve = (indicator_dataframe[\"return\"] + 1).cumprod()\nequity_curve.plot(title=\"Equity Curve\", ylabel=\"Equity\", xlabel=\"time\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Trade Bar Indicators",
      "section_number": "6.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.4",
    "title": "Combining Indicators",
    "level": 2,
    "path": "Indicators > Combining Indicators",
    "content": "### Introduction\n\nThis page explains how to create, update, and visualize LEAN Composite indicators.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market dataand create a composite indicator in order to calculate a timeseries of indicator values. In this example, use a 10-periodSimpleMovingAverageof a 10-periodRelativeStrengthIndexindicator.\n\n// Create 10-period RSI and 10-period SMA indicator objects.\nvar rsi = new RelativeStrengthIndex(10);\nvar sma = new SimpleMovingAverage(10);\n// Create a composite indicator by feeding the value of 10-period RSI to the 10-period SMA indicator.\nvar smaOfRsi = IndicatorExtensions.Of(sma, rsi);# Create 10-period RSI and 10-period SMA indicator objects.\nrsi = RelativeStrengthIndex(10)\nsma = SimpleMovingAverage(10)\n# Create a composite indicator by feeding the value of 10-period RSI to the 10-period SMA indicator.\nsma_of_rsi = IndicatorExtensions.of(sma, rsi)\n\nFollow these steps to create an indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Create aRollingWindowfor each attribute of the indicator to hold their values.In this example, save 50 data points.// Create a window dictionary to store RollingWindow objects.\nvar window = new Dictionary<string, RollingWindow<decimal>>();\n// Store the RollingWindow objects, index by key is the property of the indicator.\nvar time = new RollingWindow<DateTime>(50);\nwindow[\"SMA Of RSI\"] = new RollingWindow<decimal>(50);\nwindow[\"rollingsum\"] = new RollingWindow<decimal>(50);# Create a window dictionary to store RollingWindow objects.\nwindow = {}\n# Store the RollingWindow objects, index by key is the property of the indicator.\nwindow['time'] = RollingWindow[DateTime](50)\nwindow[\"SMA Of RSI\"] = RollingWindow[float](50)\nwindow[\"rollingsum\"] = RollingWindow[float](50)Attach a handler method to the indicator that updates theRollingWindowobjects.// Define an update function to add the indicator values to the RollingWindow object.\nsmaOfRsi.Updated += (sender, updated) =>\n{\nvar indicator = (SimpleMovingAverage)sender;    // Use terminal indicator class.\ntime.Add(updated.EndTime);\nwindow[\"SMA Of RSI\"].Add(updated);\nwindow[\"rollingsum\"].Add(indicator.RollingSum);\n};# Define an update function to add the indicator values to the RollingWindow object.\ndef update_sma_of_rsi_window(sender: object, updated: IndicatorDataPoint) -> None:\nindicator = sender\nwindow['time'].add(updated.end_time)\nwindow[\"SMA Of RSI\"].add(updated.value)\nwindow[\"rollingsum\"].add(indicator.rolling_sum.current.value)\n\nsma_of_rsi.updated += UpdateSmaOfRsiWindowWhen the indicator receives new data, the preceding handler method adds the newIndicatorDataPointvalues into the respectiveRollingWindow.Iterate thehistorical market datato update the indicators and theRollingWindows.foreach(var bar in history){\n// Update the base indicators, the composite indicator will update automatically when the base indicator is updated.\nrsi.Update(bar.EndTime, bar.Close);\n}for bar in history:\n# Update the base indicators, the composite indicator will update automatically when the base indicator is updated.\nrsi.update(bar.end_time, bar.close)Display the data.Console.WriteLine($\"time,{string.Join(',', window.Select(kvp => kvp.Key))}\");\nforeach (var i in Enumerable.Range(0, 5).Reverse())\n{\nvar data = string.Join(\", \", window.Select(kvp => Math.Round(kvp.Value[i],6)));\nConsole.WriteLine($\"{time[i]:yyyyMMdd}, {data}\");\n}Populate aDataFramewith the data in theRollingWindowobjects.sma_of_rsi_dataframe = pd.DataFrame(window).set_index('time')\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot composite indicators.\n\nFollow these steps to plot the indicator values:\n\nSelect the columns/features to plot.sma_of_rsi_plot = sma_of_rsi_dataframe[[\"SMA Of RSI\"]]Call theplotmethod.sma_of_rsi_plot.plot(title=\"SPY SMA(10) of RSI(10)\", figsize=(15, 10))Show the plots.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with combining indicators.\n\nExample 1: Plot Standard Deviation Of Return\n\nThe following example demonstrates a quick backtest to testify the effectiveness of a Standard Deviation On Return mean-reversal under the research enviornment.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Create the SD on Return indicator with parameters to be studied.\nvar roc = new RateOfChange(1);\nvar sd = new StandardDeviation(252);\nvar indicator = IndicatorExtensions.Of(sd, roc);\n\n// Get the history of SPY to update the indicator and trade.\nvar history = qb.History<TradeBar>(symbol, 500, Resolution.Daily).ToList();\n\nvar indicatorValues = new List<decimal>();\nvar time = new List<DateTime>();\nfor (int i = 0; i < history.Count - 1; i++)\n{\n// Update the indicator value.\nvar bar = history[i];\nroc.Update(bar);\n\nindicatorValues.Add(indicator.Current.Value);\ntime.Add(bar.EndTime);\n}\n\n// Create line chart of the SD of Return.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nindicatorValues\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"%\");\nTitle title = Title.init($\"Return SD of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Get the historical data for trading.\nhistory = qb.history(symbol, 500, Resolution.DAILY).close.unstack(0)\nhistory = history.groupby(history.index.date).sum()\n\n# Create the SD on Return with parameters to be studied.\nroc = RateOfChange(1)\nsd = StandardDeviation(252)\nindicator = IndicatorExtensions.of(sd, roc)\n\n# Update and obtain the indicator value\ndef update(row):\nroc.update(row.name, row.iloc[0])\nreturn indicator.current.value\nindicator_dataframe = history.apply(update, axis=1).iloc[252:]\n\nindicator_dataframe.plot(title=f\"Return SD of {symbol}\", ylabel=\"%\", xlabel=\"Time\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Combining Indicators",
      "section_number": "6.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.5",
    "title": "Custom Indicators",
    "level": 2,
    "path": "Indicators > Custom Indicators",
    "content": "### Introduction\n\nThis page explains how to create and update custom indicators.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market datain order to calculate a timeseries of indicator values.\n\nFollow these steps to create an indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Define a custom indicator class that inherits from theIndicatorsuperclass.Define a custom indicator class. Note thePythonIndicatorsuperclass inheritance,Valueattribute, andUpdateupdatemethod are mandatory.In this tutorial, create anExpectedShortfallPercentindicator that uses Monte Carlo to calculate the expected shortfall of returns. Use theWindowIndicatorsuperclass instead ofIndicatorfor using a period of historical data stored in aRollingWindow.In this tutorial, create anExpectedShortfallPercentindicator that uses Monte Carlo to calculate the expected shortfall of returns.public class ExpectedShortfallPercent : WindowIndicator<IndicatorDataPoint>, IIndicatorWarmUpPeriodProvider\n{\nprivate decimal _alpha;\n\n// Set up IndicatorDataPoint attributes for the indicator.\npublic IndicatorBase<IndicatorDataPoint> ValueAtRisk { get; }\n\n// Set up the WarmUpPeriod attribute to provide implementation of the IIndicatorWarmUpPeriodProvider interface.\npublic override int WarmUpPeriod => Period;\n\n// Set up the constructor.\n// period: The lookback period for return distribution.\n// alpha: Alpha level of VaR cutoff.\npublic ExpectedShortfallPercent(int period, decimal alpha)\n: base(\"ES\", period)\n{\n_alpha = alpha;\nValueAtRisk = new Identity(\"ES_VaR\");\n}\n\n// Override the IsReady method to set up the flag of the Indicator and its IndicatorDataPoint attributes are ready.\npublic override bool IsReady => ValueAtRisk.IsReady;\n\n// Mandatory: Override the ComputeNextValue method to calculate the indictor value.\nprotected override decimal ComputeNextValue(IReadOnlyWindow<IndicatorDataPoint> window, IndicatorDataPoint input)\n{\nif (Samples < 2)\nreturn 0m;\n\nvar n = Math.Min(Period, Samples);\nvar cutoff = (int) Math.Ceiling(n * _alpha);\n\nvar samples = new List<decimal>();\nfor (int i = 0; i < window.Count - 1; i++)\n{\nsamples.Add( (window[i] - window[i+1]) / window[i+1] );\n}\nvar lowest = samples.OrderBy(x => x).Take(cutoff);\n\nValueAtRisk.Update(input.Time, lowest.Last());\nreturn lowest.Average();\n}\n}class ExpectedShortfallPercent(PythonIndicator):\nimport math, numpy as np\n\ndef __init__(self, period, alpha):\nself.value = None   # Attribute represents the indicator value\nself.value_at_risk = None\n\nself.alpha = alpha\n\nself._window = RollingWindow[float](period)\n\n# Override the IsReady attribute to flag all attributes values are ready.\n@property\ndef is_ready(self) -> bool:\nreturn self.value and self.value_at_risk\n\n# Method to update the indicator values. Note that it only receives 1 IBaseData object (Tick, TradeBar, QuoteBar) argument.\ndef update(self, input: BaseData) -> bool:\ncount = self._window.Count\n\nself._window.Add(input.Close)\n\n# Update the Value and other attributes as the indicator current value.\nif count >= 2:\ncutoff = math.ceil(self.alpha * count)\n\nret = [ (self._window[i] - self._window[i+1]) / self._window[i+1] for i in range(count-1) ]\nlowest = sorted(ret)[:cutoff]\n\nself.value = np.mean(lowest)\nself.value_at_risk = lowest[-1]\n\n# return a boolean to indicate IsReady.\nreturn count >= 2Initialize a new instance of the custom indicator.var es = new ExpectedShortfallPercent(50, 0.05m);custom = ExpectedShortfallPercent(50, 0.05)Create aRollingWindowfor each attribute of the indicator to hold their values.In this example, save 20 data points.// Create a window dictionary to store RollingWindow objects.\nvar window = new Dictionary<string, RollingWindow<decimal>>();\n// Store the RollingWindow objects, index by key is the property of the indicator.\nvar time = new RollingWindow<DateTime>(20);\nwindow[\"expectedshortfall\"] = new RollingWindow<decimal>(20);\nwindow[\"valueatrisk\"] = new RollingWindow<decimal>(20);# Create a window dictionary to store RollingWindow objects.\nwindow = {}\n# Store the RollingWindow objects, index by key is the property of the indicator.\nwindow['time'] = RollingWindow[DateTime](20)\nwindow['expectedshortfall'] = RollingWindow[float](20)\nwindow['valueatrisk'] = RollingWindow[float](20)Attach a handler method to the indicator that updates theRollingWindowobjects.// Define an update function to add the indicator values to the RollingWindow object.\nes.Updated += (sender, updated) =>\n{\nvar indicator = (ExpectedShortfallPercent) sender;\ntime.Add(updated.EndTime);\nwindow[\"expectedshortfall\"].Add(updated);\nwindow[\"valueatrisk\"].Add(indicator.ValueAtRisk.Current);\n};When the indicator receives new data, the preceding handler method adds the newIndicatorDataPointvalues into the respectiveRollingWindow.Iterate through the historical market data and update the indicator.foreach(var bar in history){\nes.Update(bar.EndTime, bar.Close);\n}for bar in history:\ncustom.update(bar)\n\n# The Updated event handler is not available for custom indicator in Python, RollingWindows are needed to be updated in here.\nif custom.is_ready:\nwindow['time'].add(bar.end_time)\nwindow['expectedshortfall'].add(custom.value)\nwindow['valueatrisk'].add(custom.value_at_risk)Display the data.Console.WriteLine($\"time,{string.Join(',', window.Select(kvp => kvp.Key))}\");\nforeach (var i in Enumerable.Range(0, 5).Reverse())\n{\nvar data = string.Join(\", \", window.Select(kvp => Math.Round(kvp.Value[i],6)));\nConsole.WriteLine($\"{time[i]:yyyyMMdd}, {data}\");\n}Populate aDataFramewith the data in theRollingWindowobjects.custom_dataframe = pd.DataFrame(window).set_index('time')\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot custom indicators.\n\nFollow these steps to plot the indicator values:\n\nCall theplotmethod.custom_dataframe.plot()Show the plot.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with combining indicators.\n\nExample 1: Expected Shortfall\n\nThe following example demonstrates researching using a custom-constructed Expected Shortfall indicator. Expected Shortfall refers to the average of the N% worst-case return.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);\n\npublic class ExpectedShortfallPercent : WindowIndicator<IndicatorDataPoint>, IIndicatorWarmUpPeriodProvider\n{\nprivate decimal _alpha;\n\n// Set up IndicatorDataPoint attributes for the indicator.\npublic IndicatorBase<IndicatorDataPoint> ValueAtRisk { get; }\n\n// Set up the WarmUpPeriod attribute to provide implementation of the IIndicatorWarmUpPeriodProvider interface.\npublic override int WarmUpPeriod => Period;\n\n// Set up the constructor.\n// period: The lookback period for return distribution.\n// alpha: Alpha level of VaR cutoff.\npublic ExpectedShortfallPercent(int period, decimal alpha)\n: base(\"ES\", period)\n{\n_alpha = alpha;\nValueAtRisk = new Identity(\"ES_VaR\");\n}\n\n// Override the IsReady method to set up the flag of the Indicator and its IndicatorDataPoint attributes are ready.\npublic override bool IsReady => ValueAtRisk.IsReady;\n\n// Mandatory: Override the ComputeNextValue method to calculate the indictor value.\nprotected override decimal ComputeNextValue(IReadOnlyWindow<IndicatorDataPoint> window, IndicatorDataPoint input)\n{\nif (Samples < 2)\nreturn 0m;\n\nvar n = Math.Min(Period, Samples);\nvar cutoff = (int) Math.Ceiling(n * _alpha);\n\nvar samples = new List<decimal>();\nfor (int i = 0; i < window.Count - 1; i++)\n{\nsamples.Add( (window[i] - window[i+1]) / window[i+1] );\n}\nvar lowest = samples.OrderBy(x => x).Take(cutoff);\n\nValueAtRisk.Update(input.Time, lowest.Last());\nreturn lowest.Average();\n}\n}\n\n// Create the expected shortfall indicator to study.\nvar es = new ExpectedShortfallPercent(50, 0.05m);\n\n// Create a window dictionary to store RollingWindow objects.\nvar window = new Dictionary<string, RollingWindow<decimal>>();\n// Store the RollingWindow objects, index by key is the property of the indicator.\nvar time = new RollingWindow<DateTime>(20);\nwindow[\"expectedshortfall\"] = new RollingWindow<decimal>(20);\nwindow[\"valueatrisk\"] = new RollingWindow<decimal>(20);\n\n// Define an update function to add the indicator values to the RollingWindow object.\nes.Updated += (sender, updated) =>\n{\nvar indicator = (ExpectedShortfallPercent) sender;\ntime.Add(updated.EndTime);\nwindow[\"expectedshortfall\"].Add(updated);\nwindow[\"valueatrisk\"].Add(indicator.ValueAtRisk.Current);\n};\n\n// Iterate through the historical market data and update the indicator.\nforeach(var bar in history){\nes.Update(bar.EndTime, bar.Close);\n}\n\n// Create line chart of the Expected Shortfall Percent.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime,\nwindow[\"expectedshortfall\"]\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"%\");\nTitle title = Title.init($\"Expected Shortfall Percent of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)\n\nclass ExpectedShortfallPercent(PythonIndicator):\nimport math, numpy as np\n\ndef __init__(self, period, alpha):\nself.value = None   # Attribute represents the indicator value\nself.value_at_risk = None\n\nself.alpha = alpha\n\nself._window = RollingWindow[float](period)\n\n# Override the IsReady attribute to flag all attributes values are ready.\n@property\ndef is_ready(self) -> bool:\nreturn self.value and self.value_at_risk\n\n# Method to update the indicator values. Note that it only receives 1 IBaseData object (Tick, TradeBar, QuoteBar) argument.\ndef update(self, input: BaseData) -> bool:\ncount = self._window.Count\n\nself._window.Add(input.Close)\n\n# Update the Value and other attributes as the indicator current value.\nif count >= 2:\ncutoff = math.ceil(self.alpha * count)\n\nret = [ (self._window[i] - self._window[i+1]) / self._window[i+1] for i in range(count-1) ]\nlowest = sorted(ret)[:cutoff]\n\nself.value = np.mean(lowest)\nself.value_at_risk = lowest[-1]\n\n# return a boolean to indicate IsReady.\nreturn count >= 2\n\n# Initialize a new instance of the custom indicator.\ncustom = ExpectedShortfallPercent(50, 0.05)\n\n# Create a window dictionary to store RollingWindow objects.\nwindow = {}\n# Store the RollingWindow objects, index by key is the property of the indicator.\nwindow['time'] = RollingWindow[DateTime](20)\nwindow['expectedshortfall'] = RollingWindow[float](20)\nwindow['valueatrisk'] = RollingWindow[float](20)\n\n# Iterate through the historical market data and update the indicator.\nfor bar in history:\ncustom.update(bar)\n\n# The Updated event handler is not available for custom indicator in Python, RollingWindows are needed to be updated in here.\nif custom.is_ready:\nwindow['time'].add(bar.end_time)\nwindow['expectedshortfall'].add(custom.value)\nwindow['valueatrisk'].add(custom.value_at_risk)\n\n# Populate a DataFrame with the data in the RollingWindow objects.\ncustom_dataframe = pd.DataFrame(window).set_index('time')\n\n# Create line chart of the Expected Shortfall Percent.\ncustom_dataframe.plot(title=f\"Expected Shortfall Percent of {symbol}\", xlabel=\"Time\", ylabel=\"%\")\nplt.show()",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Custom Indicators",
      "section_number": "6.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "6.6",
    "title": "Custom Resolutions",
    "level": 2,
    "path": "Indicators > Custom Resolutions",
    "content": "### Introduction\n\nThis page explains how to create and update indicators with data of a custom resolution.\n\n### Create Subscriptions\n\nYou need tosubscribe to some market datain order to calculate indicator values.\n\nvar qb = new QuantBook();\nvar symbol = qb.AddEquity(\"SPY\").Symbol;qb = QuantBook()\nsymbol = qb.add_equity(\"SPY\").symbol\n\n### Create Indicator Timeseries\n\nYou need tosubscribe to some market dataand create an indicator in order to calculate a timeseries of indicator values.\n\nFollow these steps to create an indicator timeseries:\n\nGet somehistorical data.// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 70, Resolution.Daily);# Request historical trading data with the daily resolution.\nhistory = qb.history[TradeBar](symbol, 70, Resolution.DAILY)Create a data-point indicator.In this example, use a 20-period 2-standard-deviationBollingerBandsindicator.var bb = new BollingerBands(20, 2);bb = BollingerBands(20, 2)Create aRollingWindowfor each attribute of the indicator to hold their values.// Create a window dictionary to store RollingWindow objects.\nvar window = new Dictionary<string, RollingWindow<decimal>>();\n// Store the RollingWindow objects, index by key is the property of the indicator.\nvar time = new RollingWindow<DateTime>(50);\nwindow[\"bollingerbands\"] = new RollingWindow<decimal>(50);\nwindow[\"lowerband\"] = new RollingWindow<decimal>(50);\nwindow[\"middleband\"] = new RollingWindow<decimal>(50);\nwindow[\"upperband\"] = new RollingWindow<decimal>(50);\nwindow[\"bandwidth\"] = new RollingWindow<decimal>(50);\nwindow[\"percentb\"] = new RollingWindow<decimal>(50);\nwindow[\"standarddeviation\"] = new RollingWindow<decimal>(50);\nwindow[\"price\"] = new RollingWindow<decimal>(50);# Create a window dictionary to store RollingWindow objects.\nwindow = {}\n# Store the RollingWindow objects, index by key is the property of the indicator.\nwindow['time'] = RollingWindow[DateTime](50)\nwindow[\"bollingerbands\"] = RollingWindow[float](50)\nwindow[\"lowerband\"] = RollingWindow[float](50)\nwindow[\"middleband\"] = RollingWindow[float](50)\nwindow[\"upperband\"] = RollingWindow[float](50)\nwindow[\"bandwidth\"] = RollingWindow[float](50)\nwindow[\"percentb\"] = RollingWindow[float](50)\nwindow[\"standarddeviation\"] = RollingWindow[float](50)\nwindow[\"price\"] = RollingWindow[float](50)Attach a handler method to the indicator that updates theRollingWindowobjects.// Define an update function to add the indicator values to the RollingWindow object.\nbb.Updated += (sender, updated) =>\n{\nvar indicator = (BollingerBands)sender;\ntime.Add(updated.EndTime);\nwindow[\"bollingerbands\"].Add(updated);\nwindow[\"lowerband\"].Add(indicator.LowerBand);\nwindow[\"middleband\"].Add(indicator.MiddleBand);\nwindow[\"upperband\"].Add(indicator.UpperBand);\nwindow[\"bandwidth\"].Add(indicator.BandWidth);\nwindow[\"percentb\"].Add(indicator.PercentB);\nwindow[\"standarddeviation\"].Add(indicator.StandardDeviation);\nwindow[\"price\"].Add(indicator.Price);\n};# Define an update function to add the indicator values to the RollingWindow object.\ndef update_bollinger_band_window(sender: object, updated: IndicatorDataPoint) -> None:\nindicator = sender\nwindow['time'].add(updated.end_time)\nwindow[\"bollingerbands\"].add(updated.value)\nwindow[\"lowerband\"].add(indicator.lower_band.current.value)\nwindow[\"middleband\"].add(indicator.middle_band.current.value)\nwindow[\"upperband\"].add(indicator.upper_band.current.value)\nwindow[\"bandwidth\"].add(indicator.band_width.current.value)\nwindow[\"percentb\"].add(indicator.percent_b.current.value)\nwindow[\"standarddeviation\"].add(indicator.standard_deviation.current.value)\nwindow[\"price\"].add(indicator.price.current.value)\n\nbb.updated += update_bollinger_band_windowWhen the indicator receives new data, the preceding handler method adds the newIndicatorDataPointvalues into the respectiveRollingWindow.Create aTradeBarConsolidatortoconsolidate datainto the custom resolution.var consolidator = new TradeBarConsolidator(TimeSpan.FromDays(7));consolidator = TradeBarConsolidator(timedelta(days=7))Attach a handler method to feed data into the consolidator and updates the indicator with the consolidated bars.consolidator.DataConsolidated += (sender, consolidated) =>\n{\nbb.Update(consolidated.EndTime, consolidated.Close);\n};def on_data_consolidated(sender, consolidated):\nbb.update(consolidated.end_time, consolidated.close)\nconsolidator.data_consolidated += on_data_consolidatedWhen the consolidator receives 7 days of data, the handler generates a 7-dayTradeBarand update the indicator.Iterate through the historical market data and update the indicator.foreach(var bar in history)\n{\nconsolidator.Update(bar);\n}for bar in history:\nconsolidator.update(bar)Display the data.Console.WriteLine($\"time,{string.Join(',', window.Select(kvp => kvp.Key))}\");\nforeach (var i in Enumerable.Range(0, 5).Reverse())\n{\nvar data = string.Join(\", \", window.Select(kvp => Math.Round(kvp.Value[i],6)));\nConsole.WriteLine($\"{time[i]:yyyyMMdd}, {data}\");\n}Populate aDataFramewith the data in theRollingWindowobjects.bb_dataframe = pd.DataFrame(window).set_index('time')\n\n### Plot Indicators\n\nJupyter Notebooks don't currently support libraries to plot historical data, but we are working on adding the functionality. Until the functionality is added, use Python to plot indicators.\n\nFollow these steps to plot the indicator values:\n\nSelect the columsn to plot.df = bb_dataframe[['lowerband', 'middleband', 'upperband', 'price']]Call theplotmethod.df.plot()Show the plot.plt.show()\n\n### Examples\n\nThe following examples demonstrate some common practices for researching with data point indicators.\n\nExample 1: Quick Backtest On Bollinger Band\n\nThe following example demonstrates a quick backtest to testify the effectiveness of a Bollinger Band mean-reversal, using 5-miunte bar under the research enviornment.\n\n// Load the assembly files and data types in their own cell.\n#load \"../Initialize.csx\"\n\n// Load the necessary assembly files.\n#load \"../QuantConnect.csx\"\n#r \"../Plotly.NET.dll\"\n#r \"../Plotly.NET.Interactive.dll\"\n\n// Import the QuantConnect, Plotly.NET, and Accord packages for calculation and plotting.\nusing QuantConnect;\nusing QuantConnect.Indicators;\nusing QuantConnect.Research;\n\nusing Plotly.NET;\nusing Plotly.NET.Interactive;\nusing Plotly.NET.LayoutObjects;\n\n// Instantiate the QuantBook instance for researching.\nvar qb = new QuantBook();\n// Request SPY data to work with the indicator.\nvar symbol = qb.AddEquity(\"SPY\").Symbol;\n\n// Request historical trading data with the daily resolution.\nvar history = qb.History(symbol, 1000, Resolution.Minute).ToList();\n\n// Create a window dictionary to store RollingWindow objects.\nvar window = new Dictionary<string, RollingWindow<decimal>>();\n// Store the RollingWindow objects, index by key is the property of the indicator.\nvar time = new RollingWindow<DateTime>(50);\nwindow[\"bollingerbands\"] = new RollingWindow<decimal>(50);\nwindow[\"lowerband\"] = new RollingWindow<decimal>(50);\nwindow[\"middleband\"] = new RollingWindow<decimal>(50);\nwindow[\"upperband\"] = new RollingWindow<decimal>(50);\nwindow[\"price\"] = new RollingWindow<decimal>(50);\n\n// Create the Bollinger Band indicator with parameters to be studied.\nvar bb = new BollingerBands(20, 2);\n// Define an update function to add the indicator values to the RollingWindow object.\nbb.Updated += (sender, updated) =>\n{\nvar indicator = (BollingerBands)sender;\ntime.Add(updated.EndTime);\nwindow[\"bollingerbands\"].Add(updated);\nwindow[\"lowerband\"].Add(indicator.LowerBand);\nwindow[\"middleband\"].Add(indicator.MiddleBand);\nwindow[\"upperband\"].Add(indicator.UpperBand);\nwindow[\"price\"].Add(indicator.Price);\n};\n\n// Create a TradeBarConsolidator to consolidate data into the custom resolution.\nvar consolidator = new TradeBarConsolidator(TimeSpan.FromMinutes(5));\n// Attach a handler method to feed data into the consolidator and updates the indicator with the consolidated bars.\nconsolidator.DataConsolidated += (sender, consolidated) =>\n{\nbb.Update(consolidated.EndTime, consolidated.Close);\n};\n\n// Iterate through the historical market data and update the indicator.\nforeach(var bar in history)\n{\nconsolidator.Update(bar);\n}\n\n// Obtain the cumulative return curve as a mini-backtest.\nvar equity = new List<decimal>() { 1m };\nvar time_ = new List<DateTime>() { history[0].EndTime };\nvar lowerBand = window[\"lowerband\"].ToList();\nvar upperBand = window[\"upperband\"].ToList();\nfor (int i = history.Count - 50; i < history.Count - 1; i++)\n{\nvar bar = history[i];\nvar nextBar = history[i+1];\n\n// Get 1-day forward return.\nvar pctChg = (nextBar.Close - bar.Close) / bar.Close;\n\n// Buy if the asset is underprice (below the lower band), sell if overpriced (above the upper band)\nvar order = bar.Close < lowerBand[i - (history.Count - 50)] ? 1 : (bar.Close > upperBand[i - (history.Count - 50)] ? -1 : 0);\nvar equityChg = order * pctChg;\n\nequity.Add((1m + equityChg) * equity[^1]);\ntime_.Add(nextBar.EndTime);\n}\n\n// Create line chart of the equity curve.\nvar chart = Chart2D.Chart.Line<DateTime, decimal, string>(\ntime_,\nequity\n);\n\n// Create a Layout as the plot settings.\nLinearAxis xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nLinearAxis yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"Equity\");\nTitle title = Title.init($\"Equity by Time of {symbol}\");\n\nLayout layout = new Layout();\nlayout.SetValue(\"xaxis\", xAxis);\nlayout.SetValue(\"yaxis\", yAxis);\nlayout.SetValue(\"title\", title);\n// Assign the Layout to the chart.\nchart.WithLayout(layout);\n\n// Display the plot.\nHTML(GenericChart.toChartHTML(chart))# Instantiate the QuantBook instance for researching.\nqb = QuantBook()\n# Request SPY data to work with the indicator.\nsymbol = qb.add_equity(\"SPY\").symbol\n\n# Request historical trading data with the minute resolution.\nhistory = qb.history[TradeBar](symbol, 1000, Resolution.MINUTE)\n\n# Create a window dictionary to store RollingWindow objects.\nwindow = {}\n# Store the RollingWindow objects, index by key is the property of the indicator.\nwindow['time'] = RollingWindow[DateTime](50)\nwindow[\"bollingerbands\"] = RollingWindow[float](50)\nwindow[\"lowerband\"] = RollingWindow[float](50)\nwindow[\"middleband\"] = RollingWindow[float](50)\nwindow[\"upperband\"] = RollingWindow[float](50)\nwindow[\"price\"] = RollingWindow[float](50)\n\n# Define an update function to add the indicator values to the RollingWindow object.\ndef update_bollinger_band_window(sender: object, updated: IndicatorDataPoint) -> None:\nindicator = sender\nwindow['time'].add(updated.end_time)\nwindow[\"bollingerbands\"].add(updated.value)\nwindow[\"lowerband\"].add(indicator.lower_band.current.value)\nwindow[\"middleband\"].add(indicator.middle_band.current.value)\nwindow[\"upperband\"].add(indicator.upper_band.current.value)\nwindow[\"price\"].add(indicator.price.current.value)\n\n# Create the Bollinger Band indicator with parameters to be studied.\nbb = BollingerBands(20, 2)\nbb.updated += update_bollinger_band_window\n\n# Create a TradeBarConsolidator to consolidate data into the custom resolution.\nconsolidator = TradeBarConsolidator(timedelta(minutes=5))\n# Attach a handler method to feed data into the consolidator and updates the indicator with the consolidated bars.\ndef on_data_consolidated(sender, consolidated):\nbb.update(consolidated.end_time, consolidated.close)\nconsolidator.data_consolidated += on_data_consolidated\n\n# Iterate through the historical market data and update the indicator.\nfor bar in history:\nconsolidator.update(bar)\n\n# Populate a DataFrame with the data in the RollingWindow objects.\nbb_dataframe = pd.DataFrame(window).set_index('time')\n\n# Create a order record and return column.\n# Buy if the asset is underprice (below the lower band), sell if overpriced (above the upper band)\nbb_dataframe[\"position\"] = bb_dataframe.apply(lambda x: 1 if x.price < x.lowerband else -1 if x.price > x.upperband else 0, axis=1)\n# Get the 1-day forward return.\nbb_dataframe[\"return\"] = bb_dataframe[\"price\"].pct_change().shift(-1).fillna(0)\nbb_dataframe[\"return\"] = bb_dataframe[\"position\"] * bb_dataframe[\"return\"]\n\n# Obtain the cumulative return curve as a mini-backtest.\nequity_curve = (bb_dataframe[\"return\"] + 1).cumprod()\nequity_curve.plot(title=\"Equity Curve on BBand Mean Reversal\", ylabel=\"Equity\", xlabel=\"time\")",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "6",
      "breadcrumb": "Indicators > Custom Resolutions",
      "section_number": "6.6",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "7",
    "title": "Object Store",
    "level": 1,
    "path": "Object Store",
    "content": "### Introduction\n\nThe Object Store is a file system that you can use in your algorithms to save, read, and delete data. The Object Store is organization-specific, so you can save or read data from the same Object Store in all of your organization's projects. The Object Store works like a key-value storage system where you can store regular strings, JSON encoded strings, XML encoded strings, and bytes. You can access the data you store in the Object Store from backtests, the Research Environment, and live algorithms.\n\n### Get All Stored Data\n\nTo get all of the keys and values in the Object Store, iterate through theObjectStoreobject_storeproperty.\n\nforeach (var kvp in qb.ObjectStore)\n{\nvar key = kvp.Key;\nvar value = kvp.Value;\n}for kvp in qb.object_store:\nkey = kvp.key\nvalue = kvp.value\n\nTo iterate through just the keys in the Object Store, iterate through theKeyskeysproperty.\n\nforeach (var key in qb.ObjectStore.Keys)\n{\ncontinue;\n}for key in qb.object_store.keys:\ncontinue\n\n### Create Sample Data\n\nYou need some data to store data in the Object Store.\n\nFollow these steps to create some sample data:\n\nCreate a dictionary.var dictSample = new Dictionary<string, int> { {\"One\", 1}, {\"Two\", 2}, {\"Three\", 3} };Create astring.var stringSample = \"My string\";string_sample = \"My string\"Create aBytesobject.var bytesSample = Encoding.UTF8.GetBytes(\"My String\");bytes_sample = str.encode(\"My String\")Convert the dictionary to anXML-formatted object.var xmlSample = new XElement(\"sample\",\ndictSample.Select(kvp => new XElement(kvp.Key, kvp.Value)));\nConsole.WriteLine(xmlSample.ToString());\n\n### Save Data\n\nThe Object Store saves objects under a key-value system. If you save objects in backtests, you can access them from the Research Environment.\n\nIf you run algorithms in QuantConnect Cloud, you needstorage create permissionsto save data in the Object Store.\n\nIf you don't have data to store,create some sample data.\n\nYou can save the following types of objects in the Object Store:\n\nBytesobjectsstringobjectsJSON objectsXML-formatted objects\n\nYou can saveBytesandstringobjects in the Object Store.\n\nStrings\n\nTo save astringobject, call theSavesaveorSaveStringsave_stringmethod.\n\nvar saveSuccessful = qb.ObjectStore.Save($\"{qb.ProjectId}/stringKey\", stringSample);save_successful = qb.object_store.save(f\"{qb.project_id}/string_key\", string_sample)\n\nJSON\n\nTo save a JSON object, call theSaveJson<T>method. This method helps to serialize the data into JSON format.\n\nvar saveSuccessful = qb.ObjectStore.SaveJson<Dictionary<string, int>>($\"{qb.ProjectId}/jsonKey\", dictSample);\n\nXML\n\nTo save an XML-formatted object, call theSaveXml<T>method.\n\nvar saveSuccessful = qb.ObjectStore.SaveXml<XElement>($\"{qb.ProjectId}/xmlKey\", xmlSample);\n\nBytes\n\nTo save aBytesobject (for example, zipped data), call theSaveBytessave_bytesmethod.\n\nvar saveSuccessful = qb.ObjectStore.SaveBytes($\"{qb.ProjectId}/bytesKey\", bytesSample)\n\nvar zippedDataSample = Compression.ZipBytes(Encoding.UTF8.GetBytes(stringSample), \"data\");\nvar saveSuccessful = qb.ObjectStore.SaveBytes($\"{qb.ProjectId}/bytesKey.zip\", zippedDataSample);save_successful = qb.object_store.save_bytes(f\"{qb.project_id}/bytes_key\", bytes_sample)\n\nzipped_data_sample = Compression.zip_bytes(bytes(string_sample, \"utf-8\"), \"data\")\nzip_save_successful = qb.object_store.save_bytes(f\"{qb.project_id}/bytesKey.zip\", zipped_data_sample)\n\n### Read Data\n\nTo read data from the Object Store, you need to provide the key you used to store the object.\n\nYou can load the following types of objects from the Object Store:\n\nBytesobjectsstringobjectsJSON objectsXML-formatted objects\n\nYou can loadBytesandstringobjects from the Object Store.\n\nBefore you read data from the Object Store, check if the key exists.\n\nif (qb.ObjectStore.ContainsKey(key))\n{\n// Read data\n}if qb.object_store.contains_key(key):\n# Read data\n\nStrings\n\nTo read astringobject, call theReadreadorReadStringread_stringmethod.\n\nvar stringData = qb.ObjectStore.Read($\"{qb.ProjectId}/stringKey\");string_data = qb.object_store.read(f\"{qb.project_id}/string_key\")\n\nJSON\n\nTo read a JSON object, call theReadJson<T>method.\n\nvar jsonData = qb.ObjectStore.ReadJson<Dictionary<string, int>>($\"{qb.ProjectId}/jsonKey\");\n\nXML\n\nTo read an XML-formatted object, call theReadXml<T>method.\n\nvar xmlData = qb.ObjectStore.ReadXml<XElement>($\"{qb.ProjectId}/xmlKey\");\n\nIf you created the XML object from a dictionary, reconstruct the dictionary.\n\nvar dict = xmlData.Elements().ToDictionary(x => x.Name.LocalName, x => int.Parse(x.Value));\n\nBytes\n\nTo read aBytesobject, call theReadBytesread_bytesmethod.\n\nvar bytesData = qb.ObjectStore.ReadBytes($\"{qb.ProjectId}/bytesKey\");byte_data = qb.object_store.read_bytes(f\"{qb.project_id}/bytes_key\")\n\n### Delete Data\n\nDelete objects in the Object Store to remove objects that you no longer need. If you use the Research Environment in QuantConnect Cloud, you needstorage delete permissionsto delete data from the Object Store.\n\nTo delete objects from the Object Store, call theDeletedeletemethod. Before you delete data, check if the key exists. If you try to delete an object with a key that doesn't exist in the Object Store, the method raises an exception.\n\nif (qb.ObjectStore.ContainsKey(key))\n{\nqb.ObjectStore.Delete(key);\n}if qb.object_store.contains_key(key):\nqb.object_store.delete(key)\n\nTo delete all of the content in the Object Store, iterate through all the stored data.\n\nforeach (var kvp in qb.ObjectStore)\n{\nqb.ObjectStore.Delete(kvp.Key);\n}for kvp in qb.object_store:\nqb.object_store.delete(kvp.key)\n\n### Cache Data\n\nWhen you write to or read from the Object Store, the notebook caches the data. The cache speeds up the notebook execution because if you try to read the Object Store data again with the same key, it returns the cached data instead of downloading the data again. The cache speeds up execution, but it can cause problems if you are trying to share data between two nodes under the same Object Store key. For example, consider the following scenario:\n\nYou open project A and save data under the key123.You open project B and save new data under the same key123.In project A, you read the Object Store data under the key123, expecting the data from project B, but you get the original data you saved in step #1 instead.You get the data from step 1 instead of step 2 because the cache contains the data from step 1.\n\nTo clear the cache, call theClearmethod.\n\nqb.ObjectStore.Clear();qb.object_store.clear()\n\n### Get File Path\n\nTo get the file path for a specific key in the Object Store, call theGetFilePathget_file_pathmethod. If the key you pass to the method doesn't already exist in the Object Store, it's added to the Object Store.\n\nvar filePath = qb.ObjectStore.GetFilePath(key);file_path = qb.object_store.get_file_path(key)\n\n### Storage Quotas\n\nIf you use the Research Environment locally, you can store as much data as your hardware will allow. If you use the Research Environment in QuantConnect Cloud, you must stay within yourstorage quota. If you need more storage space,edit your storage plan.\n\n### Example for DataFrames\n\nFollow these steps to create a DataFrame, save it into the Object Store, and load it from the Object Store:\n\nGet some historical data.var spy = qb.AddEquity(\"SPY\").Symbol;\nvar history = qb.History(qb.Securities.Keys, 360, Resolution.Daily);spy = qb.add_equity(\"SPY\").symbol\ndf = qb.history(qb.securities.keys, 360, Resolution.DAILY)Create a DataFrame.using Microsoft.Data.Analysis; //\n\nvar columns = new DataFrameColumn[] {\nnew DateTimeDataFrameColumn(\"Time\", history.Select(x => (DateTime)x[spy].EndTime)),\nnew DecimalDataFrameColumn(\"SPY Open\", history.Select(x => (decimal)x[spy].Open)),\nnew DecimalDataFrameColumn(\"SPY High\", history.Select(x => (decimal)x[spy].High)),\nnew DecimalDataFrameColumn(\"SPY Low\", history.Select(x => (decimal)x[spy].Low)),\nnew DecimalDataFrameColumn(\"SPY Close\", history.Select(x => (decimal)x[spy].Close))\n};\nvar df = new DataFrame(columns);Get the file path for a specific key in the Object Store.var filePath = qb.ObjectStore.GetFilePath(\"df_to_csv\");file_path = qb.object_store.get_file_path(\"df_to_csv\")Call theSaveCsvto_csvmethod to save the DataFrame in the Object Store as a CSV file.DataFrame.SaveCsv(df, filePath);    // File size: 26520 bytesdf.to_csv(file_path)   # File size: 32721 bytesCall theLoadCsvread_csvmethod to load the CSV file from the Object Store.var reread = DataFrame.LoadCsv(filePath);reread = pd.read_csv(file_path)\n\npandassupports saving and loading DataFrame objects in the following additional formats:\n\nXMLfile_path = qb.object_store.get_file_path(\"df_to_xml\")\ndf.to_xml(file_path)   # File size: 87816 bytes\nreread = pd.read_xml(file_path)JSONfile_path = qb.object_store.get_file_path(\"df_to_json\")\ndf.to_json(file_path)   # File size: 125250 bytes\nreread = pd.read_json(file_path)Parquetfile_path = qb.object_store.get_file_path(\"df_to_parquet\")\ndf.to_parquet(file_path)   # File size: 23996 bytes\nreread = pd.read_parquet(file_path)Picklefile_path = qb.object_store.get_file_path(\"df_to_pickle\")\ndf.to_pickle(file_path)   # File size: 19868 bytes\nreread = pd.read_pickle(file_path)\n\n### Example for Plotting\n\nYou can use the Object Store to plot data from your backtests and live algorithm in the Research Environment. The following example demonstrates how to plot aSimple Moving Averageindicator that's generated during a backtest.\n\nCreate a algorithm, add a data subscription, and add a simple moving average indicator.public class ObjectStoreChartingAlgorithm : QCAlgorithm\n{\nprivate SimpleMovingAverage _sma;\nprivate string _content;\n\npublic override void Initialize()\n{\nAddEquity(\"SPY\", Resolution.Minute);\n_sma = SMA(\"SPY\", 22);\n}\n}class ObjectStoreChartingAlgorithm(QCAlgorithm):\ndef initialize(self):\nself.add_equity(\"SPY\")\n\nself.content = ''\nself._sma = self.sma(\"SPY\", 22)The algorithm will save_contentself.contentto the Object Store.Save the indicator data asstringin_contentself.content.public override void OnData(Slice data)\n{\n_content += $\"{_sma.Current.EndTime},{_sma}\\n\";\n}def on_data(self, data: Slice):\nself.plot('SMA', 'Value', self.sma.current.value)\nself.content += f'{self.sma.current.end_time},{self.sma.current.value}\\n'In theOnEndOfAlgorithmmethod, save the indicator data to the Object Store.public override void OnEndOfAlgorithm()\n{\nObjectStore.Save(\"sma_values_csharp\", _content);\n}def on_end_of_algorithm(self):\nself.object_store.save('sma_values_python', self.content)Open the Research Environmentand create aQuantBook.// Execute the following command in first\n#load \"../Initialize.csx\"\n\n// Create a QuantBook object\n#load \"../QuantConnect.csx\"\nusing QuantConnect;\nusing QuantConnect.Research;\n\nvar qb = new QuantBook();qb = QuantBook()Read the indicator data from the Object Store.var content = qb.ObjectStore.Read(\"sma_values_csharp\");content = qb.object_store.read(\"sma_values_python\")The key you provide must be the same key you used to save the object.Convert the data to a pandas object and create a chart.data = {}\nfor line in content.split('\\n'):\ncsv = line.split(',')\nif len(csv) > 1:\ndata[csv[0]] = float(csv[1])\n\nseries = pd.Series(data, index=data.keys())\nseries.plot()Import thePlotly.NETandPlotly.NET.LayoutObjectspackages.#r \"../Plotly.NET.dll\"\nusing Plotly.NET;\nusing Plotly.NET.LayoutObjects;Create theLayoutobject and set thetitle,xaxis, andyaxisproperties.var layout = new Layout();\nlayout.SetValue(\"title\", Title.init(\"SMA\"));\n\nvar xAxis = new LinearAxis();\nxAxis.SetValue(\"title\", \"Time\");\nlayout.SetValue(\"xaxis\", xAxis);\n\nvar yAxis = new LinearAxis();\nyAxis.SetValue(\"title\", \"SMA\");\nlayout.SetValue(\"yaxis\", yAxis);Convert the data to a list ofDateTimeobjects for the chart x-axis and a list ofdecimalobjects for the chart y-axis, then create aChart2D.Chart.Lineobject with the data.var index = new List<DateTimee>();\nvar values = new List<decimal>();\n\nforeach (var line in content.Split('\\n'))\n{\nvar csv = line.Split(',');\nif (csv.Length > 1)\n{\nindex.Add(Parse.DateTime(csv[0]));\nvalues.Add(decimal.Parse(csv[1]));\n}\n}\n\nvar chart = Chart2D.Chart.Linee<DateTime, decimal, stringe>(index, values);Apply the layout to theLineobject and create theHTMLobject.chart.WithLayout(layout);\nvar result = HTML(GenericChart.toChartHTML(chart));\n\npublic class ObjectStoreChartingAlgorithm : QCAlgorithm\n{\nprivate SimpleMovingAverage _sma;\nprivate string _content;\n\npublic override void Initialize()\n{\nSetStartDate(2023, 1, 1);   //Set Start Date\nSetCash(100000);            //Set Strategy Cash\n\nAddEquity(\"SPY\", Resolution.Minute);\n// Create SMA indicator for referencing.\n_sma = SMA(\"SPY\", 22);\n}\n\npublic override void OnData(Slice data)\n{\n// Cache the indicator data point to save it.\n_content += $\"{_sma.Current.EndTime},{_sma}\\n\";\n}\n\npublic override void OnEndOfAlgorithm()\n{\n// Save the indicator values to object store for logging.\nObjectStore.Save(\"sma_values_csharp\", _content);\n}\n}class ObjectStoreChartingAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\nself.set_start_date(2023, 1, 1)  # Set Start Date\nself.set_cash(100000)           # Set Strategy Cash\nself.add_equity(\"SPY\", Resolution.MINUTE)\n\nself.content = ''\n# Create SMA indicator for referencing.\nself.sma = self.SMA(\"SPY\", 22)\n\ndef on_data(self, data: Slice) -> None:\n# Cache the indicator data point to save it.\nself.content += f'{self.sma.current.end_time},{self.sma.current.value}\\n'\n\ndef on_end_of_algorithm(self) -> None:\n# Save the indicator values to object store for logging.\nself.object_store.save('sma_values_python', self.content)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Object Store",
      "section_number": "7",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8",
    "title": "Machine Learning",
    "level": 1,
    "path": "Machine Learning",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Machine Learning",
      "section_number": "8",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8.1",
    "title": "Key Concepts",
    "level": 2,
    "path": "Machine Learning > Key Concepts",
    "content": "### Introduction\n\nMachine learning is a field of study that combines statistics and computer science to build intelligent systems that predict outcomes. Quant researchers commonly use machine learning models to optimize portfolios, make trading signals, and manage risk. These models can find relationships in datasets that humans struggle to find, are subtle, or are too complex. You can use machine learning techniques in your research notebooks.\n\n### Supported Libraries\n\nThe following table shows the supported machine learning libraries:\n\n[Table - 9 rows]\n\n### Add New Libraries\n\nTo request a new library,contact us. We will add the library to the queue for review and deployment. Since the libraries run on our servers, we need to ensure they are secure and won't cause harm. The process of adding new libraries takes 2-4 weeks to complete. View the list of libraries currently under review on theIssues list of the Lean GitHub repository.\n\n### Transfer Models\n\nYou can load machine learning models from the Object Store or a custom data file like pickle. If you train a model in the Research Environment, you can alsosave it into the Object Storetotransfer itto the backtesting and live trading environment.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Machine Learning > Key Concepts",
      "section_number": "8.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Library | Research Tutorial | Documentation |\n| --- | --- | --- |\n| Keras | Tutorial | Documentation |\n| TensorFlow | Tutorial | Documentation |\n| Scikit-Learn | Tutorial | Documentation |\n| hmmlearn | Tutorial | Documentation |\n| gplearn | Tutorial | Documentation |\n| PyTorch | Tutorial | Documentation |\n| Stable Baselines | Tutorial | Documentation |\n| tslearn | Tutorial | Documentation |\n| XGBoost | Tutorial | Documentation |"
  },
  {
    "id": "8.2",
    "title": "Popular Libraries",
    "level": 2,
    "path": "Machine Learning > Popular Libraries",
    "content": "These are examples of using some of the most common machine learning libraries in an algorithm. Click one to learn more.AeseraGPlearnHmmlearnKerasPyTorchScikit-LearnStable BaselinesTensorFlowTslearnXGBoost",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Machine Learning > Popular Libraries",
      "section_number": "8.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.1",
    "title": "Aesera",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Aesera",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storeAeseramodels.\n\n### Import Libraries\n\nImport theaesera, andsklearnlibraries.\n\nimport aesara\nimport aesara.tensor as at\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport joblib\n\nYou need thejobliblibrary to store models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nObtain the close price and return direction series.close = history['close']\nreturns = data['close'].pct_change().shift(-1)[lookback*2-1:-1].reset_index(drop=True)\nlabels = pd.Series([1 if y > 0 else 0 for y in returns])   # binary classLoop through thecloseSeries and collect the features.lookback = 5\nlookback_series = []\nfor i in range(1, lookback + 1):\ndf = data['close'].shift(i)[lookback:-1]\ndf.name = f\"close-{i}\"\nlookback_series.append(df)\nX = pd.concat(lookback_series, axis=1)\n# Normalize using the 5 day interval\nX = MinMaxScaler().fit_transform(X.T).T[4:]Convert the lists of features and labels intonumpyarrays.X = np.array(features)\ny = np.array(labels)Split the data into training and testing periods.X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, build a Logistic Regression model with log loss cross entropy and square error as cost function. Follow these steps to create the model:\n\nGenerate a dataset.# D = (input_values, target_class)\nD = (np.array(X_train), np.array(y_train))Initialize variables.# Declare Aesara symbolic variables\nx = at.dmatrix(\"x\")\ny = at.dvector(\"y\")\n\n# initialize the weight vector w randomly using share so model coefficients keep their values\n# between training iterations (updates)\nrng = np.random.default_rng(100)\nw = aesara.shared(rng.standard_normal(X.shape[1]), name=\"w\")\n\n# initialize the bias term\nb = aesara.shared(0., name=\"b\")Construct the model graph.# Construct Aesara expression graph\np_1 = 1 / (1 + at.exp(-at.dot(x, w) - b))       # Logistic transformation\nprediction = p_1 > 0.5                          # The prediction thresholded\nxent = y * at.log(p_1) - (1 - y) * at.log(1 - p_1)  # Cross-entropy log-loss function\ncost = xent.mean() + 0.01 * (w ** 2).sum()      # The cost to minimize (MSE)\ngw, gb = at.grad(cost, [w, b])                  # Compute the gradient of the costCompile the model.train = aesara.function(\ninputs=[x, y],\noutputs=[prediction, xent],\nupdates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\npredict = aesara.function(inputs=[x], outputs=prediction)Train the model with training dataset.pred, err = train(D[0], D[1])\n\n# We can also inspect the final outcome\nprint(\"Final model:\")\nprint(w.get_value())\nprint(b.get_value())\nprint(\"target values for D:\")\nprint(D[1])\nprint(\"prediction on D:\")\nprint(predict(D[0]))    # whether > 0.5 or not\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nCall thepredictmethod with the features of the testing period.y_hat = predict(np.array(X_test))Plot the actual and predicted labels of the testing period.df = pd.DataFrame({'y': y_test, 'y_hat': y_hat}).astype(int)\ndf.plot(title='Model Performance: predicted vs actual return direction in closing price', figsize=(12, 5))Calculate the prediction accuracy.correct = sum([1 if x==y else 0 for x, y in zip(y_test, y_hat)])\nprint(f\"Accuracy: {correct}/{y_test.shape[0]} ({correct/y_test.shape[0]}%)\")\n\n### Store Models\n\nYou can save and loadaeseramodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thedumpmethod with the model and file path.joblib.dump(predict, file_name)If you dump the model using thejoblibmodule before you save the model, you don't need to retrain the model.\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod with the model key.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.CallGetFilePathwith the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Callloadwith the file path.loaded_model = joblib.load(file_name)This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using the Aesera library.\n\nExample 1: Predict Return Direction\n\nThe following research notebook usesAeseramachine learning model to predict the next day's return direction by the previous 5 days' close price differences.\n\n# Import the Aesera library and others.\nimport aesara\nimport aesara.tensor as at\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# We use the close price series to generate the features to be studied.\nclose = history['close']\n# Get the 1-day forward return direction as the labels for the machine to learn.\nreturns = data['close'].pct_change().shift(-1)[lookback*2-1:-1].reset_index(drop=True)\nlabels = pd.Series([1 if y > 0 else 0 for y in returns])   # binary class\n\n# Use 1- to 5-day differences as the input features for the machine to learn.\nlookback = 5\nlookback_series = []\nfor i in range(1, lookback + 1):\ndf = data['close'].shift(i)[lookback:-1]\ndf.name = f\"close-{i}\"\nlookback_series.append(df)\nX = pd.concat(lookback_series, axis=1)\n# Normalize using the 5 day interval\nX = MinMaxScaler().fit_transform(X.T).T[4:]\n\n# Split the data as a training set and test set for validation.\nX = np.array(features)\ny = np.array(labels)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Create a dataset.\nD = (np.array(X_train), np.array(y_train))\n\n# Declare Aesara symbolic variables.\nx = at.dmatrix(\"x\")\ny = at.dvector(\"y\")\n\n# Initialize the weight vector w randomly using share so model coefficients keep their values\n# between training iterations (updates).\nrng = np.random.default_rng(100)\nw = aesara.shared(rng.standard_normal(X.shape[1]), name=\"w\")\n\n# initialize the bias term.\nb = aesara.shared(0., name=\"b\")\n\n# Construct an Aesara expression graph.\np_1 = 1 / (1 + at.exp(-at.dot(x, w) - b))       # Logistic transformation\nprediction = p_1 > 0.5                          # The prediction thresholded\nxent = y * at.log(p_1) - (1 - y) * at.log(1 - p_1)  # Cross-entropy log-loss function\ncost = xent.mean() + 0.01 * (w ** 2).sum()      # The cost to minimize (MSE)\ngw, gb = at.grad(cost, [w, b])                  # Compute the gradient of the cost\n\n# Compile the model. In this example, we set the step size as 0.1 times gradients.\ntrain = aesara.function(\ninputs=[x, y],\noutputs=[prediction, xent],\nupdates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\npredict = aesara.function(inputs=[x], outputs=prediction)\n\n# Train the model with the training dataset.\npred, err = train(D[0], D[1])\n\n# We can also inspect the final outcome\nprint(\"Final model:\")\nprint(w.get_value())\nprint(b.get_value())\nprint(\"target values for D:\")\nprint(D[1])\nprint(\"prediction on D:\")\nprint(predict(D[0]))    # whether > 0.5 or not\n\n# Predict the label of the testing set data.\ny_hat = predict(np.array(X_test))\n\n# Plot and calculate the accuracy of the predicted testing set labels.\ndf = pd.DataFrame({'y': y_test, 'y_hat': y_hat}).astype(int)\ndf.plot(title='Model Performance: predicted vs actual return direction in closing price', figsize=(12, 5))\ncorrect = sum([1 if x==y else 0 for x, y in zip(y_test, y_hat)])\nprint(f\"Accuracy: {correct}/{y_test.shape[0]} ({correct/y_test.shape[0]}%)\")\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\njoblib.dump(predict, file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Aesera",
      "section_number": "8.2.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | Normalized close price of the SPY over the last 5 days |\n| Labels | Return direction of the SPY over the next day |"
  },
  {
    "id": "8.2.2",
    "title": "GPlearn",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > GPlearn",
    "content": "### Introduction\n\nThis page introduces how to build, train, test, and storeGPlearnmodels.\n\n### Import Libraries\n\nImport theGPlearnlibrary.\n\nfrom gplearn.genetic import SymbolicRegressor, SymbolicTransformer\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\nYou need thesklearnlibrary to prepare the data and thejobliblibrary to store models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nCall thepct_changemethod and then drop the first row.daily_returns = history['close'].pct_change()[1:]Loop through thedaily_returnsDataFrame and collect the features and labels.n_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(daily_returns)-n_steps):\nfeatures.append(daily_returns.iloc[i:i+n_steps].values)\nlabels.append(daily_returns.iloc[i+n_steps])Convert the lists of features and labels intonumpyarrays.X = np.array(features)\ny = np.array(labels)Split the data into training and testing periods.X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, create a Symbolic Transformer to generate new non-linear features and then build a Symbolic Regressor model. Follow these steps to create the model:\n\nDeclare a set of functions to use for feature engineering.function_set = ['add', 'sub', 'mul', 'div',\n'sqrt', 'log', 'abs', 'neg', 'inv',\n'max', 'min']Call theSymbolicTransformerconstructor with the preceding set of functions.gp_transformer = SymbolicTransformer(function_set=function_set,\nrandom_state=0,\nverbose=1)Call thefitmethod with the training features and labels.gp_transformer.fit(X_train, y_train)This method displays the following output:Call thetransformmethod with the original features.gp_features_train = gp_transformer.transform(X_train)Call thehstackmethod with the original features and the transformed features.new_X_train = np.hstack((X_train, gp_features_train))Call theSymbolicRegressorconstructor.gp_regressor = SymbolicRegressor(random_state=0, verbose=1)Call thefitmethod with the engineered features and the original labels.gp_regressor.fit(new_X_train, y_train)\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nFeature engineer the testing set data.gp_features_test = gp_transformer.transform(X_test)\nnew_X_test = np.hstack((X_test, gp_features_test))Call thepredictmethod with the engineered testing set data.y_predict = gp_regressor.predict(new_X_test)Plot the actual and predicted labels of the testing period.df = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual closing price', figsize=(15, 10))\nplt.show()Calculate the R-square value.r2 = gp_regressor.score(new_X_test, y_test)\nprint(f\"The explained variance of the GP model: {r2*100:.2f}%\")\n\n### Store Models\n\nYou can save and loadGPlearnmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key names of the models to be stored in the Object Store.transformer_key = \"transformer\"\nregressor_key = \"regressor\"Call theGetFilePathget_file_pathmethod with the key names.transformer_file = qb.object_store.get_file_path(transformer_key)\nregressor_file = qb.object_store.get_file_path(regressor_key)This method returns the file paths where the models will be stored.Call thedumpmethod with the models and file paths.joblib.dump(gp_transformer, transformer_file)\njoblib.dump(gp_regressor, regressor_file)If you dump the model using thejoblibmodule before you save the model, you don't need to retrain the model.\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(transformer_key)\nqb.object_store.contains_key(regressor_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the keys.transformer_file = qb.object_store.get_file_path(transformer_key)\nregressor_file = qb.object_store.get_file_path(regressor_key)This method returns the path where the model is stored.Call theloadmethod with the file paths.loaded_transformer = joblib.load(transformer_file)\nloaded_regressor = joblib.load(regressor_file)This method returns the saved models.\n\n### Examples\n\nThe following examples demonstrate some common practices for using theGPLearnlibrary.\n\nExample 1: Predict Next Return\n\nThe following research notebook usesGPLearnmachine learning model to predict the next day's return direction by the previous 5 days' daily returns.\n\n# Import the GPLearn library and others.\nfrom gplearn.genetic import SymbolicRegressor, SymbolicTransformer\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Obtain the daily returns to be the features and labels.\ndaily_returns = history['close'].pct_change()[1:]\n# We use the previous 5 day returns as the features to be studied.\n# Get the 1-day forward return as the labels for the machine to learn.\nn_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(daily_returns)-n_steps):\nfeatures.append(daily_returns.iloc[i:i+n_steps].values)\nlabels.append(daily_returns.iloc[i+n_steps])\n\n# Split the data as a training set and test set for validation.\nX = np.array(features)\ny = np.array(labels)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Declare a set of functions to use for feature engineering.\nfunction_set = ['add', 'sub', 'mul', 'div',\n'sqrt', 'log', 'abs', 'neg', 'inv',\n'max', 'min']\n# Call the SymbolicTransformer constructor with the preceding set of functions.\ngp_transformer = SymbolicTransformer(function_set=function_set,\nrandom_state=0,\nverbose=1)\n# Call the fit method with the training features and labels to obtain the set of significant features.\ngp_transformer.fit(X_train, y_train)\n# Call the transform method to transform the original features.\ngp_features_train = gp_transformer.transform(X_train)\n# Call the hstack method with the original features and the transformed features to stack them.\nnew_X_train = np.hstack((X_train, gp_features_train))\n\n# Call the SymbolicRegressor constructor for the non-linear regression fitting.\ngp_regressor = SymbolicRegressor(random_state=0, verbose=1)\n# Call the fit method with the engineered features and the original labels to fit a non-linear model.\ngp_regressor.fit(new_X_train, y_train)\n\n# Feature engineer the testing set data to test with.\ngp_features_test = gp_transformer.transform(X_test)\nnew_X_test = np.hstack((X_test, gp_features_test))\n# Call the predict method with the engineered testing set data to get the prediction from the GPLearn model.\ny_predict = gp_regressor.predict(new_X_test)\n\n# Plot the actual and predicted labels of the testing period.\ndf = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual closing price', figsize=(15, 10))\nplt.show()\n\n# Calculate the R-square value to evaluate the model fitness.\nr2 = gp_regressor.score(new_X_test, y_test)\nprint(f\"The explained variance of the GP model: {r2*100:.2f}%\")\n\n# Predict the label of the testing set data.\ny_hat = predict(np.array(X_test))\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\ntransformer_key = \"transformer\"\nregressor_key = \"regressor\"\ntransformer_file = qb.object_store.get_file_path(transformer_key)\nregressor_file = qb.object_store.get_file_path(regressor_key)\njoblib.dump(gp_transformer, transformer_file)\njoblib.dump(gp_regressor, regressor_file)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > GPlearn",
      "section_number": "8.2.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | Daily percent change of the open, high, low, close, and volume of the SPY over the last 5 days |\n| Labels | Daily percent return of the SPY over the next day |"
  },
  {
    "id": "8.2.3",
    "title": "Hmmlearn",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Hmmlearn",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storeHmmlearnmodels.\n\n### Import Libraries\n\nImport theHmmlearnlibrary.\n\nfrom hmmlearn import hmm\nimport joblib\n\nYou need thejobliblibrary to store models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. Follow these steps to prepare the data:\n\nSelect the close column of the historical data DataFrame.closes = history['close']Call thepct_changemethod and then drop the first row.daily_returns = closes.pct_change().iloc[1:]Call thereshapemethod.X = daily_returns.values.reshape(-1, 1)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, assume the market has only 2 regimes and the market returns follow a Gaussian distribution. Therefore, create a 2-component Hidden Markov Model with Gaussian emissions, which is equivalent to a Gaussian mixture model with 2 means. Follow these steps to create the model:\n\nCall theGaussianHMMconstructor with the number of components, a covariance type, and the number of iterations.model = hmm.GaussianHMM(n_components=2, covariance_type=\"full\", n_iter=100)Call thefitmethod with the training data.model.fit(X)\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nCall the predict method with the testing dataset.y = model.predict(X)Plot the regimes in a scatter plot.plt.figure(figsize=(15, 10))\nplt.scatter(ret.index, [f'Regime {n+1}' for n in y])\nplt.title(f'{symbol} market regime')\nplt.xlabel(\"time\")\nplt.show()\n\n### Store Models\n\nYou can save and loadHmmlearnmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thedumpmethod with the model and file path.joblib.dump(model, file_name)If you dump the model using thejoblibmodule before you save the model, you don't need to retrain the model.\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Call theloadmethod with the file path.loaded_model = joblib.load(file_name)This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using theHmmlearnlibrary.\n\nExample 1: Regime Detection\n\nThe following research notebook usesHmmlearnmachine learning model to obtain the current market regime and predict the conditional probabilities of each market state that the current regime would turn into by a Hidden Markov Model (HMM).\n\n# Import the Hmmlearn library and others.\nfrom hmmlearn import hmm\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Obtain the daily returns to be analyzed.\ndaily_returns = history['close'].pct_change()[1:]\nX = daily_returns.values.reshape(-1, 1)\n\n# Call the GaussianHMM constructor with the number of components, a covariance type, and the number of iterations to create the hidden markov model.\nmodel = hmm.GaussianHMM(n_components=2, covariance_type=\"full\", n_iter=100)\n# Call the fit method with the training data to fit the model.\nmodel.fit(X)\n\n# Call the predict method with the testing dataset to get the prediction from the model.\ny = model.predict(X)\n\n# Plot the regimes in a scatter plot.\nplt.figure(figsize=(15, 10))\nplt.scatter(ret.index, [f'Regime {n+1}' for n in y])\nplt.title(f'{symbol} market regime')\nplt.xlabel(\"time\")\nplt.show()\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\njoblib.dump(model, file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Hmmlearn",
      "section_number": "8.2.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.4",
    "title": "Keras",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Keras",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storekerasmodels.\n\n### Import Libraries\n\nImport thekeraslibraries.\n\nfrom tensorflow.keras import utils, models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.saving import load_model\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nCall thepct_changeanddropnamethods.daily_pct_change = history.pct_change().dropna()Loop through thedaily_pct_changeDataFrame and collect the features and labels.n_steps = 5features = []\nlabels = []\nfor i in range(len(daily_pct_change)-n_steps):\nfeatures.append(daily_pct_change.iloc[i:i+n_steps].values)\nlabels.append(daily_pct_change['close'].iloc[i+n_steps])Convert the lists of features and labels intonumpyarrays.features = np.array(features)\nlabels = np.array(labels)Split the data into training and testing periods.train_length = int(len(features) * 0.7)\nX_train = features[:train_length]\nX_test = features[train_length:]\ny_train = labels[:train_length]\ny_test = labels[train_length:]\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, build a neural network model that predicts the future return of the SPY. Follow these steps to create the model:\n\nCall theSequentialconstructor with a list of layers.model = Sequential([Dense(10, input_shape=(5,5), activation='relu'),\nDense(10, activation='relu'),\nFlatten(),\nDense(1)])Set theinput_shapeof the first layer to(5, 5)because each sample contains the percent change of 5 factors (percent change of the open, high, low, close, and volume) over the previous 5 days. Call theFlattenconstructor because the input is 2-dimensional but the output is just a single value.Call thecompilemethod with a loss function, an optimizer, and a list of metrics to monitor.model.compile(loss='mse',\noptimizer=RMSprop(0.001),\nmetrics=['mae', 'mse'])Call thefitmethod with the features and labels of the training dataset and a number of epochs.model.fit(X_train, y_train, epochs=5)\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nCall thepredictmethod with the features of the testing period.y_hat = model.predict(X_test)Plot the actual and predicted labels of the testing period.results = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\nresults.plot(title='Model Performance: predicted vs actual %change in closing price')\n\n### Store Models\n\nYou can save and loadkerasmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.The key must end with a.kerasextension for the native Keras format (recommended) or a.h5extension.model_key = \"model.keras\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thesavemethod the file path.model.save(file_name)\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod with the model key.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the key name.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Call theload_modelmethod with the file path.loaded_model = load_model(file_name)This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using the Keras library.\n\nExample 1: Predict Next Return\n\nThe following research notebook usesKerasmachine learning model to predict the next day's return by the previous 5 days' daily returns.\n\n# Import the Keras library.\nfrom tensorflow.keras import utils, models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.saving import load_model\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Obtain the daily returns to be the features and labels.\ndaily_returns = history['close'].pct_change()[1:]\n# We use the previous 5 day returns as the features to be studied.\n# Get the 1-day forward return as the labels for the machine to learn.\nn_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(daily_returns)-n_steps):\nfeatures.append(daily_returns.iloc[i:i+n_steps].values)\nlabels.append(daily_returns.iloc[i+n_steps])\n\n# Split the data as a training set and test set for validation. In this example, we use 70% of the data points to train the model and test with the rest.\nfeatures = np.array(features)\nlabels = np.array(labels)\ntrain_length = int(len(features) * 0.7)\nX_train = features[:train_length]\nX_test = features[train_length:]\ny_train = labels[:train_length]\ny_test = labels[train_length:]\n\n# Call the Sequential constructor with a list of layers to create the model.\nmodel = Sequential([Dense(10, input_shape=(5,5), activation='relu'),\nDense(10, activation='relu'),\nFlatten(),\nDense(1)])\n# Call the compile method with a loss function, an optimizer, and a list of metrics to monitor to set how should the model be fitted.\nmodel.compile(loss='mse',\noptimizer=RMSprop(0.001),\nmetrics=['mae', 'mse'])\n# Call the fit method with the features and labels of the training dataset and a number of epochs to fit the model.\nmodel.fit(X_train, y_train, epochs=5)\n\n# Call the predict method with the features of the testing period.\ny_hat = model.predict(X_test)\n# Plot the actual and predicted labels of the testing period.\nresults = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\nresults.plot(title='Model Performance: predicted vs actual %change in closing price')\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model.keras\"\nfile_name = qb.object_store.get_file_path(model_key)\nmodel.save(file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Keras",
      "section_number": "8.2.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | Daily percent change of the open, high, low, close, and volume of the SPY over the last 5 days |\n| Labels | Daily percent return of the SPY over the next day |"
  },
  {
    "id": "8.2.5",
    "title": "PyTorch",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > PyTorch",
    "content": "### Introduction\n\nThis page explains how how to build, train, test, and storePyTorchmodels.\n\n### Import Libraries\n\nImport thetorch,sklearn, andjobliblibraries by the following:\n\nimport torch\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\nYou need thesklearnlibrary to prepare the data and thejobliblibrary to store models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nPerform fractional differencing on the historical data.df = (history['close'] * 0.5 + history['close'].diff() * 0.5)[1:]Fractional differencing helps make the data stationary yet retains the variance information.Loop through thedfDataFrame and collect the features and labels.n_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(df)-n_steps):\nfeatures.append(df.iloc[i:i+n_steps].values)\nlabels.append(df.iloc[i+n_steps])Convert the lists of features and labels intonumpyarrays.features = np.array(features)\nlabels = np.array(labels)Standardize the features and labelsX = (features - features.mean()) / features.std()\ny = (labels - labels.mean()) / labels.std()Split the data into training and testing periods.X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, create a deep neural network with 2 hidden layers. Follow these steps to create the model:\n\nDefine a subclass ofnn.Moduleto be the model.In this example, use the ReLU activation function for each layer.class NeuralNetwork(nn.Module):\n# Model Structure\ndef __init__(self):\nsuper(NeuralNetwork, self).__init__()\nself.flatten = nn.Flatten()\nself.linear_relu_stack = nn.Sequential(\nnn.Linear(5, 5),   # input size, output size of the layer\nnn.ReLU(),         # Relu non-linear transformation\nnn.Linear(5, 5),\nnn.ReLU(),\nnn.Linear(5, 1),   # Output size = 1 for regression\n)\n\n# Feed-forward training/prediction\ndef forward(self, x):\nx = torch.from_numpy(x).float()   # Convert to tensor in type float\nresult = self.linear_relu_stack(x)\nreturn resultCreate an instance of the model and set its configuration to train on the GPU if it's available.device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = NeuralNetwork().to(device)Set the loss and optimization functions.In this example, use the mean squared error as the loss function and stochastic gradient descent as the optimizer.loss_fn = nn.MSELoss()\nlearning_rate = 0.001\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)Train the model.In this example, train the model through 5 epochs.epochs = 5\nfor t in range(epochs):\nprint(f\"Epoch {t+1}\\n-------------------------------\")\n\n# Since we're using SGD, we'll be using the size of data as batch number.\nfor batch, (X, y) in enumerate(zip(X_train, y_train)):\n# Compute prediction and loss\npred = model(X)\nreal = torch.from_numpy(np.array(y).flatten()).float()\nloss = loss_fn(pred, real)\n\n# Backpropagation\noptimizer.zero_grad()\nloss.backward()\noptimizer.step()\n\nif batch % 100 == 0:\nloss, current = loss.item(), batch\nprint(f\"loss: {loss:.5f}  [{current:5d}/{len(X_train):5d}]\")\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nPredict with the testing data.predict = model(X_test)\ny_predict = predict.detach().numpy()   # Convert tensor to numpy ndarrayPlot the actual and predicted values of the testing period.df = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual standardized fractional return', figsize=(15, 10))\nplt.show()Calculate the R-square value.r2 = 1 - np.sum(np.square(y_test.flatten() - y_predict.flatten())) / np.sum(np.square(y_test.flatten() - y_test.mean()))\nprint(f\"The explained variance by the model (r-square): {r2*100:.2f}%\")\n\n### Store Models\n\nYou can save and loadPyTorchmodels using the Object Store.\n\nSave Models\n\nDon't use thetorch.savemethod to save models because the tensor data will be lost and corrupt the save. Follow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thedumpmethod with the model and file path.joblib.dump(model, file_name)If you dump the model using thejoblibmodule before you save the model, you don't need to retrain the model.\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Call theloadmethod with the file path.loaded_model = joblib.load(file_name)This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using the Pytorch library.\n\nExample 1: Predict Next Return\n\nThe following research notebook usesPytorchmachine learning model to predict the next day's return by the previous 5 days' daily fractional differencing.\n\n# Import the Pytorch library and others.\nimport torch\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Perform fractional differencing on the historical data.\ndf = (history['close'] * 0.5 + history['close'].diff() * 0.5)[1:]\n# We use the previous 5 day fractional differencing as the features to be studied.\n# Get the 1-day forward differencing as the labels for the machine to learn.\nn_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(df)-n_steps):\nfeatures.append(df.iloc[i:i+n_steps].values)\nlabels.append(df.iloc[i+n_steps])\n\n# Clean the data and normalize for fast convergence.\nfeatures = np.array(features)\nlabels = np.array(labels)\nX = (features - features.mean()) / features.std()\ny = (labels - labels.mean()) / labels.std()\n\n# Split the data as a training set and test set for validation. In this example, we use 70% of the data points to train the model and test with the rest.\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Define a subclass of nn.Module to be the model. In this example, use the ReLU activation function for each layer.\nclass NeuralNetwork(nn.Module):\n# Model Structure\ndef __init__(self):\nsuper(NeuralNetwork, self).__init__()\nself.flatten = nn.Flatten()\nself.linear_relu_stack = nn.Sequential(\nnn.Linear(5, 5),   # input size, output size of the layer\nnn.ReLU(),         # Relu non-linear transformation\nnn.Linear(5, 5),\nnn.ReLU(),\nnn.Linear(5, 1),   # Output size = 1 for regression\n)\n\n# Feed-forward training/prediction\ndef forward(self, x):\nx = torch.from_numpy(x).float()   # Convert to tensor in type float\nresult = self.linear_relu_stack(x)\nreturn result\n# Create an instance of the model and set its configuration to train on the GPU if it's available.\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = NeuralNetwork().to(device)\n# Set the loss and optimization functions. In this example, use the mean squared error as the loss function and stochastic gradient descent as the optimizer.\nloss_fn = nn.MSELoss()\nlearning_rate = 0.001\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# Train the model. In this example, train the model through 5 epochs.\nepochs = 5\nfor t in range(epochs):\nprint(f\"Epoch {t+1}\\n-------------------------------\")\n\n# Since we're using SGD, we'll be using the size of data as batch number.\nfor batch, (X, y) in enumerate(zip(X_train, y_train)):\n# Compute prediction and loss\npred = model(X)\nreal = torch.from_numpy(np.array(y).flatten()).float()\nloss = loss_fn(pred, real)\n\n# Backpropagation\noptimizer.zero_grad()\nloss.backward()\noptimizer.step()\n\nif batch % 100 == 0:\nloss, current = loss.item(), batch\nprint(f\"loss: {loss:.5f}  [{current:5d}/{len(X_train):5d}]\")\n\n# Predict with the testing data.\npredict = model(X_test)\ny_predict = predict.detach().numpy()   # Convert tensor to numpy ndarray\n# Plot the actual and predicted labels of the testing period.\ndf = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual standardized fractional return', figsize=(15, 10))\nplt.show()\n# Calculate the R-square value.\nr2 = 1 - np.sum(np.square(y_test.flatten() - y_predict.flatten())) / np.sum(np.square(y_test.flatten() - y_test.mean()))\nprint(f\"The explained variance by the model (r-square): {r2*100:.2f}%\")\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\njoblib.dump(model, file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > PyTorch",
      "section_number": "8.2.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | The last 5 closing prices |\n| Labels | The following day's closing price |"
  },
  {
    "id": "8.2.6",
    "title": "Scikit-Learn",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Scikit-Learn",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storeScikit-Learn/sklearnmodels.\n\n### Import Libraries\n\nImport thesklearnlibraries.\n\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\nYou need thejobliblibrary to store models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nCall thepct_changemethod and then drop the first row.daily_returns = history['close'].pct_change()[1:]Loop through thedaily_returnsDataFrame and collect the features and labels.n_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(daily_returns)-n_steps):\nfeatures.append(daily_returns.iloc[i:i+n_steps].values)\nlabels.append(daily_returns.iloc[i+n_steps])Convert the lists of features and labels intonumpyarrays.X = np.array(features)\ny = np.array(labels)Split the data into training and testing periods.X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, build a Support Vector Regressor model and optimize its hyperparameters with grid search cross-validation. Follow these steps to create the model:\n\nSet the choices of hyperparameters used for grid search testing.param_grid = {'C': [.05, .1, .5, 1, 5, 10],\n'epsilon': [0.001, 0.005, 0.01, 0.05, 0.1],\n'gamma': ['auto', 'scale']}Call theGridSearchCVconstructor with the SVR model, the parameter grid, a scoring method, the number of cross-validation folds.gsc = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', cv=5)Call thefitmethod and then select the best estimator.model = gsc.fit(X_train, y_train).best_estimator_\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nCall thepredictmethod with the features of the testing period.y_hat = model.predict(X_test)Plot the actual and predicted labels of the testing period.df = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\ndf.plot(title='Model Performance: predicted vs actual %change in closing price', figsize=(15, 10))\n\n### Store Models\n\nYou can save and loadsklearnmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thedumpmethod with the model and file path.joblib.dump(model, file_name)If you dump the model using thejoblibmodule before you save the model, you don't need to retrain the model.\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod with the model key.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.CallGetFilePathwith the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Callloadwith the file path.loaded_model = joblib.load(file_name)This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using the sklearn library.\n\nExample 1: Predict Next Return\n\nThe following research notebook usessklearnmachine learning model to predict the next day's return by the previous 5 days' daily returns.\n\n# Import the sklearn library and others.\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Obtain the daily returns to be the features and labels.\ndaily_returns = history['close'].pct_change()[1:]\n# We use the previous 5 day returns as the features to be studied.\n# Get the 1-day forward return as the labels for the machine to learn.\nn_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(daily_returns)-n_steps):\nfeatures.append(daily_returns.iloc[i:i+n_steps].values)\nlabels.append(daily_returns.iloc[i+n_steps])\n\n# Split the data as a training set and test set for validation.\nfeatures = np.array(features)\nlabels = np.array(labels)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Set the choices of hyperparameters used for grid search testing.\nparam_grid = {'C': [.05, .1, .5, 1, 5, 10],\n'epsilon': [0.001, 0.005, 0.01, 0.05, 0.1],\n'gamma': ['auto', 'scale']}\n# Call the GridSearchCV constructor with the SVR model, the parameter grid, a scoring method, the number of cross-validation folds.\ngsc = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', cv=5)\n# Call the fit method and then select the best estimator.\nmodel = gsc.fit(X_train, y_train).best_estimator_\n\n# Call the predict method with the features of the testing period.\ny_hat = model.predict(X_test)\n# Plot the actual and predicted labels of the testing period.\ndf = pd.DataFrame({'y': y_test.flatten(), 'y_hat': y_hat.flatten()})\ndf.plot(title='Model Performance: predicted vs actual %change in closing price', figsize=(15, 10))\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\njoblib.dump(model, file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Scikit-Learn",
      "section_number": "8.2.6",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | Daily percent change of the open, high, low, close, and volume of the SPY over the last 5 days |\n| Labels | Daily percent return of the SPY over the next day |"
  },
  {
    "id": "8.2.7",
    "title": "Stable Baselines",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Stable Baselines",
    "content": "### Introduction\n\nThis page introduces how to usestable baselineslibrary in Python for reinforcement machine learning (RL) model building, training, saving in the Object Store, and loading, through an example of a Proximal Policy Optimization (PPO) portfolio optimization trading bot.\n\n### Import Libraries\n\nImport thestable_baselinesandgymlibraries.\n\nimport gym\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the different asset class ETFs during 2010 and 2023, run:\n\nqb = QuantBook()\nsymbols = [\nqb.add_equity(\"SPY\", Resolution.DAILY).symbol,\nqb.add_equity(\"GLD\", Resolution.DAILY).symbol,\nqb.add_equity(\"TLT\", Resolution.DAILY).symbol,\nqb.add_equity(\"USO\", Resolution.DAILY).symbol,\nqb.add_equity(\"UUP\", Resolution.DAILY).symbol\n]\ndf = qb.history(symbols, datetime(2010, 1, 1), datetime(2024, 1, 1))\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model.\nIf you have historical data, manipulate it to train and test the model.\nIn this example, extract the close price series as the outcome and obtain the partial-differenced time-series of OHLCV values as the observation.\n\nhistory = df.unstack(0)\n# we arbitrarily select weight 0.5 here, but ideally one should strike a balance between variance retained and stationarity.\npartial_diff = (history.diff() * 0.5 + history * 0.5).iloc[1:].fillna(0)\nhistory = history.close.iloc[1:]\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the environment and the model. In this example, create agymenvironment to initialize the training environment, agent and reward. Then, create a RL model by DQN algorithm. Follow these steps to create the environment and the model:\n\nSplit the data for training and testing to evaluate our model.X_train = partial_diff.iloc[:-100].values\nX_test = partial_diff.iloc[-100:].values\ny_train = history.iloc[:-100].values\ny_test = history.iloc[-100:].valuesCreate a customgymenvironment class.In this example, create a custom environment with previous 5 OHLCV partial-differenced price data as the observation and the lowest maximum drawdown as the reward.class PortfolioEnv(gym.Env):\ndef __init__(self, data, prediction, num_stocks):\nsuper(PortfolioEnv, self).__init__()\n\nself.data = data\nself.prediction = prediction\nself.num_stocks = num_stocks\n\nself.current_step = 5\nself.portfolio_value = []\nself.portfolio_weights = np.ones(num_stocks) / num_stocks\n\n# Define your action and observation spaces\nself.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(num_stocks, ), dtype=np.float32)\nself.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(5, data.shape[1]))\n\ndef reset(self):\nself.current_step = 5\nself.portfolio_value = []\nself.portfolio_weights = np.ones(self.num_stocks) / self.num_stocks\n\nreturn self._get_observation()\n\ndef step(self, action):\n# Normalize the portfolio weights\nsum_weights = np.sum(np.abs(action))\nif sum_weights > 1:\naction /= sum_weights\n\n# deduct transaction fee\nvalue = self.prediction[self.current_step]\nfees = np.abs(self.portfolio_weights - action) @ value\n\n# Update portfolio weights based on the chosen action\nself.portfolio_weights = action\n\n# Update portfolio value based on the new weights and the market prices less fee\nself.portfolio_value.append(np.dot(self.portfolio_weights, value) - fees)\n\n# Move to the next time step\nself.current_step += 1\n\n# Check if the episode is done (end of data)\ndone = self.current_step >= len(self.data) - 1\n\n# Calculate the reward, in here, we use max drawdown\nreward = self._neg_max_drawdown\n\nreturn self._get_observation(), reward, done, {}\n\ndef _get_observation(self):\n# Return the last 5 partial differencing OHLCV as the observation\nreturn self.data[self.current_step-5:self.current_step]\n\n@property\ndef _neg_max_drawdown(self):\n# Return max drawdown within 20 days in portfolio value as reward (negate since max reward is preferred)\nportfolio_value_20d = np.array(self.portfolio_value[-min(len(self.portfolio_value), 20):])\nacc_max = np.maximum.accumulate(portfolio_value_20d)\nreturn -(portfolio_value_20d - acc_max).min()\n\ndef render(self, mode='human'):\n# Implement rendering if needed\npassInitialize the environment.# Initialize the environment\nenv = PortfolioEnv(X_train, y_train, 5)\n\n# Wrap the environment in a vectorized environment\nenv = DummyVecEnv([lambda: env])\n\n# Normalize the observation space\nenv = VecNormalize(env, norm_obs=True, norm_reward=False)Train the model.In this example, create a RL model and train with MLP-policy PPO algorithm.# Define the PPO agent\nmodel = PPO(\"MlpPolicy\", env, verbose=0)\n\n# Train the agent\nmodel.learn(total_timesteps=100000)\n\n### Test Models\n\nYou need tobuild and train the modelbefore you test its performance. If you have trained the model, test it on the out-of-sample data. Follow these steps to test the model:\n\nInitialize a return series to calculate performance and a list to store the equity value at each timestep.test = np.log(y_test[1:]/y_test[:-1])\nequity = [1]Iterate each testing data point for prediction and trading.for i in range(5, X_test.shape[0]-1):\naction, _ = model.predict(X_test[i-5:i], deterministic=True)\nsum_weights = np.sum(np.abs(action))\nif sum_weights > 1:\naction /= sum_weights\nvalue = test[i] @ action.T\n\nequity.append((1+value) * equity[i-5])Plot the result.plt.figure(figsize=(15, 10))\nplt.title(\"Equity Curve\")\nplt.xlabel(\"timestep\")\nplt.ylabel(\"equity\")\nplt.plot(equity)\nplt.show()\n\n### Store Models\n\nYou can save and loadstable baselinesmodels using the Object Store.\n\nSave Models\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thesavemethod with the file path.model.save(file_name)\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Call theloadmethod with the file path, environment and policy.loaded_model = PPO.load(file_name, env=env, policy=\"MlpPolicy\")This method returns the saved model.\n\n### Examples\n\nThe following examples demonstrate some common practices for using the Stable Baselines library.\n\nExample 1: Machine Trading\n\nThe following research notebook usesStable Baselinesmachine learning model to make trading decision, based on the previous 5 OHLCV partial differencing as observation.\n\n# Import the gym and stable_baselines3 library.\nimport gym\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily history with the date range to be studied.\nsymbols = [\nqb.add_equity(\"SPY\", Resolution.DAILY).symbol,\nqb.add_equity(\"GLD\", Resolution.DAILY).symbol,\nqb.add_equity(\"TLT\", Resolution.DAILY).symbol,\nqb.add_equity(\"USO\", Resolution.DAILY).symbol,\nqb.add_equity(\"UUP\", Resolution.DAILY).symbol\n]\ndf = qb.history(symbols, datetime(2010, 1, 1), datetime(2024, 1, 1))\n\n# Obtain the daily partial differencing to be the features and labels.\nhistory = df.unstack(0)\n# we arbitrarily select weight 0.5 here, but ideally one should strike a balance between variance retained and stationarity.\npartial_diff = (history.diff() * 0.5 + history * 0.5).iloc[1:].fillna(0)\nhistory = history.close.iloc[1:]\n\n# Split the data for training and testing to evaluate our model.\nX_train = partial_diff.iloc[:-100].values\nX_test = partial_diff.iloc[-100:].values\ny_train = history.iloc[:-100].values\ny_test = history.iloc[-100:].values\n\n# Create a custom gym environment class. In this example, create a custom environment with previous 5 OHLCV partial-differenced price data as the observation and the lowest maximum drawdown as the reward.\nclass PortfolioEnv(gym.Env):\ndef __init__(self, data, prediction, num_stocks):\nsuper(PortfolioEnv, self).__init__()\n\nself.data = data\nself.prediction = prediction\nself.num_stocks = num_stocks\n\nself.current_step = 5\nself.portfolio_value = []\nself.portfolio_weights = np.ones(num_stocks) / num_stocks\n\n# Define your action and observation spaces\nself.action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(num_stocks, ), dtype=np.float32)\nself.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(5, data.shape[1]))\n\ndef reset(self):\nself.current_step = 5\nself.portfolio_value = []\nself.portfolio_weights = np.ones(self.num_stocks) / self.num_stocks\n\nreturn self._get_observation()\n\ndef step(self, action):\n# Normalize the portfolio weights\nsum_weights = np.sum(np.abs(action))\nif sum_weights > 1:\naction /= sum_weights\n\n# deduct transaction fee\nvalue = self.prediction[self.current_step]\nfees = np.abs(self.portfolio_weights - action) @ value\n\n# Update portfolio weights based on the chosen action\nself.portfolio_weights = action\n\n# Update portfolio value based on the new weights and the market prices less fee\nself.portfolio_value.append(np.dot(self.portfolio_weights, value) - fees)\n\n# Move to the next time step\nself.current_step += 1\n\n# Check if the episode is done (end of data)\ndone = self.current_step >= len(self.data) - 1\n\n# Calculate the reward, in here, we use max drawdown\nreward = self._neg_max_drawdown\n\nreturn self._get_observation(), reward, done, {}\n\ndef _get_observation(self):\n# Return the last 5 partial differencing OHLCV as the observation\nreturn self.data[self.current_step-5:self.current_step]\n\n@property\ndef _neg_max_drawdown(self):\n# Return max drawdown within 20 days in portfolio value as reward (negate since max reward is preferred)\nportfolio_value_20d = np.array(self.portfolio_value[-min(len(self.portfolio_value), 20):])\nacc_max = np.maximum.accumulate(portfolio_value_20d)\nreturn -(portfolio_value_20d - acc_max).min()\n\ndef render(self, mode='human'):\n# Implement rendering if needed\npass\n\n# Initialize the environment.\nenv = PortfolioEnv(X_train, y_train, 5)\n# Wrap the environment in a vectorized environment\nenv = DummyVecEnv([lambda: env])\n# Normalize the observation space\nenv = VecNormalize(env, norm_obs=True, norm_reward=False)\n\n# Train the model. In this example, create a RL model and train with MLP-policy PPO algorithm.\n# Define the PPO agent\nmodel = PPO(\"MlpPolicy\", env, verbose=0)\n# Train the agent\nmodel.learn(total_timesteps=100000)\n\n# Initialize a return series to calculate performance and a list to store the equity value at each timestep.\ntest = np.log(y_test[1:]/y_test[:-1])\nequity = [1]\n# Iterate each testing data point for prediction and trading.\nfor i in range(5, X_test.shape[0]-1):\naction, _ = model.predict(X_test[i-5:i], deterministic=True)\nsum_weights = np.sum(np.abs(action))\nif sum_weights > 1:\naction /= sum_weights\nvalue = test[i] @ action.T\nequity.append((1+value) * equity[i-5])\n# Plot the result.\nplt.figure(figsize=(15, 10))\nplt.title(\"Equity Curve\")\nplt.xlabel(\"timestep\")\nplt.ylabel(\"equity\")\nplt.plot(equity)\nplt.show()\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\nmodel.save(file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Stable Baselines",
      "section_number": "8.2.7",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8.2.8",
    "title": "TensorFlow",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > TensorFlow",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storeTensorflowmodels.\n\n### Import Libraries\n\nImport thetensorflow, andsklearnlibraries.\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nYou need thesklearnlibrary to prepare the data.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nFollow these steps to prepare the data:\n\nLoop through the DataFrame of historical prices and collect the features.data = history\n\nlookback = 5\nlookback_series = []\nfor i in range(1, lookback + 1):\ndf = data['close'].diff(i)[lookback:-1]\ndf.name = f\"close-{i}\"\nlookback_series.append(df)\nX = pd.concat(lookback_series, axis=1).reset_index(drop=True).dropna()\nXThe following image shows the format of the features DataFrame:Select the close column and then call theshiftmethod to collect the labels.Y = data['close'].diff(-1)Drop the first 5 samples and then call thereset_indexmethod.Y = Y[lookback:-1].reset_index(drop=True)This method aligns the history of the features and labels.Split the data into training and testing datasets.For example, to use the last third of data to test the model, run:X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)\n\n### Train Models\n\nYou need toprepare the historical datafor training before you train the model. If you have prepared the data, build and train the model. In this example, build a neural network model that predicts the future price of the SPY.\n\nBuild the Model\n\nFollow these steps to build the model:\n\nSet the number of layers, their number of nodes, the number of epoch and the learning rate.num_factors = X_test.shape[1]\nnum_neurons_1 = 10\nnum_neurons_2 = 10\nnum_neurons_3 = 5\nepochs = 20\nlearning_rate = 0.0001Create hidden layers with the set number of layer and their corresponding number of nodes.In this example, we're constructing the model with the in-built Keras API, with Relu activator for non-linear activation of each tensors.model = tf.keras.sequential([\ntf.keras.layers.dense(num_neurons_1, activation=tf.nn.relu, input_shape=(num_factors,)),  # input shape required\ntf.keras.layers.dense(num_neurons_2, activation=tf.nn.relu),\ntf.keras.layers.dense(num_neurons_3, activation=tf.nn.relu),\ntf.keras.layers.dense(1)\n])Select an optimizer.We're using Adam optimizer in this example. You may also consider others like SGD.optimizer = tf.keras.optimizers.adam(learning_rate=learning_rate)Define the loss function.In the context of numerical regression, we use MSE as our objective function. If you're doing classification, cross entropy would be more suitable.def loss_mse(target_y, predicted_y):\nreturn tf.reduce_mean(tf.square(target_y - predicted_y))\n\nTrain the Model\n\nIteratively train the model by the set epoch number. The model will train adaptively by the gradient provided by the loss function with the selected optimizer.\n\nfor i in range(epochs):\nwith tf.gradient_tape() as t:\nloss = loss_mse(y_train, model(X_train))\n\ntrain_loss = loss_mse(y_train, model(X_train))\ntest_loss = loss_mse(y_test, model(X_test))\nprint(f\"\"\"Epoch {i+1}:\nTraining loss = {train_loss.numpy()}. Test loss = {test_loss.numpy()}\"\"\")\n\njac = t.gradient(loss, model.trainable_weights)\noptimizer.apply_gradients(zip(jac, model.trainable_weights))\n\n### Test Models\n\nTo test the model, we'll setup a method to plot test set predictions ontop of the SPY price.\n\ndef test_model(actual, title, X):\nprediction = model(X).numpy()\nprediction = prediction.reshape(-1, 1)\n\nplt.figure(figsize=(16, 6))\nplt.plot(actual, label=\"Actual\")\nplt.plot(prediction, label=\"Prediction\")\nplt.title(title)\nplt.xlabel(\"Time step\")\nplt.ylabel(\"SPY Price\")\nplt.legend()\nplt.show()\n\ntest_model(y_test, \"Test Set Results from Original Model\", X_test)\n\n### Store Models\n\nYou can save and loadTensorFlowmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model.keras\"Note that the model has to have the suffix.keras.Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Call thesavemethod with the model and file path.model.save(file_name)Save the model to the file path.qb.object_store.save(model_key)\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nGet the file path from the Object Store.file_name = qb.object_store.get_file_path(model_key)Restore theTensorFlowmodel from the saved path.model = tf.keras.models.load_model(file_name)\n\n### Examples\n\nThe following examples demonstrate some common practices for using the Tensorflow library.\n\nExample 1: Predict Next Return\n\nThe following research notebook usesTensorflowmachine learning model to predict the next day's return by the previous 5 days' close price differencing.\n\n# Import the Tensorflow library and others.\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Loop through the DataFrame of historical prices and collect the features.\ndata = history\nlookback = 5\nlookback_series = []\nfor i in range(1, lookback + 1):\ndf = data['close'].diff(i)[lookback:-1]\ndf.name = f\"close-{i}\"\nlookback_series.append(df)\nX = pd.concat(lookback_series, axis=1).reset_index(drop=True).dropna()\n# Select the close column and then call the shift method to collect the labels.\n# This method aligns the history of the features and labels.\nY = data['close'].diff(-1)\nY = Y[lookback:-1].reset_index(drop=True)\n\n# Split the data into training and testing datasets. For example, to use the last third of data to test the model.\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)\n\n# Set the number of layers, their number of nodes, the number of epoch and the learning rate.\nnum_factors = X_test.shape[1]\nnum_neurons_1 = 10\nnum_neurons_2 = 10\nnum_neurons_3 = 5\nepochs = 20\nlearning_rate = 0.0001\n# Create hidden layers with the set number of layer and their corresponding number of nodes.\n# In this example, we're constructing the model with the in-built Keras API, with Relu activator for non-linear activation of each tensors.\nmodel = tf.keras.sequential([\ntf.keras.layers.dense(num_neurons_1, activation=tf.nn.relu, input_shape=(num_factors,)),  # input shape required\ntf.keras.layers.dense(num_neurons_2, activation=tf.nn.relu),\ntf.keras.layers.dense(num_neurons_3, activation=tf.nn.relu),\ntf.keras.layers.dense(1)\n])\n# We're using Adam optimizer in this example. You may also consider others like SGD.\noptimizer = tf.keras.optimizers.adam(learning_rate=learning_rate)\n# Define the loss function. In the context of numerical regression, we use MSE as our objective function. If you're doing classification, cross entropy would be more suitable.\ndef loss_mse(target_y, predicted_y):\nreturn tf.reduce_mean(tf.square(target_y - predicted_y))\n\n# Iteratively train the model by the set epoch number. The model will train adaptively by the gradient provided by the loss function with the selected optimizer.\nfor i in range(epochs):\nwith tf.gradient_tape() as t:\nloss = loss_mse(y_train, model(X_train))\n\ntrain_loss = loss_mse(y_train, model(X_train))\ntest_loss = loss_mse(y_test, model(X_test))\nprint(f\"\"\"Epoch {i+1}:\nTraining loss = {train_loss.numpy()}. Test loss = {test_loss.numpy()}\"\"\")\n\njac = t.gradient(loss, model.trainable_weights)\noptimizer.apply_gradients(zip(jac, model.trainable_weights))\n\n# To test the model, we'll setup a method to plot test set predictions ontop of the SPY price.\ndef test_model(actual, title, X):\nprediction = model(X).numpy()\nprediction = prediction.reshape(-1, 1)\n\nplt.figure(figsize=(16, 6))\nplt.plot(actual, label=\"Actual\")\nplt.plot(prediction, label=\"Prediction\")\nplt.title(title)\nplt.xlabel(\"Time step\")\nplt.ylabel(\"SPY Price\")\nplt.legend()\nplt.show()\n\ntest_model(y_test, \"Test Set Results from Original Model\", X_test)\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model.keras\"\nfile_name = qb.object_store.get_file_path(model_key)\nmodel.save(file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > TensorFlow",
      "section_number": "8.2.8",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | The last 5 close price differencing to the current price |\n| Labels | The following day's price change |"
  },
  {
    "id": "8.2.9",
    "title": "Tslearn",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > Tslearn",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storetslearnmodels.\n\n### Import Libraries\n\nImport thetslearnlibraries.\n\nfrom tslearn.barycenters import softdtw_barycenter\nfrom tslearn.clustering import TimeSeriesKMeans\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, get data for the securities shown in the following table:\n\n[Table - 6 rows]\n\nqb = QuantBook()\ntickers = [\"SPY\", \"QQQ\", \"DIA\",\n\"AAPL\", \"MSFT\", \"TSLA\",\n\"IEF\", \"TLT\", \"SHV\", \"SHY\",\n\"GLD\", \"IAU\", \"SLV\",\n\"USO\", \"XLE\", \"XOM\"]\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2020, 1, 1), datetime(2022, 2, 20))\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, standardize the log close price time-series of the securities. Follow these steps to prepare the data:\n\nUnstack the historical DataFrame and select the close column.close = history.unstack(0).closeTake the logarithm of the historical time series.log_close = np.log(close)Taking the logarithm eases the compounding effect.Standardize the data.standard_close = (log_close - log_close.mean()) / log_close.std()\n\n### Train Models\n\nInstead of using real-time comparison, we could apply a technique call Dynamic Time Wrapping (DTW) with Barycenter Averaging (DBA). Intuitively, it is a technique of averaging a few time-series into a single one without losing much of their information. Since not all time-series would move efficiently like in ideal EMH assumption, this would allow similarity analysis of different time-series with sticky lags. Check the technical details fromtslearn documentation page.\n\nWe then can separate different clusters by KMean after DBA.\n\n# Set up the Time Series KMean model with soft DBA.\nkm = TimeSeriesKMeans(n_clusters=6,   # We have 6 main groups\nmetric=\"softdtw\",  # soft for differentiable\nrandom_state=0)\n\n# Fit the model.\nkm.fit(standard_close.T)\n\n### Test Models\n\nWe visualize the clusters and their corresponding underlying series.\n\nPredict with the label of the data.labels = km.predict(standard_close.T)Create a class to aid plotting.def plot_helper(ts):\n# plot all points of the data set\nfor i in range(ts.shape[0]):\nplt.plot(ts[i, :], \"k-\", alpha=.2)\n\n# plot the given barycenter of them\nbarycenter = softdtw_barycenter(ts, gamma=1.)\nplt.plot(barycenter, \"r-\", linewidth=2)Plot the results.j = 1\nplt.figure(figsize=(15, 10))\nfor i in set(labels):\n# Select the series in the i-th cluster.\nX = standard_close.iloc[:, [n for n, k in enumerate(labels) if k == i]].values\n\n# Plot the series and barycenter-averaged series.\nplt.subplot(len(set(labels)) // 3 + (1 if len(set(labels))%3 != 0 else 0), 3, j)\nplt.title(f\"Cluster {i+1}\")\nplot_helper(X.T)\n\nj += 1\n\nplt.show()Display the groupings.for i in set(labels):\nprint(f\"Cluster {i+1}: {standard_close.columns[[n for n, k in enumerate(labels) if k == i]]}\")\n\n### Store Models\n\nYou can save and loadtslearnmodels using the Object Store.\n\nSave Models\n\nFollow these steps to save models in the Object Store:\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the file path where the model will be stored.Delete the current file to avoid aFileExistsErrorerror when you save the model.import os\nos.remove(file_name)Call theto_hdf5method with the file path.km.to_hdf5(file_name + \".hdf5\")\n\nLoad Models\n\nYou must save a model into the Object Store before you can load it from the Object Store. If you saved a model, follow these steps to load it:\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.Call theGetFilePathget_file_pathmethod with the key.file_name = qb.object_store.get_file_path(model_key)This method returns the path where the model is stored.Call thefrom_hdf5method with the file path.loaded_model = TimeSeriesKMeans.from_hdf5(file_name + \".hdf5\")This method returns the saved model.\n\n### Reference\n\n### Examples\n\nThe following examples demonstrate some common practices for using thetslearnlibrary.\n\nExample 1: DBA Clustering\n\nThe following research notebook usestslearnmachine learning model to cluster a collection of stocks applying Dynamic Time Wrapping (DTW) with Barycenter Averaging (DBA).\n\n# Import the tslearn library.\nfrom tslearn.barycenters import softdtw_barycenter\nfrom tslearn.clustering import TimeSeriesKMeans\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily history of the collection of stocks in the date range to be studied.\ntickers = [\"SPY\", \"QQQ\", \"DIA\",\n\"AAPL\", \"MSFT\", \"TSLA\",\n\"IEF\", \"TLT\", \"SHV\", \"SHY\",\n\"GLD\", \"IAU\", \"SLV\",\n\"USO\", \"XLE\", \"XOM\"]\nsymbols = [qb.add_equity(ticker, Resolution.DAILY).symbol for ticker in tickers]\nhistory = qb.history(symbols, datetime(2020, 1, 1), datetime(2022, 2, 20))\n\n# Obtain the daily log close price to be analyzed.\nclose = history.unstack(0).close\nlog_close = np.log(close)       # Taking the logarithm eases the compounding effect.\n# Standardize the data for faster convergence.\nstandard_close = (log_close - log_close.mean()) / log_close.std()\n\n# Set up the Time Series KMean model with soft DBA.\nkm = TimeSeriesKMeans(n_clusters=6,   # We have 6 main groups\nmetric=\"softdtw\",  # soft for differentiable\nrandom_state=0)\n# Fit the model.\nkm.fit(standard_close.T)\n\n# Call the predict method with the testing dataset to get the prediction from the model.\nlabels = km.predict(standard_close.T)\n\n# Create a class to aid plotting.\ndef plot_helper(ts):\n# plot all points of the data set\nfor i in range(ts.shape[0]):\nplt.plot(ts[i, :], \"k-\", alpha=.2)\n\n# plot the given barycenter of them\nbarycenter = softdtw_barycenter(ts, gamma=1.)\nplt.plot(barycenter, \"r-\", linewidth=2)\n# Plot the results.\nj = 1\nplt.figure(figsize=(15, 10))\nfor i in set(labels):\n# Select the series in the i-th cluster.\nX = standard_close.iloc[:, [n for n, k in enumerate(labels) if k == i]].values\n\n# Plot the series and barycenter-averaged series.\nplt.subplot(len(set(labels)) // 3 + (1 if len(set(labels))%3 != 0 else 0), 3, j)\nplt.title(f\"Cluster {i+1}\")\nplot_helper(X.T)\n\nj += 1\n\nplt.show()\n# Display the groupings.\nfor i in set(labels):\nprint(f\"Cluster {i+1}: {standard_close.columns[[n for n, k in enumerate(labels) if k == i]]}\")\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\nimport os\nos.remove(file_name)\nkm.to_hdf5(file_name + \".hdf5\")",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > Tslearn",
      "section_number": "8.2.9",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Group Name | Tickers |\n| --- | --- |\n| Overall US market | SPY, QQQ, DIA |\n| Tech companies | AAPL, MSFT, TSLA |\n| Long-term US Treasury ETFs | IEF, TLT |\n| Short-term US Treasury ETFs | SHV, SHY |\n| Heavy metal ETFs | GLD, IAU, SLV |\n| Energy sector | USO, XLE, XOM |"
  },
  {
    "id": "8.2.10",
    "title": "XGBoost",
    "level": 3,
    "path": "Machine Learning > Popular Libraries > XGBoost",
    "content": "### Introduction\n\nThis page explains how to build, train, test, and storeXGBoostmodels.\n\n### Import Libraries\n\nImport thexgboost,sklearn, andjobliblibraries.\n\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\nYou need thesklearnlibrary to prepare the data and thejobliblibrary to save models.\n\n### Get Historical Data\n\nGet some historical market datato train and test the model. For example, to get data for the SPY ETF during 2020 and 2021, run:\n\nqb = QuantBook()\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n### Prepare Data\n\nYou need somehistorical datato prepare the data for the model. If you have historical data, manipulate it to train and test the model. In this example, use the following features and labels:\n\n[Table - 2 rows]\n\nThe following image shows the time difference between the features and labels:\n\nFollow these steps to prepare the data:\n\nPerform fractional differencing on the historical data.df = (history['close'] * 0.5 + history['close'].diff() * 0.5)[1:]Fractional differencing helps make the data stationary yet retains the variance information.Loop through thedfDataFrame and collect the features and labels.n_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(df)-n_steps):\nfeatures.append(df.iloc[i:i+n_steps].values)\nlabels.append(df.iloc[i+n_steps])Convert the lists of features and labels intonumpyarrays.features = np.array(features)\nlabels = np.array(labels)Standardize the features and labelsX = (features - features.mean()) / features.std()\ny = (labels - labels.mean()) / labels.std()Split the data into training and testing periods.X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n### Train Models\n\nWe're about to train a gradient-boosted random forest for future price prediction.\n\nSplit the data for training and testing to evaluate our model.X_train, X_test, y_train, y_test = train_test_split(X, y)Format training set into XGBoost matrix.dtrain = xgb.DMatrix(X_train, label=y_train)Train the model with parameters.params = {\n'booster': 'gbtree',\n'colsample_bynode': 0.8,\n'learning_rate': 0.1,\n'lambda': 0.1,\n'max_depth': 5,\n'num_parallel_tree': 100,\n'objective': 'reg:squarederror',\n'subsample': 0.8,\n}\nmodel = xgb.train(params, dtrain, num_boost_round=10)\n\n### Test Models\n\nWe then make predictions on the testing data set. We compare our Predicted Values with the Expected Values by plotting both to see if our Model has predictive power.\n\nFormat testing set into XGBoost matrix.dtest = xgb.DMatrix(X_test, label=y_test)Predict with the testing set data.y_predict = model.predict(dtest)Plot the result.df = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual closing price', figsize=(15, 10))\nplt.show()\n\n### Store Models\n\nSaving the Model\n\nWe dump the model using thejoblibmodule and save it to Object Store file path. This way, the model doesn't need to be retrained, saving time and computational resources.\n\nSet the key name of the model to be stored in the Object Store.model_key = \"model\"CallGetFilePathwith the key's name to get the file path.file_name = qb.object_store.get_file_path(model_key)Call dump with the model and file path to save the model to the file path.joblib.dump(model, file_name)\n\nLoading the Model\n\nLet's retrieve the model from the Object Store file path and load byjoblib.\n\nCall theContainsKeycontains_keymethod.qb.object_store.contains_key(model_key)This method returns a boolean that represents if themodel_keyis in the Object Store. If the Object Store does not contain themodel_key, save the model using themodel_keybefore you proceed.CallGetFilePathwith the key's name to get the file path.file_name = qb.object_store.get_file_path(model_key)Callloadwith the file path to fetch the saved model.loaded_model = joblib.load(file_name)\n\nTo ensure loading the model was successfuly, let's test the model.\n\ny_pred = loaded_model.predict(dtest)\ndf = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_pred.flatten()})\ndf.plot(title='Model Performance: predicted vs actual closing price', figsize=(15, 10))\n\n### Examples\n\nThe following examples demonstrate some common practices for using the XGBoost library.\n\nExample 1: Predict Next Price\n\nThe following research notebook usesXGBoostmachine learning model to predict the next day's close price by the previous 5 days' daily closes.\n\n# Import the XGBoost library and others.\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nimport joblib\n\n# Instantiate the QuantBook for researching.\nqb = QuantBook()\n# Request the daily SPY history with the date range to be studied.\nsymbol = qb.add_equity(\"SPY\", Resolution.DAILY).symbol\nhistory = qb.history(symbol, datetime(2020, 1, 1), datetime(2022, 1, 1)).loc[symbol]\n\n# Obtain the daily fractional differencing in close price to be the features and labels.\ndf = (history['close'] * 0.5 + history['close'].diff() * 0.5)[1:]\n# We use the previous 5 day returns as the features to be studied.\n# Get the 1-day forward return as the labels for the machine to learn.\nn_steps = 5\nfeatures = []\nlabels = []\nfor i in range(len(df)-n_steps):\nfeatures.append(df.iloc[i:i+n_steps].values)\nlabels.append(df.iloc[i+n_steps])\n\n# Clean up and process the data for faster convergence.\nfeatures = np.array(features)\nlabels = np.array(labels)\nX = (features - features.mean()) / features.std()\ny = (labels - labels.mean()) / labels.std()\n\n# Split the data as a training set and test set for validation.\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Format training set into XGBoost matrix.\ndtrain = xgb.DMatrix(X_train, label=y_train)\n# Train the model with parameters.\nparams = {\n'booster': 'gbtree',\n'colsample_bynode': 0.8,\n'learning_rate': 0.1,\n'lambda': 0.1,\n'max_depth': 5,\n'num_parallel_tree': 100,\n'objective': 'reg:squarederror',\n'subsample': 0.8,\n}\nmodel = xgb.train(params, dtrain, num_boost_round=10)\n\n# Format testing set into XGBoost matrix to test it.\ndtest = xgb.DMatrix(X_test, label=y_test)\n# Predict with the testing set data.\ny_predict = model.predict(dtest)\n# Plot the result.\ndf = pd.DataFrame({'Real': y_test.flatten(), 'Predicted': y_predict.flatten()})\ndf.plot(title='Model Performance: predicted vs actual closing price', figsize=(15, 10))\nplt.show()\n\n# Store the model in the object store to allow accessing the model in the next research session or in the algorithm for trading.\nmodel_key = \"model\"\nfile_name = qb.object_store.get_file_path(model_key)\njoblib.dump(model, file_name)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "8.2",
      "breadcrumb": "Machine Learning > Popular Libraries > XGBoost",
      "section_number": "8.2.10",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Data Category | Description |\n| --- | --- |\n| Features | The last 5 closing prices |\n| Labels | The following day's closing price |"
  },
  {
    "id": "8.3",
    "title": "Hugging Face",
    "level": 2,
    "path": "Machine Learning > Hugging Face",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8",
      "breadcrumb": "Machine Learning > Hugging Face",
      "section_number": "8.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "8.3.1",
    "title": "Key Concepts",
    "level": 3,
    "path": "Machine Learning > Hugging Face > Key Concepts",
    "content": "### Introduction",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "8.3",
      "breadcrumb": "Machine Learning > Hugging Face > Key Concepts",
      "section_number": "8.3.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "9",
    "title": "Debugging",
    "level": 1,
    "path": "Debugging",
    "content": "### Introduction\n\nThe debugger is a built-in tool to help you debug coding errors while in the Research Environment. The debugger enables you to slow down the code execution, step through the program line-by-line, and inspect the variables to understand the internal state of the notebook.\n\nThe Research Environment debugger isn't currently available for C#.\n\n### Breakpoints\n\nBreakpoints are lines in your notebook where execution pauses. You need at least one breakpoint in your notebook to start the debugger.Open a projectto start adjusting its breakpoints.\n\nAdd Breakpoints\n\nClick to the left of a line to add a breakpoint on that line.\n\nEdit Breakpoint Conditions\n\nFollow these steps to customize what happens when a breakpoint is hit:\n\nRight-click the breakpoint and then clickEdit Breakpoint....Click one of the options in the following table:\n\n[Table - 2 rows]\n\nEnable and Disable Breakpoints\n\nTo enable a breakpoint, right-click it and then clickEnable Breakpoint.\n\nTo disable a breakpoint, right-click it and then clickDisable Breakpoint.\n\nFollow these steps to enable and disable all breakpoints:\n\nIn the right navigation menu, click theRun and Debugicon.In the Run and Debug panel, hover over theBreakpointssection and then click theToggle Active Breakpointsicon.\n\nRemove Breakpoints\n\nTo remove a breakpoint, right-click it and then clickRemove Breakpoint.\n\nFollow these steps to remove all breakpoints:\n\nIn the right navigation menu, click theRun and Debugicon.In the Run and Debug panel, hover over theBreakpointssection and then click theRemove All Breakpointsicon.\n\n### Launch Debugger\n\nFollow these steps to launch the debugger:\n\nOpen the projectyou want to debug.Open the notebook filein your project.In a notebook cell, add at least one breakpoint.In the top-left corner of the cell, click the drop-down arrow and then clickDebug Cell.\n\nIf the Run and Debug panel is not open, it opens when the first breakpoint is hit.\n\n### Control Debugger\n\nAfter you launch the debugger, you can use the following buttons to control it:\n\n[Table - 5 rows]\n\n### Inspect Variables\n\nAfter you launch the debugger, you can inspect the state of your notebook as it executes each line of code. You can inspect local variables or custom expressions.The values of variables in your notebook are formatted in the IDE to improve readability. For example, if you inspect a variable that references a DataFrame, the debugger represents the variable value as the following:\n\nLocal Variables\n\nTheVariablessection of the Run and Debug panel shows the local variables at the current breakpoint. If a variable in the panel is an object, click it to see its members. The panel updates as the notebook runs.\n\nFollow these steps to update the value of a variable:\n\nIn the Run and Debug panel, right-click a variable and then clickSet Value.Enter the new value and then pressEnter.\n\nCustom Expressions\n\nTheWatchsection of the Run and Debug panel shows any custom expressions you add. For example, you can add an expression to show adatetimeobject.\n\nFollow these steps to add a custom expression:\n\nHover over theWatchsection and then click theplusicon that appears.Enter an expression and then pressEnter.",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Debugging",
      "section_number": "9",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Option | Additional Steps | Description |\n| --- | --- | --- |\n| Expression | Enter an expression and then pressEnter. | The breakpoint only pauses the notebook when the expression is true. |\n| Hit Count | Enter an integer and then pressEnter. | The breakpoint doesn't pause the notebook until its hit the number of times you specify. |",
    "table_1": "| Button | Name | Default Keyboard Shortcut | Description |\n| --- | --- | --- | --- |\n|  | Continue |  | Continue execution until the next breakpoint |\n|  | Step Over | Alt+F10 | Step to the next line of code in the current or parent scope |\n|  | Step Into | Alt+F11 | Step into the definition of the function call on the current line |\n|  | Restart | Shift+F11 | Restart the debugger |\n|  | Disconnect | Shift+F5 | Exit the debugger |"
  },
  {
    "id": "10",
    "title": "Meta Analysis",
    "level": 1,
    "path": "Meta Analysis",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Meta Analysis",
      "section_number": "10",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "10.1",
    "title": "Key Concepts",
    "level": 2,
    "path": "Meta Analysis > Key Concepts",
    "content": "### Introduction\n\nUnderstanding your strategy trades in detail is key to attributing performance, and determining areas to focus for improvement. This analysis can be done with the QuantConnect API. We enable you to load backtest, optimization, and live trading results into the Research Environment.\n\n### Backtest Analysis\n\nLoad your backtest results into the Research Environment to analyze trades and easily compare them against the raw backtesting data. For more information on loading and manipulating backtest results, seeBacktest Analysis.\n\n### Optimization Analysis\n\nLoad your optimization results into the Research Environment to analyze how different combinations of parameters affect the algorithm's performance. For more information on loading and manipulating optimizations results, seeOptimization Analysis.\n\n### Live Analysis\n\nLoad your live trading results into the Research Environment to compare live trading performance against simulated backtest results, or analyze your trades to improve your slippage and fee models. For more information on loading and manipulating live trading results, seeLive Analysis.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Meta Analysis > Key Concepts",
      "section_number": "10.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "10.2",
    "title": "Backtest Analysis",
    "level": 2,
    "path": "Meta Analysis > Backtest Analysis",
    "content": "### Introduction\n\nLoad your backtest results into the Research Environment to analyze trades and easily compare them against the raw backtesting data. Compare backtests from different projects to find uncorrelated strategies to combine for better performance.\n\nLoading your backtest trades allows you to plot fills against detailed data, or locate the source of profits. Similarly you can search for periods of high churn to reduce turnover and trading fees.\n\n### Read Backtest Results\n\nTo get the results of a backtest, call theReadBacktestread_backtestmethod with the project Id and backtest ID.\n\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\n\nvar backtest = api.ReadBacktest(projectId, backtestId);backtest = api.read_backtest(project_id, backtest_id)\n\nThe following table provides links to documentation that explains how to get the project Id and backtest Id, depending on the platform you use:\n\n[Table - 3 rows]\n\nNote that this method returns a snapshot of the backtest at the current moment. If the backtest is still executing, the result won't include all of the backtest data.\n\nTheReadBacktestread_backtestmethod returns aBacktestobject, which have the following attributes:\n\n### Plot Order Fills\n\nFollow these steps to plot the daily order fills of a backtest:\n\nGet the backtest orders.orders = api.read_backtest_orders(project_id, backtest_id)The following table provides links to documentation that explains how to get the project Id and backtest Id, depending on the platform you use:PlatformProject IdBacktest IdCloud PlatformGet Project IdGet Backtest IdLocal PlatformGet Project IdGet Backtest IdCLIGet Project IdGet Backtest IdTheReadBacktestOrdersread_backtest_ordersmethod returns a list ofOrderobjects, which have the following properties:Organize the trade times and prices for each security into a dictionary.class OrderData:\ndef __init__(self):\nself.buy_fill_times = []\nself.buy_fill_prices = []\nself.sell_fill_times = []\nself.sell_fill_prices = []\n\norder_data_by_symbol = {}\nfor order in [x.order for x in orders]:\nif order.symbol not in order_data_by_symbol:\norder_data_by_symbol[order.symbol] = OrderData()\norder_data = order_data_by_symbol[order.symbol]\nis_buy = order.quantity > 0\n(order_data.buy_fill_times if is_buy else order_data.sell_fill_times).append(order.last_fill_time.date())\n(order_data.buy_fill_prices if is_buy else order_data.sell_fill_prices).append(order.price)Get the price history of each security you traded.qb = QuantBook()\nstart_date = datetime.max.date()\nend_date = datetime.min.date()\nfor symbol, order_data in order_data_by_symbol.items():\nif order_data.buy_fill_times:\nstart_date = min(start_date, min(order_data.buy_fill_times))\nend_date = max(end_date, max(order_data.buy_fill_times))\nif order_data.sell_fill_times:\nstart_date = min(start_date, min(order_data.sell_fill_times))\nend_date = max(end_date, max(order_data.sell_fill_times))\nstart_date -= timedelta(days=3)\nall_history = qb.history(list(order_data_by_symbol.keys()), start_date, end_date, Resolution.DAILY)Create a candlestick plot for each security and annotate each plot with buy and sell markers.import plotly.express as px\nimport plotly.graph_objects as go\n\nfor symbol, order_data in order_data_by_symbol.items():\nhistory = all_history.loc[symbol]\n\n# Plot security price candlesticks\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'],\nname='Price')\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol.value} Trades'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False,\nheight=600)\nfig = go.Figure(data=[candlestick], layout=layout)\n\n# Plot buys\nfig.add_trace(go.Scatter(\nx=order_data.buy_fill_times,\ny=order_data.buy_fill_prices,\nmarker=go.scatter.Marker(color='aqua', symbol='triangle-up', size=10),\nmode='markers',\nname='Buys',\n))\n\n# Plot sells\nfig.add_trace(go.Scatter(\nx=order_data.sell_fill_times,\ny=order_data.sell_fill_prices,\nmarker=go.scatter.Marker(color='indigo', symbol='triangle-down', size=10),\nmode='markers',\nname='Sells',\n))\n\nfig.show()Note: The preceding plots only show the last fill of each trade. If your trade has partial fills, the plots only display the last fill.\n\n### Plot Metadata\n\nFollow these steps to plot the equity curve, benchmark, and drawdown of a backtest:\n\nGet the backtest instance.backtest = api.read_backtest(project_id, backtest_id)The following table provides links to documentation that explains how to get the project Id and backtest Id, depending on the platform you use:PlatformProject IdBacktest IdCloud PlatformGet Project IdGet Backtest IdLocal PlatformGet Project IdGet Backtest IdCLIGet Project IdGet Backtest IdGet the \"Strategy Equity\", \"Drawdown\", and \"Benchmark\"Chartobjects.equity_chart = backtest.charts[\"Strategy Equity\"]\ndrawdown_chart = backtest.charts[\"Drawdown\"]\nbenchmark_chart = backtest.charts[\"Benchmark\"]Get the \"Equity\", \"Equity Drawdown\", and \"Benchmark\"Seriesfrom the preceding charts.equity = equity_chart.series[\"Equity\"].values\ndrawdown = drawdown_chart.series[\"Equity Drawdown\"].values\nbenchmark = benchmark_chart.series[\"Benchmark\"].valuesCreate apandas.DataFramefrom the series values.df = pd.DataFrame({\n\"Equity\": pd.Series({value.TIME: value.CLOSE for value in equity}),\n\"Drawdown\": pd.Series({value.TIME: value.Y for value in drawdown}),\n\"Benchmark\": pd.Series({value.TIME: value.Y for value in benchmark})\n}).ffill()Plot the performance chart.# Create subplots to plot series on same/different plots\nfig, ax = plt.subplots(2, 1, figsize=(12, 12), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n\n# Plot the equity curve\nax[0].plot(df.index, df[\"Equity\"])\nax[0].set_title(\"Strategy Equity Curve\")\nax[0].set_ylabel(\"Portfolio Value ($)\")\n\n# Plot the benchmark on the same plot, scale by using another y-axis\nax2 = ax[0].twinx()\nax2.plot(df.index, df[\"Benchmark\"], color=\"grey\")\nax2.set_ylabel(\"Benchmark Price ($)\", color=\"grey\")\n\n# Plot the drawdown on another plot\nax[1].plot(df.index, df[\"Drawdown\"], color=\"red\")\nax[1].set_title(\"Drawdown\")\nax[1].set_xlabel(\"Time\")\nax[1].set_ylabel(\"%\")\n\nThe following table shows all the chart series you can plot:\n\n[Table - 8 rows]\n\n### Plot Insights\n\nFollow these steps to display the insights of each asset in a backtest:\n\nGet the insights.insight_response = api.read_backtest_insights(project_id, backtest_id)The following table provides links to documentation that explains how to get the project Id and backtest Id, depending on the platform you use:PlatformProject IdBacktest IdCloud PlatformGet Project IdGet Backtest IdLocal PlatformGet Project IdGet Backtest IdCLIGet Project IdGet Backtest IdTheread_backtest_insightsmethod returns anInsightResponseobject, which have the following properties:Organize the insights into a DataFrame.import pytz\n\ndef _eastern_time(unix_timestamp):\nreturn unix_timestamp.replace(tzinfo=pytz.utc)\\\n.astimezone(pytz.timezone('US/Eastern')).replace(tzinfo=None)\n\ninsight_df = pd.DataFrame(\n[\n{\n'Symbol': i.symbol,\n'Direction': i.direction,\n'Generated Time': _eastern_time(i.generated_time_utc),\n'Close Time': _eastern_time(i.close_time_utc),\n'Weight': i.weight\n}\nfor i in insight_response.insights\n]\n)Get theprice historyof each security that has an insight.symbols = list(insight_df['Symbol'].unique())\nqb = QuantBook()\nhistory = qb.history(\nsymbols, insight_df['Generated Time'].min()-timedelta(1),\ninsight_df['Close Time'].max(), Resolution.DAILY\n)['close'].unstack(0)Plot the price and insights of each asset.colors = ['yellow', 'green', 'red']\nfig, axs = plt.subplots(len(symbols), 1, sharex=True)\nfor i, symbol in enumerate(symbols):\nax = axs[i]\nhistory[symbol].plot(ax=ax)\nfor _, insight in insight_df[insight_df['Symbol'] == symbol].iterrows():\nax.axvspan(\ninsight['Generated Time'], insight['Close Time'],\ncolor=colors[insight['Direction']], alpha=0.3\n)\nax.set_title(f'Insights for {symbol.value}')\nax.set_xlabel('Date')\nax.set_ylabel('Price')\nplt.tight_layout()\nplt.show()\n\n### Examples\n\nExample 1: Read Backtest Statistics\n\nThe following example reads the last completed backtest statistics in a jupyter notebook.\n\n// Load the necessary assemblies.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\nusing QuantConnect.Research;\n\n// Instantiate QuantBook instance for researching.\nvar qb = new QuantBook();\n\n// Get backtest list in the current project.\nvar backtests = api.ListBacktests(qb.ProjectId)\n// Get the last completed backtest to study.\nvar backtestId = backtests.Backtests\n.Where(x => x.Progress == 1m)\n.OrderByDescending(x => x.Created)\n.First()\n.BacktestId;\nvar backtest = api.ReadBacktest(qb.ProjectId, backtestId);\n\n// Obtain the backtest statistics.\nConsole.WriteLine(backtest.Statistics.ToString());# Instantiate QuantBook instance for researching.\nqb = QuantBook()\n\n# Get backtest list in the current project.\nbacktests = api.list_backtests(qb.project_id)\n# Get the last completed backtest to study.\nbacktest_id = sorted(\n[x for x in backtests.backtests if x.progress == 1],\nkey=lambda x: x.created,\nreverse=True\n)[0].backtest_id\nbacktest = api.read_backtest(project_id, backtest_id)\n\n# Obtain the backtest statistics.\nprint(backtest.statistics)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Meta Analysis > Backtest Analysis",
      "section_number": "10.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Platform | Project Id | Backtest Id |\n| --- | --- | --- |\n| Cloud Platform | Get Project Id | Get Backtest Id |\n| Local Platform | Get Project Id | Get Backtest Id |\n| CLI | Get Project Id | Get Backtest Id |",
    "table_1": "| Chart | Series | Description |\n| --- | --- | --- |\n| Strategy Equity | Equity | Time series of the equity curve |\n| Daily Performance | Time series of daily percentage change |  |\n| Capacity | Strategy Capacity | Time series ofstrategy capacitysnapshots |\n| Drawdown | Equity Drawdown | Time series of equity peak-to-trough value |\n| Benchmark | Benchmark | Time series of thebenchmarkclosing price (SPY, by default) |\n| Exposure | SecurityType- Long Ratio | Time series of the overall ratio ofSecurityTypelong positions of the whole portfolio if anySecurityTypeis ever in the universe |\n| SecurityType- Short Ratio | Time series of the overall ratio ofSecurityTypeshort position of the whole portfolio if anySecurityTypeis ever in the universe |  |\n| Custom Chart | Custom Series | Time series of aSeriesin acustom chart |"
  },
  {
    "id": "10.3",
    "title": "Optimization Analysis",
    "level": 2,
    "path": "Meta Analysis > Optimization Analysis",
    "content": "### Introduction\n\nLoad your optimization results into the Research Environment to analyze how different combinations of parameters affect the algorithm's performance.\n\n### Read Optimization Results\n\nTo get the results of an optimization, call theReadOptimizationread_optimizationmethod with the optimization Id.\n\nvar optimization = api.ReadOptimization(optimizationId);optimization = api.read_optimization(optimization_id)\n\nThe following table provides links to documentation that explains how to get the optimization Id, depending on the platform you use:\n\n[Table - 3 rows]\n\nTheReadOptimizationread_optimizationmethod returns anOptimizationobject, which have the following attributes:\n\n### Example\n\nExample 1: Read Optimization Results\n\nThe following example reads the last completed optimization job and obtains the optimum paramteters in a jupyter notebook.\n\n// Load the necessary assemblies.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\nusing QuantConnect.Research;\n\n// Instantiate QuantBook instance for researching.\nvar qb = new QuantBook();\n\n// Get optimization job list in the current project.\nvar optimizations = api.ListOptimizations(qb.ProjectId)\n// Get the last completed optimizations to study.\nvar optimizationId = optimizations.Where(x => x.Status == OptimizationStatus.Completed)\n.OrderByDescending(x => x.Created)\n.First()\n.OptimizationId;\nvar optimization = api.ReadOptimization(optimizationId);\n\n// Obtain the backtest with the best Sharpe Ratio.\nvar bestBacktest = optimization.Backtests.Values.MaxBy(x => x.Statistics[\"SharpeRatio\"])\n// Obtain the parameter set of the backtest with the best result.\nvar parameterSet = bestBacktest.ParameterSet;\nConsole.WriteLine(parameterSet.ToString());# Instantiate QuantBook instance for researching.\nqb = QuantBook()\n\n# Get optimization job list in the current project.\noptimizations = api.list_optimizations(qb.project_id)\n# Get the last completed optimizations to study.\noptimization_id = sorted(\n[x for x in optimizations if x.status == OptimizationStatus.COMPLETED],\nkey=lambda x: x.created,\nreverse=True\n)[0].optimization_id\noptimization = api.read_optimization(optimization_id)\n\n# Obtain the backtest with the best Sharpe Ratio.\nbest_backtest = max(optimization.backtests.values(), key=lambda x: x.statistics[\"SharpeRatio\"])\n# Obtain the parameter set of the backtest with the best result.\nparameter_set = best_backtest.parameter_set\nprint(parameter_set)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Meta Analysis > Optimization Analysis",
      "section_number": "10.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Platform | Optimization Id |\n| --- | --- |\n| Cloud Platform | Get Optimization Id |\n| Local Platform | Get Optimization Id |\n| CLI |  |"
  },
  {
    "id": "10.4",
    "title": "Live Analysis",
    "level": 2,
    "path": "Meta Analysis > Live Analysis",
    "content": "### Introduction\n\nLoad your live trading results into the Research Environment to compare live trading performance against simulated backtest results.\n\n### Read Live Results\n\nTo get the results of a live algorithm, call theReadLiveAlgorithmread_live_algorithmmethod with the project Id and deployment ID.\n\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\n\nvar liveAlgorithm = api.ReadLiveAlgorithm(projectId, deployId);live_algorithm = api.read_live_algorithm(project_id, deploy_id)\n\nThe following table provides links to documentation that explains how to get the project Id and deployment Id, depending on the platform you use:\n\n[Table - 3 rows]\n\nTheReadLiveAlgorithmread_live_algorithmmethod returns aLiveAlgorithmResultsobject, which have the following attributes:\n\n### Reconciliation\n\nReconciliation is a way toquantifythe difference between an algorithm's live performance and its out-of-sample (OOS) performance (a backtest run over the live deployment period).\n\nSeeing the difference between live performance and OOS performance gives you a way to determine if the algorithm is making unrealistic assumptions, exploiting data differences, or merely exhibiting behavior that is impractical or impossible in live trading.\n\nA perfectly reconciled algorithm has an exact overlap between its live equity and OOS backtest curves. Any deviation means that the performance of the algorithm has differed for some reason. Several factors can contribute to this, often stemming from the algorithm design.\n\nReconciliation is scored using two metrics: returns correlation and dynamic time warping (DTW) distance.\n\nWhat is DTW Distance?\n\nDynamic Time Warp (DTW) Distance quantifies the difference between two time-series. It is an algorithm that measures the shortest path between the points of two time-series. It uses Euclidean distance as a measurement ofpoint-to-point distanceand returns an overall measurement of the distance on the scale of the initial time-series values. We apply DTW to the returns curve of the live and OOS performance, so the DTW distance measurement is on the scale of percent returns.\n\n$$\\begin{equation}\nDTW(X,Y) = min\\bigg\\{\\sum_{l=1}^{L}\\left(x_{m_l} - y_{n_l}\\right)^{2}\\in P^{N\\times M}\\bigg\\}\n\\end{equation}$$\n\nFor the reasons outlined in our research notebook on the topic (linked below), QuantConnect annualizes the daily DTW. An annualized distance provides a user with a measurement of the annual difference in the magnitude of returns between the two curves. A perfect score is 0, meaning the returns for each day were precisely the same. A DTW score of 0 is nearly impossible to achieve, and we consider anything below 0.2 to be a decent score. A distance of 0.2 means the returns between an algorithm's live and OOS performance deviated by 20% over a year.\n\nWhat is Returns Correlation?\n\nReturns correlation is the simple Pearson correlation between the live and OOS returns. Correlation gives us a rudimentary understanding of how the returns move together. Do they trend up and down at the same time? Do they deviate in direction or timing?\n\n$$\\begin{equation}\n\\rho_{XY} = \\frac{cov(X, Y)}{\\sigma_X\\sigma_Y}\n\\end{equation}$$\n\nAn algorithm's returns correlation should be as close to 1 as possible. We consider a good score to be 0.8 or above, meaning that there is a strong positive correlation. This indicates that the returns move together most of the time and that for any given return you see from one of the curves, the other curve usually has a similar direction return (positive or negative).\n\nWhy Do We Need Both DTW and Returns Correlation?\n\nEach measurement provides insight into distinct elements of time-series similarity, but neither measurement alone gives us the whole picture. Returns correlation tells us whether or not the live and OOS returns move together, but it doesn't account for the possible differences in the magnitude of the returns. DTW distance measures the difference in magnitude of returns but provides no insight into whether or not the returns move in the same direction. It is possible for there to be two cases of equity curve similarity where both pairs have the same DTW distance, but one has perfectly negatively correlated returns, and the other has a perfectly positive correlation. Similarly, it is possible for two pairs of equity curves to each have perfect correlation but substantially different DTW distance. Having both measurements provides us with a more comprehensive understanding of the actual similarity between live and OOS performance. We outline several interesting cases and go into more depth on the topic of reconciliation inresearchwe have published.\n\n### Plot Order Fills\n\nFollow these steps to plot the daily order fills of a live algorithm:\n\nGet the live trading orders.orders = api.read_live_orders(project_id)The following table provides links to documentation that explains how to get the project Id, depending on the platform you use:PlatformProject IdCloud PlatformGet Project IdLocal PlatformGet Project IdCLIGet Project IdBy default, the orders with an ID between 0 and 100. To get orders with an ID greater than 100, passstartandendarguments to theReadLiveOrdersread_live_ordersmethod. Note thatend-startmust be less than 100.orders = api.read_live_orders(project_id, 100, 150)TheReadLiveOrdersread_live_ordersmethod returns a list ofOrderobjects, which have the following properties:Organize the trade times and prices for each security into a dictionary.class OrderData:\ndef __init__(self):\nself.buy_fill_times = []\nself.buy_fill_prices = []\nself.sell_fill_times = []\nself.sell_fill_prices = []\n\norder_data_by_symbol = {}\nfor order in [x.order for x in orders]:\nif order.symbol not in order_data_by_symbol:\norder_data_by_symbol[order.symbol] = OrderData()\norder_data = order_data_by_symbol[order.symbol]\nis_buy = order.quantity > 0\n(order_data.buy_fill_times if is_buy else order_data.sell_fill_times).append(order.last_fill_time.date())\n(order_data.buy_fill_prices if is_buy else order_data.sell_fill_prices).append(order.price)Get the price history of each security you traded.qb = QuantBook()\nstart_date = datetime.max.date()\nend_date = datetime.min.date()\nfor symbol, order_data in order_data_by_symbol.items():\nif order_data.buy_fill_times:\nstart_date = min(start_date, min(order_data.buy_fill_times))\nend_date = max(end_date, max(order_data.buy_fill_times))\nif order_data.sell_fill_times:\nstart_date = min(start_date, min(order_data.sell_fill_times))\nend_date = max(end_date, max(order_data.sell_fill_times))\nstart_date -= timedelta(days=3)\nall_history = qb.history(list(order_data_by_symbol.keys()), start_date, end_date, Resolution.DAILY)Create a candlestick plot for each security and annotate each plot with buy and sell markers.import plotly.express as px\nimport plotly.graph_objects as go\n\nfor symbol, order_data in order_data_by_symbol.items():\nhistory = all_history.loc[symbol]\n\n# Plot security price candlesticks\ncandlestick = go.Candlestick(x=history.index,\nopen=history['open'],\nhigh=history['high'],\nlow=history['low'],\nclose=history['close'],\nname='Price')\nlayout = go.Layout(title=go.layout.Title(text=f'{symbol.value} Trades'),\nxaxis_title='Date',\nyaxis_title='Price',\nxaxis_rangeslider_visible=False,\nheight=600)\nfig = go.Figure(data=[candlestick], layout=layout)\n\n# Plot buys\nfig.add_trace(go.Scatter(\nx=order_data.buy_fill_times,\ny=order_data.buy_fill_prices,\nmarker=go.scatter.Marker(color='aqua', symbol='triangle-up', size=10),\nmode='markers',\nname='Buys',\n))\n\n# Plot sells\nfig.add_trace(go.Scatter(\nx=order_data.sell_fill_times,\ny=order_data.sell_fill_prices,\nmarker=go.scatter.Marker(color='indigo', symbol='triangle-down', size=10),\nmode='markers',\nname='Sells',\n))\n\nfig.show()Note: The preceding plots only show the last fill of each trade. If your trade has partial fills, the plots only display the last fill.\n\n### Plot Charts\n\nFollow these steps to plot the equity curve, benchmark, and drawdown of a live algorithm:\n\nGet the live algorithm instance.live_algorithm = api.read_live_algorithm(project_id, deploy_id)The following table provides links to documentation that explains how to get the project Id and deployment Id, depending on the platform you use:PlatformProject IdDeployment IdCloud PlatformGet Project IdGet Deployment IdLocal PlatformGet Project IdGet Deployment IdCLIGet Project IdGet the results of the live algorithm.results = live_algorithm.live_results.resultsGet the \"Strategy Equity\", \"Drawdown\", and \"Benchmark\"Chartobjects.equity_chart = results.charts[\"Strategy Equity\"]\ndrawdown_chart = results.charts[\"Drawdown\"]\nbenchmark_chart = results.charts[\"Benchmark\"]Get the \"Equity\", \"Equity Drawdown\", and \"Benchmark\"Seriesfrom the preceding charts.equity = equity_chart.series[\"Equity\"].values\ndrawdown = drawdown_chart.series[\"Equity Drawdown\"].values\nbenchmark = benchmark_chart.series[\"Benchmark\"].valuesCreate apandas.DataFramefrom the series values.df = pd.DataFrame({\n\"Equity\": pd.Series({value.TIME: value.CLOSE for value in equity}),\n\"Drawdown\": pd.Series({value.TIME: value.Y for value in drawdown}),\n\"Benchmark\": pd.Series({value.TIME: value.Y for value in benchmark})\n}).ffill()Plot the performance chart.# Create subplots to plot series on same/different plots\nfig, ax = plt.subplots(2, 1, figsize=(12, 12), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n\n# Plot the equity curve\nax[0].plot(df.index, df[\"Equity\"])\nax[0].set_title(\"Strategy Equity Curve\")\nax[0].set_ylabel(\"Portfolio Value ($)\")\n\n# Plot the benchmark on the same plot, scale by using another y-axis\nax2 = ax[0].twinx()\nax2.plot(df.index, df[\"Benchmark\"], color=\"grey\")\nax2.set_ylabel(\"Benchmark Price ($)\", color=\"grey\")\n\n# Plot the drawdown on another plot\nax[1].plot(df.index, df[\"Drawdown\"], color=\"red\")\nax[1].set_title(\"Drawdown\")\nax[1].set_xlabel(\"Time\")\nax[1].set_ylabel(\"%\")\n\nThe following table shows all the chart series you can plot:\n\n[Table - 8 rows]\n\n### Example\n\nExample 1: Read Live Algorithm Statistics\n\nThe following example reads the current running live algorithm's statistics in a jupyter notebook.\n\n// Load the necessary assemblies.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\nusing QuantConnect.Research;\n\n// Instantiate QuantBook instance for researching.\nvar qb = new QuantBook();\n\n// Get current running live algorithm list in the current project.\nvar liveAlgorithms = api.ListLiveAlgorithms(AlgorithmStatus.Running)\nvar deployId = liveAlgorithms.Algorithms\n.Single(x => x.ProjectId == qb.ProjectId)\n.DeployId;\nvar liveAlgorithm = api.ReadLiveAlgorithm(qb.ProjectId, deployId);\n\n// Obtain the live algorithm statistics.\nConsole.WriteLine(backtest.RuntimeStatistics.ToString());# Instantiate QuantBook instance for researching.\nqb = QuantBook()\n\n# Get current running live algorithm list in the current project.\nlive_algorithms = api.list_live_algorithms(AlgorithmStatus.RUNNING)\ndeploy_id = next(\n[x for x in live_algorithms.algorithms if x.project_id == qb.project_id]\n).deploy_id\nlive_algorithm = api.read_live_algorithm(project_id, deploy_id)\n\n# Obtain the live algorithm statistics.\nprint(live_algorithm.runtime_statistics)",
    "metadata": {
      "has_code": false,
      "has_tables": true,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Meta Analysis > Live Analysis",
      "section_number": "10.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    },
    "table_0": "| Platform | Project Id | Deployment Id |\n| --- | --- | --- |\n| Cloud Platform | Get Project Id | Get Deployment Id |\n| Local Platform | Get Project Id | Get Deployment Id |\n| CLI | Get Project Id |  |",
    "table_1": "| Chart | Series | Description |\n| --- | --- | --- |\n| Strategy Equity | Equity | Time series of the equity curve |\n| Daily Performance | Time series of daily percentage change |  |\n| Capacity | Strategy Capacity | Time series ofstrategy capacitysnapshots |\n| Drawdown | Equity Drawdown | Time series of equity peak-to-trough value |\n| Benchmark | Benchmark | Time series of thebenchmarkclosing price (SPY, by default) |\n| Exposure | SecurityType- Long Ratio | Time series of the overall ratio ofSecurityTypelong positions of the whole portfolio if anySecurityTypeis ever in the universe |\n| SecurityType- Short Ratio | Time series of the overall ratio ofSecurityTypeshort position of the whole portfolio if anySecurityTypeis ever in the universe |  |\n| Custom Chart | Custom Series | Time series of aSeriesin acustom chart |"
  },
  {
    "id": "10.5",
    "title": "Live Deployment Automation",
    "level": 2,
    "path": "Meta Analysis > Live Deployment Automation",
    "content": "### Introduction\n\nThis page explains how useQuantConnect APIin an interactive notebook to deploy and stop a set of live trading algorithms in QC Cloud.\n\n### Get Project Ids\n\nTo automate live deployments for multiple projects,save the projects under a single directoryin QuantConnect Cloud. This tutorial assumes you save all the projects under a/Livedirectory.\n\nFollow the below steps to get the project Ids of all projects under the/Livedirectory:\n\nOpen a research notebook.Load the assembly files and data types in their own cell.#load \"../Initialize.csx\"Import the data types.#load \"../QuantConnect.csx\"\n#r \"../Microsoft.Data.Analysis.dll\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing QuantConnect.Indicators;\nusing Microsoft.Data.Analysis;Call thelist_projectsmethod to get a list of all project responses.list_project_response = api.list_projects()var listProjectResponse = api.ListProjects();Obtain the project Ids for the projects in/Livedirectory.project_ids = [\nproject.project_id for project in list_project_response.projects\nif project.name.split(\"/\")[0] == \"Live\"\n]var projectIds = listProjectResponse.Projects\n.Where(project => project.Name.Split('/').First() == \"Live\")\n.Select(project => project.ProjectId)\n.ToList();\n\n### Deploy Live Algorithms\n\nFollow these steps to progromatically deploy the preceding projects with the QuantConnect API:\n\nCompile all the projects and cache the compilation Ids with a dictionary.compile_id_by_project_id = {}\nfor project_id in project_ids:\ncompile_response = api.create_compile(project_id)\nif not compile_response.success:\nprint(f\"Errors compiling project {project_id}: \\n{compile_response.errors}\")\nelse:\ncompile_id_by_project_id[project_id] = compile_response.compile_idvar compileIdsByProjectIds = new Dictionary<int, string>();\nforeach (var projectId in projectIds)\n{\nvar compileResponse = api.CreateCompile(projectId);\nif (!compileResponse.Success)\n{\nConsole.WriteLine($\"Errors compiling project {projectId}: \\n{compileResponse.Errors}\");\n}\nelse\n{\ncompileIdsByProjectIds[projectId] = compileResponse.CompileId;\n}\n}Get the Ids of all the live nodes that are available and sort them by their speed.live_nodes = []\nnode_response = api.read_project_nodes(project_ids[0])\n\nif not node_response.success:\nprint(f\"Error getting nodes: \\n{node_response.errors}\")\nelse:\nnodes = sorted(\n[node for node in node_response.nodes.live_nodes if not node.busy],\nkey=lambda node: node.speed,\nreverse=True\n)\nnode_ids = [node.id for node in nodes]var liveNodes = new List<string>();\nvar nodeResponse = api.ReadProjectNodes(projectIds[0]);\n\nif (!nodeResponse.Success)\n{\nConsole.WriteLine($\"Error getting nodes: \\n{nodeResponse.Errors}\");\n}\nelse\n{\nnodesIds = nodeResponse.Nodes.LiveNodes\n.Where(node => !node.Busy)\n.OrderByDescending(node => node.Speed)\n.Select(node => node.Id)\n.ToList();\n}Check the length ofnode_idsnodeIdsis greater than 0 to ensure there are live nodes available.Configure your brokerage and environment.For example, to use the QC paper brokerage, run:base_live_algorithm_settings = {\n\"id\": \"QuantConnectBrokerage\",\n\"user\": \"\",\n\"password\": \"\",\n\"environment\": \"paper\",\n\"account\": \"\"\n}\nversion_id = \"-1\" # Master branchvar baseLiveAlgorithmSettings = new Dictionary<string, object>\n{\n{\"id\", \"QuantConnectBrokerage\"},\n{\"user\", \"\"},\n{\"password\", \"\"},\n{\"environment\", \"paper\"},\n{\"account\", \"\"}\n};\n// Master branch\nvar versionId = \"-1\";Deploy the projects and cache the project Ids of the successful deployments.deployed_ids = []\n\nfor project_id, compile_id in compile_id_by_project_id.items():\n# Deploy live algorithm\nnode_id = node_ids[len(deployed_ids)] # Fastest node available\nlive_response = api.create_live_algorithm(project_id, compile_id, node_id, base_live_algorithm_settings, version_id)\n\nif not live_response.success:\nprint(f\"Errors deploying project {project_id}: \\n{live_response.errors}\")\nelse:\nprint(f\"Deployed {project_id}\")\ndeployed_ids.append(project_id)var deployedIds = new List<int>();\n\nforeach (var kvp in compileIdsByProjectIds)\n{\nvar projectId = kvp.Key;\nvar compileId = kvp.Value;\n\n// Deploy live algorithm\nvar nodeId = nodeIds[deployedIds.Count()];\nvar liveResponse = api.CreateLiveAlgorithm(projectId, compileId, nodeId, baseLiveAlgorithmSettings, versionId);\n\nif (!liveResponse.Success)\n{\nConsole.WriteLine($\"Errors deploying project {projectId}: \\n{liveResponse.Errors}\");\n}\nelse\n{\nConsole.WriteLine($\"Deployed {projectId}\");\ndeployedIds.Add(projectId);\n}\n}\n\n### Stop Live Algorithms\n\nTo stop multiple live algorithms from an interactive notebook through the QuantConnect API, call theapi.StopLiveAlgorithmapi.stop_live_algorithmmethod with each project Id.\n\nfor project_id in project_ids:\nstop_response = api.stop_live_algorithm(project_id)\nif not stop_response.success:\nprint(f\"Errors stopping live algorithm {project_id}: \\n{stop_response.errors}\")\nelse:\nprint(f\"Successfully stopped live algorithm {project_id}\")foreach (var projectId in projectIds)\n{\nvar stopResponse = api.StopLiveAlgorithm(projectId);\nif (!stopResponse.Success)\n{\nConsole.WriteLine($\"Errors stopping live algorithm {projectId}: \\n{stopResponse.Errors}\");\n}\nelse\n{\nConsole.WriteLine($\"Successfully stopped live algorithm {projectId}\");\n}\n}\n\n### Examples\n\nExample 1: Create New GPU Deployment\n\nThe following example will create a new live algorithm deployment using a GPU live node with the Interactive Brokers in a jupyter notebook. It can help with a streamline deployment.\n\n// Load the necessary assemblies.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Api;\nusing QuantConnect.Research;\n\n// Instantiate QuantBook instance for researching.\nvar qb = new QuantBook();\n\n// Get all the nodes available in the current project.\nvar projectNodes = api.ReadProjectNodes(qb.ProjectId);\n// Obtain the most powerful live GPU node which is idling.\nvar liveNodeId = projectNodes.Nodes.LiveNodes\n.Where(x => x.HasGPU && !x.Busy)\n.MaxBy(x => x.CpuCount)\n.Id;\n\n// Compile the project before deploying.\nvar compilation = api.CreateCompile(qb.project_id);\nvar compileId = compilation.CompileId;\n\n// Deploy the live algorithm with the brokerage settings.\nvar brokerageSettings = new Dictionary<string, object>() {\n{\"id\", \"InteractiveBrokersBrokerage\"},\n{\"ib-user-name\": \"userName\"},\n{\"ib-account\": \"accountNumber\"},\n{\"ib-password\": \"password\"},\n{\"ib-weekly-restart-utc-time\": \"00:00:00\"}\n}\nvar result = api.CreateLiveAlgorithm(qb.ProjectId, compileId, liveNodeId, brokerageSettings);# Instantiate QuantBook instance for researching.\nqb = QuantBook()\n\n# Get all the nodes available in the current project.\nproject_nodes = api.read_project_nodes(qb.project_id)\n# Obtain the most powerful live GPU node which is idling.\nlive_node_id = max(\n[x for x in project_nodes.nodes.live_nodes if x.has_gpu and not x.busy],\nkey=lambda x: x.cpu_count\n).id\n\n# Compile the project before deploying.\ncompilation = api.create_compile(qb.project_id)\ncompile_id = compilation.compile_id\n\n# Deploy the live algorithm with the brokerage settings.\nbrokerage_settings = {\n\"id\": \"InteractiveBrokersBrokerage\",\n\"ib-user-name\": \"user-name\",\n\"ib-account\": \"account-number\",\n\"ib-password\": \"password\",\n\"ib-weekly-restart-utc-time\": \"00:00:00\"\n}\nresult = api.CreateLiveAlgorithm(qb.project_id, compile_id, live_node_id, brokerage_settings)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "10",
      "breadcrumb": "Meta Analysis > Live Deployment Automation",
      "section_number": "10.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11",
    "title": "Applying Research",
    "level": 1,
    "path": "Applying Research",
    "content": "",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": null,
      "breadcrumb": "Applying Research",
      "section_number": "11",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.1",
    "title": "Key Concepts",
    "level": 2,
    "path": "Applying Research > Key Concepts",
    "content": "### Introduction\n\nThe ultimate goal of research is to produce a strategy that you can backtest and eventually trade live. Once you've developed a hypothesis that you're confident in, you can start working towards exporting your research into backtesting. To export the code, you need to replaceQuantBook()withselfand replace theQuantBook methodswith theirQCAlgorithmcounterparts.\n\n### Workflow\n\nImagine that you've developed the following hypothesis: stocks that are below 1 standard deviation of their 30-day mean are due to revert and increase in value. The following Research Environment code picks out such stocks from a preselected basket of stocks:\n\nimport numpy as np\nqb = QuantBook()\n\nsymbols = {}\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\nfor i in range(len(assets)):\nsymbols[assets[i]] = qb.add_equity(assets[i],Resolution.MINUTE).symbol\n\n# Fetch history on our universe\ndf = qb.history(qb.securities.keys(), 30, Resolution.DAILY)\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Calculate the truth value of the most recent price being less than 1 std away from the mean\nclassifier = df.le(df.mean().subtract(df.std())).tail(1)\n\n# Get indexes of the True values\nclassifier_indexes = np.where(classifier)[1]\n\n# Get the Symbols for the True values\nclassifier = classifier.transpose().iloc[classifier_indexes].index.values\n\n# Get the std values for the True values (used for magnitude)\nmagnitude = df.std().transpose()[classifier_indexes].values\n\n# Zip together to iterate over later\nselected = zip(classifier, magnitude)\n\nOnce you are confident in your hypothesis, you can export this code into the backtesting environment. The algorithm will ultimately go long on the stocks that pass the classifier logic. One way to accommodate this model into a backtest is to create aScheduled Eventthat uses the model to pick stocks and place orders.\n\ndef initialize(self) -> None:\nself.set_start_date(2014, 1, 1)\nself.set_cash(1000000)\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(EqualWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"IEF\", \"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\nself.symbols = {}\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.symbols[self.assets[i]] = self.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Set the Scheduled Event method\nself.schedule.on(self.date_rules.every(DayOfWeek.MONDAY), self.time_rules.after_market_open(\"IEF\", 1), self.every_day_after_market_open)\n\nNow that theInitializeinitializemethod of the algorithm is set, export the model into the Scheduled Event method. You just need to switchqbwithselfand replaceQuantBookmethods with theirQCAlgorithmcounterparts. In this example, you don't need to switch any methods because the model only uses methods that exist inQCAlgorithm.\n\ndef every_day_after_market_open(self):\nqb = self\n# Fetch history on our universe\ndf = qb.history(qb.securities.keys(), 5, Resolution.DAILY)\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Calculate the truth value of the most recent price being less than 1 std away from the mean\nclassifier = df.le(df.mean().subtract(df.std())).tail(1)\n\n# Get indexes of the True values\nclassifier_indexes = np.where(classifier)[1]\n\n# Get the Symbols for the True values\nclassifier = classifier.transpose().iloc[classifier_indexes].index.values\n\n# Get the std values for the True values (used for magnitude)\nmagnitude = df.std().transpose()[classifier_indexes].values\n\n# Zip together to iterate over later\nselected = zip(classifier, magnitude)\n\n# ==============================\n\ninsights = []\n\nfor symbol, magnitude in selected:\ninsights.append(Insight.price(symbol, timedelta(days=5), InsightDirection.UP, magnitude))\n\nself.emit_insights(insights)\n\nWith the Research Environment model now in the backtesting environment, you can further analyze its performance with itsbacktesting metrics. If you are confident in the backtest, you can eventually live trade this strategy.\n\nTo view full examples of this Research to Production workflow, see the examples in the menu.\n\n### Contribute Tutorials\n\nIf you contribute Research to Production tutorials, you'll get the following benefits:\n\nAQCCrewardYou'll learn the Research to Production methodology to improve your own strategy research and developmentYour contribution will be featured in the community forum\n\nTo view the topics the community wants Research to Production tutorials for, seethe issues with the WishList tag in the Research GitHub repository. If you find a topic you want to create a tutorial for, make a pull request to the repository with your tutorial and we will review it.\n\nTo request new tutorial topics,contact us.",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Key Concepts",
      "section_number": "11.1",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.2",
    "title": "Mean Reversion",
    "level": 2,
    "path": "Applying Research > Mean Reversion",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Mean Reversion hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nImagine that we've developed the following hypothesis: stocks that are below 1 standard deviation of their 30-day-mean are due to revert and increase in value, statistically around 85% chance if we assume the return series is stationary and the price series is a Random Process. We've developed the following code in research to pick out such stocks from a preselected basket of stocks.\n\n### Import Libraries\n\nLoad the required assembly files and data types.\n\nWe'll need to import libraries to help with data processing. Importnumpyandscipylibraries by the following:\n\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing System;\nusing MathNet.Numerics.Distributions;import numpy as np\nfrom scipy.stats import norm, zscore\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.var qb = new QuantBook();qb = QuantBook()Select the desired tickers for research.var assets = new List<string>() {\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};assets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]Call theAddEquityadd_equitymethod with the tickers, and their corresponding resolution.foreach(var ticker in assets){\nqb.AddEquity(ticker, Resolution.Minute);\n}for i in range(len(assets)):\nqb.add_equity(assets[i],Resolution.MINUTE)If you do not pass a resolution argument,Resolution.MinuteResolution.MINUTEis used by default.Call theHistoryhistorymethod withqb.Securities.Keysqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.var history = qb.History(qb.Securities.Keys, new DateTime(2021, 1, 1), new DateTime(2021, 12, 31), Resolution.Daily);history = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data to get an extent of the signal on how much the stock is deviated from its norm for each ticker.\n\nExtract close prices for eachSymbolfromSlicedata.Select the close column and then call theunstackmethod.var closes = new Dictionary<Symbol, List<Decimal>>();\nforeach(var slice in history){\nforeach(var symbol in slice.Keys){\nif(!closes.ContainsKey(symbol)){\ncloses.Add(symbol, new List<Decimal>());\n}\ncloses[symbol].Add(slice.Bars[symbol].Close);\n}\n}df = history['close'].unstack(level=0)Get the 30-day rolling mean, standard deviation series, z-score and filtration for eachSymbol.Calculate the truth value of the most recent price being less than 1 standard deviation away from the mean price.var rollingMean = new Dictionary<Symbol, List<double>>();\nvar rollingStd = new Dictionary<Symbol, List<double>>();\nvar filter = new Dictionary<Symbol, List<bool>>();\nvar zScore = new Dictionary<Symbol, List<double>>();\nforeach(var kvp in closes)\n{\nvar symbol = kvp.Key;\nif(!rollingMean.ContainsKey(symbol)){\nrollingMean.Add(symbol, new List<double>());\nrollingStd.Add(symbol, new List<double>());\nzScore.Add(symbol, new List<double>());\nfilter.Add(symbol, new List<bool>());\n}\nfor (int i=30; i < closes.Values.ElementAt(0).Count; i++)\n{\nvar slice = kvp.Value.Skip(i).Take(30);\nrollingMean[symbol].Add(decimal.ToDouble(slice.Average()));\nrollingStd[symbol].Add(Math.Sqrt(slice.Average(v => Math.Pow(decimal.ToDouble(v-slice.Average()), 2))));\nzScore[symbol].Add((decimal.ToDouble(closes[symbol][i]) - rollingMean[symbol].Last()) / rollingStd[symbol].Last());\nfilter[symbol].Add(zScore[symbol].Last() < -1);\n}\n}classifier = df.le(df.rolling(30).mean() - df.rolling(30).std())Calculate the expected return and its probability, then calculate the weight.Get the z-score for the True values, then compute the expected return and probability (used for Insight magnitude and confidence).var magnitude = new Dictionary<Symbol, List<double>>();\nvar confidence = new Dictionary<Symbol, List<double>>();\nvar weights = new Dictionary<Symbol, List<double>>();\nforeach(var kvp in rollingMean)\n{\nvar symbol = kvp.Key;\nif(!magnitude.ContainsKey(symbol)){\nmagnitude.Add(symbol, new List<double>());\nconfidence.Add(symbol, new List<double>());\nweights.Add(symbol, new List<double>());\n}\nfor (int i=1; i < rollingMean.Values.ElementAt(0).Count; i++)\n{\nmagnitude[symbol].Add(-zScore[symbol][i] * rollingStd[symbol][i] / decimal.ToDouble(closes[symbol][i-1]));\nconfidence[symbol].Add(Normal.CDF(0, 1, -zScore[symbol][i]));\n// Filter if trade or not\nvar trade = filter[symbol][i] ? 1d : 0d;\nweights[symbol].Add(trade * Math.Max(confidence[symbol].Last() - 1 / (magnitude[symbol].Last() + 1), 0));\n}\n}z_score = df.apply(zscore)[classifier]\nmagnitude = -z_score * df.rolling(30).std() / df.shift(1)\nconfidence = (-z_score).apply(norm.cdf)Convert the weights into 2-d array.Callfillnato fill NaNs with 0.double[,] weight = new double[weights.Values.ElementAt(0).Count, weights.Count];\nint j = 0;\nforeach(var symbol in weights.Keys){\nfor(int i=0; i < weights[symbol].Count; i++){\nweight[i, j] = weights[symbol][i];\n}\nj++;\n}magnitude.fillna(0, inplace=True)\nconfidence.fillna(0, inplace=True)Get our trading weight, we'd take a long only portfolio and normalized to total weight = 1.public double[,] Normalize(double[,] array)\n{\nfor(int i=0; i < array.GetLength(0); i++)\n{\nvar sum = 0.0;\nfor (int j=0; j < array.GetLength(1); j++)\n{\nsum += array[i, j];\n}\nif (sum == 0.0) continue;\nfor (int j=0; j < array.GetLength(1); j++)\n{\narray[i, j] = array[i, j] / sum;\n}\n}\n\nreturn array;\n}\nweight = Normalize(weight);weight = confidence - 1 / (magnitude + 1)\nweight = weight[weight > 0].fillna(0)\nsum_ = np.sum(weight, axis=1)\nfor i in range(weight.shape[0]):\nif sum_[i] > 0:\nweight.iloc[i] = weight.iloc[i] / sum_[i]\nelse:\nweight.iloc[i] = 0\nweight = weight.iloc[:-1]\n\n### Test Hypothesis\n\nWe would test the performance of this strategy. To do so, we would make use of the calculated weight for portfolio optimization.\n\nConvert close price to 2-d array.double[,] close = new double[closes.Values.ElementAt(0).Count, closes.Count];\nint j = 0;\nforeach(var symbol in closes.Keys){\nfor(int i=0; i < closes[symbol].Count; i++){\nclose[i, j] = decimal.ToDouble(closes[symbol][i]);\n}\nj++;\n}Get the total daily return series.var totalValue = new List<double>{1.0};\nvar dailySum = 0.0;\nfor(int i=0; i < weight.GetLength(0) - 1; i++)\n{\ntotalValue.Add(totalValue.Last() * (1 + dailySum));\ndailySum = 0.0;\nfor (int j=0; j < weight.GetLength(1); j++)\n{\nif (close[i, j] != 0 && double.IsFinite(close[i+1, j]) && double.IsFinite(close[i, j]) && double.IsFinite(weight[i, j]))\n{\ndailySum += weight[i, j] * (close[i+1, j] - close[i, j]) / close[i, j];\n}\n}\n}ret = pd.Series(index=range(df.shape[0] - 1))\nfor i in range(df.shape[0] - 1):\nret[i] = weight.iloc[i] @ df.pct_change().iloc[i + 1].TCallcumprodto get the cumulative return.total_ret = (ret + 1).cumprod()Set index for visualization.total_ret.index = weight.indexDisplay the result.for(int i=0; i < totalValue.Count; i=i+5)\n{\nConsole.WriteLine(\"Portfolio Value in Day{0}: {1}\", i, totalValue[i]);\n}total_ret.plot(title='Strategy Equity Curve', figsize=(15, 10))\nplt.show()\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into research is to create a scheduled event which uses our model to pick stocks and goes long.\n\nprivate List<string> _asset = new List<string>{\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n\npublic override void Initialize()\n{\n// 1. Required: Five years of backtest history\nSetStartDate(2014, 1, 1);\n\n// 2. Required: Alpha Streams Models:\nSetBrokerageModel(BrokerageName.AlphaStreams);\n\n// 3. Required: Significant AUM Capacity\nSetCash(1000000);\n\n// 4. Required: Benchmark to SPY\nSetBenchmark(\"SPY\");\n\nSetPortfolioConstruction(new InsightWeightingPortfolioConstructionModel());\nSetExecution(new ImmediateExecutionModel());\n\n// Add Equity ------------------------------------------------\nforeach(var ticker in _asset)\n{\nAddEquity(ticker, Resolution.Minute);\n}\n\n// Set Scheduled Event Method For Our Model\nSchedule.On(DateRules.EveryDay(),\nTimeRules.BeforeMarketClose(\"SHY\", 5),\nEveryDayBeforeMarketClose);\n}def initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(InsightWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE)\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SHY\", 5), self.every_day_before_market_close)\n\nNow we export our model into the scheduled event method. We will removeqband replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\nprivate void EveryDayBeforeMarketClose()\n{\n// Fetch history on our universe\nvar history = History(Securities.Keys, 30, Resolution.Daily);\nif (history.Count() < 0) return;\n\n// Extract close prices for each Symbol from Slice data\nvar closes = new Dictionary<Symbol, List<Decimal>>();\nforeach(var slice in history){\nforeach(var symbol in slice.Keys){\nif(!closes.ContainsKey(symbol)){\ncloses.Add(symbol, new List<Decimal>());\n}\ncloses[symbol].Add(slice.Bars[symbol].Close);\n}\n}\n\n// Get the 30-day rolling mean, standard deviation series, z-score and filtration for each Symbol\nvar rollingMean = new Dictionary<string, double>();\nvar rollingStd = new Dictionary<string, double>();\nvar filter = new Dictionary<string, bool>();\nvar zScore = new Dictionary<string, double>();\nforeach(var kvp in closes)\n{\nvar symbol = kvp.Key;\nif(!rollingMean.ContainsKey(symbol)){\nrollingMean.Add(symbol, decimal.ToDouble(kvp.Value.Average()));\nrollingStd.Add(symbol, Math.Sqrt(kvp.Value.Average(v => Math.Pow(decimal.ToDouble(v-kvp.Value.Average()), 2))));\nzScore.Add(symbol, (decimal.ToDouble(kvp.Value.Last()) - rollingMean[symbol]) / rollingStd[symbol]);\nfilter.Add(symbol, zScore[symbol] < -1);\n}\n}\n\n// Calculate the expected return and its probability, then calculate the weight\nvar magnitude = new Dictionary<Symbol, double>();\nvar confidence = new Dictionary<Symbol, double>();\nvar weights = new Dictionary<Symbol, double>();\nforeach(var kvp in rollingMean)\n{\nvar symbol = kvp.Key;\nif(!magnitude.ContainsKey(symbol)){\nmagnitude.Add(symbol, -zScore[symbol] * rollingStd[symbol] / decimal.ToDouble(closes[symbol].Last()));\nconfidence.Add(symbol, Normal.CDF(0, 1, -zScore[symbol]));\n// Filter if trade or not\nvar trade = filter[symbol] ? 1d : 0d;\nweights.Add(symbol, trade * Math.Max(confidence[symbol] - 1 / (magnitude[symbol] + 1), 0));\n}\n}\n\n// Normalize the weights, then emit insights\nvar sum = weights.Sum(x => x.Value);\nif (sum == 0) return;\n\nforeach(var kvp in weights)\n{\nvar symbol = kvp.Key;\nweights[symbol] = kvp.Value / sum;\n\nvar insight = new Insight(symbol, TimeSpan.FromDays(1), InsightType.Price, InsightDirection.Up, magnitude[symbol], confidence[symbol], null, weights[symbol]);\nEmitInsights(insight);\n}\n}def every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\ndf = qb.history(list(qb.securities.keys()), 30, Resolution.DAILY)\nif df.empty: return\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Calculate the truth value of the most recent price being less than 1 std away from the mean\nclassifier = df.le(df.mean().subtract(df.std())).iloc[-1]\nif not classifier.any(): return\n\n# Get the z-score for the True values, then compute the expected return and probability\nz_score = df.apply(zscore)[[classifier.index[i] for i in range(classifier.size) if classifier.iloc[i]]]\n\nmagnitude = -z_score * df.std() / df\nconfidence = (-z_score).apply(norm.cdf)\n\n# Get the latest values\nmagnitude = magnitude.iloc[-1].fillna(0)\nconfidence = confidence.iloc[-1].fillna(0)\n\n# Get the weights, then zip together to iterate over later\nweight = confidence - 1 / (magnitude + 1)\nweight = weight[weight > 0].fillna(0)\nsum_ = np.sum(weight)\nif sum_ > 0:\nweight = (weight) / sum_\nselected = zip(weight.index, magnitude, confidence, weight)\nelse:\nreturn\n\n# ==============================\n\ninsights = []\n\nfor symbol, magnitude, confidence, weight in selected:\ninsights.append( Insight.price(symbol, timedelta(days=1), InsightDirection.UP, magnitude, confidence, None, weight) )\n\nself.emit_insights(insights)\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\n// Load the required assembly files and data types.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing System;\nusing MathNet.Numerics.Distributions;\n\n// Instantiate a QuantBook\nvar qb = new QuantBook();\n// Select the desired tickers for research.\nvar assets = new List<string>() {\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n// Call the AddEquity method with the tickers, and their corresponding resolution.\nforeach(var ticker in assets){\nqb.AddEquity(ticker, Resolution.Minute);\n}\n\n// Call the History method with qb.Securities.Keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nvar history = qb.History(qb.Securities.Keys, new DateTime(2020, 1, 1), new DateTime(2022, 1, 1), Resolution.Daily);\n\n// Extract close prices for each Symbol from Slice data\nvar closes = new Dictionary<Symbol, List<Decimal>>();\nforeach(var slice in history){\nforeach(var symbol in slice.Keys){\nif(!closes.ContainsKey(symbol)){\ncloses.Add(symbol, new List<Decimal>());\n}\ncloses[symbol].Add(slice.Bars[symbol].Close);\n}\n}\n\n// Get the 30-day rolling mean, standard deviation series, z-score and filtration for each Symbol\nvar rollingMean = new Dictionary<Symbol, List<double>>();\nvar rollingStd = new Dictionary<Symbol, List<double>>();\nvar filter = new Dictionary<Symbol, List<bool>>();\nvar zScore = new Dictionary<Symbol, List<double>>();\nforeach(var kvp in closes)\n{\nvar symbol = kvp.Key;\nif(!rollingMean.ContainsKey(symbol)){\nrollingMean.Add(symbol, new List<double>());\nrollingStd.Add(symbol, new List<double>());\nzScore.Add(symbol, new List<double>());\nfilter.Add(symbol, new List<bool>());\n}\nfor (int i=30; i < closes.Values.ElementAt(0).Count; i++)\n{\nvar slice = kvp.Value.Skip(i).Take(30);\nrollingMean[symbol].Add(decimal.ToDouble(slice.Average()));\nrollingStd[symbol].Add(Math.Sqrt(slice.Average(v => Math.Pow(decimal.ToDouble(v-slice.Average()), 2))));\nzScore[symbol].Add((decimal.ToDouble(closes[symbol][i]) - rollingMean[symbol].Last()) / rollingStd[symbol].Last());\nfilter[symbol].Add(zScore[symbol].Last() < -1);\n}\n}\n\n// Calculate the expected return and its probability, then calculate the weight\nvar magnitude = new Dictionary<Symbol, List<double>>();\nvar confidence = new Dictionary<Symbol, List<double>>();\nvar weights = new Dictionary<Symbol, List<double>>();\nforeach(var kvp in rollingMean)\n{\nvar symbol = kvp.Key;\nif(!magnitude.ContainsKey(symbol)){\nmagnitude.Add(symbol, new List<double>());\nconfidence.Add(symbol, new List<double>());\nweights.Add(symbol, new List<double>());\n}\nfor (int i=1; i < rollingMean.Values.ElementAt(0).Count; i++)\n{\nmagnitude[symbol].Add(-zScore[symbol][i] * rollingStd[symbol][i] / decimal.ToDouble(closes[symbol][i]));\nconfidence[symbol].Add(Normal.CDF(0, 1, -zScore[symbol][i]));\n//Filter if trade or not\nvar trade = filter[symbol][i] ? 1d : 0d;\nweights[symbol].Add(trade * Math.Max(confidence[symbol].Last() - 1 / (magnitude[symbol].Last() + 1), 0));\n}\n}\n\n// Convert the weights into 2-d array\ndouble[,] weight = new double[weights.Values.ElementAt(0).Count, weights.Count];\nint j = 0;\nforeach(var symbol in weights.Keys){\nfor(int i=0; i < weights[symbol].Count; i++){\nweight[i, j] = weights[symbol][i];\n}\nj++;\n}\n\n// Normalize the weights\npublic double[,] Normalize(double[,] array)\n{\nfor(int i=0; i < array.GetLength(0); i++)\n{\nvar sum = 0.0;\nfor (int j=0; j < array.GetLength(1); j++)\n{\nsum += array[i, j];\n}\n\nif (sum == 0.0) continue;\nfor (int j=0; j < array.GetLength(1); j++)\n{\narray[i, j] = array[i, j] / sum;\n}\n}\n\nreturn array;\n}\nweight = Normalize(weight);\n\n// Convert close price to 2-d array\ndouble[,] close = new double[closes.Values.ElementAt(0).Count, closes.Count];\nint j = 0;\nforeach(var symbol in closes.Keys){\nfor(int i=0; i < closes[symbol].Count; i++){\nclose[i, j] = decimal.ToDouble(closes[symbol][i]);\n}\nj++;\n}\n\n// Get daily total forward return series\nvar totalValue = new List<double>{1.0};\nvar dailySum = 0.0;\nfor(int i=0; i < weight.GetLength(0) - 1; i++)\n{\ntotalValue.Add(totalValue.Last() * (1 + dailySum));\ndailySum = 0.0;\nfor (int j=0; j < weight.GetLength(1); j++)\n{\nif (close[i, j] != 0 && double.IsFinite(close[i+1, j]) && double.IsFinite(close[i, j]) && double.IsFinite(weight[i, j]))\n{\ndailySum += weight[i, j] * (close[i+1, j] - close[i, j]) / close[i, j];\n}\n}\n}\n\n// Print the result\nfor(int i=0; i < totalValue.Count; i=i+20)\n{\nConsole.WriteLine(\"Portfolio Value in Day{0}: {1}\", i, totalValue[i]);\n}from scipy.stats import norm, zscore\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nsymbols = {}\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Then store their Symbols. Resolution.Minute is used by default.\nfor i in range(len(assets)):\nsymbols[assets[i]] = qb.add_equity(assets[i], Resolution.MINUTE).symbol\n\n# Call the History method with qb.Securities.Keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.Keys, datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\ndf = history['close'].unstack(level=0)\n\n# Calculate the truth value of the most recent price being less than 1 standard deviation away from the mean price.\nclassifier = df.le(df.rolling(30).mean() - df.rolling(30).std())\n\n# Get the z-score for the True values, then compute the expected return and probability (used for Insight magnitude and confidence).\nz_score = df.apply(zscore)[classifier]\nmagnitude = -z_score * df.rolling(30).std() / df\nconfidence = (-z_score).apply(norm.cdf)\n\n# Call fillna to fill NaNs with 0\nmagnitude.fillna(0, inplace=True)\nconfidence.fillna(0, inplace=True)\n\n# Get our trading weight, we'd take a long only portfolio and normalized to total weight = 1\nweight = confidence - 1 / (magnitude + 1)\nweight = weight[weight > 0].fillna(0)\nsum_ = np.sum(weight, axis=1)\nfor i in range(weight.shape[0]):\nif sum_[i] > 0:\nweight.iloc[i] = weight.iloc[i] / sum_[i]\nelse:\nweight.iloc[i] = 0\nweight = weight.iloc[:-1]\n\n# Get the total daily return series\nret = pd.Series(index=range(df.shape[0] - 1))\nfor i in range(df.shape[0] - 1):\nret[i] = weight.iloc[i] @ df.pct_change().iloc[i + 1].T\n\n# Call cumprod to get the cumulative return\ntotal_ret = (ret + 1).cumprod()\n\n# Set index for visualization\ntotal_ret.index = weight.index\n\n# Plot the result\ntotal_ret.plot(title='Strategy Equity Curve', figsize=(15, 10))\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nusing MathNet.Numerics.Distributions;\n\nnamespace QuantConnect.Algorithm.Csharp\n{\npublic class MeanReversionDemo : QCAlgorithm\n{\nList<string> _asset = new List<string>{\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n\npublic override void Initialize()\n{\n// 1. Required: Five years of backtest history\nSetStartDate(2014, 1, 1);\n\n// 2. Required: Alpha Streams Models:\nSetBrokerageModel(BrokerageName.AlphaStreams);\n\n// 3. Required: Significant AUM Capacity\nSetCash(1000000);\n\n// 4. Required: Benchmark to SPY\nSetBenchmark(\"SPY\");\n\nSetPortfolioConstruction(new InsightWeightingPortfolioConstructionModel());\nSetExecution(new ImmediateExecutionModel());\n\n// Add Equity ------------------------------------------------\nforeach(var ticker in _asset)\n{\nAddEquity(ticker, Resolution.Minute);\n}\n\n// Set Scheduled Event Method For Our Model\nSchedule.On(DateRules.EveryDay(),\nTimeRules.BeforeMarketClose(\"SHY\", 5),\nEveryDayBeforeMarketClose);\n}\n\nprivate void EveryDayBeforeMarketClose()\n{\n// Fetch history on our universe\nvar history = History(Securities.Keys, 30, Resolution.Daily);\nif (history.Count() < 0) return;\n\n// Extract close prices for each Symbol from Slice data\nvar closes = new Dictionary<Symbol, List<Decimal>>();\nforeach(var slice in history){\nforeach(var symbol in slice.Keys){\nif(!closes.ContainsKey(symbol)){\ncloses.Add(symbol, new List<Decimal>());\n}\ncloses[symbol].Add(slice.Bars[symbol].Close);\n}\n}\n\n// Get the 30-day rolling mean, standard deviation series, z-score and filtration for each Symbol\nvar rollingMean = new Dictionary<string, double>();\nvar rollingStd = new Dictionary<string, double>();\nvar filter = new Dictionary<string, bool>();\nvar zScore = new Dictionary<string, double>();\nforeach(var kvp in closes)\n{\nvar symbol = kvp.Key;\nif(!rollingMean.ContainsKey(symbol)){\nrollingMean.Add(symbol, decimal.ToDouble(kvp.Value.Average()));\nrollingStd.Add(symbol, Math.Sqrt(kvp.Value.Average(v => Math.Pow(decimal.ToDouble(v-kvp.Value.Average()), 2))));\nzScore.Add(symbol, (decimal.ToDouble(kvp.Value.Last()) - rollingMean[symbol]) / rollingStd[symbol]);\nfilter.Add(symbol, zScore[symbol] < -1);\n}\n}\n\n// Calculate the expected return and its probability, then calculate the weight\nvar magnitude = new Dictionary<Symbol, double>();\nvar confidence = new Dictionary<Symbol, double>();\nvar weights = new Dictionary<Symbol, double>();\nforeach(var kvp in rollingMean)\n{\nvar symbol = kvp.Key;\nif(!magnitude.ContainsKey(symbol)){\nmagnitude.Add(symbol, -zScore[symbol] * rollingStd[symbol] / decimal.ToDouble(closes[symbol].Last()));\nconfidence.Add(symbol, Normal.CDF(0, 1, -zScore[symbol]));\n// Filter if trade or not\nvar trade = filter[symbol] ? 1d : 0d;\nweights.Add(symbol, trade * Math.Max(confidence[symbol] - 1 / (magnitude[symbol] + 1), 0));\n}\n}\n\n// Normalize the weights, then emit insights\nList<Insight> insights = new List<Insight>{};\n\nvar sum = weights.Sum(x => x.Value);\nif (sum == 0) return;\n\nforeach(var kvp in weights)\n{\nvar symbol = kvp.Key;\nweights[symbol] = kvp.Value / sum;\n\nvar insight = new Insight(symbol, TimeSpan.FromDays(1), InsightType.Price, InsightDirection.Up, magnitude[symbol], confidence[symbol], null, weights[symbol]);\nEmitInsights(insight);\n}\n}\n}\n}from scipy.stats import norm, zscore\n\nclass MeanReversionDemo(QCAlgorithm):\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(InsightWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SHY\", 5), self.every_day_before_market_close)\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\ndf = qb.history(list(qb.securities.keys()), 30, Resolution.DAILY)\nif df.empty: return\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Calculate the truth value of the most recent price being less than 1 std away from the mean\nclassifier = df.le(df.mean().subtract(df.std())).iloc[-1]\nif not classifier.any(): return\n\n# Get the z-score for the True values, then compute the expected return and probability\nz_score = df.apply(zscore)[[classifier.index[i] for i in range(classifier.size) if classifier.iloc[i]]]\n\nmagnitude = -z_score * df.std() / df\nconfidence = (-z_score).apply(norm.cdf)\n\n# Get the latest values\nmagnitude = magnitude.iloc[-1].fillna(0)\nconfidence = confidence.iloc[-1].fillna(0)\n\n# Get the weights, then zip together to iterate over later\nweight = confidence - 1 / (magnitude + 1)\nweight = weight[weight > 0].fillna(0)\nsum_ = np.sum(weight)\nif sum_ > 0:\nweight = (weight) / sum_\nselected = zip(weight.index, magnitude, confidence, weight)\nelse:\nreturn\n\n# ==============================\n\ninsights = []\n\nfor symbol, magnitude, confidence, weight in selected:\ninsights.append( Insight.price(symbol, timedelta(days=1), InsightDirection.UP, magnitude, confidence, None, weight) )\n\nself.emit_insights(insights)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Mean Reversion",
      "section_number": "11.2",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.3",
    "title": "Random Forest Regression",
    "level": 2,
    "path": "Applying Research > Random Forest Regression",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Random Forest Regression hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nWe've assumed the price data is a time series with some auto regressive property (i.e. its expectation is related to past price information). Therefore, by using past information, we could predict the next price level. One way to do so is by Random Forest Regression, which is a supervised machine learning algorithm where its weight and bias is decided in non-linear hyperdimension.\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing and machine learning. Importsklearn,numpyandmatplotliblibraries by the following:\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the desired tickers for research.symbols = {}\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]Call theAddEquityadd_equitymethod with the tickers, and their corresponding resolution. Then store theirSymbols.for i in range(len(assets)):\nsymbols[assets[i]] = qb.add_equity(assets[i],Resolution.MINUTE).symbolIf you do not pass a resolution argument,Resolution.MinuteResolution.MINUTEis used by default.Call thehistorymethod withqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.history = qb.history(qb.securities.keys(), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data as well as to build the ML model before testing the hypothesis. Our methodology is to use fractional differencing close price as the input data in order to (1) provide stationarity, and (2) retain sufficient extent of variance of the previous price information. We assume d=0.5 is the right balance to do so.\n\nSelect the close column and then call theunstackmethod.df = history['close'].unstack(level=0)Feature engineer the data as fractional differencing for input.input_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[1:]Shift the data for 1-step backward as training output result.output = df.shift(-1).iloc[:-1]Split the data into training and testing sets.splitter = int(input_.shape[0] * 0.8)\nX_train = input_.iloc[:splitter]\nX_test = input_.iloc[splitter:]\ny_train = output.iloc[:splitter]\ny_test = output.iloc[splitter:]Initialize a Random Forest Regressor.regressor = RandomForestRegressor(n_estimators=100, min_samples_split=5, random_state = 1990)Fit the regressor.regressor.fit(X_train, y_train)\n\n### Test Hypothesis\n\nWe would test the performance of this ML model to see if it could predict 1-step forward price precisely. To do so, we would compare the predicted and actual prices.\n\nPredict the testing set.predictions = regressor.predict(X_test)Convert result intoDataFrame.predictions = pd.DataFrame(predictions, index=y_test.index, columns=y_test.columns)Plot the result for comparison.for col in y_test.columns:\nplt.figure(figsize=(15, 10))\n\ny_test[col].plot(label=\"Actual\")\npredictions[col].plot(label=\"Prediction\")\n\nplt.title(f\"{col} Regression Result\")\nplt.legend()\nplt.show()\nplt.clf()For more plots, pleaseclone the projectand run the notebook.\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into backtest is to create a scheduled event which uses our model to predict the expected return. Since we could calculate the expected return, we'd use Mean-Variance Optimization for portfolio construction.\n\ndef initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(MeanVarianceOptimizationPortfolioConstructionModel(portfolio_bias = PortfolioBias.LONG,\nperiod=252))\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE)\n\n# Initialize the timer to train the Machine Learning model\nself._time = datetime.min\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SHY\", 5), self.every_day_before_market_close)\n\nWe'll also need to create a function to train and update our model from time to time.\n\ndef build_model(self) -> None:\n# Initialize the Random Forest Regressor\nself.regressor = RandomForestRegressor(n_estimators=100, min_samples_split=5, random_state = 1990)\n\n# Get historical data\nhistory = self.history(self.securities.keys(), 360, Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\ndf = history['close'].unstack(level=0)\n\n# Feature engineer the data for input.\ninput_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[1:].ffill().fillna(0)\n\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1].ffill().fillna(0)\n\n# Fit the regressor\nself.regressor.fit(input_, output)\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef every_day_before_market_close(self) -> None:\n# Retrain the regressor every month\nif self._time < self.time:\nself.BuildModel()\nself._time = Expiry.end_of_month(self.time)\n\nqb = self\n# Fetch history on our universe\ndf = qb.history(qb.securities.keys(), 2, Resolution.DAILY)\nif df.empty: return\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Feature engineer the data for input\ninput_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[-1].fillna(0).values.reshape(1, -1)\n\n# Predict the expected price\npredictions = self.regressor.predict(input_)\n\n# Get the expected return\npredictions = (predictions - df.iloc[-1].values) / df.iloc[-1].values\npredictions = predictions.flatten()\n\n# ==============================\n\ninsights = []\n\nfor i in range(len(predictions)):\ninsights.append( Insight.price(self.assets[i], timedelta(days=1), InsightDirection.UP, predictions[i]) )\n\nself.emit_insights(insights)\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Resolution.MINUTE is used by default.\nfor i in range(len(assets)):\nqb.add_equity(assets[i],Resolution.MINUTE).symbol\n\n# Call the History method with qb.securities.keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.Keys, datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\ndf = history['close'].unstack(level=0)\n\n# Feature engineer the data for input.\ninput_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[1:]\n\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1]\n\n# Split the data into training and testing sets.\nsplitter = int(input_.shape[0] * 0.8)\nX_train = input_.iloc[:splitter]\nX_test = input_.iloc[splitter:]\ny_train = output.iloc[:splitter]\ny_test = output.iloc[splitter:]\n\n# Initialize a Random Forest Regressor\nregressor = RandomForestRegressor(n_estimators=100, min_samples_split=5, random_state = 1990)\n\n# Fit the regressor\nregressor.fit(X_train, y_train)\n\n# Predict the testing set\npredictions = regressor.predict(X_test)\n\n# Convert result into DataFrame\npredictions = pd.DataFrame(predictions, index=y_test.index, columns=y_test.columns)\n\n# Plot the result for comparison\nfor col in y_test.columns:\nplt.figure(figsize=(15, 10))\n\ny_test[col].plot(label=\"Actual\")\npredictions[col].plot(label=\"Prediction\")\n\nplt.title(f\"{col} Regression Result\")\nplt.legend()\nplt.show()\nplt.clf()\n\nThe below code snippets concludes the algorithm set up.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nclass RandomForestRegressionDemo(QCAlgorithm):\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(MeanVarianceOptimizationPortfolioConstructionModel(Resolution.DAILY, PortfolioBias.LONG,\nperiod=5))\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Initialize the timer to train the Machine Learning model\nself.last_time = datetime.min\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SHY\", 5), self.every_day_before_market_close)\n\ndef build_model(self) -> None:\n# Initialize the Random Forest Regressor\nself.regressor = RandomForestRegressor(n_estimators=100, min_samples_split=5, random_state = 1990)\n\n# Get historical data\nhistory = self.history(self.securities.Keys, 360, Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\ndf = history['close'].unstack(level=0)\n\n# Feature engineer the data for input.\ninput_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[1:].ffill().fillna(0)\n\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1].ffill().fillna(0)\n\n# Fit the regressor\nself.regressor.fit(input_, output)\n\ndef every_day_before_market_close(self) -> None:\n# Retrain the regressor every week\nif self.last_time < self.time:\nself.build_model()\nself.last_time = Expiry.end_of_week(self.last_time)\n\nqb = self\n# Fetch history on our universe\ndf = qb.history(qb.securities.Keys, 2, Resolution.DAILY)\nif df.empty: return\n\n# Make all of them into a single time index.\ndf = df.close.unstack(level=0)\n\n# Feature engineer the data for input\ninput_ = df.diff() * 0.5 + df * 0.5\ninput_ = input_.iloc[-1].fillna(0).values.reshape(1, -1)\n\n# Predict the expected price\npredictions = self.regressor.predict(input_)\n\n# Get the expected return\npredictions = (predictions - df.iloc[-1].values) / df.iloc[-1].values\npredictions = predictions.flatten()\n\n# ==============================\n\ninsights = []\n\nfor i in range(len(predictions)):\ninsights.append( Insight.price(self.assets[i], timedelta(days=1), InsightDirection.UP, predictions[i]) )\n\nself.emit_insights(insights)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Random Forest Regression",
      "section_number": "11.3",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.4",
    "title": "Uncorrelated Assets",
    "level": 2,
    "path": "Applying Research > Uncorrelated Assets",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Uncorrelated Assets hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nAccording to Modern Portfolio Thoery, asset combinations with negative or very low correlation could have lower total portfolio variance given the same level of return. Thus, uncorrelated assets allows you to find a portfolio that will, theoretically, be more diversified and resilient to extreme market events. We're testing this statement in real life scenario, while hypothesizing a portfolio with uncorrelated assets could be a consistent portfolio. In this example, we'll compare the performance of 5-least-correlated-asset portfolio (proposed) and 5-most-correlated-asset portfolio (benchmark), both equal weighting.\n\n### Import Libraries\n\nLoad the required assembly files and data types.\n\nWe'll need to import libraries to help with data processing and visualization. Importnumpyandmatplotliblibraries by the following:\n\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing System;\nusing System.Linq;\nusing Accord.Statistics;import numpy as np\nfrom matplotlib import pyplot as plt\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.var qb = new QuantBook();qb = QuantBook()Select the desired tickers for research.var assets = new List<string>() {\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};assets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]Call theAddEquityadd_equitymethod with the tickers, and their corresponding resolution.foreach(var ticker in assets){\nqb.AddEquity(ticker, Resolution.Minute);\n}for i in range(len(assets)):\nqb.add_equity(assets[i],Resolution.MINUTE)If you do not pass a resolution argument,Resolution.MinuteResolution.MINUTEis used by default.Call theHistoryhistorymethod withqb.Securities.Keysqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.var history = qb.History(qb.Securities.Keys, new DateTime(2021, 1, 1), new DateTime(2021, 12, 31), Resolution.Daily);history = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data to get their correlation and select the least and most related ones.\n\nExtract daily return for eachSymbolfromSlicedata.Select the close column and then call theunstackmethod, then callpct_changeto compute the daily return.var returns = new Dictionary<string, List<Double>>();\nvar last = new Dictionary<string, Double>();\nforeach(var slice in history){\nforeach(var symbol in slice.Bars.Keys){\nif(!returns.ContainsKey(symbol)){\nreturns.Add(symbol, new List<Double>());\nlast.Add(symbol, (Double)slice.Bars[symbol].Close);\n}\nvar change = (Double) ((Double)slice.Bars[symbol].Close - last[symbol])/last[symbol];\nlast[symbol] = (Double)slice.Bars[symbol].Close;\nreturns[symbol].Add(change);\n}\n}returns = history['close'].unstack(level=0).pct_change().iloc[1:]Extract daily return for eachSymbolfromSlicedata.double[,] ret = new double[returns.Values.ElementAt(0).Count - 1, assets.Count];\nint k = 0;\nforeach(var kvp in returns)\n{\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count - 1; i++)\n{\nret[i, k] = returns[symbol][i + 1];\n}\nk++;\n}Write a function to obtain the least and most correlated 5 assets.public Dictionary<string, Double> GetCorrelations(double[,] returns){\n// Get correlation matrix\nvar corrMatrix = Measures.Correlation(ret);\n\n// Find the absolute sum correlation of the assets\nvar correlations = new Dictionary<string, Double>();\nfor(int i=0; i < corrMatrix.GetLength(0); i++)\n{\nvar symbol = assets[i];\nif(!correlations.ContainsKey(symbol)){\ncorrelations.Add(symbol, 0);\n}\nfor (int j=0; j < corrMatrix.GetLength(1); j++)\n{\nvar value_ = corrMatrix[i, j];\ncorrelations[symbol] += value_ >= 0 ? value_ : -value_;\n}\n}\n\nreturn correlations;\n}\n\nvar corr = GetCorrelations(ret);\nvar selected = corr.OrderBy(x => x.Value).Take(5);\nvar benchmark = corr.OrderBy(x => x.Value).TakeLast(5);def get_uncorrelated_assets(returns, num_assets):\n# Get correlation\ncorrelation = returns.corr()\n\n# Find assets with lowest and highest absolute sum correlation\nselected = []\nfor index, row in correlation.iteritems():\ncorr_rank = row.abs().sum()\nselected.append((index, corr_rank))\n\n# Sort and take the top num_assets\nsort_ = sorted(selected, key = lambda x: x[1])\nuncorrelated = sort_[:num_assets]\ncorrelated = sort_[-num_assets:]\n\nreturn uncorrelated, correlated\n\nselected, benchmark = get_uncorrelated_assets(returns, 5)\n\n### Test Hypothesis\n\nTo test the hypothesis: Our desired outcome would be a consistent and low fluctuation equity curve should be seen, as compared with benchmark.\n\nConstruct a equal weighting portfolio for the 5-uncorrelated-asset-portfolio and the 5-correlated-asset-portfolio (benchmark).double[,] portRet = new double[returns.Values.ElementAt(0).Count, 5];\nint j = 0;\nforeach(var kvp in selected){\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count; i++)\n{\nportRet[i, j] = returns[symbol][i] / 5;\n}\nj++;\n}\n\ndouble[,] benchRet = new double[returns.Values.ElementAt(0).Count, 5];\nj = 0;\nforeach(var kvp in benchmark){\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count; i++)\n{\nbenchRet[i, j] = returns[symbol][i] / 5;\n}\nj++;\n}port_ret = returns[[x[0] for x in selected]] / 5\nbench_ret = returns[[x[0] for x in benchmark]] / 5Get the Equity Return for both portfolios.Callcumprodto get the cumulative return.var totalValue = new List<double>{1.0};\nvar dailySum = 0.0;\nfor(int i=0; i < portRet.GetLength(0); i++)\n{\ntotalValue.Add(totalValue.Last() * (1 + dailySum));\ndailySum = 0.0;\nfor (int j=0; j < portRet.GetLength(1); j++)\n{\nif (double.IsFinite(portRet[i, j]))\n{\ndailySum += portRet[i, j];\n}\n}\n}\n\nvar totalValueBench = new List<double>{1.0};\nvar dailySumBench = 0.0;\nfor(int i=0; i < benchRet.GetLength(0); i++)\n{\ntotalValueBench.Add(totalValueBench.Last() * (1 + dailySumBench));\ndailySumBench = 0.0;\nfor (int j=0; j < benchRet.GetLength(1); j++)\n{\nif (double.IsFinite(benchRet[i, j]))\n{\ndailySumBench += benchRet[i, j];\n}\n}\n}total_ret = (np.sum(port_ret, axis=1) + 1).cumprod()\ntotal_ret_bench = (np.sum(bench_ret, axis=1) + 1).cumprod()Calculate the variance of the 2 portfolios.var returnPort = new List<double>();\nprevious = 0.0;\nfor(int i=0; i < totalValue.Count; i++)\n{\nvar current = totalValue[i];\nreturnPort.Add((current - previous) / previous);\nprevious = current;\n}\nvar varPort = Math.Sqrt(returnPort.Skip(1).Average(v=>Math.Pow(v-returnPort.Skip(1).Average(),2)));\n\nvar returnBench = new List<double>();\nprevious = 0.0;\nfor(int i=0; i < totalValueBench.Count; i++)\n{\nvar current = totalValueBench[i];\nreturnBench.Add((current - previous) / previous);\nprevious = current;\n}\nvar varBench = Math.Sqrt(returnBench.Skip(1).Average(v=>Math.Pow(v-returnBench.Skip(1).Average(),2)));Print the result.Plot the result.Console.WriteLine(\"Portfolio Return: {0}, Variance: {1}\", (totalValue.Last() - totalValue.First())/totalValue.First(), varPort);\nConsole.WriteLine(\"Benchmark Return: {0}, Variance: {1}\", (totalValueBench.Last() - totalValueBench.First())/totalValueBench.First(), varBench);plt.figure(figsize=(15, 10))\ntotal_ret.plot(label='Proposed')\ntotal_ret_bench.plot(label='Benchmark')\nplt.title('Equity Curve')\nplt.legend()\nplt.show()\n\n-image\n\nWe can clearly see from the results, the proposed uncorrelated-asset-portfolio has a lower variance/fluctuation, thus more consistent than the benchmark. This proven our hypothesis.\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into research is to create a scheduled event which uses our model to pick stocks and goes long.\n\nprivate List<string> _asset = new List<string>{\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n\npublic override void Initialize()\n{\n// 1. Required: Five years of backtest history\nSetStartDate(2014, 1, 1);\n\n// 2. Required: Alpha Streams Models:\nSetBrokerageModel(BrokerageName.AlphaStreams);\n\n// 3. Required: Significant AUM Capacity\nSetCash(1000000);\n\n// 4. Required: Benchmark to SPY\nSetBenchmark(\"SPY\");\n\nSetPortfolioConstruction(new EqualWeightingPortfolioConstructionModel());\nSetExecution(new ImmediateExecutionModel());\n\n// Add Equity ------------------------------------------------\nforeach(var ticker in _asset)\n{\nAddEquity(ticker, Resolution.Minute);\n}\n\n// Set Scheduled Event Method For Our Model. In this example, we'll rebalance every month.\nSchedule.On(DateRules.MonthStart(),\nTimeRules.BeforeMarketClose(\"SHY\", 5),\nEveryDayBeforeMarketClose);\n}def initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(EqualWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE)\n\n# Set Scheduled Event Method For Our Model. In this example, we'll rebalance every month.\nself.schedule.on(self.date_rules.month_start(),\nself.time_rules.before_market_close(\"SHY\", 5),\nself.every_day_before_market_close)\n\nNow we export our model into the scheduled event method. We will removeqband replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\nprivate void EveryDayBeforeMarketClose()\n{\n// Fetch history on our universe\nvar history = History(Securities.Keys, 252*2, Resolution.Daily);\nif (history.Count() < 0) return;\n\n// Extract daily return of close prices for each Symbol from Slice data\nvar returns = new Dictionary<string, List<Double>>();\nvar last = new Dictionary<string, Double>();\nforeach(var slice in history){\nforeach(var symbol in slice.Bars.Keys){\nif(!returns.ContainsKey(symbol)){\nreturns.Add(symbol, new List<Double>());\nlast.Add(symbol, (Double)slice.Bars[symbol].Close);\n}\nvar change = (Double) ((Double)slice.Bars[symbol].Close - last[symbol])/last[symbol];\nlast[symbol] = (Double)slice.Bars[symbol].Close;\nreturns[symbol].Add(change);\n}\n}\n\n// Convert returns into 2-d array\ndouble[,] ret = new double[returns.Values.ElementAt(0).Count - 1, _asset.Count];\nint k = 0;\nforeach(var kvp in returns)\n{\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count - 1; i++)\n{\nret[i, k] = returns[symbol][i + 1];\n}\nk++;\n}\n\n// Get correlation matrix\nvar corrMatrix = Measures.Correlation(ret);\n\n// Find 5 assets with the least absolute sum correlation\nvar correlations = new Dictionary<string, Double>();\nfor(int i=0; i < corrMatrix.GetLength(0); i++)\n{\nvar symbol = _asset[i];\nif(!correlations.ContainsKey(symbol)){\ncorrelations.Add(symbol, 0);\n}\nfor (int j=0; j < corrMatrix.GetLength(1); j++)\n{\nvar value_ = corrMatrix[i, j];\ncorrelations[symbol] += value_ >= 0 ? value_ : -value_;\n}\n}\nvar selected = correlations.OrderBy(x => x.Value).Take(5).Select(x => x.Key).ToList();\n\n// Emit insights\nforeach(var symbol in selected)\n{\nvar insight = new Insight(symbol, Expiry.EndOfMonth, InsightType.Price, InsightDirection.Up);\nEmitInsights(insight);\n}\n}def every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\nhistory = qb.history(qb.securities.keys(), 252*2, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Select the close column and then call the unstack method, then call pct_change to compute the daily return.\nreturns = history['close'].unstack(level=0).pct_change().iloc[1:]\n\n# Get correlation\ncorrelation = returns.corr()\n\n# Find 5 assets with lowest absolute sum correlation\nselected = []\nfor index, row in correlation.iteritems():\ncorr_rank = row.abs().sum()\nselected.append((index, corr_rank))\n\nsort_ = sorted(selected, key = lambda x: x[1])\nselected = [x[0] for x in sort_[:5]]\n\n# ==============================\n\ninsights = []\n\nfor symbol in selected:\ninsights.append( Insight.price(symbol, Expiry.END_OF_MONTH, InsightDirection.UP) )\n\nself.emit_insights(insights)\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\n// Load the required assembly files and data types.\n#load \"../Initialize.csx\"\n#load \"../QuantConnect.csx\"\n\nusing QuantConnect;\nusing QuantConnect.Data;\nusing QuantConnect.Data.Market;\nusing QuantConnect.Algorithm;\nusing QuantConnect.Research;\nusing System;\nusing System.Linq;\nusing Accord.Statistics;\n\n// Instantiate a QuantBook\nvar qb = new QuantBook();\n\n// Select the desired tickers for research.\nvar assets = new List<string>() {\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n\n// Call the AddEquity method with the tickers, and their corresponding resolution.\nforeach(var ticker in assets){\nqb.AddEquity(ticker, Resolution.Minute);\n}\n\n// Call the History method with qb.Securities.Keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nvar history = qb.History(qb.Securities.Keys, new DateTime(2021, 1, 1), new DateTime(2021, 12, 31), Resolution.Daily);\n\n// Extract daily return for each Symbol from Slice data\nvar returns = new Dictionary<string, List<Double>>();\nvar last = new Dictionary<string, Double>();\nforeach(var slice in history){\nforeach(var symbol in slice.Bars.Keys){\nif(!returns.ContainsKey(symbol)){\nreturns.Add(symbol, new List<Double>());\nlast.Add(symbol, (Double)slice.Bars[symbol].Close);\n}\nvar change = (Double) ((Double)slice.Bars[symbol].Close - last[symbol])/last[symbol];\nlast[symbol] = (Double)slice.Bars[symbol].Close;\nreturns[symbol].Add(change);\n}\n}\n\n// Convert returns into 2-d array\ndouble[,] ret = new double[returns.Values.ElementAt(0).Count - 1, assets.Count];\nint k = 0;\nforeach(var kvp in returns)\n{\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count - 1; i++)\n{\nret[i, k] = returns[symbol][i + 1];\n}\nk++;\n}\n\n// Write a function to obtain the least and most correlated 5 assets.\npublic Dictionary<string, Double> GetCorrelations(double[,] returns){\n// Get correlation matrix\nvar corrMatrix = Measures.Correlation(ret);\n\n// Find the absolute sum correlation of the assets\nvar correlations = new Dictionary<string, Double>();\nfor(int i=0; i < corrMatrix.GetLength(0); i++)\n{\nvar symbol = assets[i];\nif(!correlations.ContainsKey(symbol)){\ncorrelations.Add(symbol, 0);\n}\nfor (int j=0; j < corrMatrix.GetLength(1); j++)\n{\nvar value_ = corrMatrix[i, j];\ncorrelations[symbol] += value_ >= 0 ? value_ : -value_;\n}\n}\n\nreturn correlations;\n}\n\nvar corr = GetCorrelations(ret);\nvar selected = corr.OrderBy(x => x.Value).Take(5);\nvar benchmark = corr.OrderBy(x => x.Value).TakeLast(5);\n\n// Construct an equal weighting portfolio for the 5-uncorrelated-asset-portfolio and the 5-correlated-asset-portfolio (benchmark).\ndouble[,] portRet = new double[returns.Values.ElementAt(0).Count, 5];\nint j = 0;\nforeach(var kvp in selected){\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count; i++)\n{\nportRet[i, j] = returns[symbol][i] / 5;\n}\nj++;\n}\n\ndouble[,] benchRet = new double[returns.Values.ElementAt(0).Count, 5];\nj = 0;\nforeach(var kvp in benchmark){\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count; i++)\n{\nbenchRet[i, j] = returns[symbol][i] / 5;\n}\nj++;\n}\n\n// Get the Equity Return of both portfolios.\nvar totalValue = new List<double>{1.0};\nvar dailySum = 0.0;\nfor(int i=0; i < portRet.GetLength(0); i++)\n{\ntotalValue.Add(totalValue.Last() * (1 + dailySum));\ndailySum = 0.0;\nfor (int j=0; j < portRet.GetLength(1); j++)\n{\nif (double.IsFinite(portRet[i, j]))\n{\ndailySum += portRet[i, j];\n}\n}\n}\n\nvar totalValueBench = new List<double>{1.0};\nvar dailySumBench = 0.0;\nfor(int i=0; i < benchRet.GetLength(0); i++)\n{\ntotalValueBench.Add(totalValueBench.Last() * (1 + dailySumBench));\ndailySumBench = 0.0;\nfor (int j=0; j < benchRet.GetLength(1); j++)\n{\nif (double.IsFinite(benchRet[i, j]))\n{\ndailySumBench += benchRet[i, j];\n}\n}\n}\n\n// Calculate the variance of the 2 portfolios\nvar returnPort = new List<double>();\nvar previous = 0.0;\nfor(int i=0; i < totalValue.Count; i++)\n{\nvar current = totalValue[i];\nreturnPort.Add((current - previous) / previous);\nprevious = current;\n}\nvar varPort = Math.Sqrt(returnPort.Skip(1).Average(v=>Math.Pow(v-returnPort.Skip(1).Average(),2)));\n\nvar returnBench = new List<double>();\nprevious = 0.0;\nfor(int i=0; i < totalValueBench.Count; i++)\n{\nvar current = totalValueBench[i];\nreturnBench.Add((current - previous) / previous);\nprevious = current;\n}\nvar varBench = Math.Sqrt(returnBench.Skip(1).Average(v => Math.Pow(v-returnBench.Skip(1).Average(),2)));\n\n// Print the result.\nConsole.WriteLine(\"Portfolio Return: {0}, Variance: {1}\", (totalValue.Last() - totalValue.First())/totalValue.First(), varPort);\nConsole.WriteLine(\"Benchmark Return: {0}, Variance: {1}\", (totalValueBench.Last() - totalValueBench.First())/totalValueBench.First(), varBench);# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Call the add_equity method with the tickers, and its corresponding resolution. Then store their Symbols. Resolution.MINUTE is used by default.\nfor i in range(len(assets)):\nqb.add_equity(assets[i],Resolution.MINUTE)\n\n# Call the history method with qb.securities.keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method, then call pct_change to compute the daily return.\nreturns = history['close'].unstack(level=0).pct_change().iloc[1:]\n\n# Write a function to obtain the least and most correlated 5 assets.\ndef get_uncorrelated_assets(returns, num_assets):\n# Get correlation\ncorrelation = returns.corr()\n\n# Find assets with lowest and highest absolute sum correlation\nselected = []\nfor index, row in correlation.iteritems():\ncorr_rank = row.abs().sum()\nselected.append((index, corr_rank))\n\n# Sort and take the top num_assets\nsort_ = sorted(selected, key = lambda x: x[1])\nuncorrelated = sort_[:num_assets]\ncorrelated = sort_[-num_assets:]\n\nreturn uncorrelated, correlated\n\nselected, benchmark = get_uncorrelated_assets(returns, 5)\n\n# Construct a equal weighting portfolio for the 5-uncorrelated-asset-portfolio and the 5-correlated-asset-portfolio (benchmark).\nport_ret = returns[[x[0] for x in selected]] / 5\nbench_ret = returns[[x[0] for x in benchmark]] / 5\n\n# Call cumprod to get the cumulative return.\ntotal_ret = (np.sum(port_ret, axis=1) + 1).cumprod()\ntotal_ret_bench = (np.sum(bench_ret, axis=1) + 1).cumprod()\n\n# Plot the result.\nplt.figure(figsize=(15, 10))\ntotal_ret.plot(label='Proposed')\ntotal_ret_bench.plot(label='Benchmark')\nplt.title('Equity Curve')\nplt.legend()\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nusing Accord.Statistics;\n\nnamespace QuantConnect.Algorithm.CSharp\n{\npublic class UncorrelatedAssetsDemo : QCAlgorithm\n{\nprivate List<string> _asset = new List<string>{\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"};\n\npublic override void Initialize()\n{\n// 1. Required: Five years of backtest history\nSetStartDate(2014, 1, 1);\nSetEndDate(2019, 1, 1);\n\n// 2. Required: Alpha Streams Models:\nSetBrokerageModel(BrokerageName.AlphaStreams);\n\n// 3. Required: Significant AUM Capacity\nSetCash(1000000);\n\n// 4. Required: Benchmark to SPY\nSetBenchmark(\"SPY\");\n\nSetPortfolioConstruction(new EqualWeightingPortfolioConstructionModel());\nSetExecution(new ImmediateExecutionModel());\n\n// Add Equity ------------------------------------------------\nforeach(var ticker in _asset)\n{\nAddEquity(ticker, Resolution.Minute);\n}\n\n// Set Scheduled Event Method For Our Model. In this example, we'll rebalance every month.\nSchedule.On(DateRules.MonthStart(),\nTimeRules.BeforeMarketClose(\"SHY\", 5),\nEveryDayBeforeMarketClose);\n}\n\nprivate void EveryDayBeforeMarketClose()\n{\n// Fetch history on our universe\nvar history = History(Securities.Keys, 252*2, Resolution.Daily);\nif (history.Count() < 0) return;\n\n// Extract daily return of close prices for each Symbol from Slice data\nvar returns = new Dictionary<string, List<double>>();\nvar last = new Dictionary<string, double>();\nforeach(var slice in history){\nforeach(var symbol in slice.Bars.Keys){\nif(!returns.ContainsKey(symbol)){\nreturns.Add(symbol, new List<double>());\nlast.Add(symbol, (double)slice.Bars[symbol].Close);\n}\nvar change = (double) ((double)slice.Bars[symbol].Close - last[symbol])/last[symbol];\nlast[symbol] = (double)slice.Bars[symbol].Close;\nreturns[symbol].Add(change);\n}\n}\n\n// Convert returns into 2-d array\ndouble[,] ret = new double[returns.Values.ElementAt(0).Count - 1, _asset.Count];\nint k = 0;\nforeach(var kvp in returns)\n{\nvar symbol = kvp.Key;\nfor(int i=0; i < returns[symbol].Count - 1; i++)\n{\nret[i, k] = returns[symbol][i + 1];\n}\nk++;\n}\n\n// Get correlation matrix\nvar corrMatrix = Measures.Correlation(ret);\n\n// Find 5 assets with the least absolute sum correlation\nvar correlations = new Dictionary<string, double>();\nfor(int i=0; i < corrMatrix.GetLength(0); i++)\n{\nvar symbol = _asset[i];\nif(!correlations.ContainsKey(symbol)){\ncorrelations.Add(symbol, 0);\n}\nfor (int j=0; j < corrMatrix.GetLength(1); j++)\n{\nvar value_ = corrMatrix[i, j];\ncorrelations[symbol] += value_ >= 0 ? value_ : -value_;\n}\n}\nvar selected = correlations.OrderBy(x => x.Value).Take(5).Select(x => x.Key).ToList();\n\n// Emit insights\nforeach(var symbol in selected)\n{\nvar insight = new Insight(symbol, Expiry.EndOfMonth, InsightType.Price, InsightDirection.Up);\nEmitInsights(insight);\n}\n}\n}\n}class UncorrelatedAssetsDemo(QCAlgorithm):\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\nself.set_end_date(2019, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(EqualWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\nself.assets = [\"SHY\", \"TLT\", \"IEI\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Set Scheduled Event Method For Our Model. In this example, we'll rebalance every month.\nself.schedule.on(self.date_rules.month_start(),\nself.time_rules.before_market_close(\"SHY\", 5),\nself.every_day_before_market_close)\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\nhistory = qb.history(qb.securities.Keys, 252*2, Resolution.DAILY)\nif history.empty: return\n\n# Select the close column and then call the unstack method, then call pct_change to compute the daily return.\nreturns = history['close'].unstack(level=0).pct_change().iloc[1:]\n\n# Get correlation\ncorrelation = returns.corr()\n\n# Find 5 assets with lowest absolute sum correlation\nselected = []\nfor index, row in correlation.iterrows():\ncorr_rank = row.abs().sum()\nselected.append((index, corr_rank))\n\nsort_ = sorted(selected, key = lambda x: x[1])\nselected = [x[0] for x in sort_[:5]]\n\n# ==============================\n\ninsights = []\n\nfor symbol in selected:\ninsights.append( Insight.price(symbol, Expiry.END_OF_MONTH, InsightDirection.UP) )\n\nself.emit_insights(insights)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Uncorrelated Assets",
      "section_number": "11.4",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.5",
    "title": "Kalman Filters and Stat Arb",
    "level": 2,
    "path": "Applying Research > Kalman Filters and Stat Arb",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Kalman Filters and Statistical Arbitrage hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nIn finance, we can often observe that 2 stocks with similar background and fundamentals (e.g. AAPL vs MSFT, SPY vs QQQ) move in similar manner. They could be correlated, although not necessary, but their price difference/sum (spread) is stationary. We call this cointegration. Thus, we could hypothesize that extreme spread could provide chance for arbitrage, just like a mean reversion of spread. This is known as pairs trading. Likewise, this could also be applied to more than 2 assets, this is known as statistical arbitrage.However, although the fluctuation of the spread is stationary, the mean of the spread could be changing by time due to different reasons. Thus, it is important to update our expectation on the spread in order to go in and out of the market in time, as the profit margin of this type of short-window trading is tight. Kalman Filter could come in handy in this situation. We can consider it as an updater of the underlying return Markov Chain's expectation, while we're assuming the price series is a Random Process.In this example, we're making a hypothesis on trading the spread on cointegrated assets is profitable. We'll be using forex pairs EURUSD, GBPUSD, USDCAD, USDHKD and USDJPY for this example, skipping the normalized price difference selection.\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing, model building, validation and visualization. Importarch,pykalman,scipy,statsmodels,numpy,matplotlibandpandaslibraries by the following:\n\nfrom arch.unitroot.cointegration import engle_granger\nfrom pykalman import KalmanFilter\nfrom scipy.optimize import minimize\nfrom statsmodels.tsa.vector_ar.vecm import VECM\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the desired tickers for research.assets = [\"EURUSD\", \"GBPUSD\", \"USDCAD\", \"USDHKD\", \"USDJPY\"]Call theadd_forexmethod with the tickers, and their corresponding resolution. Then store theirSymbols.for i in range(len(assets)):\nqb.add_forex(assets[i],Resolution.MINUTE)If you do not pass a resolution argument,Resolution.MINUTEis used by default.Call thehistorymethod withqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.history = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Cointegration\n\nWe'll have to test if the assets are cointegrated. If so, we'll have to obtain the cointegration vector(s).\n\nCointegration Testing\n\nSelect the close column and then call theunstackmethod.df = history['close'].unstack(level=0)Callnp.logto convert the close price into log-price series to eliminate compounding effect.log_price = np.log(data)Apply Engle Granger Test to check if the series are cointegrated.coint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1:], trend='n', method='bic')It shows a p-value < 0.05 for the unit test, with lag-level 0. This proven the log price series are cointegrated in realtime. The spread of the 5 forex pairs are stationary.\n\nGet Cointegration Vectors\n\nWe would use a VECM model to obtain the cointegrated vectors.\n\nInitialize aVECMmodel by following the unit test parameters, then fit to our data.vecm_result = VECM(log_price, k_ar_diff=0, coint_rank=len(assets)-1, deterministic='n').fit()Obtain theBetaattribute. This is the cointegration subspaces' unit vectors.beta = vecm_result.betaCheck the spread of different cointegration subspaces.spread = log_price @ betaPlot the results.fig, axs = plt.subplots(beta.shape[1], figsize=(15, 15))\nfig.suptitle('Spread for various cointegrating vectors')\nfor i in range(beta.shape[1]):\naxs[i].plot(spread.iloc[:, i])\naxs[i].set_title(f\"The {i+1}th normalized cointegrating subspace\")\nplt.show()\n\nOptimization of Cointegration Subspaces\n\nAlthough the 4 cointegratoin subspaces are not looking stationarym, we can optimize for a mean-reverting portfolio by putting various weights in different subspaces. We use the Portmanteau statistics as a proxy for the mean reversion. So we formulate:\n\n$$\\begin{equation*}\n\\begin{aligned}\n& \\underset{w}{\\text{minimize}}\n& & \\mathrm (\\frac {w^{T}M_{1}w} {w^{T}M_{0}w}) ^{2} \\\\\n& \\text{subject to}\n& & w^{T}M_{0}w = \\nu\\\\\n&&& 1^Tw = 0\\\\\n& \\text{where}\n& & M_i \\triangleq Cov(s_t, s_{t+i}) = E[(s_t - E[s_t]) (s_{t+i} - E[s_{t+i}])^T] \\\\\n\\end{aligned}\n\\end{equation*}$$\n\nwith s is spread, v is predetermined desirable variance level (the larger the higher the profit, but lower the trading frequency)\n\nWe set the weight on each vector is between -1 and 1. While overall sum is 0.x0 = np.array([-1**i/beta.shape[1] for i in range(beta.shape[1])])\nbounds = tuple((-1, 1) for i in range(beta.shape[1]))\nconstraints = [{'type':'eq', 'fun':lambda x: np.sum(x)}]Optimize the Portmanteau statistics.opt = minimize(lambda w: ((w.T @ np.cov(spread.T, spread.shift(1).fillna(0).T)[spread.shape[1]:, :spread.shape[1]] @ w)/(w.T @ np.cov(spread.T) @ w))**2,\nx0=x0,\nbounds=bounds,\nconstraints=constraints,\nmethod=\"SLSQP\")Normalize the result.opt.x = opt.x/np.sum(abs(opt.x))\nfor i in range(len(opt.x)):\nprint(f\"The weight put on {i+1}th normalized cointegrating subspace: {opt.x[i]}\")Plot the weighted spread.new_spread = spread @ opt.x\nnew_spread.plot(title=\"Weighted spread\", figsize=(15, 10))\nplt.ylabel(\"Spread\")\nplt.show()\n\n### Kalman Filter\n\nThe weighted spread looks more stationary. However, the fluctuation half-life is very long accrossing zero. We aim to trade as much as we can to maximize the profit of this strategy. Kalman Filter then comes into the play. It could modify the expectation of the next step based on smoothening the prediction and actual probability distribution of return.\n\nImage Source: Understanding Kalman Filters, Part 3: An Optimal State Estimator. Melda Ulusoy (2017). MathWorks. Retreived from: https://www.mathworks.com/videos/understanding-kalman-filters-part-3-optimal-state-estimator--1490710645421.html\n\nInitialize aKalmanFilter.In this example, we use the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].kalmanFilter = KalmanFilter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = new_spread.iloc[:20].mean(),\nobservation_covariance = new_spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nkalmanFilter = kalmanFilter.em(new_spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = kalmanFilter.filter(new_spread.iloc[:20])Obtain the current Mean and Covariance Matrix expectations.currentMean = filtered_state_means[-1, :]\ncurrentCov = filtered_state_covariances[-1, :]Initialize a mean series for spread normalization using theKalmanFilter's results.mean_series = np.array([None]*(new_spread.shape[0]-100))Roll over the Kalman Filter to obtain the mean series.for i in range(100, new_spread.shape[0]):\n(currentMean, currentCov) = kalmanFilter.filter_update(filtered_state_mean = currentMean,\nfiltered_state_covariance = currentCov,\nobservation = new_spread.iloc[i])\nmean_series[i-100] = float(currentMean)Obtain the normalized spread series.normalized_spread = (new_spread.iloc[100:] - mean_series)Plot the normalized spread series.plt.figure(figsize=(15, 10))\nplt.plot(normalized_spread, label=\"Processed spread\")\nplt.title(\"Normalized spread series\")\nplt.ylabel(\"Spread - Expectation\")\nplt.legend()\nplt.show()\n\n### Determine Trading Threshold\n\nNow we need to determine the threshold of entry. We want to maximize profit from each trade (variance of spread) x frequency of entry. To do so, we formulate:\n\n$$\\begin{equation*}\n\\begin{aligned}\n& \\underset{f}{\\text{minimize}}\n& & \\begin{Vmatrix}\n\\bar{f} - f\n\\end{Vmatrix}_{2}^{2} + \\lambda\\ \\begin{Vmatrix}Df\\end{Vmatrix}_{2}^{2} \\\\\n& \\text{where}\n& & \\bar{f_j} = \\frac{\\sum_{t=1}^T 1_{\\{spread_t\\ >\\ set\\ level_j\\}}}{T}\\\\\n&&& D = \\begin{bmatrix}\n1 & -1 & & &\\\\\n& 1 & -1 & &\\\\\n&  & \\ddots & \\ddots & \\\\\n&  &  & 1 & -1\n\\end{bmatrix}\n\\in \\mathbb{R}^{(j - 1) \\times j}\\\\\n\\end{aligned}\n\\end{equation*}$$\n\nso $f^* = (I+\\lambda D^TD)^{-1}\\bar{f}$\n\nInitialize 50 set levels for testing.s0 = np.linspace(0, max(normalized_spread), 50)Calculate the profit levels using the 50 set levels.f_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]]) / normalized_spread.shape[0]Set trading frequency matrix.D = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1Set level of lambda.l = 1.0Obtain the normalized profit level.f_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]Get the maximum profit level as threshold.threshold = s0[s_star.index(max(s_star))]\nprint(f\"The optimal threshold is {threshold}\")Plot the result.plt.figure(figsize=(15, 10))\nplt.plot(s0, s_star)\nplt.title(\"Profit of mean-revertion trading\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Profit\")\nplt.show()\n\n### Test Hypothesis\n\nTo test the hypothesis. We wish to obtain a profiting strategy.\n\nSet the trading weight. We would like the portfolio absolute total weight is 1 when trading.trading_weight = beta @ opt.x\ntrading_weight /= np.sum(abs(trading_weight))Set up the trading data.testing_ret = data.pct_change().iloc[1:].shift(-1)   # Shift 1 step backward as forward return result\nequity = pd.DataFrame(np.ones((testing_ret.shape[0], 1)), index=testing_ret.index, columns=[\"Daily value\"])Set the buy and sell preiod when the spread exceeds the threshold.buy_period = normalized_spread[normalized_spread < -threshold].index\nsell_period = normalized_spread[normalized_spread > threshold].indexTrade the portfolio.equity.loc[buy_period, \"Daily value\"] = testing_ret.loc[buy_period] @ trading_weight + 1\nequity.loc[sell_period, \"Daily value\"] = testing_ret.loc[sell_period] @ -trading_weight + 1Get the total portfolio value.value = equity.cumprod()Plot the result.value.plot(title=\"Equity Curve\", figsize=(15, 10))\nplt.ylabel(\"Portfolio Value\")\nplt.show()\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into backtest is to create a scheduled event which uses our model to predict the expected return.\n\ndef initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"EURUSD\", \"GBPUSD\", \"USDCAD\", \"USDHKD\", \"USDJPY\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_forex(self.assets[i], Resolution.MINUTE)\n\n# Instantiate our model\nself.recalibrate()\n\n# Set a variable to indicate the trading bias of the portfolio\nself.state = 0\n\n# Set Scheduled Event Method For Recalibrate Our Model Every Week.\nself.schedule.on(self.date_rules.week_start(),\nself.time_rules.at(0, 0),\nself.recalibrate)\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"EURUSD\"),\nself.every_day_before_market_close)\n\nWe'll also need to create a function to train and update our model from time to time. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef recalibrate(self) -> None:\nqb = self\nhistory = qb.history(self.assets, 252*2, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Select the close column and then call the unstack method\ndata = history['close'].unstack(level=0)\n\n# Convert into log-price series to eliminate compounding effect\nlog_price = np.log(data)\n\n### Get Cointegration Vectors\n# Initialize a VECM model following the unit test parameters, then fit to our data.\nvecm_result = VECM(log_price, k_ar_diff=0, coint_rank=len(self.assets)-1, deterministic='n').fit()\n\n# Obtain the Beta attribute. This is the cointegration subspaces' unit vectors.\nbeta = vecm_result.beta\n\n# Check the spread of different cointegration subspaces.\nspread = log_price @ beta\n\n### Optimization of Cointegration Subspaces\n# We set the weight on each vector is between -1 and 1. While overall sum is 0.\nx0 = np.array([-1**i/beta.shape[1] for i in range(beta.shape[1])])\nbounds = tuple((-1, 1) for i in range(beta.shape[1]))\nconstraints = [{'type':'eq', 'fun':lambda x: np.sum(x)}]\n\n# Optimize the Portmanteau statistics\nopt = minimize(lambda w: ((w.T @ np.cov(spread.T, spread.shift(1).fillna(0).T)[spread.shape[1]:, :spread.shape[1]] @ w)/(w.T @ np.cov(spread.T) @ w))**2,\nx0=x0,\nbounds=bounds,\nconstraints=constraints,\nmethod=\"SLSQP\")\n\n# Normalize the result\nopt.x = opt.x/np.sum(abs(opt.x))\nnew_spread = spread @ opt.x\n\n### Kalman Filter\n# Initialize a Kalman Filter. Using the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].\nself.kalman_filter = kalman_filter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = new_spread.iloc[:20].mean(),\nobservation_covariance = new_spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nself.kalman_filter = self.kalman_filter.em(new_spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = self.kalman_filter.filter(new_spread.iloc[:20])\n\n# Obtain the current Mean and Covariance Matrix expectations.\nself.current_mean = filtered_state_means[-1, :]\nself.current_cov = filtered_state_covariances[-1, :]\n\n# Initialize a mean series for spread normalization using the Kalman Filter's results.\nmean_series = np.array([None]*(new_spread.shape[0]-20))\n\n# Roll over the Kalman Filter to obtain the mean series.\nfor i in range(20, new_spread.shape[0]):\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = new_spread.iloc[i])\nmean_series[i-20] = float(self.current_mean)\n\n# Obtain the normalized spread series.\nnormalized_spread = (new_spread.iloc[20:] - mean_series)\n\n### Determine Trading Threshold\n# Initialize 50 set levels for testing.\ns0 = np.linspace(0, max(normalized_spread), 50)\n\n# Calculate the profit levels using the 50 set levels.\nf_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]]) \\\n/ normalized_spread.shape[0]\n\n# Set trading frequency matrix.\nD = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1\n\n# Set level of lambda.\nl = 1.0\n\n# Obtain the normalized profit level.\nf_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]\nself.threshold = s0[s_star.index(max(s_star))]\n\n# Set the trading weight. We would like the portfolio absolute total weight is 1 when trading.\ntrading_weight = beta @ opt.x\nself.trading_weight = trading_weight / np.sum(abs(trading_weight))\n\nNow we export our model into the scheduled event method for trading. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n\n# Get the real-time log close price for all assets and store in a Series\nseries = pd.Series()\nfor symbol in qb.securities.keys():\nseries[symbol] = np.log(qb.securities[symbol].close)\n\n# Get the spread\nspread = series @ self.trading_weight\n\n# Update the Kalman Filter with the Series\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread)\n\n# Obtain the normalized spread.\nnormalized_spread = spread - self.current_mean\n\n# ==============================\n\n# Mean-reversion\nif normalized_spread < -self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = 1\n\nelif normalized_spread > self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], -1 * self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = -1\n\n# Out of position if spread recovered\nelif self.state == 1 and normalized_spread > -self.threshold or self.state == -1 and normalized_spread < self.threshold:\nself.liquidate()\n\nself.state = 0\n\n### Reference\n\nA Signal Processing Perspective on Financial Engineering. Y. Feng, D. P. Palomer (2016).Foundations and Trends in Signal Processing. 9(1-2). p173-200.\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom arch.unitroot.cointegration import engle_granger\nfrom pykalman import KalmanFilter\nfrom scipy.optimize import minimize\nfrom statsmodels.tsa.vector_ar.vecm import VECM\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nassets = [\"EURUSD\", \"GBPUSD\", \"USDCAD\", \"USDHKD\", \"USDJPY\"]\n\n# Call the AddForex method with the tickers, and its corresponding resolution. Then store their Symbols. Resolution.Minute is used by default.\nfor i in range(len(assets)):\nqb.add_forex(assets[i],Resolution.MINUTE).symbol\n\n# Call the History method with qb.Securities.Keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\ndata = history['close'].unstack(level=0)\n\n# Convert into log-price series to eliminate compounding effect.\nlog_price = np.log(data)\n\n# Apply Engle Granger Test to check if the series are cointegrated.\ncoint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1:], trend='n', method='bic')\n\n# Initialize a VECM model following the unit test parameters, then fit to our data.\nvecm_result = VECM(log_price, k_ar_diff=0, coint_rank=len(assets)-1, deterministic='n').fit()\n\n# Obtain the Beta attribute. This is the cointegration subspaces' unit vectors.\nbeta = vecm_result.beta\n\n# Check the spread of different cointegration subspaces.\nspread = log_price @ beta\n\n# Plot the results.\nfig, axs = plt.subplots(beta.shape[1], figsize=(15, 15))\nfig.suptitle('Spread for various cointegrating vectors')\nfor i in range(beta.shape[1]):\naxs[i].plot(spread.iloc[:, i])\naxs[i].set_title(f\"The {i+1}th normalized cointegrating subspace\")\nplt.show()\n\n# We set the weight on each vector is between -1 and 1. While overall sum is 0.\nx0 = np.array([-1**i/beta.shape[1] for i in range(beta.shape[1])])\nbounds = tuple((-1, 1) for i in range(beta.shape[1]))\nconstraints = [{'type':'eq', 'fun':lambda x: np.sum(x)}]\n\n# Optimize the Portmanteau statistics.\nopt = minimize(lambda w: ((w.T @ np.cov(spread.T, spread.shift(1).fillna(0).T)[spread.shape[1]:, :spread.shape[1]] @ w)/(w.T @ np.cov(spread.T) @ w))**2,\nx0=x0,\nbounds=bounds,\nconstraints=constraints,\nmethod=\"SLSQP\")\n\n# Normalize the result.\nopt.x = opt.x/np.sum(abs(opt.x))\nfor i in range(len(opt.x)):\nprint(f\"The weight put on {i+1}th normalized cointegrating subspace: {opt.x[i]}\")\n\n# Plot the weighted spread.\nnew_spread = spread @ opt.x\nnew_spread.plot(title=\"Weighted spread\", figsize=(15, 10))\nplt.ylabel(\"Spread\")\nplt.show()\n\n# Initialize a Kalman Filter. Using the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].\nkalman_filter = KalmanFilter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = new_spread.iloc[:20].mean(),\nobservation_covariance = new_spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nkalman_filter = kalman_filter.em(new_spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = kalman_filter.filter(new_spread.iloc[:20])\n\n# Obtain the current Mean and Covariance Matrix expectations.\ncurrent_mean = filtered_state_means[-1, :]\ncurrent_cov = filtered_state_covariances[-1, :]\n\n# Initialize a mean series for spread normalization using the Kalman Filter's results.\nmean_series = np.array([None]*(new_spread.shape[0]-100))\n\n# Roll over the Kalman Filter to obtain the mean series.\nfor i in range(100, new_spread.shape[0]):\n(current_mean, current_cov) = kalman_filter.filter_update(filtered_state_mean = current_mean,\nfiltered_state_covariance = current_cov,\nobservation = new_spread.iloc[i])\nmean_series[i-100] = float(current_mean)\n\n# Obtain the normalized spread series.\nnormalized_spread = (new_spread.iloc[100:] - mean_series)\n\n# Plot the normalized spread series.\nplt.figure(figsize=(15, 10))\nplt.plot(normalized_spread, label=\"Processed spread\")\nplt.title(\"Normalized spread series\")\nplt.ylabel(\"Spread - Expectation\")\nplt.legend()\nplt.show()\n\n# Initialize 50 set levels for testing.\ns0 = np.linspace(0, max(normalized_spread), 50)\n\n# Calculate the profit levels using the 50 set levels.\nf_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]]) \\\n/ normalized_spread.shape[0]\n\n# Set trading frequency matrix.\nD = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1\n\n# Set level of lambda.\nl = 1.0\n\n# Obtain the normalized profit level.\nf_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]\n\n# Plot the result.\nplt.figure(figsize=(15, 10))\nplt.plot(s0, s_star)\nplt.title(\"Profit of mean-revertion trading\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Profit\")\nplt.show()\n\nthreshold = s0[s_star.index(max(s_star))]\nprint(f\"The optimal threshold is {threshold}\")\n\n# Set the trading weight. We would like the portfolio absolute total weight is 1 when trading.\ntrading_weight = beta @ opt.x\ntrading_weight /= np.sum(abs(trading_weight))\n\n# Set up the trading data.\ntesting_ret = data.pct_change().iloc[1:].shift(-1)   # Shift 1 step backward as forward return result\nequity = pd.DataFrame(np.ones((testing_ret.shape[0], 1)), index=testing_ret.index, columns=[\"Daily value\"])\n\n# Set the buy and sell preiod when the spread exceeds the threshold.\nbuy_period = normalized_spread[normalized_spread < -threshold].index\nsell_period = normalized_spread[normalized_spread > threshold].index\n\n# Trade the portfolio.\nequity.loc[buy_period, \"Daily value\"] = testing_ret.loc[buy_period] @ trading_weight + 1\nequity.loc[sell_period, \"Daily value\"] = testing_ret.loc[sell_period] @ -trading_weight + 1\n\n# Get the total portfolio value.\nvalue = equity.cumprod()\n\n# Plot the result.\nvalue.plot(title=\"Equity Curve\", figsize=(15, 10))\nplt.ylabel(\"Portfolio Value\")\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nfrom pykalman import KalmanFilter\nfrom scipy.optimize import minimize\nfrom statsmodels.tsa.vector_ar.vecm import VECM\n\nclass KalmanFilterStatisticalArbitrageDemo(QCAlgorithm):\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\nself.set_end_date(2019, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"EURUSD\", \"GBPUSD\", \"USDCAD\", \"USDHKD\", \"USDJPY\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_forex(self.assets[i], Resolution.MINUTE).symbol\n\n# Instantiate our model\nself.recalibrate()\n\n# Set a variable to indicate the trading bias of the portfolio\nself.state = 0\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.week_start(),\nself.time_rules.at(0, 0),\nself.recalibrate)\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"EURUSD\"),\nself.every_day_before_market_close)\n\ndef recalibrate(self) -> None:\nqb = self\nhistory = qb.history(self.assets, 252*2, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Select the close column and then call the unstack method\ndata = history['close'].unstack(level=0)\n\n# Convert into log-price series to eliminate compounding effect\nlog_price = np.log(data)\n\n### Get Cointegration Vectors\n# Initialize a VECM model following the unit test parameters, then fit to our data.\nvecm_result = VECM(log_price, k_ar_diff=0, coint_rank=len(self.assets)-1, deterministic='n').fit()\n\n# Obtain the Beta attribute. This is the cointegration subspaces' unit vectors.\nbeta = vecm_result.beta\n\n# Check the spread of different cointegration subspaces.\nspread = log_price @ beta\n\n### Optimization of Cointegration Subspaces\n# We set the weight on each vector is between -1 and 1. While overall sum is 0.\nx0 = np.array([-1**i/beta.shape[1] for i in range(beta.shape[1])])\nbounds = tuple((-1, 1) for i in range(beta.shape[1]))\nconstraints = [{'type':'eq', 'fun':lambda x: np.sum(x)}]\n\n# Optimize the Portmanteau statistics\nopt = minimize(lambda w: ((w.T @ np.cov(spread.T, spread.shift(1).fillna(0).T)[spread.shape[1]:, :spread.shape[1]] @ w)/(w.T @ np.cov(spread.T) @ w))**2,\nx0=x0,\nbounds=bounds,\nconstraints=constraints,\nmethod=\"SLSQP\")\n\n# Normalize the result\nopt.x = opt.x/np.sum(abs(opt.x))\nnew_spread = spread @ opt.x\n\n### Kalman Filter\n# Initialize a Kalman Filter. Using the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].\nself.kalman_filter = KalmanFilter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = new_spread.iloc[:20].mean(),\nobservation_covariance = new_spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nself.kalman_filter = self.kalman_filter.em(new_spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = self.kalman_filter.filter(new_spread.iloc[:20])\n\n# Obtain the current Mean and Covariance Matrix expectations.\nself.current_mean = filtered_state_means[-1, :]\nself.current_cov = filtered_state_covariances[-1, :]\n\n# Initialize a mean series for spread normalization using the Kalman Filter's results.\nmean_series = np.array([None]*(new_spread.shape[0]-20))\n\n# Roll over the Kalman Filter to obtain the mean series.\nfor i in range(20, new_spread.shape[0]):\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = new_spread.iloc[i])\nmean_series[i-20] = float(self.current_mean)\n\n# Obtain the normalized spread series.\nnormalized_spread = (new_spread.iloc[20:] - mean_series)\n\n### Determine Trading Threshold\n# Initialize 50 set levels for testing.\ns0 = np.linspace(0, max(normalized_spread), 50)\n\n# Calculate the profit levels using the 50 set levels.\nf_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]])               / normalized_spread.shape[0]\n\n# Set trading frequency matrix.\nD = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1\n\n# Set level of lambda.\nl = 1.0\n\n# Obtain the normalized profit level.\nf_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]\nself.threshold = s0[s_star.index(max(s_star))]\n\n# Set the trading weight. We would like the portfolio absolute total weight is 1 when trading.\ntrading_weight = beta @ opt.x\nself.trading_weight = trading_weight / np.sum(abs(trading_weight))\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n\n# Get the real-time log close price for all assets and store in a Series\nseries = pd.Series()\nfor symbol in qb.securities.Keys:\nseries[symbol] = np.log(qb.securities[symbol].close)\n\n# Get the spread\nspread = series @ self.trading_weight\n\n# Update the Kalman Filter with the Series\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread)\n\n# Obtain the normalized spread.\nnormalized_spread = spread - self.current_mean\n\n# ==============================\n\n# Mean-reversion\nif normalized_spread < -self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = 1\n\nelif normalized_spread > self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], -1 * self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = -1\n\n# Out of position if spread recovered\nelif self.state == 1 and normalized_spread > -self.threshold or self.state == -1 and normalized_spread < self.threshold:\nself.liquidate()\n\nself.state = 0",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Kalman Filters and Stat Arb",
      "section_number": "11.5",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.6",
    "title": "PCA and Pairs Trading",
    "level": 2,
    "path": "Applying Research > PCA and Pairs Trading",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Principle Component Analysis hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nPrincipal Component Analysis (PCA) a way of mapping the existing dataset into a new \"space\", where the dimensions of the new data are linearly-independent, orthogonal vectors. PCA eliminates the problem of multicollinearity. In another way of thought, can we actually make use of the collinearity it implied, to find the collinear assets to perform pairs trading?\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing, validation and visualization. Importsklearn,arch,statsmodels,numpyandmatplotliblibraries by the following:\n\nfrom sklearn.decomposition import PCA\nfrom arch.unitroot.cointegration import engle_granger\nfrom statsmodels.tsa.stattools import adfuller\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the desired tickers for research.symbols = {}\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]Call theadd_equitymethod with the tickers, and their corresponding resolution. Then store theirSymbols.for i in range(len(assets)):\nsymbols[assets[i]] = qb.add_equity(assets[i],Resolution.MINUTE).symbolIf you do not pass a resolution argument,Resolution.MINUTEis used by default.Call thehistorymethod withqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.history = qb.history(qb.securities.keys(), datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data to get the principle component unit vector that explains the most variance, then find the highest- and lowest-absolute-weighing assets as the pair, since the lowest one's variance is mostly explained by the highest.\n\nSelect the close column and then call theunstackmethod.close_price = history['close'].unstack(level=0)Callpct_changeto compute the daily return.returns = close_price.pct_change().iloc[1:]Initialize aPCAmodel, then get the principle components by the maximum likelihood.pca = PCA()\npca.fit(returns)Get the number of principle component in a list, and their corresponding explained variance ratio.components = [str(x + 1) for x in range(pca.n_components_)]\nexplained_variance_pct = pca.explained_variance_ratio_ * 100Plot the principle components' explained variance ratio.plt.figure(figsize=(15, 10))\nplt.bar(components, explained_variance_pct)\nplt.title(\"Ratio of Explained Variance\")\nplt.xlabel(\"Principle Component #\")\nplt.ylabel(\"%\")\nplt.show()We can see over 95% of the variance is explained by the first principle. We could conclude that collinearity exists and most assets' return are correlated. Now, we can extract the 2 most correlated pairs.Get the weighting of each asset in the first principle component.first_component = pca.components_[0, :]Select the highest- and lowest-absolute-weighing asset.highest = assets[abs(first_component).argmax()]\nlowest = assets[abs(first_component).argmin()]\nprint(f'The highest-absolute-weighing asset: {highest}\\nThe lowest-absolute-weighing asset: {lowest}')Plot their weighings.plt.figure(figsize=(15, 10))\nplt.bar(assets, first_component)\nplt.title(\"Weightings of each asset in the first component\")\nplt.xlabel(\"Assets\")\nplt.ylabel(\"Weighting\")\nplt.xticks(rotation=30)\nplt.show()\n\n### Test Hypothesis\n\nWe now selected 2 assets as candidate for pair-trading. Hence, we're going to test if they are cointegrated and their spread is stationary to do so.\n\nCallnp.logto get the log price of the pair.log_price = np.log(close_price[[highest, lowest]])Test cointegration by Engle Granger Test.coint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1], trend=\"c\", lags=0)\ndisplay(coint_result)Get their cointegrating vector.coint_vector = coint_result.cointegrating_vector[:2]Calculate the spread.spread = log_price @ coint_vectorUse Augmented Dickey Fuller test to test its stationarity.pvalue = adfuller(spread, maxlag=0)[1]\nprint(f\"The ADF test p-value is {pvalue}, so it is {'' if pvalue < 0.05 else 'not '}stationary.\")Plot the spread.spread.plot(figsize=(15, 10), title=f\"Spread of {highest} and {lowest}\")\nplt.ylabel(\"Spread\")\nplt.show()Result shown that the pair is cointegrated and their spread is stationary, so they are potential pair for pair-trading.\n\n### Set Up Algorithm\n\nPairs trading is exactly a 2-asset version of statistical arbitrage. Thus, we can just modify the algorithm fromthe Kalman Filter and Statistical Arbitrage tutorial, except we're using only a single cointegrating unit vector so no optimization of cointegration subspace is needed.\n\ndef initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"SCHO\", \"SHY\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Instantiate our model\nself.recalibrate()\n\n# Set a variable to indicate the trading bias of the portfolio\nself.state = 0\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.week_start(),\nself.time_rules.at(0, 0),\nself.recalibrate)\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SHY\"),\nself.every_day_before_market_close)\n\ndef recalibrate(self) -> None:\nqb = self\nhistory = qb.history(self.assets, 252*2, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Select the close column and then call the unstack method\ndata = history['close'].unstack(level=0)\n\n# Convert into log-price series to eliminate compounding effect\nlog_price = np.log(data)\n\n### Get Cointegration Vectors\n# Get the cointegration vector\ncoint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1], trend=\"c\", lags=0)\ncoint_vector = coint_result.cointegrating_vector[:2]\n\n# Get the spread\nspread = log_price @ coint_vector\n\n### Kalman Filter\n# Initialize a Kalman Filter. Using the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].\nself.kalman_filter = KalmanFilter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = spread.iloc[:20].mean(),\nobservation_covariance = spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nself.kalman_filter = self.kalman_filter.em(spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = self.kalman_filter.filter(spread.iloc[:20])\n\n# Obtain the current Mean and Covariance Matrix expectations.\nself.current_mean = filtered_state_means[-1, :]\nself.current_cov = filtered_state_covariances[-1, :]\n\n# Initialize a mean series for spread normalization using the Kalman Filter's results.\nmean_series = np.array([None]*(spread.shape[0]-20))\n\n# Roll over the Kalman Filter to obtain the mean series.\nfor i in range(20, spread.shape[0]):\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread.iloc[i])\nmean_series[i-20] = float(self.current_mean)\n\n# Obtain the normalized spread series.\nnormalized_spread = (spread.iloc[20:] - mean_series)\n\n### Determine Trading Threshold\n# Initialize 50 set levels for testing.\ns0 = np.linspace(0, max(normalized_spread), 50)\n\n# Calculate the profit levels using the 50 set levels.\nf_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]])               / normalized_spread.shape[0]\n\n# Set trading frequency matrix.\nD = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1\n\n# Set level of lambda.\nl = 1.0\n\n# Obtain the normalized profit level.\nf_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]\nself.threshold = s0[s_star.index(max(s_star))]\n\n# Set the trading weight. We would like the portfolio absolute total weight is 1 when trading.\nself.trading_weight = coint_vector / np.sum(abs(coint_vector))\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n\n# Get the real-time log close price for all assets and store in a Series\nseries = pd.Series()\nfor symbol in qb.securities.keys():\nseries[symbol] = np.log(qb.securities[symbol].close)\n\n# Get the spread\nspread = np.sum(series * self.trading_weight)\n\n# Update the Kalman Filter with the Series\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread)\n\n# Obtain the normalized spread.\nnormalized_spread = spread - self.current_mean\n\n# ==============================\n\n# Mean-reversion\nif normalized_spread < -self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = 1\n\nelif normalized_spread > self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], -1 * self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = -1\n\n# Out of position if spread recovered\nelif self.state == 1 and normalized_spread > -self.threshold or self.state == -1 and normalized_spread < self.threshold:\nself.liquidate()\n\nself.state = 0\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom sklearn.decomposition import PCA\nfrom arch.unitroot.cointegration import engle_granger\nfrom statsmodels.tsa.stattools import adfuller\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nassets = [\"SHY\", \"TLT\", \"SHV\", \"TLH\", \"EDV\", \"BIL\",\n\"SPTL\", \"TBT\", \"TMF\", \"TMV\", \"TBF\", \"VGSH\", \"VGIT\",\n\"VGLT\", \"SCHO\", \"SCHR\", \"SPTS\", \"GOVT\"]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Then store their Symbols. Resolution.Minute is used by default.\nfor i in range(len(assets)):\nqb.add_equity(assets[i],Resolution.MINUTE).symbol\n\n# Call the History method with qb.Securities.Keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.Securities.Keys, datetime(2021, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\nclose_price = history['close'].unstack(level=0)\n\n# Call pct_change to compute the daily return.\nreturns = close_price.pct_change().iloc[1:]\n\n# Initialize a PCA model, then get the principle components by the maximum likelihood.\npca = PCA()\npca.fit(returns)\n\n# Get the number of principle component in a list, and their corresponding explained variance ratio.\ncomponents = [str(x + 1) for x in range(pca.n_components_)]\nexplained_variance_pct = pca.explained_variance_ratio_ * 100\n\n# Plot the principle components' explained variance ratio.\nplt.figure(figsize=(15, 10))\nplt.bar(components, explained_variance_pct)\nplt.title(\"Ratio of Explained Variance\")\nplt.xlabel(\"Principle Component #\")\nplt.ylabel(\"%\")\nplt.show()\n\n# Get the weighting of each asset in the first principle component.\nfirst_component = pca.components_[0, :]\n\n# Select the highest- and lowest-absolute-weighing asset.\nhighest = assets[abs(first_component).argmax()]\nlowest = assets[abs(first_component).argmin()]\nprint(f'The highest-absolute-weighing asset: {highest}\\nThe lowest-absolute-weighing asset: {lowest}')\n\n# Plot their weighings.\nplt.figure(figsize=(15, 10))\nplt.bar(assets, first_component)\nplt.title(\"Weightings of each asset in the first component\")\nplt.xlabel(\"Assets\")\nplt.ylabel(\"Weighting\")\nplt.xticks(rotation=30)\nplt.show()\n\n# Call np.log to get the log price of the pair.\nlog_price = np.log(close_price[[highest, lowest]])\n\n# Test cointegration by Engle Granger Test.\ncoint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1], trend=\"c\", lags=0)\ndisplay(coint_result)\n\n# Get their cointegrating vector.\ncoint_vector = coint_result.cointegrating_vector[:2]\n\n# Calculate the spread.\nspread = log_price @ coint_vector\n\n# Use Augmented Dickey Fuller test to test its stationarity.\npvalue = adfuller(spread, maxlag=0)[1]\nprint(f\"The ADF test p-value is {pvalue}, so it is {'' if pvalue < 0.05 else 'not '}stationary.\")\n\n# Plot the spread.\nspread.plot(figsize=(15, 10), title=f\"Spread of {highest} and {lowest}\")\nplt.ylabel(\"Spread\")\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nfrom arch.unitroot.cointegration import engle_granger\nfrom pykalman import KalmanFilter\n\nclass PCADemo(QCAlgorithm):\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2014, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"SCHO\", \"SHY\"]\n\n# Add Equity ------------------------------------------------\nfor i in range(len(self.assets)):\nself.add_equity(self.assets[i], Resolution.MINUTE).symbol\n\n# Instantiate our model\nself.recalibrate()\n\n# Set a variable to indicate the trading bias of the portfolio\nself.state = 0\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.week_start(),\nself.time_rules.at(0, 0),\nself.recalibrate)\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SHY\"),\nself.every_day_before_market_close)\n\ndef recalibrate(self) -> None:\nqb = self\nhistory = qb.history(self.assets, 252*2, Resolution.DAILY)\nif history.empty: return\n\n# Select the close column and then call the unstack method\ndata = history['close'].unstack(level=0)\n\n# Convert into log-price series to eliminate compounding effect\nlog_price = np.log(data)\n\n### Get Cointegration Vectors\n# Get the cointegration vector\ncoint_result = engle_granger(log_price.iloc[:, 0], log_price.iloc[:, 1], trend=\"c\", lags=0)\ncoint_vector = coint_result.cointegrating_vector[:2]\n\n# Get the spread\nspread = log_price @ coint_vector\n\n### Kalman Filter\n# Initialize a Kalman Filter. Using the first 20 data points to optimize its initial state. We assume the market has no regime change so that the transitional matrix and observation matrix is [1].\nself.kalman_filter = KalmanFilter(transition_matrices = [1],\nobservation_matrices = [1],\ninitial_state_mean = spread.iloc[:20].mean(),\nobservation_covariance = spread.iloc[:20].var(),\nem_vars=['transition_covariance', 'initial_state_covariance'])\nself.kalman_filter = self.kalman_filter.em(spread.iloc[:20], n_iter=5)\n(filtered_state_means, filtered_state_covariances) = self.kalman_filter.filter(spread.iloc[:20])\n\n# Obtain the current Mean and Covariance Matrix expectations.\nself.current_mean = filtered_state_means[-1, :]\nself.current_cov = filtered_state_covariances[-1, :]\n\n# Initialize a mean series for spread normalization using the Kalman Filter's results.\nmean_series = np.array([None]*(spread.shape[0]-20))\n\n# Roll over the Kalman Filter to obtain the mean series.\nfor i in range(20, spread.shape[0]):\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread.iloc[i])\nmean_series[i-20] = float(self.current_mean)\n\n# Obtain the normalized spread series.\nnormalized_spread = (spread.iloc[20:] - mean_series)\n\n### Determine Trading Threshold\n# Initialize 50 set levels for testing.\ns0 = np.linspace(0, max(normalized_spread), 50)\n\n# Calculate the profit levels using the 50 set levels.\nf_bar = np.array([None]*50)\nfor i in range(50):\nf_bar[i] = len(normalized_spread.values[normalized_spread.values > s0[i]])               / normalized_spread.shape[0]\n\n# Set trading frequency matrix.\nD = np.zeros((49, 50))\nfor i in range(D.shape[0]):\nD[i, i] = 1\nD[i, i+1] = -1\n\n# Set level of lambda.\nl = 1.0\n\n# Obtain the normalized profit level.\nf_star = np.linalg.inv(np.eye(50) + l * D.T@D) @ f_bar.reshape(-1, 1)\ns_star = [f_star[i]*s0[i] for i in range(50)]\nself.threshold = s0[s_star.index(max(s_star))]\n\n# Set the trading weight. We would like the portfolio absolute total weight is 1 when trading.\nself.trading_weight = coint_vector / np.sum(abs(coint_vector))\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n\n# Get the real-time log close price for all assets and store in a Series\nseries = pd.Series()\nfor symbol in qb.securities.Keys:\nseries[symbol] = np.log(qb.securities[symbol].close)\n\n# Get the spread\nspread = np.sum(series * self.trading_weight)\n\n# Update the Kalman Filter with the Series\n(self.current_mean, self.current_cov) = self.kalman_filter.filter_update(filtered_state_mean = self.current_mean,\nfiltered_state_covariance = self.current_cov,\nobservation = spread)\n\n# Obtain the normalized spread.\nnormalized_spread = spread - self.current_mean\n\n# ==============================\n\n# Mean-reversion\nif normalized_spread < -self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = 1\n\nelif normalized_spread > self.threshold:\norders = []\nfor i in range(len(self.assets)):\norders.append(PortfolioTarget(self.assets[i], -1 * self.trading_weight[i]))\nself.set_holdings(orders)\n\nself.state = -1\n\n# Out of position if spread recovered\nelif self.state == 1 and normalized_spread > -self.threshold or self.state == -1 and normalized_spread < self.threshold:\nself.liquidate()\n\nself.state = 0",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > PCA and Pairs Trading",
      "section_number": "11.6",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.7",
    "title": "Hidden Markov Models",
    "level": 2,
    "path": "Applying Research > Hidden Markov Models",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Hidden Markov Model hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nA Markov process is a stochastic process where the possibility of switching to another state depends only on the current state of the model by the current state's probability distribution (it is usually represented by a state transition matrix). It is history-independent, or memoryless. While often a Markov process's state is observable, the states of a Hidden Markov Model (HMM) is not observable. This means the input(s) and output(s) are observable, but their intermediate, the state, is non-observable/hidden.\n\nA 3-state HMM example, where S are the hidden states, O are the observable states and a are the probabilities of state transition.Image source: Modeling Strategic Use of Human Computer Interfaces with Novel Hidden Markov Models. L. J. Mariano, et. al. (2015). Frontiers in Psychology 6:919. DOI:10.3389/fpsyg.2015.00919\n\nIn finance, HMM is particularly useful in determining the market regime, usually classified into \"Bull\" and \"Bear\" markets. Another popular classification is \"Volatile\" vs \"Involatile\" market, such that we can avoid entering the market when it is too risky. We hypothesis a HMM could be able to do the later, so we can produce a SPY-out-performing portfolio (positive alpha).\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing, validation and visualization. Importstatsmodels,scipy,numpy,matplotlibandpandaslibraries by the following:\n\nfrom statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\nfrom scipy.stats import multivariate_normal\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the desired index for research.asset = \"SPX\"Call theadd_indexmethod with the tickers, and their corresponding resolution.qb.add_index(asset, Resolution.MINUTE)If you do not pass a resolution argument,Resolution.MINUTEis used by default.Call thehistorymethod withqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.history = qb.history(qb.securities.keys(), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data to get the volatility of the market for classification.\n\nSelect the close column and then call theunstackmethod.close_price = history['close'].unstack(level=0)Callpct_changeto compute the daily return.returns = close_price.pct_change().iloc[1:]Initialize the HMM, then fit by the daily return data. Note that we're using varinace as switching regime, soswitching_varianceargument is set asTrue.model = MarkovRegression(returns, k_regimes=2, switching_variance=True).fit()\ndisplay(model.summary())All p-values of the regime self-transition coefficients and the regime transition probability matrix's coefficient is smaller than 0.05, indicating the model should be able to classify the data into 2 different volatility regimes.\n\n### Test Hypothesis\n\nWe now verify if the model can detect high and low volatility period effectively.\n\nGet the regime as a column, 1 as Low Variance Regime, 2 as High Variance Regime.regime = pd.Series(model.smoothed_marginal_probabilities.values.argmax(axis=1)+1,\nindex=returns.index, name='regime')\ndf_1 = close.loc[returns.index][regime == 1]\ndf_2 = close.loc[returns.index][regime == 2]Get the mean and covariance matrix of the 2 regimes, assume 0 covariance between the two.mean = np.array([returns.loc[df_1.index].mean(), returns.loc[df_2.index].mean()])\ncov = np.array([[returns.loc[df_1.index].var(), 0], [0, returns.loc[df_2.index].var()]])Fit a 2-dimensional multivariate normal distribution by the 2 means and covriance matrix.dist = multivariate_normal(mean=mean.flatten(), cov=cov)\nmean_1, mean_2 = mean[0], mean[1]\nsigma_1, sigma_2 = cov[0,0], cov[1,1]Get the normal distribution of each of the distribution.x = np.linspace(-0.05, 0.05, num=100)\ny = np.linspace(-0.05, 0.05, num=100)\nX, Y = np.meshgrid(x,y)\npdf = np.zeros(X.shape)\nfor i in range(X.shape[0]):\nfor j in range(X.shape[1]):\npdf[i,j] = dist.pdf([X[i,j], Y[i,j]])Plot the probability of data in different regimes.fig, axes = plt.subplots(2, figsize=(15, 10))\nax = axes[0]\nax.plot(model.smoothed_marginal_probabilities[0])\nax.set(title='Smoothed probability of Low Variance Regime')\nax = axes[1]\nax.plot(model.smoothed_marginal_probabilities[1])\nax.set(title='Smoothed probability of High Variance Regime')\nfig.tight_layout()\nplt.show()Plot the series into regime-wise.df_1.index = pd.to_datetime(df_1.index)\ndf_1 = df_1.sort_index()\ndf_2.index = pd.to_datetime(df_2.index)\ndf_2 = df_2.sort_index()\nplt.figure(figsize=(15, 10))\nplt.scatter(df_1.index, df_1, color='blue', label=\"Low Variance Regime\")\nplt.scatter(df_2.index, df_2, color='red', label=\"High Variance Regime\")\nplt.title(\"Price series\")\nplt.ylabel(\"Price ($)\")\nplt.xlabel(\"Date\")\nplt.legend()\nplt.show()Plot the distribution surface.fig = plt.figure(figsize=(20, 10))\nax = fig.add_subplot(122, projection = '3d')\nax.plot_surface(X, Y, pdf, cmap = 'viridis')\nax.axes.zaxis.set_ticks([])\nplt.xlabel(\"Low Volatility Regime\")\nplt.ylabel(\"High Volatility Regime\")\nplt.title('Bivariate normal distribution of the Regimes')\nplt.tight_layout()\nplt.show()Plot the contour.plt.figure(figsize=(12, 8))\nplt.contourf(X, Y, pdf, cmap = 'viridis')\nplt.xlabel(\"Low Volatility Regime\")\nplt.ylabel(\"High Volatility Regime\")\nplt.title('Bivariate normal distribution of the Regimes')\nplt.tight_layout()\nplt.show()\n\nWe can clearly seen from the results, the Low Volatility Regime has much lower variance than the High Volatility Regime, proven the model works.\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into backtest is to create a scheduled event which uses our model to predict the expected return. Since we could calculate the expected return, we'd use Mean-Variance Optimization for portfolio construction.\n\ndef initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2008, 1, 1)\nself.set_end_date(2021, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"SPY\", \"TLT\"]    # \"TLT\" as fix income in out-of-market period (high volatility)\n\n# Add Equity ------------------------------------------------\nfor ticker in self.assets:\nself.add_equity(ticker, Resolution.MINUTE)\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SPY\", 5),\nself.every_day_before_market_close)\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n\n# Get history\nhistory = qb.history([\"SPY\"], datetime(2010, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Get the close price daily return.\nclose = history['close'].unstack(level=0)\n\n# Call pct_change to obtain the daily return\nreturns = close.pct_change().iloc[1:]\n\n# Initialize the HMM, then fit by the standard deviation data.\nmodel = MarkovRegression(returns, k_regimes=2, switching_variance=True).fit()\n\n# Obtain the market regime\nregime = model.smoothed_marginal_probabilities.values.argmax(axis=1)[-1]\n\n# ==============================\n\nif regime == 0:\nself.set_holdings([PortfolioTarget(\"TLT\", 0.), PortfolioTarget(\"SPY\", 1.)])\nelse:\nself.set_holdings([PortfolioTarget(\"TLT\", 1.), PortfolioTarget(\"SPY\", 0.)])\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\nfrom scipy.stats import multivariate_normal\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired tickers for research.\nasset = \"SPX\"\n\n# Call the AddIndex method with the tickers, and its corresponding resolution. Then store their Symbols. Resolution.Minute is used by default.\nqb.add_index(asset, Resolution.MINUTE)\n\n# Call the history method with qb.securities.keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.keys(), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Get the close price daily return.\nclose = history['close'].unstack(level=0)\n\n# Call pct_change to obtain the daily return\nreturns = close.pct_change().iloc[1:]\n\n# Initialize the HMM, then fit by the daily return data. Note that we're using varinace as switching regime, so switching_variance is set as True.\nmodel = MarkovRegression(returns, k_regimes=2, switching_variance=True).fit()\ndisplay(model.summary())\n\n# Get the regime as a column, 1 as Low Variance Regime, 2 as High Variance Regime.\nregime = pd.Series(model.smoothed_marginal_probabilities.values.argmax(axis=1)+1,\nindex=returns.index, name='regime')\ndf_1 = close.loc[returns.index][regime == 1]\ndf_2 = close.loc[returns.index][regime == 2]\n\n# Get the mean and covariance matrix of the 2 regimes, assume 0 covariance between the two.\nmean = np.array([returns.loc[df_1.index].mean(), returns.loc[df_2.index].mean()])\ncov = np.array([[returns.loc[df_1.index].var()[0], 0], [0, returns.loc[df_2.index].var()[0]]])\n\n# Fit a 2-dimensional multivariate normal distribution by the 2 means and covriance matrix.\ndist = multivariate_normal(mean=mean.flatten(), cov=cov)\nmean_1, mean_2 = mean[0], mean[1]\nsigma_1, sigma_2 = cov[0,0], cov[1,1]\n\n# Get the normal distribution of each of the distribution.\nx = np.linspace(-0.05, 0.05, num=100)\ny = np.linspace(-0.05, 0.05, num=100)\nX, Y = np.meshgrid(x,y)\npdf = np.zeros(X.shape)\nfor i in range(X.shape[0]):\nfor j in range(X.shape[1]):\npdf[i,j] = dist.pdf([X[i,j], Y[i,j]])\n\n# Plot the probability of data in different regimes.\nfig, axes = plt.subplots(2, figsize=(15, 10))\nax = axes[0]\nax.plot(model.smoothed_marginal_probabilities[0])\nax.set(title='Smoothed probability of Low Variance Regime')\nax = axes[1]\nax.plot(model.smoothed_marginal_probabilities[1])\nax.set(title='Smoothed probability of High Variance Regime')\nfig.tight_layout()\nplt.show()\n\n# Plot the series into regime-wise.\ndf_1.index = pd.to_datetime(df_1.index)\ndf_1 = df_1.sort_index()\ndf_2.index = pd.to_datetime(df_2.index)\ndf_2 = df_2.sort_index()\nplt.figure(figsize=(15, 10))\nplt.scatter(df_1.index, df_1, color='blue', label=\"Low Variance Regime\")\nplt.scatter(df_2.index, df_2, color='red', label=\"High Variance Regime\")\nplt.title(\"Price series\")\nplt.ylabel(\"Price ($)\")\nplt.xlabel(\"Date\")\nplt.legend()\nplt.show()\n\n# Plot the distribution surface.\nfig = plt.figure(figsize=(20, 10))\nax = fig.add_subplot(122, projection = '3d')\nax.plot_surface(X, Y, pdf, cmap = 'viridis')\nax.axes.zaxis.set_ticks([])\nplt.xlabel(\"Low Volatility Regime\")\nplt.ylabel(\"High Volatility Regime\")\nplt.title('Bivariate normal distribution of the Regimes')\nplt.tight_layout()\nplt.show()\n\n# plot the contour\nplt.figure(figsize=(12, 8))\nplt.contourf(X, Y, pdf, cmap = 'viridis')\nplt.xlabel(\"Low Volatility Regime\")\nplt.ylabel(\"High Volatility Regime\")\nplt.title('Bivariate normal distribution of the Regimes')\nplt.tight_layout()\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nfrom statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n\nclass HMMDemo(QCAlgorithm):\ndef initialize(self):\nself.set_start_date(2008, 1, 1)\nself.set_end_date(2021, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.assets = [\"SPY\", \"TLT\"]    # \"TLT\" as fix income in out-of-market period (high volatility)\n\n# Add Equity ------------------------------------------------\nfor ticker in self.assets:\nself.add_equity(ticker, Resolution.MINUTE).symbol\n\n# Set Scheduled Event Method For Kalman Filter updating.\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SPY\", 5),\nself.every_day_before_market_close)\n\ndef every_day_before_market_close(self):\nqb = self\n\n# Get history\nhistory = qb.history([\"SPY\"], 252*3, Resolution.DAILY)\n\n# Get the close price daily return.\nclose = history['close'].unstack(level=0)\n\n# Call pct_change to obtain the daily return\nreturns = close.pct_change().iloc[1:]\n\n# Initialize the HMM, then fit by the standard deviation data.\nmodel = MarkovRegression(returns, k_regimes=2, switching_variance=True).fit()\n\n# Obtain the market regime\nregime = model.smoothed_marginal_probabilities.values.argmax(axis=1)[-1]\n\n# ==============================\n\nif regime == 0:\nself.set_holdings([PortfolioTarget(\"TLT\", 0.), PortfolioTarget(\"SPY\", 1.)])\nelse:\nself.set_holdings([PortfolioTarget(\"TLT\", 1.), PortfolioTarget(\"SPY\", 0.)])",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Hidden Markov Models",
      "section_number": "11.7",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.8",
    "title": "Long Short-Term Memory",
    "level": 2,
    "path": "Applying Research > Long Short-Term Memory",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Long Short Term Memory hypothesis, then put the hypothesis in production.\n\nRecurrent neural networks (RNN) are a powerful tool in deep learning. These models quite accurately mimic how humans process sequencial information and learn. Unlike traditional feedforward neural networks, RNNs have memory. That is, information fed into them persists and the network is able to draw on this to make inferences.Long Short-term Memory (LSTM) is a type of RNN. Instead of one layer, LSTM cells generally have four, three of which are part of \"gates\" -- ways to optionally let information through. The three gates are commonly referred to as the forget, input, and output gates. The forget gate layer is where the model decides what information to keep from prior states. At the input gate layer, the model decides which values to update. Finally, the output gate layer is where the final output of the cell state is decided. Essentially, LSTM separately decides what to remember and the rate at which it should update.\n\nAn exmaple of a LSTM cell: x is the input data, c is the long-term memory, h is the current state and serve as short-term memory, $\\sigma$ and $tanh$ is the non-linear activation function of the gates.Image source: https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:LSTM_Cell.svg\n\n### Create Hypothesis\n\nLSTM models have produced some great results when applied to time-series prediction. One of the central challenges with conventional time-series models is that, despite trying to account for trends or other non-stationary elements, it is almost impossible to truly predict an outlier like a recession, flash crash, liquidity crisis, etc. By having a long memory, LSTM models are better able to capture these difficult trends in the data without suffering from the level of overfitting a conventional model would need in order to capture the same data.For a very basic application, we're hypothesizing LSTM can offer an accurate prediction in future price.\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing, validation and visualization. Importkeras,sklearn,numpyandmatplotliblibraries by the following:\n\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the desired index for research.asset = \"SPY\"Call theadd_equitymethod with the tickers, and their corresponding resolution.qb.add_equity(asset, Resolution.MINUTE)If you do not pass a resolution argument,Resolution.MINUTEis used by default.Call thehistorymethod withqb.securities.keysfor all tickers, time argument(s), and resolution to request historical data for the symbol.history = qb.history(qb.securities.keys(), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data as well as build the LSTM model before testing the hypothesis. We would scale our data to for better covergence.\n\nSelect the close column and then call theunstackmethod.close_price = history['close'].unstack(level=0)InitializeMinMaxScalerto scale the data onto [0,1].scaler = MinMaxScaler(feature_range = (0, 1))Transform our data.df = pd.DataFrame(scaler.fit_transform(close), index=close.index)Select input datascaler = MinMaxScaler(feature_range = (0, 1))Shift the data for 1-step backward as training output result.output = df.shift(-1).iloc[:-1]Split the data into training and testing sets.In this example, we use the first 80% data for trianing, and the last 20% for testing.splitter = int(input_.shape[0] * 0.8)\nX_train = input_.iloc[:splitter]\nX_test = input_.iloc[splitter:]\ny_train = output.iloc[:splitter]\ny_test = output.iloc[splitter:]Build feauture and label sets (using number of steps 60, and feature rank 1).features_set = []\nlabels = []\nfor i in range(60, X_train.shape[0]):\nfeatures_set.append(X_train.iloc[i-60:i].values.reshape(-1, 1))\nlabels.append(y_train.iloc[i])\nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n\n### Build Model\n\nWe construct the LSTM model.\n\nBuild aSequentialkeras model.model = Sequential()Create the model infrastructure.# Add our first LSTM layer - 50 nodes.\nmodel.add(LSTM(units = 50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n# Add Dropout layer to avoid overfitting\nmodel.add(Dropout(0.2))\n# Add additional layers\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 5))\nmodel.add(Dense(units = 1))Compile the model.We use Adam as optimizer for adpative step size and MSE as loss function since it is continuous data.model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mae', 'acc'])Set early stopping callback method.callback = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True)Display the model structure.model.summary()Fit the model to our data, running 20 training epochs.Note that different training session's results will not be the same since the batch is randomly selected.model.fit(features_set, labels, epochs = 20, batch_size = 100, callbacks=[callback])\n\n### Test Hypothesis\n\nWe would test the performance of this ML model to see if it could predict 1-step forward price precisely. To do so, we would compare the predicted and actual prices.\n\nGet testing set features for input.test_features = []\nfor i in range(60, X_test.shape[0]):\ntest_features.append(X_test.iloc[i-60:i].values.reshape(-1, 1))\ntest_features = np.array(test_features)\ntest_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))Make predictions.predictions = model.predict(test_features)Transform predictions back to original data-scale.predictions = scaler.inverse_transform(predictions)\nactual = scaler.inverse_transform(y_test.values)Plot the results.plt.figure(figsize=(15, 10))\nplt.plot(actual[60:], color='blue', label='Actual')\nplt.plot(predictions , color='red', label='Prediction')\nplt.title('Price vs Predicted Price ')\nplt.legend()\nplt.show()\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into backtest is to create a scheduled event which uses our model to predict the expected return. If we predict the price will go up, we long SPY, else, we short it.\n\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2016, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.asset = \"SPY\"\n\n# Add Equity ------------------------------------------------\nself.add_equity(self.asset, Resolution.MINUTE)\n\n# Initialize the LSTM model\nself.build_model()\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SPY\", 5),\nself.every_day_before_market_close)\n\n# Set Scheduled Event Method For Our Model Retraining every month\nself.schedule.on(self.date_rules.month_start(),\nself.time_rules.at(0, 0),\nself.build_model)\n\nWe'll also need to create a function to train and update our model from time to time.\n\ndef build_model(self) -> None:\nqb = self\n\n### Preparing Data\n# Get historical data\nhistory = qb.history(qb.securities.keys(), 252*2, Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\nclose = history['close'].unstack(level=0)\n\n# Scale data onto [0,1]\nself.scaler = MinMaxScaler(feature_range = (0, 1))\n\n# Transform our data\ndf = pd.DataFrame(self.scaler.fit_transform(close), index=close.index)\n\n# Feature engineer the data for input.\ninput_ = df.iloc[1:]\n\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1]\n\n# Build feauture and label sets (using number of steps 60, and feature rank 1)\nfeatures_set = []\nlabels = []\nfor i in range(60, input_.shape[0]):\nfeatures_set.append(input_.iloc[i-60:i].values.reshape(-1, 1))\nlabels.append(output.iloc[i])\nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n\n### Build Model\n# Build a Sequential keras model\nself.model = Sequential()\n\n# Add our first LSTM layer - 50 nodes\nself.model.add(LSTM(units = 50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n# Add Dropout layer to avoid overfitting\nself.model.add(Dropout(0.2))\n# Add additional layers\nself.model.add(LSTM(units=50, return_sequences=True))\nself.model.add(Dropout(0.2))\nself.model.add(LSTM(units=50))\nself.model.add(Dropout(0.2))\nself.model.add(Dense(units = 5))\nself.model.add(Dense(units = 1))\n\n# Compile the model. We use Adam as optimizer for adpative step size and MSE as loss function since it is continuous data.\nself.model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mae', 'acc'])\n\n# Set early stopping callback method\ncallback = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n\n# Fit the model to our data, running 20 training epochs\nself.model.fit(features_set, labels, epochs = 20, batch_size = 1000, callbacks=[callback])\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\nhistory = qb.history(qb.securities.keys(), 60, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Make all of them into a single time index.\nclose = history.close.unstack(level=0)\n\n# Scale our data\ndf = pd.DataFrame(self.scaler.transform(close), index=close.index)\n\n# Feature engineer the data for input\ninput_ = []\ninput_.append(df.values.reshape(-1, 1))\ninput_ = np.array(input_)\ninput_ = np.reshape(input_, (input_.shape[0], input_.shape[1], 1))\n\n# Prediction\nprediction = self.model.predict(input_)\n\n# Revert the scaling into price\nprediction = self.scaler.inverse_transform(prediction)\n\n# ==============================\n\nif prediction > qb.Securities[self.asset].Price:\nself.set_holdings(self.asset, 1.)\nelse:\nself.set_holdings(self.asset, -1.)\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the desired index for research.\nasset = \"SPY\"\n# Call the add_equity method with the tickers, and their corresponding resolution.\nqb.add_equity(asset, Resolution.MINUTE)\n# If you do not pass a resolution argument, Resolution.MINUTE is used by default.\n# Call the history method with qb.securities.keys for all tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(qb.securities.keys(), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\nclose_price = history['close'].unstack(level=0)\n# Initialize MinMaxScaler to scale the data onto [0,1].\nscaler = MinMaxScaler(feature_range = (0, 1))\n# Transform our data.\ndf = pd.DataFrame(scaler.fit_transform(close), index=close.index)\n# Select input data\nscaler = MinMaxScaler(feature_range = (0, 1))\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1]\n# Split the data into training and testing sets.\n# In this example, we use the first 80% data for trianing, and the last 20% for testing.\nsplitter = int(input_.shape[0] * 0.8)\nX_train = input_.iloc[:splitter]\nX_test = input_.iloc[splitter:]\ny_train = output.iloc[:splitter]\ny_test = output.iloc[splitter:]\n# Build feauture and label sets (using number of steps 60, and feature rank 1).\nfeatures_set = []\nlabels = []\nfor i in range(60, X_train.shape[0]):\nfeatures_set.append(X_train.iloc[i-60:i].values.reshape(-1, 1))\nlabels.append(y_train.iloc[i])\nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n\n# Build a Sequential keras model.\nmodel = Sequential()\n# Create the model infrastructure.\n# Add our first LSTM layer - 50 nodes.\nmodel.add(LSTM(units = 50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n# Add Dropout layer to avoid overfitting\nmodel.add(Dropout(0.2))\n# Add additional layers\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 5))\nmodel.add(Dense(units = 1))\n# Compile the model. We use Adam as optimizer for adpative step size and MSE as loss function since it is continuous data.\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mae', 'acc'])\n# Set early stopping callback method.\ncallback = EarlyStopping(monitor='loss', patience=3, verbose=1, restore_best_weights=True)\n# Display the model structure.\nmodel.summary()\n# Fit the model to our data, running 20 training epochs.\n# Note that different training session's results will not be the same since the batch is randomly selected.\nmodel.fit(features_set, labels, epochs = 20, batch_size = 100, callbacks=[callback])\n\n# Get testing set features for input.\ntest_features = []\nfor i in range(60, X_test.shape[0]):\ntest_features.append(X_test.iloc[i-60:i].values.reshape(-1, 1))\ntest_features = np.array(test_features)\ntest_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))\n# Make predictions.\npredictions = model.predict(test_features)\n# Transform predictions back to original data-scale.\npredictions = scaler.inverse_transform(predictions)\nactual = scaler.inverse_transform(y_test.values)\n# Plot the results.\nplt.figure(figsize=(15, 10))\nplt.plot(actual[60:], color='blue', label='Actual')\nplt.plot(predictions , color='red', label='Prediction')\nplt.title('Price vs Predicted Price ')\nplt.legend()\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\n\nclass LongShortTermMemoryAlgorithm(QCAlgorithm):\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2016, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.asset = \"SPY\"\n\n# Add Equity ------------------------------------------------\nself.add_equity(self.asset, Resolution.MINUTE)\n\n# Initialize the LSTM model\nself.build_model()\n\n# Set Scheduled Event Method For Our Model\nself.schedule.on(self.date_rules.every_day(),\nself.time_rules.before_market_close(\"SPY\", 5),\nself.every_day_before_market_close)\n\n# Set Scheduled Event Method For Our Model Retraining every month\nself.schedule.on(self.date_rules.month_start(),\nself.time_rules.at(0, 0),\nself.build_model)\n\ndef build_model(self) -> None:\nqb = self\n\n### Preparing Data\n# Get historical data\nhistory = qb.history(qb.securities.keys(), 252*2, Resolution.DAILY)\n\n# Select the close column and then call the unstack method.\nclose = history['close'].unstack(level=0)\n\n# Scale data onto [0,1]\nself.scaler = MinMaxScaler(feature_range = (0, 1))\n\n# Transform our data\ndf = pd.DataFrame(self.scaler.fit_transform(close), index=close.index)\n\n# Feature engineer the data for input.\ninput_ = df.iloc[1:]\n\n# Shift the data for 1-step backward as training output result.\noutput = df.shift(-1).iloc[:-1]\n\n# Build feauture and label sets (using number of steps 60, and feature rank 1)\nfeatures_set = []\nlabels = []\nfor i in range(60, input_.shape[0]):\nfeatures_set.append(input_.iloc[i-60:i].values.reshape(-1, 1))\nlabels.append(output.iloc[i])\nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n\n### Build Model\n# Build a Sequential keras model\nself.model = Sequential()\n\n# Add our first LSTM layer - 50 nodes\nself.model.add(LSTM(units = 50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n# Add Dropout layer to avoid overfitting\nself.model.add(Dropout(0.2))\n# Add additional layers\nself.model.add(LSTM(units=50, return_sequences=True))\nself.model.add(Dropout(0.2))\nself.model.add(LSTM(units=50))\nself.model.add(Dropout(0.2))\nself.model.add(Dense(units = 5))\nself.model.add(Dense(units = 1))\n\n# Compile the model. We use Adam as optimizer for adpative step size and MSE as loss function since it is continuous data.\nself.model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mae', 'acc'])\n\n# Set early stopping callback method\ncallback = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n\n# Fit the model to our data, running 20 training epochs\nself.model.fit(features_set, labels, epochs = 20, batch_size = 1000, callbacks=[callback])\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Fetch history on our universe\nhistory = qb.history(qb.securities.keys(), 60, Resolution.DAILY)\nif history.empty:\nreturn\n\n# Make all of them into a single time index.\nclose = history.close.unstack(level=0)\n\n# Scale our data\ndf = pd.DataFrame(self.scaler.transform(close), index=close.index)\n\n# Feature engineer the data for input\ninput_ = []\ninput_.append(df.values.reshape(-1, 1))\ninput_ = np.array(input_)\ninput_ = np.reshape(input_, (input_.shape[0], input_.shape[1], 1))\n\n# Prediction\nprediction = self.model.predict(input_)\n\n# Revert the scaling into price\nprediction = self.scaler.inverse_transform(prediction)\n\n# ==============================\n\nif prediction > qb.Securities[self.asset].Price:\nself.set_holdings(self.asset, 1.)\nelse:\nself.set_holdings(self.asset, -1.)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Long Short-Term Memory",
      "section_number": "11.8",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.9",
    "title": "Airline Buybacks",
    "level": 2,
    "path": "Applying Research > Airline Buybacks",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Airline Buybacks hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nBuyback represents a company buy back its own stocks in the market, as (1) management is confident on its own future, and (2) wants more control over its development. Since usually buyback is in large scale on a schedule, the price of repurchasing often causes price fluctuation.Airlines is one of the largest buyback sectors. Major US Airlines use over 90% of their free cashflow to buy back their own stocks in the recent years.[1]Therefore, we can use airline companies to test the hypothesis of buybacks would cause price action. In this particular exmaple, we're hypothesizing that difference in buyback price and close price would suggest price change in certain direction. (we don't know forward return would be in momentum or mean-reversion in this case!)\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing, validation and visualization. ImportSmartInsiderTransactionclass,statsmodels,sklearn,numpy,pandasandseabornlibraries by the following:\n\nfrom QuantConnect.DataSource import SmartInsiderTransaction\n\nfrom statsmodels.discrete.discrete_model import Logit\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nInstantiate aQuantBook.qb = QuantBook()Select the airline tickers for research.assets = [\"LUV\",   # Southwest Airlines\n\"DAL\",   # Delta Airlines\n\"UAL\",   # United Airlines Holdings\n\"AAL\",   # American Airlines Group\n\"SKYW\",  # SkyWest Inc.\n\"ALGT\",  # Allegiant Travel Co.\n\"ALK\"    # Alaska Air Group Inc.\n]Call theadd_equitymethod with the tickers, and its corresponding resolution. Then calladd_datawithSmartInsiderTransactionto subscribe to their buyback transaction data. Save theSymbols into a dictionary.symbols = {}\nfor ticker in assets:\nsymbol = qb.add_equity(ticker, Resolution.MINUTE).symbol\nsymbols[symbol] = qb.add_data(SmartInsiderTransaction, symbol).symbolIf you do not pass a resolution argument,Resolution.MINUTEis used by default.Call thehistorymethod with a list ofSymbols for all tickers, time argument(s), and resolution to request historical data for the symbols.history = qb.history(list(symbols.keys()), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)Call SPY history as reference.spy = qb.history(qb.add_equity(\"SPY\").symbol, datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)Call thehistorymethod with a list ofSmartInsiderTransactionSymbols for all tickers, time argument(s), and resolution to request historical data for the symbols.history_buybacks = qb.history(list(symbols.values()), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n### Prepare Data\n\nWe'll have to process our data to get the buyback premium/discount% vs forward return data.\n\nSelect the close column and then call theunstackmethod.df = history['close'].unstack(level=0)\nspy_close = spy['close'].unstack(level=0)Callpct_changeto get the daily return of close price, then shift 1-step backward as prediction.ret = df.pct_change().shift(-1).iloc[:-1]\nret_spy = spy_close.pct_change().shift(-1).iloc[:-1]Get the active forward return.active_ret = ret.sub(ret_spy.values, axis=0)Select the ExecutionPrice column and then call theunstackmethod to get the buyback dataframe.df_buybacks = history_buybacks['executionprice'].unstack(level=0)Convert buyback history into daily mean data.df_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\ndf_buybacks.columns = df.columnsGet the buyback premium/discount %.df_close = df.reindex(df_buybacks.index)[~df_buybacks.isna()]\ndf_buybacks = (df_buybacks - df_close)/df_closeCreate aDataframeto hold the buyback and 1-day forward return data.data = pd.DataFrame(columns=[\"Buybacks\", \"Return\"])Append the data into theDataframe.for row, row_buyback in zip(active_ret.reindex(df_buybacks.index).itertuples(), df_buybacks.itertuples()):\nindex = row[0]\nfor i in range(1, df_buybacks.shape[1]+1):\nif row_buyback[i] != 0:\ndata = pd.concat([data, pd.DataFrame({\"Buybacks\": row_buyback[i], \"Return\":row[i]}, index=[index])])Calldropnato drop NaNs.data.dropna(inplace=True)\n\n### Test Hypothesis\n\nWe would test (1) if buyback has statistically significant effect on return direction, and (2) buyback could be a return predictor.\n\nGet binary return (+/-).binary_ret = data[\"Return\"].copy()\nbinary_ret[binary_ret < 0] = 0\nbinary_ret[binary_ret > 0] = 1Construct a logistic regression model.model = Logit(binary_ret.values, data[\"Buybacks\"].values).fit()Display logistic regression results.display(model.summary())We can see a p-value of < 0.05 in the logistic regression model, meaning the separation of positive and negative using buyback premium/discount% is statistically significant.Plot the results.plt.figure(figsize=(10, 6))\nsns.regplot(x=data[\"Buybacks\"]*100, y=binary_ret, logistic=True, ci=None, line_kws={'label': \" Logistic Regression Line\"})\nplt.plot([-50, 50], [0.5, 0.5], \"r--\", label=\"Selection Cutoff Line\")\nplt.title(\"Buyback premium vs Profit/Loss\")\nplt.xlabel(\"Buyback premium %\")\nplt.xlim([-50, 50])\nplt.ylabel(\"Profit/Loss\")\nplt.legend()\nplt.show()Interesting, from the logistic regression line, we observe that when the airlines brought their stock in premium price, the price tended to go down, while the opposite for buying back in discount.Let's also study how good is the logistic regression.Get in-sample prediction result.predictions = model.predict(data[\"Buybacks\"].values)\nfor i in range(len(predictions)):\npredictions[i] = 1 if predictions[i] > 0.5 else 0Callconfusion_matrixto contrast the results.cm = confusion_matrix(binary_ret, predictions)Display the result.df_result = pd.DataFrame(cm,\nindex=pd.MultiIndex.from_tuples([(\"Prediction\", \"Positive\"), (\"Prediction\", \"Negative\")]),\ncolumns=pd.MultiIndex.from_tuples([(\"Actual\", \"Positive\"), (\"Actual\", \"Negative\")]))The logistic regression is having a 55.8% accuracy (55% sensitivity and 56.3% specificity), this can suggest a > 50% win rate before friction costs, proven our hypothesis.\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting. One way to accomodate this model into backtest is to create a scheduled event which uses our model to predict the expected return.\n\ndef initialize(self) -> None:\n\n#1. Required: Five years of backtest history\nself.set_start_date(2017, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(EqualWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\n# Set our strategy to be take 5% profit and 5% stop loss.\nself.add_risk_management(MaximumUnrealizedProfitPercentPerSecurity(0.05))\nself.add_risk_management(MaximumDrawdownPercentPerSecurity(0.05))\n\n# Select the airline tickers for research.\nself.symbols = {}\nassets = [\"LUV\",   # Southwest Airlines\n\"DAL\",   # Delta Airlines\n\"UAL\",   # United Airlines Holdings\n\"AAL\",   # American Airlines Group\n\"SKYW\",  # SkyWest Inc.\n\"ALGT\",  # Allegiant Travel Co.\n\"ALK\"    # Alaska Air Group Inc.\n]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Then call AddData with SmartInsiderTransaction to subscribe to their buyback transaction data.\nfor ticker in assets:\nsymbol = self.add_equity(ticker, Resolution.MINUTE).symbol\nself.symbols[symbol] = self.add_data(SmartInsiderTransaction, symbol).symbol\n\nself.add_equity(\"SPY\")\n\n# Initialize the model\nself.build_model()\n\n# Set Scheduled Event Method For Our Model Recalibration every month\nself.schedule.on(self.date_rules.month_start(), self.time_rules.at(0, 0), self.build_model)\n\n# Set Scheduled Event Method For Trading\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SPY\", 5), self.every_day_before_market_close)\n\nWe'll also need to create a function to train and update the logistic regression model from time to time.\n\ndef build_model(self) -> None:\nqb = self\n# Call the History method with list of tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(list(self.symbols.keys()), datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Call SPY history as reference\nspy = qb.history([\"SPY\"], datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Call the History method with list of buyback tickers, time argument(s), and resolution to request buyback data for the symbol.\nhistory_buybacks = qb.history(list(self.symbols.values()), datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Select the close column and then call the unstack method to get the close price dataframe.\ndf = history['close'].unstack(level=0)\nspy_close = spy['close'].unstack(level=0)\n\n# Call pct_change to get the daily return of close price, then shift 1-step backward as prediction.\nret = df.pct_change().shift(-1).iloc[:-1]\nret_spy = spy_close.pct_change().shift(-1).iloc[:-1]\n\n# Get the active return\nactive_ret = ret.sub(ret_spy.values, axis=0)\n\n# Select the ExecutionPrice column and then call the unstack method to get the dataframe.\ndf_buybacks = history_buybacks['executionprice'].unstack(level=0)\n\n# Convert buyback history into daily mean data\ndf_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\ndf_buybacks.columns = df.columns\n\n# Get the buyback premium/discount\ndf_close = df.reindex(df_buybacks.index)[~df_buybacks.isna()]\ndf_buybacks = (df_buybacks - df_close)/df_close\n\n# Create a dataframe to hold the buyback and 1-day forward return data\ndata = pd.DataFrame(columns=[\"Buybacks\", \"Return\"])\n\n# Append the data into the dataframe\nfor row, row_buyback in zip(active_ret.reindex(df_buybacks.index).itertuples(), df_buybacks.itertuples()):\nindex = row[0]\nfor i in range(1, df_buybacks.shape[1]+1):\nif row_buyback[i] != 0:\ndata = pd.concat([data, pd.DataFrame({\"Buybacks\": row_buyback[i], \"Return\":row[i]}, index=[index])])\n\n# Call dropna to drop NaNs\ndata.dropna(inplace=True)\n\n# Get binary return (+/-)\nbinary_ret = data[\"Return\"].copy()\nbinary_ret[binary_ret < 0] = 0\nbinary_ret[binary_ret > 0] = 1\n\n# Construct a logistic regression model\nself.model = Logit(binary_ret.values, data[\"Buybacks\"].values).fit()\n\nNow we export our model into the scheduled event method. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Get any buyback event today\nhistory_buybacks = qb.history(list(self.symbols.values()), timedelta(days=1), Resolution.DAILY)\nif history_buybacks.empty or \"executionprice\" not in history_buybacks.columns: return\n\n# Select the ExecutionPrice column and then call the unstack method to get the dataframe.\ndf_buybacks = history_buybacks['executionprice'].unstack(level=0)\n\n# Convert buyback history into daily mean data\ndf_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\n\n# ==============================\n\ninsights = []\n\n# Iterate the buyback data, thne pass to the model for prediction\nrow = df_buybacks.iloc[-1]\nfor i in range(len(row)):\nprediction = self.model.predict(row[i])\n\n# Long if the prediction predict price goes up, short otherwise. Do opposite for SPY (active return)\nif prediction > 0.5:\ninsights.append( Insight.price(row.index[i].split(\".\")[0], timedelta(days=1), InsightDirection.UP) )\ninsights.append( Insight.price(\"SPY\", timedelta(days=1), InsightDirection.DOWN) )\nelse:\ninsights.append( Insight.price(row.index[i].split(\".\")[0], timedelta(days=1), InsightDirection.DOWN) )\ninsights.append( Insight.price(\"SPY\", timedelta(days=1), InsightDirection.UP) )\n\nself.emit_insights(insights)\n\n### Reference\n\nUS Airlines Spent 96% of Free Cash Flow on Buybacks: Chart. B. Kochkodin (17 March 2020).Bloomberg. Retrieve from: https://www.bloomberg.com/news/articles/2020-03-16/u-s-airlines-spent-96-of-free-cash-flow-on-buybacks-chart.\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom QuantConnect.DataSource import SmartInsiderTransaction\nfrom statsmodels.discrete.discrete_model import Logit\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Select the airline tickers for research.\nassets = [\"LUV\",   # Southwest Airlines\n\"DAL\",   # Delta Airlines\n\"UAL\",   # United Airlines Holdings\n\"AAL\",   # American Airlines Group\n\"SKYW\",  # SkyWest Inc.\n\"ALGT\",  # Allegiant Travel Co.\n\"ALK\"    # Alaska Air Group Inc.\n]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Then call AddData with SmartInsiderTransaction to subscribe to their buyback transaction data. Save the Symbols into a dictionary.\nsymbols = {}\nfor ticker in assets:\nSymbol = qb.add_equity(ticker, Resolution.MINUTE).symbol\nsymbols[Symbol] = qb.add_data(SmartInsiderTransaction, Symbol).symbol\n\n# Call the History method with list of tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(list(symbols.keys()), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Call SPY history as reference.\nspy = qb.history(qb.add_equity(\"SPY\").Symbol, datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Call the History method with list of buyback tickers, time argument(s), and resolution to request buyback data for the symbol.\nhistory_buybacks = qb.history(list(symbols.values()), datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)\n\n# Select the close column and then call the unstack method to get the close price dataframe.\ndf = history['close'].unstack(level=0)\nspy_close = spy['close'].unstack(level=0)\n\n# Call pct_change to get the daily return of close price, then shift 1-step backward as prediction.\nret = df.pct_change().shift(-1).iloc[:-1]\nret_spy = spy_close.pct_change().shift(-1).iloc[:-1]\n\n# Get the active forward return.\nactive_ret = ret.sub(ret_spy.values, axis=0)\n\n# Select the close column and then call the unstack method to get the close price dataframe.\ndf = history['close'].unstack(level=0)\nspy_close = spy['close'].unstack(level=0)\n\n# Call pct_change to get the daily return of close price, then shift 1-step backward as prediction.\nret = df.pct_change().shift(-1).iloc[:-1]\nret_spy = spy_close.pct_change().shift(-1).iloc[:-1]\n\n# Get the active forward return.\nactive_ret = ret.sub(ret_spy.values, axis=0)\n\n# Select the ExecutionPrice column and then call the unstack method to get the dataframe.\n# Remove duplicate values from the index\nhistory_buybacks = history_buybacks[~history_buybacks.index.duplicated(keep='first')]\ndf_buybacks = history_buybacks['executionprice'].unstack(level=0)\n\n# Convert buyback history into daily mean data.\ndf_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\ndf_buybacks.columns = df.columns\n\n# Get the buyback premium/discount %.\ndf_close = df.reindex(df_buybacks.index)[~df_buybacks.isna()]\ndf_buybacks = (df_buybacks - df_close)/df_close\n\n# Create a dataframe to hold the buyback and 1-day forward return data.\ndata = pd.DataFrame(columns=[\"Buybacks\", \"Return\"])\n\n# Append the data into the dataframe.\nfor row, row_buyback in zip(active_ret.reindex(df_buybacks.index).itertuples(), df_buybacks.itertuples()):\nindex = row[0]\nfor i in range(1, df_buybacks.shape[1]+1):\nif row_buyback[i] != 0:\ndata = pd.concat([data, pd.DataFrame({\"Buybacks\": row_buyback[i], \"Return\":row[i]}, index=[index])])\n\n# Call dropna to drop NaNs.\ndata.dropna(inplace=True)\n\n# Get binary return (+/-).\nbinary_ret = data[\"Return\"].copy()\nbinary_ret[binary_ret < 0] = 0\nbinary_ret[binary_ret > 0] = 1\n\n# Construct a logistic regression model.\nmodel = Logit(binary_ret.values, data[\"Buybacks\"].values).fit()\n\n# Display logistic regression results.\ndisplay(model.summary())\n\n# Plot the result.\nplt.figure(figsize=(10, 6))\nsns.regplot(x=data[\"Buybacks\"]*100, y=binary_ret, logistic=True, ci=None, line_kws={'label': \" Logistic Regression Line\"})\nplt.plot([-50, 50], [0.5, 0.5], \"r--\", label=\"Selection Cutoff Line\")\nplt.title(\"Buyback premium vs Profit/Loss\")\nplt.xlabel(\"Buyback premium %\")\nplt.xlim([-50, 50])\nplt.ylabel(\"Profit/Loss\")\nplt.legend()\nplt.show()\n\n# Get in-sample prediction result.\npredictions = model.predict(data[\"Buybacks\"].values)\nfor i in range(len(predictions)):\npredictions[i] = 1 if predictions[i] > 0.5 else 0\n\n# Call confusion_matrix to contrast the results.\ncm = confusion_matrix(binary_ret, predictions)\n\n# Display the result.\ndf_result = pd.DataFrame(cm,\nindex=pd.MultiIndex.from_tuples([(\"Prediction\", \"Positive\"), (\"Prediction\", \"Negative\")]),\ncolumns=pd.MultiIndex.from_tuples([(\"Actual\", \"Positive\"), (\"Actual\", \"Negative\")]))\n\nThe below code snippets concludes the algorithm set up.\n\nfrom statsmodels.discrete.discrete_model import Logit\n\nclass AirlineBuybacksDemo(QCAlgorithm):\ndef initialize(self) -> None:\n#1. Required: Five years of backtest history\nself.set_start_date(2017, 1, 1)\nself.set_end_date(2022, 1, 1)\n\n#2. Required: Alpha Streams Models:\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\n\n#3. Required: Significant AUM Capacity\nself.set_cash(1000000)\n\n#4. Required: Benchmark to SPY\nself.set_benchmark(\"SPY\")\n\nself.set_portfolio_construction(EqualWeightingPortfolioConstructionModel())\nself.set_execution(ImmediateExecutionModel())\n\n# Set our strategy to be take 5% profit and 5% stop loss.\nself.add_risk_management(MaximumUnrealizedProfitPercentPerSecurity(0.05))\nself.add_risk_management(MaximumDrawdownPercentPerSecurity(0.05))\n\n# Select the airline tickers for research.\nself.symbols = {}\nassets = [\"LUV\",   # Southwest Airlines\n\"DAL\",   # Delta Airlines\n\"UAL\",   # United Airlines Holdings\n\"AAL\",   # American Airlines Group\n\"SKYW\",  # SkyWest Inc.\n\"ALGT\",  # Allegiant Travel Co.\n\"ALK\"    # Alaska Air Group Inc.\n]\n\n# Call the AddEquity method with the tickers, and its corresponding resolution. Then call AddData with SmartInsiderTransaction to subscribe to their buyback transaction data.\nfor ticker in assets:\nsymbol = self.add_equity(ticker, Resolution.MINUTE).symbol\nself.symbols[symbol] = self.add_data(SmartInsiderTransaction, symbol).symbol\n\nself.add_equity(\"SPY\")\n\n# Initialize the model\nself.build_model()\n\n# Set Scheduled Event Method For Our Model Recalibration every month\nself.schedule.on(self.date_rules.month_start(), self.time_rules.at(0, 0), self.build_model)\n\n# Set Scheduled Event Method For Trading\nself.schedule.on(self.date_rules.every_day(), self.time_rules.before_market_close(\"SPY\", 5), self.every_day_before_market_close)\n\ndef build_model(self) -> None:\nqb = self\n# Call the History method with list of tickers, time argument(s), and resolution to request historical data for the symbol.\nhistory = qb.history(list(self.symbols.keys()), datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Call SPY history as reference\nspy = qb.history([\"SPY\"], datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Call the History method with list of buyback tickers, time argument(s), and resolution to request buyback data for the symbol.\nhistory_buybacks = qb.history(list(self.symbols.values()), datetime(2015, 1, 1), datetime.now(), Resolution.DAILY)\n\n# Select the close column and then call the unstack method to get the close price dataframe.\ndf = history['close'].unstack(level=0)\nspy_close = spy['close'].unstack(level=0)\n\n# Call pct_change to get the daily return of close price, then shift 1-step backward as prediction.\nret = df.pct_change().shift(-1).iloc[:-1]\nret_spy = spy_close.pct_change().shift(-1).iloc[:-1]\n\n# Get the active return\nactive_ret = ret.sub(ret_spy.values, axis=0)\n\n# Select the ExecutionPrice column and then call the unstack method to get the dataframe.\nhistory_buybacks = history_buybacks[~history_buybacks.index.duplicated(keep='first')]\ndf_buybacks = history_buybacks['executionprice'].unstack(level=0)\n\n# Convert buyback history into daily mean data\ndf_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\ndf_buybacks.columns = df.columns\n\n# Get the buyback premium/discount\ndf_close = df.reindex(df_buybacks.index)[~df_buybacks.isna()]\ndf_buybacks = (df_buybacks - df_close)/df_close\n\n# Create a dataframe to hold the buyback and 1-day forward return data\ndata = pd.DataFrame(columns=[\"Buybacks\", \"Return\"])\n\n# Append the data into the dataframe\nfor row, row_buyback in zip(active_ret.reindex(df_buybacks.index).itertuples(), df_buybacks.itertuples()):\nindex = row[0]\nfor i in range(1, df_buybacks.shape[1]+1):\nif row_buyback[i] != 0:\ndata = pd.concat([data, pd.DataFrame({\"Buybacks\": row_buyback[i], \"Return\":row[i]}, index=[index])])\n\n# Call dropna to drop NaNs\ndata.dropna(inplace=True)\n\n# Get binary return (+/-)\nbinary_ret = data[\"Return\"].copy()\nbinary_ret[binary_ret < 0] = 0\nbinary_ret[binary_ret > 0] = 1\n\n# Construct a logistic regression model\nself.model = Logit(binary_ret.values, data[\"Buybacks\"].values).fit()\n\ndef every_day_before_market_close(self) -> None:\nqb = self\n# Get any buyback event today\nhistory_buybacks = qb.history(list(self.symbols.values()), timedelta(days=1), Resolution.DAILY)\nif history_buybacks.empty or \"executionprice\" not in history_buybacks.columns: return\n\n# Select the ExecutionPrice column and then call the unstack method to get the dataframe.\nhistory_buybacks = history_buybacks[~history_buybacks.index.duplicated(keep='first')]\ndf_buybacks = history_buybacks['executionprice'].unstack(level=0)\n\n# Convert buyback history into daily mean data\ndf_buybacks = df_buybacks.groupby(df_buybacks.index.date).mean()\n\n# ==============================\n\ninsights = []\n\n# Iterate the buyback data, thne pass to the model for prediction\nrow = df_buybacks.iloc[-1]\nfor i in range(len(row)):\nprediction = self.model.predict(row[i])\n\n# Long if the prediction predict price goes up, short otherwise. Do opposite for SPY (active return)\nif prediction > 0.5:\ninsights.append( Insight.price(row.index[i].split(\".\")[0], timedelta(days=1), InsightDirection.UP) )\ninsights.append( Insight.price(\"SPY\", timedelta(days=1), InsightDirection.DOWN) )\nelse:\ninsights.append( Insight.price(row.index[i].split(\".\")[0], timedelta(days=1), InsightDirection.DOWN) )\ninsights.append( Insight.price(\"SPY\", timedelta(days=1), InsightDirection.UP) )\n\nself.emit_insights(insights)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Airline Buybacks",
      "section_number": "11.9",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  },
  {
    "id": "11.10",
    "title": "Sparse Optimization",
    "level": 2,
    "path": "Applying Research > Sparse Optimization",
    "content": "### Introduction\n\nThis page explains how to you can use the Research Environment to develop and test a Sparse Optimization Index Tracking hypothesis, then put the hypothesis in production.\n\n### Create Hypothesis\n\nPassive index fund portfolio managers will buy in corresponding weighting of stocks from an index's constituents. The main idea is allowing market participants to trade an index in a smaller cost. Their performance is measured by Tracking Error (TE), which is the standard deviation of the active return of the portfolio versus its benchmark index. The lower the TE means that the portfolio tracks the index very accurately and consistently.\n\nA technique called Sparse Optimization comes into the screen as the portfolio managers want to cut their cost even lower by trading less frequently and with more liquid stocks. They select a desired group/all constituents from an index and try to strike a balance between the number of stocks in the portfolio and the TE, like the idea of L1/L2-normalization.\n\nOn the other hand, long-only active fund aimed to beat the benchmark index. Their performance are measured by the mean-adjusted tracking error, which also take the mean active return into account, so the better fund can be identified as consisitently beating the index by n%.\n\nWe can combine the 2 ideas. In this tutorial, we are about to generate our own active fund and try to use Sparse Optimization to beat QQQ. However, we need a new measure on active fund for this technique -- Downward Risk (DR). This is a measure just like the tracking error, but taking out the downward period of the index, i.e. we only want to model the index's upward return, but not downward loss. We would also, for a more robust regression, combining Huber function as our loss function. This is known as Huber Downward Risk (HDR). Please refer toOptimization Methods for Financial Index Tracking: From Theory to Practice.K. Benidis, Y. Feng, D. P. Palomer (2018)for technical details.\n\n### Import Libraries\n\nWe'll need to import libraries to help with data processing and visualization. Importnumpy,matplotlibandpandaslibraries by the following:\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n### Get Historical Data\n\nTo begin, we retrieve historical data for researching.\n\nCreate a class to get the index/ETF constituents on a particular date.class ETFUniverse:\n\"\"\"\nA class to create a universe of equities from the constituents of an ETF\n\"\"\"\ndef __init__(self, etf_ticker, universe_date):\n\"\"\"\nInput:\n- etf_ticker\nTicker of the ETF\n- universe_date\nThe date to gather the constituents of the ETF\n\"\"\"\nself.etf_ticker = etf_ticker\nself.universe_date = universe_date\n\ndef get_symbols(self, qb):\n\"\"\"\nSubscribes to the universe constituents and returns a list of symbols and their timezone\n\nInput:\n- qb\nThe QuantBook instance inside the DatasetAnalyzer\n\nReturns a list of symbols and their timezone\n\"\"\"\netf_symbols = self._get_etf_constituents(qb, self.etf_ticker, self.universe_date)\nsecurity_timezone = None\nsecurity_symbols = []\n\n# Subscribe to the universe price data\nfor symbol in etf_symbols:\nsecurity = qb.add_security(symbol, Resolution.DAILY)\nsecurity_timezone = security.exchange.time_zone\nsecurity_symbols.append(symbol)\n\nreturn security_symbols, security_timezone\n\ndef _get_etf_constituents(self, qb, etf_ticker, date):\n\"\"\"\nA helper method to retreive the ETF constituents on a given date\n\nInput:\n- qb\nThe QuantBook instance inside the DatasetAnalyzer\n- etf_ticker\nTicker of the ETF\n- universe_date\nThe date to gather the constituents of the ETF\n\nReturns a list of symbols\n\"\"\"\ndate_str = date.strftime(\"%Y%m%d\")\nfilename = f\"/data/equity/usa/universes/etf/{etf_ticker.lower()}/{date_str}.csv\"\ntry:\ndf = pd.read_csv(filename)\nexcept:\nprint(f'Error: The ETF universe file does not exist')\nreturn\nsecurity_ids = df[df.columns[1]].values\nsymbols = [qb.symbol(security_id) for security_id in security_ids]\nreturn symbolsInstantiate aQuantBook.qb = QuantBook()Subscribe to the index/ETF.In this tutorial, we'll be using QQQ.qqq = qb.add_equity(\"QQQ\").symbolSelect all the constituents for research.In this tutorial, we select the constituents of QQQ on 2020-12-31.assets, _ = ETFUniverse(\"QQQ\", datetime(2020, 12, 31)).get_symbols(qb)Prepare the historical return data of the constituents and the benchmark index to track.spy = qb.history(qb.add_equity(\"SPY\").symbol, datetime(2019, 1, 1), datetime(2021, 12, 31), Resolution.DAILY)Call thehistorymethod with a list ofSmartInsiderTransactionSymbols for all tickers, time argument(s), and resolution to request historical data for the symbols.history = qb.history(assets, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)\nhistoryPortfolio = history.close.unstack(0).loc[:\"2021-01-01\"]\npctChangePortfolio = np.log(historyPortfolio/historyPortfolio.shift(1)).dropna()\n\nhistoryQQQ_ = qb.history(qqq, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)\nhistoryQQQ = historyQQQ_.close.unstack(0).loc[:\"2021-01-01\"]\npctChangeQQQ = np.log(historyQQQ/historyQQQ.shift(1)).loc[pctChangePortfolio.index]\n\n### Prepare Data\n\nWe'll have to process our data and construct the proposed sparse index tracking portfolio.\n\nGet the dimensional sizes.m = pctChangePortfolio.shape[0]; n = pctChangePortfolio.shape[1]Set up optimization parameters (penalty of exceeding bounds, Huber statistics M-value, penalty weight).p = 0.5\nM = 0.0001\nl = 0.01Set up convergence tolerance, maximum iteration of optimization, iteration counter and HDR as minimization indicator.tol = 0.001\nmaxIter = 20\niters = 1\nhdr = 10000Initial weightings and placeholders.w_ = np.array([1/n] * n).reshape(n, 1)\nweights = pd.Series()\na = np.array([None] * m).reshape(m, 1)\nc = np.array([None] * m).reshape(m, 1)\nd = np.array([None] * n).reshape(n, 1)Iterate minimization algorithm to minimize the HDR.while iters < maxIter:\nx_k = (pctChangeQQQ.values - pctChangePortfolio.values @ w_)\nfor i in range(n):\nw = w_[i]\nd[i] = d_ = 1/(np.log(1+l/p)*(p+w))\nfor i in range(m):\nxk = float(x_k[i])\nif xk < 0:\na[i] = M / (M - 2*xk)\nc[i] = xk\nelse:\nc[i] = 0\nif 0 <= xk <= M:\na[i] = 1\nelse:\na[i] = M/abs(xk)\n\nL3 = 1/m * pctChangePortfolio.T.values @ np.diagflat(a.T) @ pctChangePortfolio.values\neigVal, eigVec = np.linalg.eig(L3.astype(float))\neigVal = np.real(eigVal); eigVec = np.real(eigVec)\nq3 = 1/max(eigVal) * (2 * (L3 - max(eigVal) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pctChangePortfolio.T.values @ np.diagflat(a.T) @ (c - pctChangeQQQ.values))\n\n# We want to keep the upper bound of each asset to be 0.1\nu = 0.1\nmu = float(-(np.sum(q3) + 2)/n); mu_ = 0\nwhile mu > mu_:\nmu = mu_\nindex1 = [i for i, q in enumerate(q3) if mu + q < -u*2]\nindex2 = [i for i, q in enumerate(q3) if -u*2 < mu + q < 0]\nmu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*u*2)/len(index2))\n\n# Obtain the weights and HDR of this iteration.\nw_ = np.amax(np.concatenate((-(mu + q3)/2, u*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)\nw_ = w_/np.sum(abs(w_))\nhdr_ = float(w_.T @ w_ + q3.T @ w_)\n\n# If the HDR converges, we take the current weights\nif abs(hdr - hdr_) < tol:\nbreak\n\n# Else, we would increase the iteration count and use the current weights for the next iteration.\niters += 1\nhdr = hdr_Save the final weights.for i in range(n):\nweights[pctChangePortfolio.columns[i]] = w_[i]Get the historical return of the proposed portfolio.histPort = historyPortfolio.dropna() @ np.array([weights[pctChangePortfolio.columns[i]] for i in range(pctChangePortfolio.shape[1])])\n\n### Test Hypothesis\n\nTo test the hypothesis. We wish to (1) outcompete the benchmark and (2) the active return is consistent in the in- and out-of-sample period.\n\nObtain the equity curve of our portfolio and normalized benchmark for comparison.proposed = history.close.unstack(0).dropna() @ np.array([weights[pctChangePortfolio.columns[i]] for i in range(pctChangePortfolio.shape[1])])\nbenchmark = historyQQQ_.close.unstack(0).loc[proposed.index]\nnormalized_benchmark = benchmark / (float(benchmark.iloc[0])/float(proposed.iloc[0]))Obtain the active return.proposed_ret = proposed.pct_change().iloc[1:]\nbenchmark_ret = benchmark.pct_change().iloc[1:]\nactive_ret = proposed_ret - benchmark_ret.valuesPlot the result.fig = plt.figure(figsize=(15, 10))\nplt.plot(proposed, label=\"Proposed Portfolio\")\nplt.plot(normalized_benchmark, label=\"Normalized Benchmark\")\nmin_ = min(min(proposed.values), min(normalized_benchmark.values))\nmax_ = max(max(proposed.values), max(normalized_benchmark.values))\nplt.plot([pd.to_datetime(\"2021-01-01\")]*100, np.linspace(min_, max_, 100), \"r--\", label=\"in- and out- of sample separation\")\nplt.title(\"Equity Curve\")\nplt.legend()\nplt.show()\nplt.clf()\n\nfig, ax = plt.subplots(1, 1)\nactive_ret[\"Mean\"] = float(active_ret.mean())\nactive_ret.plot(figsize=(15, 5), title=\"Active Return\", ax=ax)\nplt.show()\n\nWe can see from the plots, both in- and out-of-sample period the proposed portfolio out preform the benchmark while remaining a high correlation with it. Although the active return might not be very consistent, but it is a stationary series above zero. So, in a long run, it does consistently outcompete the QQQ benchmark!\n\n### Set Up Algorithm\n\nOnce we are confident in our hypothesis, we can export this code into backtesting.\n\ndef initialize(self) -> None:\nself.set_start_date(2017, 1, 1)\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\nself.set_cash(1000000)\n\n# Add our ETF constituents of the index that we would like to track.\nqqq = self.add_equity(\"QQQ\", Resolution.MINUTE).symbol\nself.universe_settings.asynchronous = True\nself.universe_settings.resolution = Resolution.MINUTE\nself.add_universe(self.universe.etf(qqq, self.universe_settings, self.etf_selection))\n\nself.set_benchmark(\"QQQ\")\n\n# Set up varaibles to flag the time to recalibrate and hold the constituents.\nself._time = datetime.min\nself.assets = []\n\nWe'll also need to create a function for getting the ETF constituents.\n\ndef etf_selection(self, constituents: ETFConstituentUniverse) -> list[Symbol]:\n# We want all constituents to be considered.\nself.assets = [x.symbol for x in constituents]\nreturn self.assets\n\nNow we export our model into theOnDataon_datamethod. We will switchqbwithselfand replace methods with theirQCAlgorithmcounterparts as needed. In this example, this is not an issue because all the methods we used in research also exist inQCAlgorithm.\n\ndef on_data(self, slice: Slice) -> None:\nqb = self\nif self._time > self.time:\nreturn\n\n# Prepare the historical return data of the constituents and the ETF (as index to track).\nhistory = qb.history(self.assets, 252, Resolution.DAILY)\nif history.empty:\nreturn\n\nhistory_portfolio = history.close.unstack(0)\npct_change_portfolio = np.log(history_portfolio/history_portfolio.shift(1)).dropna()\n\nhistory_qqq = qb.history(self.add_equity(\"QQQ\").symbol, 252, Resolution.DAILY)\nhistory_qqq = history_qqq.close.unstack(0)\npct_change_qqq = np.log(history_qqq/history_qqq.shift(1)).loc[pct_change_portfolio.index]\n\nm = pct_change_portfolio.shape[0]; n = pct_change_portfolio.shape[1]\n\n# Set up optimization parameters.\np = 0.5; M = 0.0001; l = 0.01\n\n# Set up convergence tolerance, maximum iteration of optimization, iteration counter and Huber downward risk as minimization indicator.\ntol = 0.001; maxIter = 20; iters = 1; hdr = 10000\n\n# Initial weightings and placeholders.\nw_ = np.array([1/n] * n).reshape(n, 1)\nself.weights = pd.Series()\na = np.array([None] * m).reshape(m, 1)\nc = np.array([None] * m).reshape(m, 1)\nd = np.array([None] * n).reshape(n, 1)\n\n# Iterate to minimize the HDR.\nwhile iters < maxIter:\nx_k = (pct_change_qqq.values - pct_change_portfolio.values @ w_)\nfor i in range(n):\nw = w_[i]\nd[i] = d_ = 1/(np.log(1+l/p)*(p+w))\nfor i in range(m):\nxk = float(x_k[i])\nif xk < 0:\na[i] = M / (M - 2*xk)\nc[i] = xk\nelse:\nc[i] = 0\nif 0 <= xk <= M:\na[i] = 1\nelse:\na[i] = M/abs(xk)\n\nL3 = 1/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ pct_change_portfolio.values\neigVal, eigVec = np.linalg.eig(L3.astype(float))\neigVal = np.real(eigVal); eigVec = np.real(eigVec)\nq3 = 1/max(eigVal) * (2 * (L3 - max(eigVal) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ (c - pct_change_qqq.values))\n\n# We want to keep the upper bound of each asset to be 0.1\nu = 0.1\nmu = float(-(np.sum(q3) + 2)/n); mu_ = 0\nwhile mu > mu_:\nmu = mu_\nindex1 = [i for i, q in enumerate(q3) if mu + q < -u*2]\nindex2 = [i for i, q in enumerate(q3) if -u*2 < mu + q < 0]\nmu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*u*2)/len(index2))\n\n# Obtain the weights and HDR of this iteration.\nw_ = np.amax(np.concatenate((-(mu + q3)/2, u*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)\nw_ = w_/np.sum(abs(w_))\nhdr_ = float(w_.T @ w_ + q3.T @ w_)\n\n# If the HDR converges, we take the current weights\nif abs(hdr - hdr_) < tol:\nbreak\n\n# Else, we would increase the iteration count and use the current weights for the next iteration.\niters += 1\nhdr = hdr_\n\n# -----------------------------------------------------------------------------------------\norders = []\nfor i in range(n):\norders.append(PortfolioTarget(pct_change_portfolio.columns[i], float(w_[i])))\nself.set_holdings(orders)\n\n# Recalibrate on quarter end.\nself._time = Expiry.end_of_quarter(self.time)\n\n### Reference\n\nOptimization Methods for Financial Index Tracking: From Theory to Practice. K. Benidis, Y. Feng, D. P. Palomer (2018).Foundations and Trends in Signal Processing. 3-3. p171-279.\n\n### Examples\n\nThe below code snippets concludes the above jupyter research notebook content.\n\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\n# Create a class to get the ETF constituents on a particular date.\n\nclass ETFUniverse:\n\"\"\"\nA class to create a universe of equities from the constituents of an ETF\n\"\"\"\ndef __init__(self, etf_ticker, universe_date):\n\"\"\"\nInput:\n- etf_ticker\nTicker of the ETF\n- universe_date\nThe date to gather the constituents of the ETF\n\"\"\"\nself.etf_ticker = etf_ticker\nself.universe_date = universe_date\n\ndef get_symbols(self, qb):\n\"\"\"\nSubscribes to the universe constituents and returns a list of symbols and their timezone\n\nInput:\n- qb\nThe QuantBook instance inside the DatasetAnalyzer\n\nReturns a list of symbols and their timezone\n\"\"\"\netf_symbols = self._get_etf_constituents(qb, self.etf_ticker, self.universe_date)\nsecurity_timezone = None\nsecurity_symbols = []\n\n# Subscribe to the universe price data\nfor symbol in etf_symbols:\nsecurity = qb.AddSecurity(symbol, Resolution.Daily)\nsecurity_timezone = security.Exchange.TimeZone\nsecurity_symbols.append(symbol)\n\nreturn security_symbols, security_timezone\n\ndef _get_etf_constituents(self, qb, etf_ticker, date):\n\"\"\"\nA helper method to retreive the ETF constituents on a given date\n\nInput:\n- qb\nThe QuantBook instance inside the DatasetAnalyzer\n- etf_ticker\nTicker of the ETF\n- universe_date\nThe date to gather the constituents of the ETF\n\nReturns a list of symbols\n\"\"\"\ndate_str = date.strftime(\"%Y%m%d\")\nfilename = f\"/data/equity/usa/universes/etf/{etf_ticker.lower()}/{date_str}.csv\"\ntry:\ndf = pd.read_csv(filename)\nexcept:\nprint(f'Error: The ETF universe file does not exist')\nreturn\nsecurity_ids = df[df.columns[1]].values\nsymbols = [qb.Symbol(security_id) for security_id in security_ids]\nreturn symbols\n\n# Instantiate a QuantBook.\nqb = QuantBook()\n\n# Subscribe to the index/ETF.\nqqq = qb.add_equity(\"QQQ\").symbol\n\n# Select all the constituents for research.\n# In this tutorial, we select the constituents of QQQ on 2020-12-31.\nassets, _ = ETFUniverse(\"QQQ\", datetime(2020, 12, 31)).get_symbols(qb)\n\n# Prepare the historical return data of the constituents and the ETF (as index to track).\nhistory = qb.history(assets, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)\nhistory_portfolio = history.close.unstack(0).loc[:\"2021-01-01\"]\npct_change_portfolio = np.log(history_portfolio/history_portfolio.shift(1)).dropna()\n\nhistory_qqq = qb.history(qqq, datetime(2020, 1, 1), datetime(2021, 3, 31), Resolution.DAILY)\nhistory_qqq = history_qqq.close.unstack(0).loc[:\"2021-01-01\"]\npct_change_qqq = np.log(history_qqq/history_qqq.shift(1)).loc[pct_change_portfolio.index]\n\n# Get the dimensional sizes.\nm = pct_change_portfolio.shape[0]; n = pct_change_portfolio.shape[1]\n\n# Set up optimization parameters (penalty of exceeding bounds, Huber statistics M-value, penalty weight).\np = 0.5; M = 0.0001; l = 0.01\n\n# Set up convergence tolerance, maximum iteration of optimization, iteration counter and HDR as minimization indicator.\ntol = 0.001; max_iter = 20; iters = 1; hdr = 10000\n\n# Initial weightings and placeholders.\nw_ = np.array([1/n] * n).reshape(n, 1)\nweights = pd.Series()\na = np.array([None] * m).reshape(m, 1)\nc = np.array([None] * m).reshape(m, 1)\nd = np.array([None] * n).reshape(n, 1)\n\n# Iterate to minimize the HDR.\nwhile iters < max_iter:\nx_k = (pct_change_qqq.values - pct_change_portfolio.values @ w_)\nfor i in range(n):\nw = w_[i]\nd[i] = d_ = 1/(np.log(1+l/p)*(p+w))\nfor i in range(m):\nxk = float(x_k[i])\nif xk < 0:\na[i] = M / (M - 2*xk)\nc[i] = xk\nelse:\nc[i] = 0\nif 0 <= xk <= M:\na[i] = 1\nelse:\na[i] = M/abs(xk)\n\nL3 = 1/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ pct_change_portfolio.values\neig_val, eigVec = np.linalg.eig(L3.astype(float))\neig_val = np.real(eig_val); eigVec = np.real(eigVec)\nq3 = 1/max(eig_val) * (2 * (L3 - max(eig_val) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ (c - pct_change_qqq.values))\n\n# We want to keep the upper bound of each asset to be 0.1\nu = 0.1\nmu = float(-(np.sum(q3) + 2)/n); mu_ = 0\nwhile mu > mu_:\nmu = mu_\nindex1 = [i for i, q in enumerate(q3) if mu + q < -u*2]\nindex2 = [i for i, q in enumerate(q3) if -u*2 < mu + q < 0]\nmu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*u*2)/len(index2))\n\n# Obtain the weights and HDR of this iteration.\nw_ = np.amax(np.concatenate((-(mu + q3)/2, u*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)\nw_ = w_/np.sum(abs(w_))\nhdr_ = float(w_.T @ w_ + q3.T @ w_)\n\n# If the HDR converges, we take the current weights\nif abs(hdr - hdr_) < tol:\nbreak\n\n# Else, we would increase the iteration count and use the current weights for the next iteration.\niters += 1\nhdr = hdr_\n\nfor i in range(n):\nweights[pct_change_portfolio.columns[i]] = w_[i]\n\n# Get the historical return of the proposed portfolio.\nhist_port = historyPortfolio.dropna() @ np.array([weights[pct_change_portfolio.columns[i]] for i in range(pct_change_portfolio.shape[1])])\n\n# Obtain the equity curve of our portfolio and normalized benchmark for comparison.\nproposed = history.close.unstack(0).dropna() @ np.array([weights[pctChangePortfolio.columns[i]] for i in range(pctChangePortfolio.shape[1])])\nbenchmark = historyQQQ_.close.unstack(0).loc[proposed.index]\nnormalized_benchmark = benchmark / (float(benchmark.iloc[0])/float(proposed.iloc[0]))\n\n# Obtain the active return.\nproposed_ret = proposed.pct_change().iloc[1:]\nbenchmark_ret = benchmark.pct_change().iloc[1:]\nactive_ret = proposed_ret - benchmark_ret.values\n\n# Plot the result.\nfig = plt.figure(figsize=(15, 10))\nplt.plot(proposed, label=\"Proposed Portfolio\")\nplt.plot(normalized_benchmark, label=\"Normalized Benchmark\")\nmin_ = min(min(proposed.values), min(normalized_benchmark.values))\nmax_ = max(max(proposed.values), max(normalized_benchmark.values))\nplt.plot([pd.to_datetime(\"2021-01-01\")]*100, np.linspace(min_, max_, 100), \"r--\", label=\"in- and out- of sample separation\")\nplt.title(\"Equity Curve\")\nplt.legend()\nplt.show()\nplt.clf()\n\nfig, ax = plt.subplots(1, 1)\nactive_ret[\"Mean\"] = float(active_ret.mean())\nactive_ret.plot(figsize=(15, 5), title=\"Active Return\", ax=ax)\nplt.show()\n\nThe below code snippets concludes the algorithm set up.\n\nclass SparseOptimizationIndexTrackingDemo(QCAlgorithm):\n\ndef initialize(self):\nself.set_start_date(2017, 1, 1)\nself.set_start_date(2022, 1, 1)\nself.set_brokerage_model(BrokerageName.ALPHA_STREAMS)\nself.set_cash(1000000)\n\n# Add our ETF constituents of the index that we would like to track.\nqqq = self.add_equity(\"QQQ\", Resolution.MINUTE).symbol\nself.universe_settings.resolution = Resolution.MINUTE\nself.add_universe(self.universe.etf(qqq, self.universe_settings, self.etf_selection))\n\nself.set_benchmark(\"QQQ\")\n\n# Set up varaibles to flag the time to recalibrate and hold the constituents.\nself.last_time = datetime.min\nself.assets = []\n\ndef etf_selection(self, constituents):\n# We want all constituents to be considered.\nself.assets = [x.symbol for x in constituents]\nreturn self.assets\n\ndef on_data(self, data):\nqb = self\nif self.last_time > self.time:\nreturn\n\n# Prepare the historical return data of the constituents and the ETF (as index to track).\nhistory = qb.history(self.assets, 252, Resolution.DAILY)\nif history.empty: return\n\nhistory_portfolio = history.close.unstack(0)\npct_change_portfolio = np.log(history_portfolio/history_portfolio.shift(1)).dropna()\n\nhistory_qqq = qb.history(self.add_equity(\"QQQ\").symbol, 252, Resolution.DAILY)\nhistory_qqq = history_qqq.close.unstack(0)\npct_change_qqq = np.log(history_qqq/history_qqq.shift(1)).loc[pct_change_portfolio.index]\n\nm = pct_change_portfolio.shape[0]; n = pct_change_portfolio.shape[1]\n\n# Set up optimization parameters.\np = 0.5; M = 0.0001; l = 0.01\n\n# Set up convergence tolerance, maximum iteration of optimization, iteration counter and Huber downward risk as minimization indicator.\ntol = 0.001; max_iter = 20; iters = 1; hdr = 10000\n\n# Initial weightings and placeholders.\nw_ = np.array([1/n] * n).reshape(n, 1)\nself.weights = pd.Series()\na = np.array([None] * m).reshape(m, 1)\nc = np.array([None] * m).reshape(m, 1)\nd = np.array([None] * n).reshape(n, 1)\n\n# Iterate to minimize the HDR.\nwhile iters < max_iter:\nx_k = (pct_change_qqq.values - pct_change_portfolio.values @ w_)\nfor i in range(n):\nw = w_[i]\nd[i] = d_ = 1/(np.log(1+l/p)*(p+w))\nfor i in range(m):\nxk = float(x_k[i])\nif xk < 0:\na[i] = M / (M - 2*xk)\nc[i] = xk\nelse:\nc[i] = 0\nif 0 <= xk <= M:\na[i] = 1\nelse:\na[i] = M/abs(xk)\n\nL3 = 1/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ pct_change_portfolio.values\neig_val, eigVec = np.linalg.eig(L3.astype(float))\neig_val = np.real(eig_val); eigVec = np.real(eigVec)\nq3 = 1/max(eig_val) * (2 * (L3 - max(eig_val) * np.eye(n)) @ w_ + eigVec @ d - 2/m * pct_change_portfolio.T.values @ np.diagflat(a.T) @ (c - pct_change_qqq.values))\n\n# We want to keep the upper bound of each asset to be 0.1\nmu = float(-(np.sum(q3) + 2)/n); mu_ = 0\nwhile mu > mu_:\nmu = mu_\nindex1 = [i for i, q in enumerate(q3) if mu + q < -0.1*2]\nindex2 = [i for i, q in enumerate(q3) if -0.1*2 < mu + q < 0]\nmu_ = float(-(np.sum([q3[i] for i in index2]) + 2 - len(index1)*0.1*2)/len(index2))\n\n# Obtain the weights and HDR of this iteration.\nw_ = np.amax(np.concatenate((-(mu + q3)/2, 0.1*np.ones((n, 1))), axis=1), axis=1).reshape(-1, 1)\nw_ = w_/np.sum(abs(w_))\nhdr_ = float(w_.T @ w_ + q3.T @ w_)\n\n# If the HDR converges, we take the current weights\nif abs(hdr - hdr_) < tol:\nbreak\n\n# Else, we would increase the iteration count and use the current weights for the next iteration.\niters += 1\nhdr = hdr_\n\n# -----------------------------------------------------------------------------------------\norders = []\nfor i in range(n):\norders.append(PortfolioTarget(pct_change_portfolio.columns[i], float(w_[i])))\nself.set_holdings(orders)\n\n# Recalibrate on quarter end.\nself.last_time = Expiry.end_of_quarter(self.time)",
    "metadata": {
      "has_code": false,
      "has_tables": false,
      "code_languages": [],
      "parent_id": "11",
      "breadcrumb": "Applying Research > Sparse Optimization",
      "section_number": "11.10",
      "source_file": "Quantconnect-Research-Environment.html",
      "document_index": 1
    }
  }
]